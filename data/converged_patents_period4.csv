"국가코드","DB종류","특허/실용 구분","문헌종류 코드","발명의 명칭","요약","대표청구항","청구항 수","출원번호","출원일","공개번호","공개일","등록번호","등록일","출원인","발명자","우선권 번호","우선권 국가","우선권 주장일","Original CPC Main","Original CPC All","Original IPC Main","Original IPC All","Original US Class Main","Original US Class All","Original FI[JP]","Original F-term[JP]","Original Theme Code [JP]","WIPS ON key"
"US","US","P","B2","Method of bionic control of technical devices","Methods of bionic control of a device include passing an alternating current through a muscle to cause the muscle to contract, recording an electrophysiological signal from the contracting muscle, processing the electrophysiological signal to determine a measurement of electrical impedance, forwarding the measurement of electrical impedance to a controller, and controlling the device with a control action. A change of electrical impedance during muscle contraction is used as a basis for the control action.","1. A method of enhancing mechanical function in a subject with a prosthetic device, the method comprising: using electrodes to pass an alternating current through a muscle in the subject to cause the muscle to contract,using a first recording electrode to record an electrical impedance signal from the contracting muscle,using a processor to generate a control signal that is based on a change in the electrical impedance in the muscle in real time during contraction of the muscle,forwarding the control signal to a controller, andcontrolling the prosthetic device with the controller and control signal to achieve the enhancement of mechanical function in the subject, the enhancement of mechanical function occurring by mechanical function of the prosthetic device.","17","16/085529","2017-03-06","2019-0099279","2019-04-04","10874530","2020-12-29","Sergey Igorevich Shchukin | Aleksandr Viktorovich Kobelev | Igor Konstantinovich Sergeev | Oleg Stepanovich Naraykin","Sergey Igorevich  Shchukin | Aleksandr Viktorovich  Kobelev | Igor Konstantinovich  Sergeev | Oleg Stepanovich  Naraykin","20160109214","RU","2016-03-15","A61F-0002/72","A61F-0002/72 | A61B-0005/04001 | A61B-0005/04012 | A61B-0005/0488 | A61B-0005/0492 | A61B-0005/04888 | A61B-0005/053 | A61B-0005/4851 | A61F-0002/02 | A63F-0013/212 | G06F-0003/015 | A61B-0005/0531 | A61B-0005/0538 | A61F-2002/482","A61F-002/72","A61F-002/72 | A61F-002/48 | A61B-005/04 | A61B-005/053 | A63F-013/212 | A61B-005/0488 | A61B-005/0492 | A61B-005/00 | A61F-002/02 | G06F-003/01","","","","","","4920053001211"
"US","US","P","B2","Dynamic sauna","Systems and methods are provided for controlling infrared radiation (IR) sources of a sauna including tuning IR wavelength-ranges and radiated power-levels of IR sources, and directing IR to locations on a user's body. In one illustrative embodiment, a sauna may be provided having adjustable IR emitters to emit IR at any wavelength resulting in a desirable radiation treatment for the sauna user. In another illustrative embodiment, a method is provided for tuning IR emitters in a sauna.","1. An infrared-therapy device comprising: an enclosure assembly for accommodating a user;a first heating element coupled with the enclosure assembly and operable to emit infrared radiation in a near-infrared radiation spectrum;a second heating element coupled with the enclosure assembly and operable to emit infrared radiation in a far-infrared radiation spectrum; anda control module operably coupled to one or both of the first heating element and the second heating element and configured to allow a user to specify desired output infrared radiation from the one or both of the first heating element and the second heating element.","20","16/538117","2019-08-12","2019-0358120","2019-11-28","10874586","2020-12-29","SUNLIGHTEN, INC.","James T.  O'Keeffe | Aaron Michael  Zack | Martin C.  Ku | Ian Richard  Kuklenski | Steven J.  Murray","","","","A61H-0033/063","A61H-0033/063 | A61H-0033/06 | A61H-0033/066 | A61N-0005/0625 | G06F-0019/3481 | G06Q-0010/0639 | G06Q-0050/22 | G16H-0020/40 | G16H-0040/63 | H05B-0001/0275 | H05B-0003/008 | H05B-0003/009 | H05B-0003/267 | A61H-0033/067 | A61H-2033/061 | A61H-2201/0188 | A61H-2201/0228 | A61H-2201/10 | A61H-2201/5012 | A61H-2201/5015 | A61H-2201/5035 | A61H-2201/5038 | A61H-2201/5043 | A61H-2201/5046 | A61H-2201/5048 | A61H-2201/5087 | A61H-2230/04 | A61H-2230/06 | A61H-2230/207 | A61H-2230/30 | A61H-2230/40 | A61H-2230/42 | A61H-2230/50 | A61H-2230/80 | A61N-2005/0636 | A61N-2005/0652 | A61N-2005/0659 | H05B-2203/032","A61H-033/06","A61H-033/06 | G16H-040/63 | G06Q-010/06 | G06Q-050/22 | H05B-001/02 | H05B-003/26 | A61N-005/06 | G06F-019/00 | H05B-003/00 | G16H-020/40","","","","","","4920053001266"
"US","US","P","B2","Managing medication administration in clinical care room","Methods, computer systems, and computer readable media are provided for transitioning a clinical care room from a first scene to a second scene in order to facilitate completion of a medication-administration process. The first scene in the clinical care room is presented where the clinical care room has one or more zones. The first scene is associated with a first group of setting for components within the one or more zones. An input indicating that the medication-administration process has been initiated is received. Incident to receiving the input, the second scene is provided. The second scene is associated with a second group of settings for the components. The second group of settings is optimized to facilitate completion medication-administration process.","1. One or more computer-readable media having embodied thereon computer-executable instructions that, when executed by a computing device, cause the computing device to perform a method for automatically and without human intervention transitioning a patient'ss clinical care room from a first scene to a second scene in order to facilitate completion of a medication-administration process, the method comprising: automatically and without human intervention receiving, at a computing device communicatively coupled to a medication dispensing station, an input from the medication dispensing station indicating that a clinician has initiated the medication-administration process for the patient in the clinical care room, wherein the input is received upon the clinician retrieving medication(s) associated with the patient from the medication dispensing station;determining that at least one of the medications comprises a first medication administered by intravenous (IV) infusion; andbased on determining that at least one of the medications retrieved is administered by IV infusion, automatically and without human intervention powering on an IV infusion pump located in the patient'ss clinical care room.","20","15/843314","2017-12-15","2018-0104409","2018-04-19","10874794","2020-12-29","CERNER INNOVATION, INC.","Stephanie Palmer  Bechtel | Mark  Nolte","","","","A61M-0005/172","A61M-0005/172 | A61B-0005/0205 | A61B-0005/1113 | A61B-0005/6889 | A61B-0005/7275 | A61B-0090/30 | A61G-0007/002 | A61M-0005/142 | A61M-0005/1723 | A61M-0021/02 | G06F-0019/30 | G06F-0019/3418 | G06K-0009/00302 | G06Q-0010/00 | G06Q-0050/22 | G08B-0021/02 | G08B-0021/043 | G08B-0021/0476 | G08B-0021/0492 | G09B-0005/02 | G16H-0010/60 | G16H-0020/10 | G16H-0040/63 | G16H-0040/67 | G16H-0050/50 | G16H-0050/70 | G16H-0070/00 | A61B-0005/1115 | A61B-0005/1128 | A61B-0005/4824 | A61B-0005/6891 | A61B-0005/743 | A61B-0005/7475 | A61B-0007/00 | A61B-2562/029 | A61B-2562/0252 | A61G-0007/00 | A61M-0016/0051 | A61M-0016/024 | A61M-2005/14208 | A61M-2021/005 | A61M-2021/0016 | A61M-2021/0027 | A61M-2021/0044 | A61M-2202/0241 | A61M-2205/18 | A61M-2205/3306 | A61M-2205/3334 | A61M-2205/3368 | A61M-2205/3375 | A61M-2205/3553 | A61M-2205/3561 | A61M-2205/3584 | A61M-2205/3592 | A61M-2205/505 | A61M-2205/52 | A61M-2205/581 | A61M-2205/582 | A61M-2205/583 | A61M-2205/6018 | A61M-2205/6054 | A61M-2205/6072 | A61M-2205/80 | A61M-2210/12 | A61M-2230/06 | A61M-2230/42 | A61M-2230/62 | A61M-2230/63","A61M-005/172","A61M-005/172 | A61M-021/02 | A61B-090/30 | A61B-005/00 | A61B-005/0205 | A61B-005/11 | A61M-005/142 | G08B-021/04 | G06F-019/00 | G16H-040/63 | G06Q-050/22 | G06K-009/00 | A61G-007/002 | G09B-005/02 | G16H-010/60 | G16H-020/10 | G16H-040/67 | G16H-070/00 | G16H-050/50 | G06Q-010/00 | G08B-021/02 | G16H-050/70 | A61M-021/00 | A61B-007/00 | A61G-007/00 | A61M-016/00","","","","","","4920053001472"
"US","US","P","B2","Coordinated vehicle response system and method for driver behavior","Methods of assessing driver behavior include monitoring vehicle systems and driver monitoring systems to accommodate for a slow reaction time, attention lapse and/or alertness of a driver. When it is determined that a driver is drowsy, for example, the response system may modify the operation of one or more vehicle systems. The response system can modify the control of two or more systems simultaneously in response to driver behavior.","1. A method of controlling a vehicle system in a vehicle, comprising: receiving vehicle operating information about the vehicle and monitoring information about a driver;detecting a hazard based on the vehicle operating information;determining a risk level based on the hazard, wherein the risk level indicates a likelihood that the vehicle will encounter the hazard;determining a driver state index based on the monitoring information;determining if the hazard is confirmed based on the driver state index;determining a control coefficient using the driver state index;modifying the vehicle system based on the driver state index and the control coefficient; andcontrolling the modified vehicle system based on the hazard and the risk level.","20","15/836341","2017-12-08","2018-0105180","2018-04-19","10875536","2020-12-29","HONDA MOTOR CO., LTD.","Kin C.  Fung | Timothy J.  Dick","","","","B60W-0040/08","B60W-0040/08 | A61B-0005/1114 | A61B-0005/1122 | A61B-0005/18 | A61B-0005/6893 | B60K-0028/06 | B60K-0028/066 | B60T-0008/172 | B60W-0040/09 | B60W-0050/12 | B62D-0006/00 | B62D-0006/001 | B62D-0006/007 | B62D-0015/025 | G06F-0017/00 | G06K-0009/00845 | G08G-0001/166 | G08G-0001/167 | A61B-0005/0205 | A61B-0005/0476 | A61B-0005/055 | A61B-0005/1103 | A61B-0005/14553 | A61B-2562/0257 | B60T-2201/03 | B60T-2201/08 | B60T-2201/12 | B60T-2220/02 | B60W-2040/0827 | B60W-2050/0071 | B60W-2540/22 | B60W-2540/26 | B60W-2554/00 | G01C-0021/3697 | G08B-0021/06","B60W-040/08","B60W-040/08 | B62D-006/00 | A61B-005/00 | A61B-005/11 | G06F-017/00 | A61B-005/18 | B60K-028/06 | B60T-008/172 | G08G-001/16 | B62D-015/02 | B60W-040/09 | G06K-009/00 | B60W-050/12 | A61B-005/0205 | A61B-005/0476 | A61B-005/055 | A61B-005/1455 | G01C-021/36 | G08B-021/06 | B60W-050/00","","","","","","4920053002209"
"US","US","P","B2","Integrated biosensor and simulation system for diagnosis and therapy","BioMEMS/NEMS appliance biologically monitors an individual, using biosensors to detect cellular components. Data is simulated or analyzed using systems-biology software, which provides diagnostic or therapeutic guidance.","1. Integrated reconfigurable multi-channel biosensor system for diagnosing circulating cancer or tumor cells comprising: a biosensor chip that collects micro-fluidically one or more bodily fluid to detect circulating micro-metastatic tumor or cancer cells, said biosensor chip comprising multi-channel micro-fluidic collection elements that reconfigure electronically to collect and enrich tumor or cancer bio-marker comprising nanoparticles or paramagnetic microbeads or immunomagnetic beads conjugated with antigen or antibody to endothelial or epithelial cell adhesion molecule, thereby being microfluidically collected and enriched for detection of tumor or cancer cells of endothelial or epithelial origin; anda digital signal processor coupled to the biosensor chip that electronically reconfigures one or more micro-fluidic collection element to collect and enrich said nanoparticles or paramagnetic microbeads or immunomagnetic beads conjugated with antigen or antibody to endothelial or epithelial cell adhesion molecule via at least one reconfigurable micro-fluidic channel that reconfigures microelectromechanically to collect and enrich in response to the digital signal processor electronically comparing one or more tumor or cancer cell biomarker sensed empirically by said biosensor chip with one or more diagnostic factor automatically to diagnose the tumor or cancer cells.","12","15/044710","2016-02-16","2019-0251230","2019-08-15","10878936","2020-12-29","Dennis Sunga Fernandez","Dennis Sunga  Fernandez","","","","G16B-0005/00","G16B-0005/00 | A61B-0005/0002 | A61B-0005/024 | A61B-0005/026 | A61B-0005/0215 | A61B-0005/02028 | A61B-0005/076 | A61B-0005/145 | A61B-0005/14539 | A61B-0005/14542 | A61B-0005/14546 | A61B-0005/411 | A61B-0005/413 | A61B-0005/415 | A61B-0005/418 | A61B-0005/486 | A61B-0005/4839 | A61B-0005/686 | A61B-0005/7264 | C12Q-0001/04 | C12Q-0001/68 | C12Q-0001/6886 | C12Q-0001/70 | G01N-0033/53 | G06F-0019/30 | G06Q-0040/08 | G06Q-0050/22 | G06Q-0050/24 | G16H-0050/50 | A61B-2562/028 | C12Q-2600/156 | G06F-0019/32 | Y02A-0090/10","G01N-033/48","G01N-033/48 | G16B-005/00 | G16H-050/50 | A61B-005/0215 | A61B-005/145 | A61B-005/00 | G06Q-040/08 | G06Q-050/22 | A61B-005/07 | G06Q-050/24 | A61B-005/02 | A61B-005/024 | A61B-005/026 | G06F-019/00 | C12Q-001/04 | C12Q-001/68 | C12Q-001/70 | G01N-033/53 | C12Q-001/6886 | G06G-007/58","","","","","","4920053005578"
"US","US","P","B2","Utilizing random parameters in an intensity transform augmentation system","An intensity transform augmentation system is operable to receive a training set of medical scans. Random intensity transformation function parameters are generated for each medical scan of the training set of medical scans. A plurality of augmented images are generated, where each of the plurality of augmented images is generated by performing a intensity transformation function on one of the training set of medical scans by utilizing the random intensity transform parameters generated for the one of the training set of medical scan. A computer vision model is generated by performing a training step on the plurality of augmented images. A new medical scan is received via the receiver. Inference data is generated by performing an inference function that utilizes the computer vision model on the new medical scan. The inference data is transmitted to a client device for display via a display device.","1. An intensity transform augmentation system, comprising: at least one processor; anda memory that stores operational instructions that, when executed by the at least one processor, cause the intensity transform augmentation system to: receive, via a receiver, a training set of medical scans;generate random intensity transformation function parameters for each medical scan of the training set of medical scans;generate a plurality of augmented images, wherein each of the plurality of augmented images is generated by performing an intensity transformation function on one of the training set of medical scans by utilizing the random intensity transformation function parameters generated for the one of the training set of medical scans, wherein a set of augmented images are generated for each of the training set of medical scans, and wherein the random intensity transformation function parameters are generated separately for utilization in performing the intensity transformation function on the each of the training set of medical scans to generate each of the set of augmented images;generate a computer vision model by performing a training step on the plurality of augmented images;receive, via the receiver, a new medical scan;generate inference data by performing an inference function that utilizes the computer vision model on the new medical scan; andtransmit, via a transmitter, the inference data to a client device for display via a display device.","19","16/360631","2019-03-21","2020-0160978","2020-05-21","10878949","2020-12-29","ENLITIC, INC.","Jordan  Prosky | Li  Yao | Eric C.  Poblenz | Kevin  Lyman | Ben  Covington | Anthony  Upton","","","","G16H-0010/60","G16H-0010/60 | A61B-0005/7264 | G06F-0003/0482 | G06F-0003/0484 | G06F-0009/542 | G06F-0016/245 | G06F-0021/6254 | G06K-0009/2063 | G06K-0009/6231 | G06K-0009/6254 | G06K-0009/6256 | G06K-0009/6262 | G06K-0009/6277 | G06N-0005/04 | G06N-0005/045 | G06N-0020/00 | G06N-0020/20 | G06Q-0010/06315 | G06Q-0020/14 | G06T-0003/40 | G06T-0005/002 | G06T-0005/008 | G06T-0005/50 | G06T-0007/0012 | G06T-0007/0014 | G06T-0007/10 | G06T-0007/11 | G06T-0007/187 | G06T-0007/44 | G06T-0007/97 | G06T-0011/001 | G06T-0011/006 | G06T-0011/206 | G16H-0010/20 | G16H-0015/00 | G16H-0030/20 | G16H-0030/40 | G16H-0040/20 | G16H-0050/20 | H04L-0067/12 | H04L-0067/42 | A61B-0005/055 | A61B-0006/032 | A61B-0006/5217 | A61B-0008/4416 | G06F-0040/295 | G06K-0009/6229 | G06K-0009/6267 | G06K-0009/66 | G06K-2209/05 | G06Q-0050/22 | G06T-0007/70 | G06T-2200/24 | G06T-2207/10048 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/10116 | G06T-2207/10132 | G06T-2207/20076 | G06T-2207/20081 | G06T-2207/20084 | G06T-2207/30004 | G06T-2207/30008 | G06T-2207/30016 | G06T-2207/30061 | G16H-0050/30 | G16H-0050/70","G06T-007/187","G06T-007/187 | G16H-010/60 | H04L-029/06 | G16H-030/40 | G16H-015/00 | G06K-009/62 | G06T-005/00 | G06T-005/50 | G06T-007/00 | G06T-011/00 | G06N-005/04 | G16H-030/20 | G06N-020/00 | G06F-009/54 | G06T-007/11 | G06F-003/0482 | G06T-003/40 | A61B-005/00 | G16H-050/20 | G06F-021/62 | G06Q-020/14 | G16H-040/20 | G06F-003/0484 | G06Q-010/06 | G16H-010/20 | G06T-007/10 | G06T-011/20 | G06F-016/245 | G06T-007/44 | G06N-020/20 | G06K-009/20 | H04L-029/08 | G16H-050/70 | G06T-007/70 | G16H-050/30 | A61B-005/055 | A61B-006/03 | A61B-008/00 | G06K-009/66 | A61B-006/00 | G06Q-050/22 | G06F-040/295","","","","","","4920053005591"
"US","US","P","B2","Identification device and identification method","An identification device includes: M transmission antenna elements each of which transmits a first transmission signal to a predetermined area including a first living body; N receivers disposed surrounding the predetermined area, and each including a reception antenna element and receiving, using the reception antenna element, a first reception signal including a reflection signal obtained as a result of the first transmission signal being reflected by the first living body, during a predetermined period; a memory storing teacher signals which are M×N second reception signals obtained about a second living body; and a circuit which calculates a plurality of correlation coefficients from the teacher signals and M×N first reception signals obtained as a result of each of the N receivers receiving the first reception signal, performs biometric authentication of the first living body, and identifies the first living body and the second living body as identical.","1. An identification device comprising: M transmission antenna elements each of which transmits a first transmission signal to a predetermined area including a first living body, M being an integer greater than or equal to 1;N receivers disposed surrounding the predetermined area, each of the N receivers including a reception antenna element and receiving a first reception signal using the reception antenna element during a predetermined period, N being an integer greater than or equal to 3, the first reception signal including a reflection signal obtained as a result of the first transmission signal being reflected by the first living body;a memory in which teacher signals are stored, the teacher signals being M×N second reception signals obtained as a result of the N receivers receiving, in advance, second reception signals including reflection signals obtained as a result of second transmission signals being transmitted from the M transmission antenna elements to a second living body and reflected by the second living body; anda circuit which calculates a plurality of correlation coefficients from the teacher signals and M×N first reception signals obtained as a result of each of the N receivers receiving the first reception signal, performs biometric authentication of the first living body according to whether or not a maximum value of the plurality of correlation coefficients calculated exceeds a threshold, and when the biometric authentication of the first living body is to be performed, identifies by a predetermined method the first living body and the second living body as identical, wherein the circuit removes by a predetermined method a direct current (DC) component from at least the first reception signal among the first reception signal and the second reception signals.","6","16/196853","2018-11-20","2019-0158494","2019-05-23","10880301","2020-12-29","PANASONIC INTELLECTUAL PROPERTY MANAGEMENT CO., LTD.","Takeshi  Nakayama | Shoichi  Iizuka | Naoki  Honma | Dai  Sasakawa","2017-223430 | 2018-105032","JP | JP","2017-11-21 | 2018-05-31","H04L-0063/0861","H04L-0063/0861 | A61B-0005/0536 | A61B-0005/117 | A61B-0005/7264 | G06F-0017/15 | G06F-0021/32 | G06K-0009/00536 | G06K-0009/00906 | H04L-0025/061","H04L-029/06","H04L-029/06 | G06F-017/15 | H04L-025/06 | G06K-009/00 | A61B-005/117 | A61B-005/00 | G06F-021/32","","","","","","4920053006933"
"US","US","P","B2","Medical imaging and efficient sharing of medical imaging information","An MRI image processing and analysis system may identify instances of structure in MRI flow data, e.g., coherency, derive contours and/or clinical markers based on the identified structures. The system may be remotely located from one or more MRI acquisition systems, and perform: error detection and/or correction on MRI data sets (e.g., phase error correction, phase aliasing, signal unwrapping, and/or on other artifacts); segmentation; visualization of flow (e.g., velocity, arterial versus venous flow, shunts) superimposed on anatomical structure, quantification; verification; and/or generation of patient specific 4-D flow protocols. A protected health information (PHI) service is provided which de-identifies medical study data and allows medical providers to control PHI data, and uploads the de-identified data to an analytics service provider (ASP) system. A web application is provided which merges the PHI data with the de-identified data while keeping control of the PHI data with the medical provider.","1. A method of operating a medical analytics platform, the medical analytics platform comprising an analytics service provider (ASP) system and a protected health information (PHI) system, the method comprising: storing, by at least one processor of the ASP system, de-identified medical study data on at least one nontransitory processor-readable storage medium of the ASP system;storing, by at least one processor of the PHI system, PHI data including information personally identifiable to one or more patients on at least one nontransitory processor-readable storage medium of the PHI system, wherein the PHI data is associated with the de-identified medical study data;validating, by the at least one processor of the ASP system, an access token for a client processor-based device to access the PHI data stored on at least one nontransitory processor-readable storage medium of the PHI system;based at least partially on successful validation of the access token by the at least one processor of the ASP system, sending, by the at least one processor of the PHI system, PHI data for a requested medical study to the client processor-based device over at least one communications network;sending, by the at least one processor of the ASP system, de-identified medical study data for the requested medical study to the client processor-based device over the at least one communications network;generating, by the at least one processor of the ASP system, analytics data relating to the de-identified medical study data; andsending, by the at least one processor of the ASP system, the generated analytics data to the PHI system over the at least one communications network.","28","15/779445","2016-11-29","2018-0256041","2018-09-13","10869608","2020-12-22","ARTERYS INC.","Kyle  Dormer | Hussein  Patni | Darryl  Bidulock | John  Axerio-Cilies | Torin Arni  Taerum","","","","A61B-0005/0263","A61B-0005/0263 | A61B-0005/0013 | A61B-0005/0044 | A61B-0005/02 | A61B-0005/021 | A61B-0005/026 | A61B-0005/055 | A61B-0005/7203 | A61B-0005/725 | A61B-0005/7207 | A61B-0005/7257 | G01R-0033/5608 | G06T-0007/0012 | G06T-0007/269 | G16H-0010/60 | G16H-0030/20 | G16H-0030/40 | H04L-0009/3213 | H04L-0063/0209 | A61B-0005/0022 | A61B-0005/02007 | A61B-0005/02014 | A61B-2576/023 | G01R-0033/56316 | G06T-2207/10076 | G06T-2207/10088 | G06T-2207/30104","A61B-005/00","A61B-005/00 | A61B-005/026 | A61B-005/055 | A61B-005/021 | A61B-005/02 | G01R-033/56 | G16H-010/60 | G16H-030/20 | G06T-007/00 | H04L-009/32 | H04L-029/06 | G06T-007/269 | G16H-030/40 | G01R-033/563","","","","","","4920052000780"
"US","US","P","B2","Biometric identification by garments having a plurality of sensors","Biometric identification methods and apparatuses (including devices and systems) for uniquely identifying one an individual based on wearable garments including a plurality of sensors, including but not limited to sensors having multiple sensing modalities (e.g., movement, respiratory movements, heart rate, ECG, EEG, etc.).","1. A method of confirming a user'ss identity, the method comprising: wearing a garment comprising a plurality of integrated sensors at predetermined locations;synchronously recording sensor data from multiple predetermined locations on the garment;identifying a feature set based on which type of recorded sensor data distinguishes between different users;generating, in the garment, a biometric token from the recorded sensor data, using the feature set, wherein the biometric token is a private secure biometric token;transmitting the biometric token to a logger in or on the garment;confirming the user'ss identity using the biometric token; andsending a coded message from a third party requesting approval of a transaction to the garment.","28","16/222603","2018-12-17","2019-0133474","2019-05-09","10869620","2020-12-22","L.I.F.E. CORPORATION S.A.","Gianluigi  Longinotti-Buitoni","","","","A61B-0005/117","A61B-0005/117 | A41D-0013/1281 | A61B-0005/04 | A61B-0005/0428 | A61B-0005/053 | A61B-0005/6804 | A61B-0005/6805 | G06F-0001/163 | G06F-0003/011 | G06F-0003/015 | G06F-0003/017 | G06F-0021/32 | G06F-0021/34 | G06K-0009/00342 | G06K-0009/00355 | G06K-0009/00892 | G06K-0009/00906 | G06K-0009/4609 | H04L-0063/0861 | H04W-0012/0605 | A61B-0005/0024 | A61B-0005/0205 | A61B-0005/0404 | A61B-0005/0488 | A61B-0005/0816 | A61B-0005/11 | A61B-2562/0219 | G06K-2009/00939","A61B-005/00","A61B-005/00 | A61B-005/117 | G06F-021/32 | G06K-009/00 | H04L-029/06 | G06F-001/16 | G06F-021/34 | G06F-003/01 | H04W-012/06 | A41D-013/12 | A61B-005/04 | A61B-005/0428 | A61B-005/053 | G06K-009/46 | A61B-005/0205 | A61B-005/0404 | A61B-005/0488 | A61B-005/08 | A61B-005/11","","","","","","4920052000792"
"US","US","P","B2","Biological information measurement device and method for determining correctness of biological information","A biological information measurement device includes: an information input request unit configured to request an input of identification information at each of a plurality of timings after measurement of the biological information is started; a personal identification unit configured to determine whether a user wearing the biological information measurement device is a pre-registered person in synchronization with each of the plurality of timings, based on the identification information; an identification result information generation unit configured to generate identification result information indicative of a relationship between a first number of times that the request is made by the information input request unit and a second number of times that the user is determined to be the pre-registered person by the personal identification unit; and a correctness determination unit configured to determine correctness of the biological information on the basis of the identification result information.","1. A biological information measurement device configured to continuously measure biological information from a living body with being worn on the living body, the biological information measurement device comprising: a storage control unit configured to perform storage control of the measured biological information in a storage medium;an input unit for inputting identification information necessary for personal identification;an information input request unit configured to request an input of the identification information by the input unit at each of a plurality of timings after measurement of the biological information is started;a personal identification unit configured to determine whether a user wearing the biological information measurement device is a pre-registered person in synchronization with each of the plurality of timings, based on the identification information input by the input unit;an identification result information generation unit configured to generate identification result information indicative of a relationship between a first number of times that the request is made by the information input request unit and a second number of times that the user is determined to be the pre-registered person by the personal identification unit; anda correctness determination unit configured to determine correctness of the biological information stored in the storage medium on the basis of the identification result information.","13","16/203746","2018-11-29","2019-0090787","2019-03-28","10869621","2020-12-22","OMRON HEALTHCARE CO., LTD. | OMRON CORPORATION","Shingo  Yamashita | Naoki  Maeda","2016-110369","JP","2016-06-01","A61B-0005/1176","A61B-0005/1176 | A61B-0005/0002 | A61B-0005/024 | A61B-0005/0205 | A61B-0005/117 | A61B-0005/1118 | A61B-0005/1172 | A61B-0005/4809 | A61B-0005/681 | A61B-0005/6824 | G06K-0009/00342 | G16H-0010/60 | G16H-0040/63 | G16H-0050/30 | A61B-0005/0402 | A61B-2562/043 | G06F-0021/32 | G06K-0009/00087 | G06K-0009/036 | G06K-2009/00932 | G06K-2009/00939 | G06Q-0040/08 | G16H-0010/20","A61B-005/11","A61B-005/11 | A61B-005/1171 | G06K-009/00 | A61B-005/00 | A61B-005/117 | A61B-005/0205 | G16H-050/30 | G16H-040/63 | G16H-010/60 | A61B-005/024 | A61B-005/1172 | G16H-010/20 | A61B-005/0402 | G06F-021/32 | G06K-009/03 | G06Q-040/08","","","","","","4920052000793"
"US","US","P","B2","System and method for fusing information related to a driver of a vehicle","A method, apparatus and computer program product of determining a state of a vehicle driver, the method comprising: receiving an image of the driver captured by a hyper spectral camera capable of imaging body features invisible to a human; receiving telemetry information from a car telemetry system; analyzing the image to receive at least one indicator to a clinical parameter of the driver; and fusing the at least one indicator with the telemetry information to obtain an assessment to a stress level of the driver.","1. A method of determining a state of a vehicle driver, to be performed by a device comprising a processor and a memory device, the method comprising: receiving by a vehicle telemetry interface, vehicle-related telemetry information from a car telemetry system, wherein the vehicle-related telemetry information comprises at least one of vehicle speed, vehicle acceleration, lane passing and honking;assessing by a telemetric analysis engine, a stress level of the driver from the information received from the car telemetry system;receiving by an information fusing apparatus, an image of the driver captured by a hyper spectral camera capable of imaging body features invisible to a human;analyzing the image by an image analysis engine, to receive at least one indicator to a clinical parameter of the driver;learning by a learning engine, stress-related parameters or thresholds from a behavior of the driver over time;fusing by a stress level analysis engine, the stress level assessed from the vehicle-related telemetry information received from the car telemetry system, with the at least one indicator received from analyzing the image, and using the stress-related parameters or thresholds as learned to obtain a combined assessment to a stress level of the driver;based on the combined assessment, determining an action by an action selection engine; andtaking the action by an action activation engine, in response to the stress level exceeding a predetermined threshold.","18","15/642323","2017-07-05","2019-0008437","2019-01-10","10869627","2020-12-22","OSR ENTERPRISES AG","Yosef  Ben-Ezra | Samuel  Hazak | Yaniv  Ben-Haim | Shai  Nissim | Yoni  Schiff","","","","A61B-0005/18","A61B-0005/18 | A61B-0005/0075 | A61B-0005/14551 | A61B-0005/165 | B60W-0050/0098 | B60W-0050/14 | G05D-0001/0088 | G06K-0009/00845 | G06K-0009/2018 | G06K-0009/6289 | G06Q-0040/08 | G08B-0021/06 | G08B-0021/182 | B60W-2420/403 | B60W-2540/043 | B60W-2540/21 | B60W-2540/22 | B60W-2555/20 | B60W-2556/60 | G06K-0009/00255 | G06K-0009/00335","A61B-005/18","A61B-005/18 | G06Q-040/08 | G08B-021/18 | G06K-009/00 | G06K-009/62 | G05D-001/00 | B60W-050/00 | B60W-050/14 | A61B-005/00 | A61B-005/1455 | A61B-005/16 | G06K-009/20 | G08B-021/06","","","","","","4920052000799"
"US","US","P","B2","System and method for ergonomic analysis, in particular of a worker","Described herein is a system and method for ergonomic analysis including a sensorized glove having an inner glove including a plurality of extensometer sensors for detecting relative movements between parts of a worker's hand, and an outer glove including a plurality of pressure sensors distributed over a palmar surface and for detecting pressure exerted in corresponding areas of said palmar surface; a wearable network of sensors being located in the network so that they can be associated to corresponding joints of the human body; a unit for generating a sequence of images of a worker task; and a processing unit for receiving data and/or signals from the sensorized glove, from the wearable sensor network, and/or from the unit, and configured for processing said data and/or signals to estimate ergonomic indicators and/or to obtain local information of effort and/or posture.","1. A system for ergonomic analysis including: a sensorized glove, said sensorized glove comprising an inner glove, which includes a plurality of extensometer sensors configured for detecting relative movements between parts of a worker'ss hand of a human body, andan outer glove, which includes a plurality of pressure sensors distributed over an outer glove palmar surface and configured for detecting pressure exerted in corresponding areas of said outer glove palmar surface;a wearable network of sensors being located in a network so that they can be associated to corresponding joints of the human body;a system for generating a sequence of images of a task performed by the worker; anda processing unit configured for receiving data and/or signals from the sensorized glove, and/or from the wearable network of sensors, and/or from the system for generating a sequence of images, and configured for processing said data and/or signals in order to estimate ergonomic indicators, and/or to obtain local information of effort and/or posture.","15","16/254708","2019-01-23","2019-0290202","2019-09-26","10869632","2020-12-22","C.R.F. SOCIET? CONSORTILE PER AZIONI","Massimo  Di Pardo | Giorgio  Pasquettaz | Rossella  Monferino | Francesca  Gallo","2018-153311","EP","2018-01-24","A61B-0005/6806","A61B-0005/6806 | A41D-0019/001 | A41D-0019/0027 | A61B-0005/0024 | A61B-0005/0077 | A61B-0005/1116 | A61B-0005/1122 | A61B-0005/1125 | A61B-0005/1128 | A61B-0005/22 | A61B-0005/225 | A61B-0005/4561 | G06F-0003/014 | G06F-0003/017 | G06Q-0010/06398 | G06T-0011/60 | G16H-0020/30 | G16H-0040/63 | A41D-2600/20 | A61B-0005/1071 | A61B-2503/20 | A61B-2562/0219 | A61B-2562/0247 | A61B-2562/04 | A61B-2562/066 | H04L-0067/12","A61B-005/00","A61B-005/00 | A41D-019/00 | A61B-005/11 | G06F-003/01 | G06T-011/60 | G16H-020/30 | A61B-005/22 | G16H-040/63 | G06Q-010/06 | H04L-029/08 | A61B-005/107","","","","","","4920052000804"
"US","US","P","B2","Live 3D holographic guidance and navigation for performing interventional procedures","An interventional procedure can be performed less invasively with live 3D holographic guidance and navigation. Advantageously, the 3D holographic guidance and navigation overcomes the limitations of conventional displays of medical images on standard 2D flat panel screens. The live 3D holographic guidance can utilize a 3D holographic visualization that is derived from complementary imaging modalities (e.g., ultrasound and computed tomography) to provide a complete holographic view of a portion of the patient's body to enable navigation of a tracked interventional instrument/device.","1. A method comprising: receiving, by a physical head-mounted device comprising a processor and a head-tracking mechanism, live tracking data from a procedure in 3D Cartesian coordinates of a navigation system,wherein the live tracking data comprises a position and orientation of: a tracked physical ultrasound transducer/probe connected to an ultrasound system,a tracked physical interventional device/instrument, andphysical fiducial location sensors at specific anatomical locations on a physical patient;receiving, by the physical head-mounted device, a live ultrasound image stream acquired by the physical ultrasound transducer/probe connected to the ultrasound system;transforming, by the head-mounted device, the live ultrasound image stream to a headset coordinate system;transforming, by the head-mounted device, the live tracking data to the headset coordinate system;displaying, in a head-mounted display of the head mounted device, a live holographic projection of the live ultrasound image stream in the headset coordinate system, wherein the live holographic projection of the ultrasound image stream is based on the tracked position and tracked orientation of the transducer/probe, wherein the live holographic projection is scaled to the physical anatomy consistent with an operator'ss view assessed with the head-tracking mechanism;retrieving, by the head mounted device, digital anatomical objects derived from pre-operative 3D computed tomography (CT) image data of the physical patient, wherein the CT image data is in 3D coordinates of a CT coordinate system;transforming, by the head-mounted device, the digital anatomical objects from the 3D CT coordinate system to the headset coordinate system;translating, by the head mounted device, the anatomical objects in the headset coordinate system by a 3D vector computed based on a 3D point location on the live holographic projection of the live image stream and a corresponding point within the stored pre-operative CT image data in the headset coordinate system to correct for a live anatomical motion of the physical patient during the procedure; anddisplaying, in the head mounted display of the head mounted device, a holographic visualization comprising a holographic representation of the tracked physical interventional device/instrument congruent with the registered holographic projection of the live ultrasound image stream and the holographic anatomical objects derived from CT, wherein the holographic visualization is used to navigate the tracked physical ultrasound transducer/probe and guide the physical interventional device/instrument to a therapeutic target during the procedure.","23","16/405875","2019-05-07","2019-0339525","2019-11-07","10869727","2020-12-22","THE CLEVELAND CLINIC FOUNDATION","Jeffrey H.  Yanof | Karl  West | Sara  Al-Nimer","","","","A61B-0034/20","A61B-0034/20 | A61B-0008/463 | A61B-0008/466 | A61B-0008/483 | A61B-0008/5238 | G02B-0027/0172 | G06F-0003/011 | G06K-0009/00671 | G06K-0009/3216 | A61B-0008/4245 | A61B-2017/00216 | A61B-2034/107 | A61B-2034/2048 | A61B-2034/2051 | A61B-2034/2055 | A61B-2034/2063 | A61B-2090/365 | A61B-2090/368 | A61B-2090/378 | A61B-2090/502 | A61M-2205/507 | G02B-0027/0093 | G02B-2027/0138 | G06F-0003/012 | G06K-2009/3225 | G06K-2209/05","A61B-034/20","A61B-034/20 | G02B-027/01 | A61B-008/00 | A61B-008/08 | G06K-009/32 | G06K-009/00 | G06F-003/01 | A61B-090/00 | A61B-034/10 | A61B-017/00 | G02B-027/00 | A61B-090/50","","","","","","4920052000899"
"US","US","P","B2","Patient positioning support apparatus with virtual pivot-shift pelvic pads, upper body stabilization and fail-safe table attachment mechanism","A patient support apparatus for supporting a patient in a prone position during a surgical procedure is provided, including an open fixed frame suspended above a floor and a pair of spaced opposed radially sliding joints cooperating with the frame, each joint including a virtual pivot point and an arc of motion spaced from the virtual pivot point, the joints being movable along the arc providing a pivot ship mechanism for a pair of pelvic pads attached to the joints. A base for supporting and suspending a patient support structure above the floor, for supporting a patient during a surgical procedure, the base including a pair of spaced opposed vertical translation subassemblies reversibly attachable to a patient support structure, a cross-bar, and a rotation subassembly having two degrees of rotational freedom; wherein a location of each vertical translation subassembly is substantially constant during operation of the patient support structure.","1. A base structure for supporting a patient support structure above a floor, the base structure comprising: a head end support structure comprising a head end lower portion and a head end upper portion, the head end upper portion configured to change elevation relative to the floor;a foot end support structure opposite the head end support structure and comprising a foot end lower portion and a foot end upper portion, the foot end upper portion configured to change elevation relative to the floor;a cross-bar extending between the head end support structure and the foot end support structure;a head end rotation assembly rotatably coupled with the head end support structure, the head end rotation assembly comprising a head end motor, a head end rotation shaft rotatably coupled to the head end motor, and a head end rotation block pivotally coupled to the head end rotation shaft via a head end yaw pin, the head end yaw pin extending through the head end rotation shaft, the head end rotation block configured to operably couple with a head end of the patient support structure, the head end motor configured to rotate the head end shaft, the head end rotation block, and the patient support structure about a head end rotation axis extending through the head end rotation shaft, the head end rotation block configured to pivot about a head end yaw axis extending through the head end yaw pin, the head end rotation axis oriented perpendicular to the head end yaw axis; anda foot end rotation assembly rotatably coupled with the foot end support structure, the foot end rotation assembly comprising a foot end motor, a foot end rotation shaft rotatably coupled to the foot end motor, and a foot end rotation block pivotally coupled to the foot end rotation shaft via a foot end yaw pin, the foot end rotation block configured to operably couple with a foot end of the patient support structure, the foot end motor configured to rotate the foot end shaft, the foot end rotation block, and the patient support structure about a foot end rotation axis extending through the foot end rotation shaft, the foot end rotation block configured to pivot about a foot end yaw axis extending through the foot end yaw pin, the foot end rotation axis oriented perpendicular to the foot end yaw axis.","28","15/421994","2017-02-01","2017-0181908","2017-06-29","10869798","2020-12-22","WARSAW ORTHOPEDIC, INC.","Roger P.  Jackson | Lawrence E.  Guerra | Trevor A.  Waggoner | Steven R.  Walton | Michael A.  Herron","","","","A61G-0013/04","A61G-0013/04 | A61B-0005/4836 | A61B-0005/704 | A61B-0005/7425 | A61G-0007/001 | A61G-0007/005 | A61G-0007/008 | A61G-0007/012 | A61G-0007/015 | A61G-0007/018 | A61G-0013/0036 | A61G-0013/0054 | A61G-0013/02 | A61G-0013/06 | A61G-0013/08 | A61G-0013/101 | A61G-0013/104 | A61G-0013/121 | A61G-0013/122 | A61G-0013/123 | A61G-0013/1205 | A61G-0013/1235 | G06F-0003/04842 | G06F-0019/32 | A61B-2017/00022 | A61G-0007/002","A61G-013/04","A61G-013/04 | A61G-013/06 | A61G-013/08 | A61G-013/10 | A61G-013/00 | A61G-013/12 | A61G-013/02 | G06F-019/00 | A61B-005/00 | A61G-007/00 | A61G-007/005 | A61G-007/008 | A61G-007/012 | A61G-007/015 | A61G-007/018 | G06F-003/0484 | A61B-017/00 | A61G-007/002","","","","","","4920052000970"
"US","US","P","B2","Smart device","An Internet of Thing (IoT) device includes a body with a processor, a camera and a wireless transceiver coupled to the processor.","1. A method for determining real-time vehicle operation cost for a driver during a trip, comprising: mounting cameras on a vehicle to monitor traffic data, wherein at least one camera determines distances of neighboring objects from the camera;generating a 3D model and determining obstacle information from nearby cars;adjusting the 3D model based on the weather information and weather impact on sensors;generating a comprehensive 3D model with traffic flow information;collecting data from vehicle sensors monitoring vehicle operation and collecting vehicle driver behavior data including a driver emotional state, contextual information, driver history, and real-time driving information based on operation of the vehicle by the driver;determining a real-time rate of operating the vehicle based on the adjusted 3D model traffic and vehicle speed, wherein each item of driver behavior data is weighted in determining the real-time rate or cost;displaying the determined real-time rate to the driver.","20","16/252543","2019-01-18","2020-0008023","2020-01-02","10873837","2020-12-22","Bao Tran | Ha Tran","Bao  Tran | Ha  Tran","","","","H04W-0004/38","H04W-0004/38 | A42B-0003/0433 | A61B-0005/11 | A61B-0005/6804 | A63B-0024/0006 | A63B-0024/0021 | A63B-0024/0062 | A63B-0024/0075 | A63B-0043/004 | A63B-0060/46 | A63B-0069/36 | A63B-0069/38 | A63B-0071/06 | A63B-0071/145 | A63F-0011/00 | A63F-0013/211 | B33Y-0010/00 | G01L-0005/0052 | G06F-0001/163 | G06F-0003/00 | G06F-0003/017 | G06K-0009/00342 | G06K-0009/00355 | G06K-0009/00671 | G06K-0019/025 | G06K-0019/07762 | G06Q-0040/08 | G09B-0019/003 | G09B-0019/0038 | G16H-0020/30 | G16H-0030/20 | G16H-0040/63 | G16H-0040/67 | H04N-0005/2253 | H04N-0007/18 | H04Q-0009/00 | H04W-0084/18 | A61B-0005/0022 | A61B-0005/01 | A61B-0005/024 | A61B-0005/0402 | A61B-0005/053 | A61B-0005/055 | A61B-0005/0533 | A61B-0005/4872 | A61B-0005/6806 | A61B-0005/6895 | A61B-2503/10 | A61B-2562/0219 | A63B-0021/072 | A63B-0021/0724 | A63B-0021/0726 | A63B-0069/0002 | A63B-0069/0026 | A63B-0069/0028 | A63B-0069/0048 | A63B-0069/0071 | A63B-0069/02 | A63B-0069/06 | A63B-0069/16 | A63B-0069/3632 | A63B-0071/085 | A63B-0071/10 | A63B-0071/1216 | A63B-0071/1291 | A63B-0071/141 | A63B-2071/125 | A63B-2071/1233 | A63B-2071/1283 | A63B-2208/0204 | A63B-2220/12 | A63B-2220/13 | A63B-2220/16 | A63B-2220/20 | A63B-2220/24 | A63B-2220/30 | A63B-2220/40 | A63B-2220/51 | A63B-2220/53 | A63B-2220/56 | A63B-2220/72 | A63B-2220/74 | A63B-2220/75 | A63B-2220/76 | A63B-2220/803 | A63B-2220/806 | A63B-2220/807 | A63B-2220/833 | A63B-2220/836 | A63B-2225/30 | A63B-2225/50 | A63B-2225/54 | A63B-2225/74 | A63B-2230/04 | A63B-2230/06 | A63B-2230/50 | A63B-2230/60 | A63B-2230/70 | A63B-2243/007 | A63B-2243/0025 | A63B-2243/0037 | A63B-2243/0054 | A63B-2243/0066 | A63B-2243/0095 | A63B-2244/102 | A63B-2244/18 | A63B-2244/19 | A63B-2244/20 | A63B-2244/203 | G16H-0050/20 | H04B-0001/04 | H04L-0067/10 | H04Q-2209/40 | H04W-0088/02","G06Q-040/08","G06Q-040/08 | H04W-004/38 | A63B-071/14 | A63B-069/36 | A61B-005/11 | G06F-003/00 | G06K-009/00 | G09B-019/00 | G06F-001/16 | B33Y-010/00 | G01L-005/00 | H04W-084/18 | G16H-040/63 | G16H-040/67 | A61B-005/00 | A63B-060/46 | A63B-024/00 | A63B-069/38 | A42B-003/04 | A63B-071/06 | H04Q-009/00 | G16H-030/20 | A63B-043/00 | G06F-003/01 | H04N-005/225 | H04N-007/18 | A63F-013/211 | A63F-011/00 | G16H-020/30 | G06K-019/02 | G06K-019/077 | G16H-050/20 | A63B-071/12 | A63B-069/00 | A63B-069/02 | A63B-069/06 | A63B-069/16 | A63B-071/08 | A63B-071/10 | A63B-021/072 | A61B-005/01 | A61B-005/024 | A61B-005/0402 | A61B-005/053 | A61B-005/055 | H04B-001/04 | H04L-029/08 | H04W-088/02","","","","","","4920052004980"
"US","US","P","B2","Annotation histogram","Systems and methods for facilitating processing of cardiac information based on sensed electrical signals include a processing unit configured to receive a set of electrical signals; receive an indication of a measurement location corresponding to each electrical signal of the set of electrical signals; and generate, based on at least one of an annotation waveform corresponding to each electrical signal of the set of electrical signals and a set of annotation mapping values, an annotation histogram.","1. A system for facilitating processing of cardiac information based on sensed electrical signals, the system comprising: a processing unit configured to: receive a set of electrical signals;receive an indication of a measurement location corresponding to each electrical signal of the set of electrical signals;generate an annotation waveform corresponding to the set of electrical signals, the annotation waveform based on deflections of the set of electrical signals from a baseline signal, wherein the baseline signal comprises at least one non-zero value and a deflection of the deflections from the baseline signal for the annotation waveform is from the non-zero value; andgenerate, based on the annotation waveform and a set of annotation mapping values, an annotation histogram.","20","15/955505","2018-04-17","2018-0296108","2018-10-18","10863915","2020-12-15","BOSTON SCIENTIFIC SCIMED, INC.","Brian  Stewart | Vasiliy E.  Buharin | Mordechai  Perlman | Nathan H.  Bennett","","","","A61B-0005/044","A61B-0005/044 | A61B-0005/0245 | A61B-0005/0402 | A61B-0005/0452 | A61B-0005/743 | A61B-0034/20 | A61B-0034/25 | G06F-0003/04842 | G06F-0040/169 | G06T-0011/206 | A61B-0005/0422 | A61B-0005/0538 | A61B-0005/063 | A61B-0005/6852 | A61B-0005/7221 | A61B-0018/1492 | A61B-2018/00351 | A61B-2018/00577 | A61B-2018/00839 | A61B-2018/00875 | A61B-2034/2051 | A61B-2562/04 | A61B-2562/06 | G06T-2200/24","A61B-005/044","A61B-005/044 | G06T-011/20 | G06F-017/24 | G06F-003/0484 | A61B-034/20 | A61B-005/00 | A61B-005/0452 | A61B-005/0245 | A61B-034/00 | A61B-005/0402 | G06F-040/169 | A61B-018/14 | A61B-018/00 | A61B-005/06 | A61B-005/042","","","","","","4920051000957"
"US","US","P","B2","Data analytics and insight delivery for the management and control of diabetes","A computer-implemented system and related method of managing use of a diabetes management device are presented here. An embodiment of the method obtains input data for a user of the diabetes management device, and compares the input data against historical event/outcome combinations maintained for the user. Each of the event/outcome combinations includes insight event data indicative of a glycemic event and a glycemic outcome corresponding to the insight event data. The method determines, based on the comparing, a correlation between the input data and a glycemic outcome. The method continues by generating a glycemic insight message for delivery to the user, wherein the glycemic insight message includes information regarding a relationship between at least some of the input data and the glycemic outcome.","1. A computer-implemented method of managing use of an insulin infusion device, the method comprising: obtaining, at a cloud-based computer-implemented server system, input data for a user of the insulin infusion device;comparing, with the server system, the input data against historical event/outcome combinations maintained for the user, each of the event/outcome combinations comprising insight event data indicative of a respective glycemic event and a respective glycemic outcome corresponding to the insight event data;determining, based on the comparing, a correlation between the input data and a particular glycemic outcome, the determining step performed by the server system, wherein the determining step comprises: analyzing the historical event/outcome combinations to count a number of times that an insight event has occurred in a designated historical window of time;comparing the number of times to a predetermined threshold number; andconfirming that insight generation criteria is satisfied only when the number of times exceeds the predetermined threshold number;in response to the determining, generating, with the server system, a glycemic insight message for delivery to the user, the glycemic insight message comprising information regarding a relationship between at least some of the input data and the particular glycemic outcome;delivering the generated glycemic insight message from the server system to the insulin infusion device operated by the user;displaying a calendar screen of a calendar application, the calendar screen comprising a scheduled event displayed as a calendar entry, wherein the scheduled event is associated with at least some of the input data, and the glycemic insight message comprises one or more active elements that, when selected, cause additional details related to a relationship between the at least some of the input data and the particular glycemic outcome to be displayed;predictively triggering display of the glycemic insight message to appear before the start of the displayed calendar entry;displaying the glycemic insight message on the calendar screen of the calendar application, and rendered in association with and proximate to the displayed calendar entry, to link the glycemic insight message contextually and temporally to the scheduled event as an annotation of the displayed calendar entry; andadjusting administration of insulin by the insulin infusion device, wherein the adjusting is performed by the insulin infusion device in accordance with recommended glycemic control parameters included in the glycemic insight message delivered to the insulin infusion device.","14","15/240891","2016-08-18","2017-0053072","2017-02-23","10867012","2020-12-15","MEDTRONIC MINIMED, INC.","Pratik  Agrawal | Chantal M.  McMahon | Yuxiang  Zhong | Boyi  Jiang | Michael P.  Stone | Huzefa F.  Neemuchwala | Kelly F.  Joy","","","","G06F-0019/324","G06F-0019/324 | A61B-0005/0022 | A61B-0005/14532 | A61B-0005/14542 | A61B-0005/486 | A61B-0005/4848 | A61B-0005/7275 | A61B-0005/7282 | A61B-0005/742 | A61B-0005/743 | A61B-0005/7405 | A61B-0005/746 | A61M-0005/003 | A61M-0005/142 | A61M-0005/1723 | G06F-0019/3418 | G06Q-0010/109 | G09B-0005/125 | G09B-0019/0092 | G16H-0040/63 | G16H-0050/20 | G16H-0070/00 | A61M-2005/1402 | A61M-2205/18 | A61M-2205/3584 | A61M-2205/502 | A61M-2205/52","G06F-019/00","G06F-019/00 | A61B-005/00 | A61B-005/145 | A61M-005/172 | G16H-050/20 | A61M-005/142 | G16H-040/63 | G16H-070/00 | G06Q-010/10 | A61M-005/00 | G09B-005/12 | G09B-019/00 | A61M-005/14","","","","","","4920051004032"
"US","US","P","B2","Drowsiness mental state analysis using blink rate","Drowsiness mental state analysis is performed using blink rate. Video is obtained of an individual or group. The individual or group can be within a vehicle. The video is analyzed to detect a blink event based on a classifier, where the blink event is determined by identifying that eyes are closed for a frame in the video. A blink duration is evaluated for the blink event. Blink-rate information is determined using the blink event and one or more other blink events. The evaluating can include evaluating blinking for a group of people. The blink-rate information is compensated to determine drowsiness, based on the temporal distribution mapping of the blink-rate information. Mental states of the individual are inferred for the blink event based on the blink event, the blink duration of the individual, and the blink-rate information that was compensated. The compensating is biased based on demographic information of the individual.","1. A computer-implemented method for mental state analysis comprising: obtaining video of an individual with an image capture device;analyzing, using one or more processors, the video to detect a blink event based on a classifier for a blink that was determined wherein the blink event is determined by identifying that eyes of the individual are closed for a frame in the video using temporal analysis;evaluating, using the one or more processors, a blink duration of the individual for the blink event;determining, using the one or more processors, blink-rate information using the blink event and one or more other blink events, wherein the determining yields a blink-rate frequency, wherein a higher blink-rate frequency infers more drowsiness over the temporal distribution of the blink-rate information;compensating, using the one or more processors, the blink-rate information to determine drowsiness, based on a temporal distribution of the blink-rate information; andinferring, using the one or more processors, mental states of the individual for the blink event, wherein the mental states are based on the blink event, the blink duration of the individual, and the blink-rate information that was compensated.","24","16/685071","2019-11-15","2020-0104616","2020-04-02","10867197","2020-12-15","AFFECTIVA, INC.","Rana  el Kaliouby | Survi  Kyal | Abdelrahman N.  Mahmoud | Seyedmohammad  Mavadati | Panu James  Turcot","","","","G06K-0009/00845","G06K-0009/00845 | A61B-0005/0077 | A61B-0005/1103 | A61B-0005/165 | A61B-0005/18 | A61B-0005/6893 | B60K-0028/06 | B60R-0011/04 | G06K-0009/00281 | A61B-0005/02055 | G06Q-0030/0271 | G06T-2207/30201 | G06T-2207/30268 | G16H-0050/20","B60Q-001/00","B60Q-001/00 | G06K-009/00 | A61B-005/16 | B60K-028/06 | B60R-011/04 | A61B-005/00 | A61B-005/11 | A61B-005/18 | A61B-005/0205 | G06Q-030/02 | G16H-050/20","","","","","","4920051004214"
"US","US","P","B2","Geo-fencing system and method","A method, computer program product, and computing system for administering an alertness test on a client electronic device to determine a result for a user, wherein the result is indicative of a level of alertness of the user. A location of the client electronic device is determined, thus defining a determined location. Remedial action is taken if the level of alertness of the user is insufficient for the user to perform a task at the determined location.","1. A computer-implemented method, executed on a computing device, comprising: administering an alertness test on a client electronic device to determine a result for a user, wherein the result is indicative of a level of alertness of the user, wherein administering the alertness test to the user includes: rendering a plurality of objects for use within the alertness test being administered to the user,rendering a disrupter configured to distract the user from observing the plurality of objects, wherein the disrupter is configured to rotate over the plurality of objects and, while rotating, temporarily obscure at least a portion of one or more objects of the plurality of objects rendered on the graphical user interface during the alertness test, andsoliciting a response from the user concerning whether the user can identify at least a pair of objects of the plurality of objects rendered within the alertness test that are identical to each other;determining a first location of the client electronic device, thus defining a first determined location;determining a minimum level of alertness to perform a task based upon, at least in part, the first determined location;determining a second location of the client electronic device, thus defining a second determined location;determining a change in the minimum level of alertness to perform the task based upon, at least in part, the second determined location; andtaking remedial action if the level of alertness of the user is insufficient for the user to perform the task at the second determined location based upon, at least in part, the determined change in the minimum level of alertness to perform the task.","21","15/625926","2017-06-16","2017-0365146","2017-12-21","10867272","2020-12-15","PREDICTIVE SAFETY SRP, INC.","Henry M.  Bowles | Marcus T.  Wichmann | Darren B.  Chamberlin","","","","G06Q-0010/06398","G06Q-0010/06398 | A61B-0005/0002 | A61B-0005/0022 | A61B-0005/0077 | A61B-0005/0205 | A61B-0005/1112 | A61B-0005/14542 | A61B-0005/16 | A61B-0005/162 | A61B-0005/165 | A61B-0005/18 | A61B-0005/4064 | A61B-0005/4088 | A61B-0005/6898 | G06F-0003/0482 | G06F-0003/0484 | G06F-0003/04812 | G06F-0021/36 | G06Q-0010/1091 | G07C-0009/20 | G07C-0009/28 | G07C-0009/30 | G08B-0021/02 | G08B-0021/06 | G09B-0005/065 | G09B-0007/00 | G09B-0007/10 | G16H-0010/20 | G16H-0015/00 | H04L-0063/10 | H04W-0012/08 | A61B-0005/024 | A61B-0005/14532 | A61B-0005/4857 | A61B-2503/20 | A61B-2560/0247 | A61B-2562/0204 | H04W-0012/00503 | H04W-0080/12 | H04W-0084/042","G06F-003/0484","G06F-003/0484 | G06Q-010/06 | G06F-003/0481 | G08B-021/06 | H04W-012/08 | G07C-009/20 | G07C-009/28 | G07C-009/30 | G06F-021/36 | H04L-029/06 | A61B-005/18 | G06Q-010/10 | G06F-003/0482 | G09B-005/06 | G09B-007/10 | A61B-005/00 | A61B-005/11 | A61B-005/16 | G09B-007/00 | G08B-021/02 | G16H-015/00 | A61B-005/0205 | A61B-005/145 | G16H-010/20 | H04W-012/00 | H04W-080/12 | H04W-084/04 | A61B-005/024","","","","","","4920051004288"
"US","US","P","B2","Devices, systems, and processes for authenticating devices","Devices, systems and process for authenticating devices are described. For at least one embodiment, a process for authenticating an IoT device with a hub to initiate an authenticated session, includes the operations of establishing an electronic data connection between an IoT device and a hub, sending an initial authentication signal including a cryptologic component and at least two perceptible components, receiving a responsive message secured by a cryptologic component and including a selection of at least one of the at least two perceptible components, determining whether the selection includes the identifying perceptible component, and establishing an authenticated session between the hub and the IoT device, if the result of the determining step is affirmative.","1. A process for authenticating an IoT device with a hub to initiate an authenticated session, comprising: establishing an electronic data connection between an IoT device and a hub;sending, by the hub, an initial authentication signal; wherein the initial authentication signal includes a cryptologic component and at least two perceptible components; wherein the cryptological component includes a public key of a public key-private key keychain;wherein at least one of the at least two perceptible components is a randomly generated identifying perceptible component; andwherein the randomly generated identifying perceptible component includes at least two icons;receiving, by the hub, a responsive message; wherein the responsive message is secured, prior to transmission by the IoT device, by the cryptologic component by the private key for the public key-private key keychain; andwherein the responsive message includes a selection of a unique identifying icon selected from at least two icons of the randomly generated identifying perceptible component, and a unique identifying keyword;determining, by the hub, whether the selection includes the randomly generated identifying perceptible component; andif the result of the determining step is affirmative, establishing an authenticated session between the hub and the IoT device.","18","15/853329","2017-12-22","2019-0200222","2019-06-27","10869194","2020-12-15","DISH NETWORK L.L.C.","Nathan  Sones","","","","H04W-0012/06","H04W-0012/06 | G06F-0021/36 | G06K-0009/00006 | G06K-0009/00221 | H04L-0009/0825 | H04L-0009/30 | H04L-0009/3226 | H04L-0063/0428 | H04L-0067/20 | H04W-0004/80 | H04W-0064/003 | H04W-0076/11 | A61B-0005/02438 | A61B-0005/083","H04W-012/06","H04W-012/06 | G06F-021/36 | H04L-029/06 | H04L-009/30 | H04L-029/08 | H04W-076/11 | G06K-009/00 | H04W-004/80 | H04W-064/00 | H04L-009/08 | H04L-009/32 | A61B-005/024 | A61B-005/083","","","","","","4920051006188"
"US","US","P","B2","Removable smartphone case for radio wave based health monitoring that generates alignment signals","A removable smartphone case is disclosed. The removable smartphone case includes a case body configured to receive a smartphone, a radio frequency (RF) front-end connected to the case body and including a semiconductor substrate and an antenna array including at least one transmit antenna configured to transmit radio waves below the skin surface of a person and a two-dimensional array of receive antennas configured to receive radio waves, the received radio waves including a reflected portion of the transmitted radio waves, wherein the semiconductor substrate includes circuits configured to generate signals in response to the received radio waves, wherein the signals correspond to an alignment of the antenna array relative to a vein below the skin surface of the person, and a communications interface configured to transmit digital data that corresponds to the signals generated by the semiconductor substrate from the removable smartphone case.","1. A removable smartphone case comprising: a case body configured to receive a smartphone;a radio frequency (RF) front-end connected to the case body and including a semiconductor substrate and an antenna array including at least one transmit antenna configured to transmit radio waves below the skin surface of a person and a two-dimensional array of receive antennas configured to receive radio waves, the received radio waves including a reflected portion of the transmitted radio waves, wherein the semiconductor substrate includes circuits configured to generate signals in response to the received radio waves, wherein the signals correspond to an alignment of the antenna array relative to a vein below the skin surface of the person; anda communications interface configured to transmit digital data that corresponds to the signals generated by the semiconductor substrate from the removable smartphone case.","21","16/682989","2019-11-13","2020-0195293","2020-06-18","10856766","2020-12-08","MOVANO INC.","Michael A.  Leabman","","","","A61B-0005/05","A61B-0005/05 | A45C-0011/00 | A61B-0005/0004 | A61B-0005/0022 | A61B-0005/0024 | A61B-0005/021 | A61B-0005/022 | A61B-0005/02116 | A61B-0005/02444 | A61B-0005/14532 | A61B-0005/489 | A61B-0005/681 | A61B-0005/684 | A61B-0005/6815 | A61B-0005/6824 | A61B-0005/6898 | A61B-0005/7257 | A61B-0005/7264 | A61B-0005/742 | A61B-0005/7405 | A61B-0005/7455 | G01S-0007/4004 | G01S-0007/4026 | G01S-0013/87 | G01S-0013/88 | G06F-0001/163 | G06F-0003/016 | G06F-0003/04812 | G06F-0003/167 | G06F-0017/142 | H01Q-0001/273 | H01Q-0001/38 | H01Q-0021/061 | H04B-0001/3888 | H04B-0007/0617 | A45C-2011/002 | A61B-0005/0265 | G01S-2007/028 | G06N-0020/00","H04B-001/3888","H04B-001/3888 | G01S-007/40 | A61B-005/05 | A61B-005/021 | A61B-005/024 | A61B-005/145 | A61B-005/00 | G01S-013/88 | G06F-001/16 | G06F-003/01 | G06F-003/0481 | G06F-003/16 | H01Q-001/38 | H01Q-021/06 | A61B-005/022 | G06F-017/14 | H04B-007/06 | H01Q-001/27 | A45C-011/00 | G01S-013/87 | G01S-007/02 | G06N-020/00 | A61B-005/0265","","","","","","4920050001105"
"US","US","P","B2","Calculation device, calculation method, and non-transitory computer readable recording medium","A calculation device, a calculation method, and a non-transitory computer readable recording medium including a calculation program with which a length of a target region required for a body model can be determined by means of a simple motion are provided. This calculation device configures a wearable device to initiate measurement of a measurement target region. After the measurement of the measurement target region is initiated, a worker wearing the wearable device performs a motion such as rotation of an arm, for example, etc. The calculation device acquires measured information two or more times over time and calculates a body model on the basis of the acquired measured information. During calculation of the body model, calculation is performed to determine a length of a calculation target region by approximately determining a circle or sphere having the length from the rotation center to the calculation target region as a radius using a mathematical method such as a least-squares method on the basis of the measured information acquired over time. Then, the calculation device records the calculated body model in a body model recording unit.","1. A calculation device that calculates a length of a calculation target region of a human body on the basis of results of measuring a measurement target region of the human body, the calculation device comprising: a processor configured to:acquire state information that indicates a position or the position and a state of a posture of the measurement target region of the human body on the basis of measured results;calculate a length using a region from a rotation center in a motion of the human body to the measurement target region as the calculation target region on the basis of the state information; andgenerate a body model relevant to a shape of the human body on the basis of the calculated length for applying to a motion sensing technique,wherein the processor calculates a length using a region from a first rotation center to the measurement target region as a first calculation target region; the processor calculates a length using a region from a second rotation center between the first rotation center and the measurement target region to the measurement target region as a second calculation target region; and the processor calculates a length using a region from the first rotation center to the second rotation center as a third calculation target region on the basis of a difference between the length of the first calculation target region and the length of the second calculation target region.","11","15/751479","2017-01-06","2018-0235515","2018-08-23","10856772","2020-12-08","OMRON CORPORATION","Sayaka  Naito | Yoshikazu  Mori | Kazuki  Kasai","2016-025958","JP","2016-02-15","A61B-0005/1072","A61B-0005/1072 | A61B-0005/1121 | G01B-0021/06 | G06F-0003/011 | G06K-0009/00342 | G06K-0009/00369 | G06T-0017/00 | A61B-2503/20","A61B-005/107","A61B-005/107 | G01B-021/06 | G06K-009/00 | G06F-003/01 | G06T-017/00 | A61B-005/11","","","","","","4920050001111"
"US","US","P","B2","Spoof detection for biometric validation","The invention provides an Optical Coherence Tomography (OCT) system capable of acquiring two orthogonally polarized depth scans from a target such as the fingerprint region of a finger. In the preferred embodiment the birefringence of tissue components and, optionally, other aspects of the target are measured in order determine a characteristic of the target, such as whether it is real of fake finger.","1. An optical coherence tomography system, said system capable of simultaneously acquiring two orthogonally polarized depth scans from a target, said system comprising: an optical coherence tomography system;a first and a second optical path for reference beams that generate a first and second orthogonally polarized reference beams, wherein simultaneous interrogation of two orthogonally polarized components of probe beam back scattered from said target is enabled, such that a first orthogonally polarized depth scan of said target and a second orthogonally polarized depth scan of said target are generated;a processor, wherein said processor receives said first and said second orthogonally polarized depth scans, and wherein said processor determines the difference between said first and said second orthogonally polarized depth scans, and thereby providing a measure of the birefringence of said target, and determines if said target is fake.","3","16/185781","2018-11-09","2019-0138828","2019-05-09","10856780","2020-12-08","COMPACT IMAGING, INC.","Joshua Noel  Hogan","","","","A61B-0005/1172","A61B-0005/1172 | A61B-0005/0066 | G01B-0009/02091 | G06F-0021/32 | G06K-0009/00087 | A61B-0005/14532 | G01B-2290/70 | G01N-2021/1787 | G06K-0009/00114 | G06K-0009/00906","A61B-005/1172","A61B-005/1172 | G01B-009/02 | G06F-021/32 | A61B-005/00 | G06K-009/00 | A61B-005/145 | G01N-021/17","","","","","","4920050001119"
"US","US","P","B2","Method of recognition based on iris recognition and electronic device supporting the same","An iris-based authentication method is provided. The method includes emitting light of an infrared wavelength band and obtaining an image based on the light of the infrared wavelength band, determining whether a specified condition is satisfied, if the specified condition is satisfied, performing user authentication (e.g., complex authentication) based on at least part of a face image and an iris image of the image that a biometric sensor obtains, or, if the specified condition is not satisfied, performing the user authentication (e.g., iris-only authentication) based on the iris image in the image that the biometric sensor obtains.","1. An electronic device comprising: an illuminance sensor;a biometric sensor including: a light emitting element, andan infrared camera;a memory; anda processor operatively coupled to the biometric sensor and the memory,wherein the processor is configured to: determine, prior to performing user authentication in response to an authentication request, whether an external illuminance value, obtained from the illuminance sensor, meets a specified condition,when the specified condition is satisfied, perform the user authentication based on at least a portion of a face image and an iris image obtained by the biometric sensor,when the specified condition is not satisfied, perform the user authentication based on the iris image obtained by the biometric sensor, andwhen the external illuminance value corresponds to an indoor environment and a capture distance between a subject and the biometric sensor corresponds to a first distance in association with the specified condition, perform the user authentication based on the at least the portion of the face image and the iris image.","19","15/895582","2018-02-13","2018-0276465","2018-09-27","10860850","2020-12-08","SAMSUNG ELECTRONICS CO., LTD.","Kwang Hyun  Lee | Ju Woan  Yoo | Hee Jun  Lee | Dae Kyu  Shin | Ji Yoon  Park","10-2017-0038207","KR","2017-03-27","G06K-0009/00604","G06K-0009/00604 | A61B-0005/1176 | G06F-0021/32 | G06K-0009/00597 | G06K-0009/00617 | G06K-0009/00892 | G06K-0009/2018 | G06K-0009/2027","G06K-009/00","G06K-009/00 | A61B-005/1171 | G06F-021/32 | G06K-009/20","","","","","","4920050005162"
"US","US","P","B2","Sensor device with resistive memory for signal compression and reconstruction","A sensor device comprising a computational memory and electronic circuitry. The sensor device is configured to receive an input signal, to compress the input signal into a compressed signal and to compute a reconstructed signal from the compressed signal. The electronic circuitry is configured to perform a reconstruction algorithm to compute the reconstructed signal. The computational memory is configured to compute the compressed signal and partial results of the reconstruction algorithm. A related method and a related design structure may be provided.","1. A sensor device comprising a computational memory, the computational memory comprising at least two programmable resistance states; andelectronic circuitry;the sensor device being configured to receive an input signal;compress the input signal into a compressed signal; andcompute a reconstructed signal from the compressed signal;wherein the electronic circuitry is configured to perform a reconstruction algorithm to compute the reconstructed signal; andthe computational memory is configured to compute the compressed signal and partial results of the reconstruction algorithm.","20","16/430720","2019-06-04","2019-0287613","2019-09-19","10861538","2020-12-08","INTERNATIONAL BUSINESS MACHINES CORPORATION","Manuel  Le Gallo-Bourdeau | Abu  Sebastian | Giovanni  Cherubini","","","","G11C-0013/0004","G11C-0013/0004 | G06F-0017/10 | G06F-0017/16 | G11C-0007/1006 | G11C-0013/0002 | G11C-0013/004 | G11C-0013/0064 | G11C-0013/0069 | H03M-0007/30 | H03M-0007/3062 | H04N-0005/335 | H04N-0005/378 | A61B-0005/0033 | A61B-0005/7203 | A61B-0005/726 | A61B-2560/0475 | G06K-0009/40 | G06T-0009/00 | G11C-2213/15 | G11C-2213/77 | G11C-2213/79 | H03M-0001/12","H04N-003/14","H04N-003/14 | G11C-013/00 | G06F-017/16 | H04N-005/378 | G11C-007/10 | H04N-005/335 | H03M-007/30 | G06F-017/10 | G06T-009/00 | G06K-009/40 | H03M-001/12 | A61B-005/00","","","","","","4920050005847"
"US","US","P","B2","Privacy-protecting system and method for wireless medical devices","Systems and methods are provided for protecting the privacy of wireless enabled medical device (WEMD) communications, particularly against traffic-analysis attacks. In an exemplary method, a WEMD measures a physiological parameter and conveys that physiological parameter to a WEMD-receiver using messages that simulate at least one message from a cover device, for example by embedding physiological data in a message from a simulated cover device. In some embodiments, the WEMD sends messages that simulate traffic patterns of the cover device. The cover device may be a device not associated with serious medical conditions, such as a fitness-oriented heart rate monitor. In some embodiments, the simulation is discontinued under emergency conditions or in particular regions that are deemed to be safe.","1. A method comprising, at a first wireless communication device: detecting at least one device type of at least one second wireless communication device in a neighborhood of the first wireless communication device;selecting a cover device type based at least in part on the detected device type;communicating, to a third wireless communication device, information indicating the selected cover device type; andwirelessly receiving data from the third wireless communication device, the received data being encapsulated in a message having a message type associated with the selected cover device type.","14","16/258278","2019-01-25","2019-0158472","2019-05-23","10862875","2020-12-08","PCMS HOLDINGS, INC.","Ari  Juels","","","","H04L-0063/0492","H04L-0063/0492 | A61B-0005/0031 | A61N-0001/37254 | G06F-0019/3418 | G16H-0010/65 | G16H-0040/63 | H04L-0012/00 | H04L-0012/6418 | H04W-0012/003 | H04W-0012/02 | H04W-0012/00503 | H04W-0012/08 | H04W-0012/10 | H04W-0084/18","H04M-001/66","H04M-001/66 | H04L-029/06 | A61B-005/00 | H04L-012/00 | H04L-012/64 | H04W-012/02 | A61N-001/372 | G16H-040/63 | G06F-019/00 | H04W-012/00 | G16H-010/65 | H04W-084/18 | H04W-012/08 | H04W-012/10","","","","","","4920050007169"
"US","US","P","B2","Automatic cardiac therapy advisor with hidden markov model processing","Apparatus for automatically determining which type of resuscitation treatment is most appropriate for a patient. The apparatus comprising at least one processor, circuitry for delivering time-domain signal measurements to the processor(s), which transforms the time-domain signal measurements into frequency domain data representative of a frequency content of the time-domain signal measurements, processes the frequency domain data to form a plurality of spectral bands, a content of each of the plurality of spectral bands representing the frequency content of the time-domain signal measurements within a different frequency band, form a weighted sum of the content of the plurality of spectral bands, with different weighting coefficients applied to the plurality of spectral bands, wherein magnitudes of the weighting coefficients are non-linearly proportional to frequencies of the plurality of spectral bands to which the weighting coefficients are applied, and determines the type of resuscitation treatment based on the weighted sum.","1. An apparatus for automatically determining which type of resuscitation treatment is most appropriate for a patient, the apparatus comprising: one or more processors;circuitry for delivering time-domain signal measurements from the patient to the one or more processors, wherein the one or more processors configured to: transform one or more of the time-domain signal measurements into frequency domain data representative of a frequency content of the time-domain signal measurements,process the frequency domain data to form a plurality of spectral bands, a content of each of the plurality of spectral bands representing the frequency content of the time- domain signal measurements within a different frequency band,form a weighted sum of the content of the plurality of spectral bands, with different weighting coefficients applied to at least some of the plurality of spectral bands, wherein the weighting coefficients are chosen such that the magnitudes of the weighting coefficients are non-linearly proportional to frequencies of the at least some of the plurality of spectral bands to which the weighting coefficients are applied,determine a recommended resuscitation treatment based on the weighted sum, andprovide an output indication of the recommended resuscitation treatment.","20","15/817521","2017-11-20","2018-0070885","2018-03-15","10849564","2020-12-01","ZOLL MEDICAL CORPORATION","Gary A  Freeman | James E  Brewer","","","","A61B-0005/7264","A61B-0005/7264 | A61B-0005/0464 | A61B-0005/726 | A61B-0005/7207 | A61B-0005/7257 | A61H-0031/005 | A61N-0001/3925 | G09B-0023/288 | G16H-0050/20 | A61H-2201/5015 | A61H-2230/04 | Y10S-0128/92 | Y10S-0128/923 | Y10S-0128/924 | Y10S-0706/924","A61B-005/00","A61B-005/00 | A61B-005/0464 | A61N-001/39 | G09B-023/28 | G16H-050/20 | A61H-031/00","","","","","","4920049001108"
"US","US","P","B2","Determining eye openness with an eye tracking device","A method for determining eye openness with an eye tracking device is disclosed. The method may include determining, for pixels of an image sensor of an eye tracking device, during a first time period when an eye of a user is open, a first sum of intensity of the pixels. The method may also include determining, during a second time period when the eye of the user is closed, a second sum of intensity of the pixels. The method may further include determining, during a third time period, a third sum of intensity of the pixels. The method may additionally include determining that upon the third sum exceeding a fourth sum of the first sum plus a threshold amount, that the eye of the user is closed, the threshold amount is equal to a product of a threshold fraction and a difference between the first sum and the second sum.","1. A method for determining eye openness with an eye tracking device, wherein the method comprises: receiving, at one or more processors, an image of an eye of a user from an image sensor of an eye tracking device;determining, with the one or more processors, based on the image of the eye, a radius of the pupil;determining, with the one or more processors, based on the radius of the pupil, a total area of the pupil;determining, with the one or more processors, based on the image of the eye and the radius of the pupil, an amount of the total area of the pupil which is not obscured by either eyelid; anddetermining, with the one or more processors, based on the amount of the total area of the pupil which is not obscured by the eyelid and the total area of the pupil, whether the eye of the user is closed.","13","16/449828","2019-06-24","2020-0026068","2020-01-23","10852531","2020-12-01","TOBII AB","Mark  Ryan | Torbjorn  Sundberg | Pravin  Rana | Yimu  Wang","","","","G02B-0026/0875","G02B-0026/0875 | A61B-0003/112 | A61B-0003/113 | A61B-0005/1079 | A61B-0005/1103 | A61B-0005/163 | A61B-0005/6803 | G02B-0027/0093 | G06F-0003/013 | G06K-0009/00597 | G06K-0009/00604 | G06T-0007/70 | G06T-0007/73 | G06T-2207/30201","G02B-026/08","G02B-026/08 | G06F-003/01 | G06K-009/00 | G02B-027/00 | G06T-007/73 | A61B-005/16 | A61B-003/11 | A61B-003/113 | A61B-005/107 | A61B-005/11 | A61B-005/00 | G06T-007/70","","","","","","4920049004049"
"US","US","P","B2","Optical fingerprint authentication device","An optical fingerprint authentication device includes at least a light source and an image sensor and detects diffused light. The light source is an organic electroluminescence panel. The organic electroluminescence panel comprises a light emitting portion region and a light-transmitting non-light emitting portion, the light emitting portion region being shaped by an organic electroluminescence element. A fingerprint information reader having the image sensor arranged at a position adjacent to the non-light emitting portion is provided.","1. An optical fingerprint authentication device which comprises at least a light source and an image sensor that detects diffused light from a finger surface side of the optical fingerprint authentication device and optically reads an entire fingerprint information of a specimen that is used to perform fingerprint authentication, wherein the light source is an organic electroluminescence panel,wherein the organic electroluminescence panel comprises a light emitting portion region and a light-transmitting non-light emitting portion, the light emitting portion region being shaped by an organic electroluminescence element, andwherein a fingerprint information reader having the image sensor arranged at a position adjacent to the non-light emitting portion is provided and an entire surface of the image sensor facing the finger surface side receives the diffused light.","13","16/060532","2016-09-01","2018-0357402","2018-12-13","10853465","2020-12-01","MERCK PERFORMANCE MATERIALS GERMANY GMBH | MERCK PATENT GMBH","Kazuyoshi  Omata | Tsukasa  Yagi | Natsuki  Yamamoto | Hirofumi  Ohtani","2015-239048","JP","2015-12-08","G06F-0021/32","G06F-0021/32 | A61B-0005/1172 | G06K-0009/0004 | G06K-0009/00087 | G06T-0001/00 | H01L-0027/3225 | H01L-0051/50 | H01L-0051/5012 | H01L-0051/5203 | H01L-0051/5246 | H05B-0033/28","G06F-021/32","G06F-021/32 | A61B-005/1172 | G06T-001/00 | G06K-009/00 | H05B-033/28 | H01L-051/50 | H01L-027/32 | H01L-051/52","","","","","","4920049004976"
"US","US","P","B2","Optical detection of an image on a container","A container is mounted with respect to a fluid processing device using first and second supports, with the first support engaging a first portion of the container and the second support engaging a second portion of the container. The second support is positioned above or below the first support. The first and second supports cooperate to restrain the container in a fixed orientation, such as aligning an image on the container with an optical detector of a fluid processing device. The first and second supports may be components of a fixture that is separate from a surface of the fluid processing device or may themselves be incorporated into and extend from the surface of the fluid processing device.","1. A fixture for mounting a container, comprising: a frame;a first support extending from a first portion of the frame and configured to engage a first portion of a container; anda second support extending from a second portion of the frame positioned above or below the first portion of the frame, the second support being configured to engage a second portion of the container, wherein the first and second supports are configured to cooperate to restrain the container in a fixed orientation.","21","16/401132","2019-05-02","2019-0340403","2019-11-07","10853612","2020-12-01","FENWAL, INC.","Carlos  Calderon","","","","G06K-0007/1434","G06K-0007/1434 | A61J-0001/10 | A61M-0001/0209 | A61M-0039/18 | A61M-2205/10","G06F-017/00","G06F-017/00 | G06K-007/14 | A61J-001/10 | A61M-001/02 | A61M-039/18","","","","","","4920049005123"
"US","US","P","B2","Manipulation of a respiratory model via adjustment of parameters associated with model images","A method and apparatus for manipulation of a respiratory model via adjustment of parameters associated with model images is described. A subset of the images that are used with the model that is associated with the position and motion of a targeted region of the patient to receive radiation treatment may be identified. The subset of images may be sorted. A graphical user interface (GUI) that identifies two or more of the images of the sorted subset may be provided. A selection associated with one of the images of the sorted subset may be received by the GUI. Furthermore, a new model to identify the targeted region based on the selection that is associated with one of the two or more images may be generated.","1. A method comprising: receiving imaging data comprising a plurality of images associated with a patient;identifying a subset of the plurality of images that are used with a previously generated model associated with a position and motion of a targeted region of the patient to receive radiation treatment;sorting the subset of the plurality of images;providing, by a processing device, a graphical user interface (GUI) that identifies two or more images of the sorted subset of the plurality of images;receiving, by the GUI, a selection associated with one of the two or more images of the sorted subset of the plurality images;generating, by the processing device, a new model to be associated with the position and motion of the targeted region based on the selection that is associated with one of the two or more images, wherein the new model is a relationship between a series of internal features and external marker positions; anddelivering radiation to the targeted region based on the new model.","19","15/971694","2018-05-04","2018-0253846","2018-09-06","10853940","2020-12-01","ACCURAY INCORPORATED","Kolos  Lugosi | Matthew  Core | Robert  Kahn","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0006/032 | A61B-0006/4085 | A61B-0006/463 | A61B-0006/465 | A61B-0006/5235 | A61B-0006/5264 | A61B-0006/5288 | A61B-0006/5294 | A61N-0005/1037 | A61N-0005/1067 | G06F-0003/04842 | G06T-0007/11 | G06T-0007/246 | G06T-0007/251 | G06T-0007/38 | G06T-0011/60 | G06T-0017/00 | G06T-0017/10 | G06T-0019/20 | A61B-0005/0816 | A61B-0005/113 | A61B-0005/1127 | A61B-0006/022 | A61B-0006/12 | A61B-0006/4014 | A61B-0006/4266 | A61B-0006/4464 | A61B-0006/5223 | A61B-2034/2055 | A61B-2090/364 | A61B-2090/3945 | A61B-2090/3966 | A61N-0005/1083 | A61N-2005/1051 | A61N-2005/1061 | A61N-2005/1062 | G06T-2200/08 | G06T-2207/10116 | G06T-2207/30241","G06T-007/00","G06T-007/00 | G06F-003/0484 | G06T-017/10 | G06T-011/60 | A61B-006/03 | A61B-006/00 | A61N-005/10 | G06T-007/246 | G06T-017/00 | G06T-019/20 | G06T-007/38 | G06T-007/11 | A61B-006/02 | A61B-006/12 | A61B-005/08 | A61B-005/11 | A61B-005/113 | A61B-090/00 | A61B-034/20","","","","","","4920049005450"
"US","US","P","B1","Methods and systems for customizing informed advisor pairings","A system for customizing informed advisor pairings, the system including a computing device. The computing device is configured to identify a user feature wherein the user feature contains a user biological extraction. The computing device is configured to generate using element training data and using a first machine-learning algorithm a first machine-learning model that outputs advisor elements. The computing device receives an informed advisor element relating to an informed advisor. The computing device determines using output advisor elements whether an informed advisor is compatible for a user.","1. A system for customizing informed advisor pairings, the system comprising a computing device, the computing device further configured to: generate a first machine-learning model, wherein the first machine-learning model comprises a trained machine-learning model trained by physiological training data including a plurality of pairs of physiological data sets and user features and wherein the first machine-learning model is configured to receive a physiological data set associated with a user as an input and output a user feature associated with the user including an internal physical measurement of the user as a function of correlating the plurality of pairs of physiological data sets and user features of the physiological training data;generate a second machine-learning model, wherein the second machine-learning model comprises a trained machine-learning model trained by element training data including a plurality of user features and a plurality of correlated advisor elements and wherein the first machine-learning model is configured to receive the user feature associated with the user as an input and output a plurality of advisor elements as a function of the correlations between the plurality of user features and a plurality of correlated advisor elements;receive at least an informed advisor element relating to an informed advisor; anddisplay, on a graphical user interface, a compatibility of the informed advisor with the user based upon a comparison of the plurality of advisor elements to the at least an informed advisor element to determine.","18","16/727088","2019-12-26","","","10854336","2020-12-01","KPN INNOVATIONS, LLC","Kenneth  Neumann","","","","G16H-0050/20","G16H-0050/20 | G06F-0003/0482 | G06N-0020/00 | A61B-0005/14535 | A61B-0005/14546","G16H-050/20","G16H-050/20 | G06N-020/00 | G06F-003/0482 | A61B-005/145","","","","","","4920049005843"
"US","US","P","B2","Digital healthcare practice system for digital citizens","A web server based digital healthcare practice system to provide digital transformation of physician practice to twenty first century. Physician can provide in home remote patient examination using a smart pocketable integrated multi function device to perform all head to toe examination similar to his office. And can perform computer assisted cardio and pulmonary, abdominal sound diagnosis, ear, nose, throat analysis, and skin analysis from remote to pin point accurate ailment and write prescription to pharmacy, and bill insurance companies. Invention allows patients seek health care 24/7 in state, out of state, out of country and use in state insurance company to pay for the services. A virtual reality model of physician is available for normal everyday ailments. The smart pocketable integrated device used is remotely controlled by the physician and has smarts build to make it very user friendly and is wirelessly connected to an application running on a smartphone/tablet/laptop which is connected to physician server.","1. A Web Server based digital health care practice system which allows a patient to be seen remotely by a physician or a virtual physician, the system comprising: a smart compact pocketable integrated wireless digital device comprising; a digital camera for examining eyes, ear and throat,a digital thermometer,a digital MEMS barometric sensor configured to measure the patient'ss height, and motion of the smart compact pocketable integrated wireless digital device such that an optimum position of the smart compact pocketable integrated wireless digital device on the patient is determined,eight dual plate digital MEMS microphones for body sound listening, wherein the microphones are arranged in two concentric circle with four of the eight MEMS microphones in each circle, wherein the four MEMS microphones on each circle are spaced ninety degrees apart from a center of each circle, where each dual plate digital MEMS microphone is configured to be remotely turned on and off,a digital processor configured to recognize and process keyword voice command,a separate digital signal processor for filtering heart sound during lung sound auscultation, anda microcomputer with embedded firmware that controls collection of data from the smart compact pocketable integrated wireless digital device;at least one physician server comprising a multi core single server or separate servers, the at least one physician server is configured to handle secure communications with a patient application and a physician application and includes at least one of crypto technology, authentication using digital face and age, digital voice and finger print recognition, and password with one time password matching, the at least one physician server is configured to maintain calendars for patient'ss remote and in office visits, a home location register and visitor location register of the patient, the at least one physician server is configured to perform voice and video conferencing, virtual reality, virtual reality based examination scripts, voice and video text, email messaging and text alerts, and the at least one physician server is further configured to connect and communicate with home and visiting patient'ss billing application, pharmacy application, insurance billing, global patient'ss bill reconciliation, and data analytic tools, the at least one physician server further includes a medical assistant server which includes analytical tools using mathematical analysis to assist with diagnosis, picture and sound records during examination, the medical assistant server is configured to provide an independent diagnosis of the patient, a prescription assistant configured to suggest possible medicine for the patient and a symptom assistant that is configured to run a virtual reality examination;a data base system to store, retrieve, and archive data associated with the web server based digital health care practice system;the physician application is configured to run on a smartphone, a tablet, a laptop, or a desktop and allows the physician to give an examination in the physician'ss office or a remote location by connecting with the at least one physician server, the data base system and the compact pocketable integrated wireless digital device, the physician application is configured to control the smart compact pocketable integrated wireless digital device; andthe patient application is configured to run on a smartphone, a tablet, a laptop, or a desktop and allows the patient to connect with the at least one physician server, the data base system and the compact pocketable integrated wireless digital device, the patient application is configured to control the smart compact pocketable integrated wireless digital device based on commands received from the physician application.","1","15/880530","2018-01-26","2018-0160907","2018-06-14","10842378","2020-11-24","Shiv Prakash Verma","Shiv Prakash  Verma","","","","A61B-0005/0022","A61B-0005/0022 | A61B-0001/00016 | A61B-0001/00034 | A61B-0001/00096 | A61B-0001/00188 | A61B-0001/04 | A61B-0001/0684 | A61B-0001/227 | A61B-0001/233 | A61B-0001/24 | A61B-0005/0205 | A61B-0005/02055 | A61B-0005/6898 | A61B-0005/725 | A61B-0005/7232 | A61B-0005/7465 | A61B-0007/00 | A61B-0007/008 | A61B-0007/02 | A61B-0007/026 | A61B-0007/04 | G06Q-0010/101 | G06Q-0030/04 | G06Q-0050/22 | G16H-0040/67 | G16H-0050/20 | G16H-0080/00 | A61B-0005/0008 | A61B-0005/01 | A61B-0005/0402 | A61B-0005/04012 | A61B-0005/12 | A61B-0005/145 | A61B-0005/441 | A61B-0005/4552 | A61B-0005/486 | A61B-0005/7435 | A61B-0007/003 | A61B-2503/04 | A61B-2560/0209 | A61B-2560/0257 | A61B-2560/0431 | A61B-2562/0204 | A61B-2562/046 | Y02A-0090/22 | Y02A-0090/26","A61B-005/00","A61B-005/00 | G16H-080/00 | G16H-040/67 | A61B-001/00 | A61B-001/04 | A61B-001/227 | A61B-001/233 | A61B-001/24 | A61B-005/01 | A61B-007/00 | A61B-007/02 | A61B-007/04 | A61B-005/0402 | A61B-005/04 | A61B-005/0205 | A61B-005/12 | G06Q-030/04 | G06Q-010/10 | G06Q-050/22 | A61B-001/06 | G16H-050/20 | A61B-005/145","","","","","","4920048001061"
"US","US","P","B2","Camera-guided interpretation of neuromuscular signals","Computerized systems, methods, and computer-readable storage media storing code for implementing the methods are provided for training an inference model used to generate a musculoskeletal representation. One such system includes a processor programmed to: determine, based on information obtained from at least one image, position information describing a spatial relationship between two or more connected musculoskeletal segments of a user; determine, based on a plurality of neuromuscular signals, force information; associate the position information with the force information; train an inference model to output a musculoskeletal representation consistent with the position information and/or the force information when neuromuscular input signals provided to the inference model have at least one predetermined characteristic, to produce an updated inference model; and cause the updated inference model to be stored in a memory.","1. A computerized system for training one or more inference models used to generate a musculoskeletal representation, the system comprising: one or more neuromuscular sensors configured to obtain one or more neuromuscular signals from a user, wherein the one or more neuromuscular sensors are arranged on one or more wearable devices;at least one camera configured to capture one or more images while the one or more neuromuscular signals are obtained; andat least one computer processor programmed to: determine image-based position information describing a spatial relationship between two or more connected musculoskeletal segments of the user based on the one or more images;determine neuromuscular-based position and/or force information for the two or more connected musculoskeletal segments of the user based on the neuromuscular signals;associate the image-based position information with the neuromuscular-based position and/or force information for the two or more connected musculoskeletal segments of the user; andtrain the one or more inference models to output the musculoskeletal representation based on the image-based position information and the neuromuscular-based position and/or force information when one or more additional neuromuscular signals obtained from the user have at least one predetermined characteristic.","30","16/557427","2019-08-30","2020-0069211","2020-03-05","10842407","2020-11-24","FACEBOOK TECHNOLOGIES, INC.","Adam  Berenzweig | Thomas  Reardon | Christopher  Osborn | Patrick  Kaifosh | Brett  Jurman | Daniel  Wetmore","","","","A61B-0005/0488","A61B-0005/0488 | A61B-0005/04001 | A61B-0005/04004 | A61B-0005/04012 | A61B-0005/6824 | A61B-0090/361 | G06F-0003/011 | G06F-0003/015 | G06K-0009/00355 | G06K-0009/6215 | G06N-0005/04 | G06N-0020/00 | G06T-0007/70 | A61B-0005/1107 | A61B-0005/681 | A61B-0005/7267 | A61B-2562/0219 | G06F-0003/016 | G06F-0003/017 | G06T-0019/006 | G06T-2207/20081 | G06T-2207/30196","A61B-005/0488","A61B-005/0488 | G06F-003/01 | A61B-005/00 | A61B-090/00 | A61B-005/04 | G06T-007/70 | G06N-020/00 | G06K-009/00 | G06K-009/62 | G06N-005/04 | G06T-019/00 | A61B-005/11","","","","","","4920048001089"
"US","US","P","B2","Device power saving during exercise","A method includes: supporting a normal operation mode, during which functionalities of a portable apparatus are available through an operating system of the apparatus, wherein the operating system includes a plurality of layers including a kernel and library functions layer; supporting a limited operation mode during which the apparatus is configured to execute a physical activity algorithm based on physical activity data corresponding to a physical activity session performed by a user of the apparatus, wherein the physical activity algorithm applies a direct low-level hardware access bypassing at least the layers above the kernel and the library functions-layer; and switching between the normal operation mode and the limited operation mode.","1. A smartwatch comprising: a motion sensor configured to measure a motion;a positioning unit configured to obtain location data;an optical heart activity sensor configured to optically measure a heart activity;a display configured to act as a user interface;a touch controller configured to make the display touch sensitive;a high power processing unit configured to, during a normal operation mode, run an operating system, control functionality of the display and the touch controller, and measure physical activity using data obtained from the motion sensor, data obtained from the positioning unit and data obtained from the optical heart activity sensor; anda low power processing unit configured to, during a watch operation mode, control functionality of the display, run a watch configured to keep track of the time, run a physical activity algorithm, and measure physical activity using data obtained from the motion sensor, andduring a limited operation mode, control functionality of the display, measure physical activity using data obtained from the motion sensor, data obtained from the positioning unit and the data obtained from the optical heart activity sensor,wherein the low power processing unit has a lower power consumption in performing a given task than the high power processing unit.","20","16/715030","2019-12-16","2020-0179761","2020-06-11","10843042","2020-11-24","POLAR ELECTRO OY","David  Munoz | Mikko  Tuunanen | Matti  Korpela | Markku  Karjalainen | Jarmo  Torvinen","","","","A63B-0024/0087","A63B-0024/0087 | A61B-0005/0205 | A61B-0005/1118 | A61B-0005/4806 | A61B-0005/681 | A61B-0005/7465 | G06F-0001/163 | G06F-0001/324 | G06F-0001/3212 | G06F-0001/3228 | G06F-0001/3265 | G06F-0001/3287 | G06F-0001/3293 | A61B-0005/01 | A61B-0005/1112 | A63B-0022/02 | A63B-0022/0605 | A63B-0071/0622 | A63B-2071/0625 | A63B-2071/0655 | A63B-2220/12 | A63B-2220/17 | A63B-2220/20 | A63B-2220/30 | A63B-2220/40 | A63B-2220/51 | A63B-2220/72 | A63B-2220/75 | A63B-2220/803 | A63B-2220/805 | A63B-2220/808 | A63B-2220/833 | A63B-2220/836 | A63B-2220/89 | A63B-2225/20 | A63B-2225/50 | A63B-2230/01 | A63B-2230/06 | A63B-2230/50 | A63B-2230/75 | G06F-0009/4411 | G06F-0009/4418 | Y02D-0010/00","G06F-001/32","G06F-001/32 | G06F-001/324 | G06F-009/44 | A63B-024/00 | G06F-001/3228 | A61B-005/00 | A61B-005/0205 | A61B-005/11 | G06F-001/3234 | G06F-001/3287 | G06F-001/3212 | G06F-001/16 | G06F-001/3293 | G06F-003/06 | G06F-009/4401 | A61B-005/01 | A63B-071/06 | A63B-022/02 | A63B-022/06","","","","","","4920048001722"
"US","US","P","B2","Breathing apparatus and method for user interaction therewith","A breathing apparatus has one or more electronic processors and a touch screen communicatively coupled to at least one of the processors. The processor is configured to provide a user interface on the touch screen for modification of at least one operational parameter of the breathing apparatus. The user interface includes at least two touch sensitive display areas on the display area of the touch screen for modification of the operational parameter by an operator of the breathing apparatus. Each of the two touch sensitive display areas is dedicated for different types of user interaction, i.e. different user interaction modes are provided for by each of the two different display areas.","1. A breathing apparatus comprising: a respiratory ventilator or an anesthesia machine that provides a breathing gas to a subject; andat least one processor and a touch screen communicatively coupled to said processor;said processor configured to provide a user interface on said touch screen that enables modification of at least one operational parameter of said breathing apparatus, wherein said at least one operational parameter is selected from the group consisting of oxygen content in the breathing gas, positive end expiratory pressure, inspiratory pressure, tidal volume, respiratory rate, pressure trigger sensitivity and flow trigger sensitivity;said user interface comprising a display including at least two simultaneously displayed touch sensitive display areas for user modification of said operational parameter, wherein each of the at least two touch sensitive display areas are configured to be responsive to different types of touch-based user interaction modes in order to provide modification of the same operational parameter, thereby producing a modified operation and parameter, and wherein modification of said same operational parameter is effected by touching any of said at least two touch-sensitive display areas;wherein a first interaction mode, of said different types of touch-based user interaction modes, is a touch based stepwise modification mode, and a first display area of said interface comprises first input elements for stepwise modification of said operational parameter upon user touch within said first display area;wherein a second interaction mode, of said different types of touch-based user interaction modes, is a coarse modification mode, and a second display area of said interface comprises second input elements for selecting a particular value, from a displayed range of values for said at least one operational parameter, upon user touch within said second display area, thereby modifying said at least one operational parameter more coarsely but more quickly than upon said user touch within said first display area, wherein the second input elements comprise a slider bar for the displayed range of said operational parameter, wherein the slider bar includes visual indications of a current value of said operational parameter before modification and at least one ofan operation range between a lower limit and an upper limit of said operational parameter; anda threshold value on the slider bar for indication of a clinically unusual value, wherein when the threshold value is passed upon user input, on the slider bar a sub-range adjacent the clinically unusual value in a different color or shade than other parts of the operational range is displayed; andsaid processor configured to display a variable scale in said user interface for said at least one operational parameter of the second interaction mode of said breathing apparatus, said variable scale having a total scale range, and said processor configured to adapt said variable scale to the operational range of said at least one operational parameter by hiding or deactivating at least one of an upper portion of said total scale range and a lower portion of said total scale range.","17","14/405027","2012-06-03","2015-0160845","2015-06-11","10845973","2020-11-24","MAQUET CRITICAL CARE","Madlene  Lahtivuori | Anette  Sunna | Helena  Stone","","","","G06F-0003/04847","G06F-0003/04847 | G06F-0003/0488 | G06F-0003/04842 | G16H-0020/40 | G16H-0040/63 | A61B-0005/08 | A61M-0016/0051 | G06F-0003/04883 | G06F-0003/04886","H04N-005/445","H04N-005/445 | A61N-001/362 | G06F-003/048 | G06F-003/0484 | G16H-040/63 | G16H-020/40 | G06F-003/0488 | A61M-016/00 | A61B-005/08","","","","","","4920048004634"
"US","US","P","B2","Personalized communications to improve user engagement","The systems and methods of the invention provide a network querying or content system which drives high relevance question sets or content to users and presents it in the optimal template to ensure user interaction. In accord with at least one aspect, the system assesses the context (of a user) by interpreting the optimal template based on personality mapping of the user and relevancy mapping of the query or content. In a technically efficient manner, the system employs client-based managers and builders to select, supplement, or build user profiles and user interface templates to optimize queries or content based on a user's present profile. The systems and methods of the invention perform processing, in a technically efficient manner, to assess question or content set interaction and relevancy to generate targeted question sets or content that encourage overall user health and wellness.","1. A method for determining a message to send to a recipient device, the method comprising: analyzing, by a server system, a message stored in a system database to determine at least one attribute corresponding to the message;analyzing, by the server system, a plurality of user profiles stored in a profile database of the server system to determine a plurality of user profile attributes;selecting, by the server system, a user profile for the recipient device from among the plurality of user profiles based on the at least one attribute corresponding to the message and the plurality of user profile attributes, wherein the selected user profile has the at least one attribute and is associated with the recipient device;receiving, by the server system, a communication from the recipient device, wherein the communication includes information from a recipient device user profile maintained by the recipient device for a user of the recipient device;updating, by the server system, the selected user profile for the recipient device by merging the received information from the recipient device user profile maintained by the recipient device with the selected user profile in the profile database of the server system;determining, by the server system, that the updated user profile is associated with the at least one attribute that corresponds to the message; andtransmitting, by the server system, the message to the recipient device.","23","16/269842","2019-02-07","2019-0306093","2019-10-03","10846484","2020-11-24","VIGNET, INC.","Josh  Schilling | Praduman  Jain | Dave  Klein","","","","G06F-0040/35","G06F-0040/35 | G06F-0011/3438 | G06F-0016/245 | G06F-0016/2455 | G09B-0007/06 | H04L-0051/06 | H04L-0067/306 | A61B-0005/165 | G06N-0020/00","G06F-017/00","G06F-017/00 | G06F-040/35 | G06F-011/34 | G09B-007/06 | G06F-016/245 | G06F-016/2455 | H04L-012/58 | H04L-029/08 | A61B-005/16 | G06N-020/00","","","","","","4920048005143"
"US","US","P","B2","Simulated sandtray system","The simulated sandtray system consists of camera device, controller, digital processor, display device, physical sandtray mark, and physical sand cabinet mark. Camera devices are linked with digital processor and display device. Physical sandtray mark is connected to cameral devices for the purpose of delivering optical information. Physical sand cabinet mark is linked to camera devices for the purpose of delivering optical information. The advantages and features of this invention are as follows: a number of initiators, online connection and simultaneous inter-regional operation of 3D virtual sandtray.","1. A simulated sandtray system comprising: camera devices, wherein the camera devices are configured to capture real scenses;a controller, wherein the controller comprises a motion capture lever and other handheld devices for mapping user'ss behaviors through sensor;a digital processor, wherein the digital processor is linked to the camera devices and the controller, and the digital processor receive, analyzed and digitally processed real scene data captured by the camera device;a display device, wherein the camera devices and the controller are connected to the digital processer and the display device, the display device is configured to display the real scene data;physical sandtray mark, wherein the physical sandtray mark is configured to for virtual sandtray mapping when real sandtray cannot be placed in real environment for a variety reasons, and the physical sandtray mark is connected with the camera devices for delivering optical information;cabinet mark, wherein the cabinet mark is configured for virtual sand cabinet mapping when the real environment cannot accommodate a real cabinet for a variety of reasons, and the cabinet mark is connected with camera devices for delivering optical information; andwherein simulated sandtray system further comprises an external device, when certain requirements are satisfied, the external device emit harmless gas to simulate real smell environment.","11","15/951193","2018-04-12","2019-0180089","2019-06-13","10846520","2020-11-24","Zi-Nan Wang","Zi-Nan  Wang","2017-11316947","CN","2017-12-12","G06K-0009/00335","G06K-0009/00335 | A61B-0005/165 | G06F-0003/04815 | G06F-0003/04842 | G06K-0009/00671 | G09B-0009/00 | H04N-0005/225","G06K-009/00","G06K-009/00 | H04N-005/225 | G06F-003/0484 | A61B-005/16 | G06F-003/0481 | G09B-009/00","","","","","","4920048005179"
"US","US","P","B2","Method and system for outputting augmented reality information","A method and system are disclosed for outputting augmented reality information to a first user. In an embodiment, the method includes acquiring first information, including image information, depth information, coordinate information and combinations thereof, the first information relating to at least one of a medical device and a medical examination of a patient; creating the augmented reality information, relating to the medical device and/or the medical examination of the patient, based on the first information; and outputting the augmented reality information such that the augmented reality information is perceivable in a field of view of the first user.","1. A method for outputting augmented reality information to a user, the method comprising: acquiring a medical imaging dataset relating to an anatomical structure of a patient;acquiring first information, the first information including one or more of image information, depth information, and coordinate information;creating the augmented reality information by evaluating, via a machine learning algorithm, the first information and the medical imaging dataset, the augmented reality information including a structure marking, including a 3-dimensional (3D) image marking the anatomical structure of the patient; andoutputting the augmented reality information in response to the user placing the anatomical structure of the patient in a field of view of the user, the augmented reality information being combined, in an anatomically correct manner, with the anatomical structure of the patient and being perceivable in the field of view of the user.","35","16/430744","2019-06-04","2019-0333213","2019-10-31","10846851","2020-11-24","SIEMENS HEALTHCARE GMBH","Thomas  Boettger | Christophe  Della Monta | Thilo  Hannemann | Philipp  Hoelzer | Gerhard  Kraemer | Stefan  Reichelt | Grzegorz  Soza","10-2015-226669","DE","2015-12-23","G06T-0007/0012","G06T-0007/0012 | A61B-0005/0013 | A61B-0005/055 | A61B-0005/743 | A61B-0005/745 | A61B-0005/748 | A61B-0090/30 | G06F-0003/011 | G06F-0003/012 | G06F-0003/013 | G06F-0003/0304 | G06F-0003/0346 | G06F-0003/04815 | G06T-0007/50 | G06T-0007/70 | G06T-0019/006 | A61B-0005/744 | A61B-0006/032 | A61B-2090/365 | A61B-2576/00 | G06T-2207/30004 | G06T-2207/30204 | G06T-2210/41","G06T-007/00","G06T-007/00 | A61B-090/30 | A61B-005/00 | G06F-003/01 | G06F-003/03 | G06F-003/0481 | G06F-003/0346 | G06T-007/50 | G06T-007/70 | A61B-005/055 | G06T-019/00 | A61B-090/00 | A61B-006/03","","","","","","4920048005507"
"US","US","P","B2","Transmitting treatment information","A system includes a first computing device comprising a processor coupled to a memory. The processor and the memory are configured to receive at least one of (i) information indicative of treatment of a victim by a first caregiver using the first computing device and (ii) information indicative of a health status of the victim; determine that treatment of the victim by the first caregiver using the first computing device is completed; and transmit the received information to a second computing device.","1. A system for reviewing patient information as a result of medical treatment, comprising: a defibrillation device comprising one or more electrodes;storage for storing one or more treatment profiles comprising patient treatment data;a display interface configured to present the patient treatment data of the one or more treatment profiles, wherein the patient treatment data comprises one or more representations of electrocardiogram (ECG) signals associated with the one or more treatment profiles;one or more controls configured to control presentation of the patient treatment data by the display interface; andat least one processor coupled to a memory, the at least one processor and the memory configured to perform operations comprising: receiving, from the defibrillation device, the patient treatment data comprising a plurality of ECG signals,storing, in a particular treatment profile of the storage, the plurality of ECG signals,retrieving, from the storage, particular patient treatment data of the particular treatment profile of the one or more treatment profiles, the particular patient treatment data comprising at least one ECG signal of the plurality of ECG signals,in response to receiving a first signal from the one or more controls, causing the display interface to present at least a first portion of the at least one ECG signal, the first portion corresponding to a first period of time, andin response to receiving a second signal from the one or more controls, causing the display interface to present at least a second portion of the at least one ECG signal, the second portion corresponding to a second period of time that is different from the first period of time,wherein the one or more controls are configured to enable selection of the at least one ECG signal from the plurality of ECG signals.","30","16/190661","2018-11-14","2019-0143134","2019-05-16","10835121","2020-11-17","ZOLL MEDICAL CORPORATION","John  Amann | Gary A.  Freeman","","","","A61B-0005/0006","A61B-0005/0006 | A61B-0005/0404 | A61B-0005/04012 | A61N-0001/025 | A61N-0001/3904 | A61N-0001/3931 | A61N-0001/3937 | A61N-0001/39044 | A61N-0001/3968 | A61N-0001/3987 | A61N-0001/3993 | G06F-0019/00 | A61B-0005/053 | A61B-0005/4848 | G06Q-0050/22","A61N-001/39","A61N-001/39 | A61B-005/00 | A61B-005/04 | A61B-005/0404 | A61N-001/02 | G06F-019/00 | G06Q-050/22 | A61B-005/053","","","","","","4920047001008"
"US","US","P","B2","Wearable device having sensor-dependent behavior modification","A wearable device having sensor-dependent behavior modification, according to one embodiment, includes a housing configured for positioning on a human body. A plurality of sensors are positioned in and/or on the housing for detecting a condition of the wearable device and/or an environment of the wearable device. A processing circuit in the housing is coupled to the sensors for receiving sensor data therefrom. A computer readable storage medium is coupled to the processing circuit, the computer readable storage medium having program instructions stored therein, which when executed by the processing circuit cause the processing circuit to change a state of the wearable device based on the sensor data.","1. A wearable device having sensor-dependent behavior modification of the wearable device, comprising: a housing configured for positioning on a human body;a plurality of sensors in and/or on the housing for detecting a condition of the wearable device and/or an environment of the wearable device,wherein a first of the plurality of sensors is a thermal sensor;a processing circuit in the housing, the processing circuit being coupled to the sensors for receiving sensor data therefrom; anda computer readable storage medium coupled to the processing circuit, the computer readable storage medium having program instructions stored therein, which when executed by the processing circuit cause the processing circuit to: change a current state of the wearable device to a new state of the wearable device based on the sensor data;wherein changing the state of the wearable device includes increasing a rate of sensor data acquisition for enabling heart rate waveform sensing,wherein increasing a rate of sensor data acquisition includes increasing a sampling rate of at least some of the plurality of sensors and increasing a frequency of a cadence of at least some of the plurality of sensors.","14","16/457535","2019-06-28","2019-0339789","2019-11-07","10835136","2020-11-17","CAEDEN, INC.","Skip Thomas  Orvis | Nora Elam  Levinson | Jamal Eddine  Mouline | Colden Amsel  Prime | Conan  Zhang","","","","A61B-0005/02438","A61B-0005/02438 | A61B-0005/0004 | A61B-0005/0006 | A61B-0005/0022 | A61B-0005/0205 | A61B-0005/02405 | A61B-0005/087 | A61B-0005/0816 | A61B-0005/486 | A61B-0005/4866 | A61B-0005/6823 | A61B-0005/725 | A61B-0005/7264 | A61B-0005/7278 | A61B-0005/742 | A61B-0005/7405 | A61B-0005/746 | A61B-0005/7455 | G04G-0017/04 | G06F-0001/163 | G06F-0003/011 | G06F-0003/0304 | G06K-0009/00892 | A61B-0005/0245 | A61B-0005/02416 | A61B-0005/02433 | A61B-0005/6824 | A61B-2560/0247 | G06K-2009/00939","G06F-003/03","G06F-003/03 | A61B-005/024 | A61B-005/00 | A61B-005/0205 | A61B-005/08 | A61B-005/087 | G04G-017/04 | G06F-001/16 | G06F-003/01 | G06K-009/00 | A61B-005/0245","","","","","","4920047001023"
"US","US","P","B2","Autonomous brain-machine interface","A reinforcement learning brain-machine interface (RL-BMI) can have a policy that governs how detected signals, emanating from a motor cortex of a subject's brain, are translated into action. The policy can be improved by detecting a motor signal having a characteristic and emanating from the motor cortex. The system can provide, to a device and based on (i) the motor signal and (ii) an instruction policy, a command signal resulting in a first action by a device. Additionally, an evaluation signal, emanating from the motor cortex in response to the first action, can also be detected. With the foregoing information, the system can adjust the policy based on the evaluation signal such that a subsequent motor signal, from the subject's brain, having the characteristic results in a second action, by the device, different from the first action, as needed.","1. A method for improving reinforcement learning by machine, the method comprising: detecting a motor signal having a characteristic and emanating from a primary motor cortex of a subject'ss brain;providing, to a device and based on (i) the motor signal and (ii) an instruction policy, a command signal resulting in a first action by the device;detecting an evaluation signal emanating from the primary motor cortex in response to the first action; andadjusting the policy based on the evaluation signal such that a subsequent motor signal, emanating from the primary motor cortex and having the characteristic, results in a second action, by the device, different from the first action,wherein the detecting steps are performed by one or more electrode array and the providing and the adjusting are performed by one or more processor.","22","15/534956","2015-12-11","2019-0025917","2019-01-24","10835146","2020-11-17","THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK","Joseph T.  Francis | Venkata S. Aditya  Tarigoppula | Brandi T.  Marsh","","","","A61B-0005/0482","A61B-0005/0482 | A61B-0005/04001 | A61B-0005/0476 | A61F-0002/68 | G06F-0003/015 | A61F-2002/6827 | A61F-2002/704 | G06N-0003/049 | G06N-0003/0454 | G06N-0003/061","A61B-005/0482","A61B-005/0482 | A61B-005/0476 | G06F-003/01 | A61B-005/04 | A61F-002/68 | A61F-002/70 | G06N-003/04 | G06N-003/06","","","","","","4920047001033"
"US","US","P","B2","Orthopedic fixation control and manipulation","A fixation apparatus may be attached to first and second anatomical structure segments. Images of the fixation apparatus and the attached anatomical structure segments may then be captured. In some examples, the images need not necessarily be orthogonal with respect to one another. Configuration information associated with the fixation apparatus may then be received. Additionally, first image information may be received, for example including indications of one or more locations, within the images, of at least part of one or more elements of the fixation apparatus. Additionally, second image information may be received, for example including indications of one or more locations, within the images, of at least part of the first and the second anatomical structure segments. Manipulations to the fixation apparatus for correction of the anatomical structure deformity may then be determined, and indications of the determined manipulations may then be provided to one or more users.","1. A computer-implemented method for controlling manipulation of a fixation apparatus including rings and struts to correct an anatomical structure deformity of first and second anatomical structure segments comprising: receiving, using one or more graphical user interfaces of a computing system, configuration information associated with the fixation apparatus, the configuration information comprising one or more geometric characteristics of one or more elements of the fixation apparatus;displaying, using the one or more graphical user interfaces, images of the fixation apparatus and the first and the second anatomical structure segments attached thereto;receiving, using the one or more graphical user interfaces, first image information comprising indications of one or more locations, within the images, of at least part of the one or more elements of the fixation apparatus, wherein the one or more elements of the fixation apparatus comprise a hinge of the fixation apparatus, wherein the one or more locations comprise a location of the hinge, wherein an enlarged view of an area of one of the images is displayed, the enlarged view depicting the hinge of the fixation apparatus, and wherein the enlarged view allows a user to manipulate the location of the hinge;receiving, using the one or more graphical user interfaces, second image information comprising indications of one or more locations, within the images, of at least part of the first and the second anatomical structure segments;determining, by the computing system, based at least in part on the configuration information, the first image information, and the second image information, positions and orientations of the first and the second anatomical structure segments in three-dimensional space;determining, by the computing system, manipulations to the fixation apparatus for correction of the anatomical structure deformity, the manipulations comprising planned adjustment lengths by which to adjust the struts; andproviding, by the computing system, to one or more users, indications of the manipulations to the fixation apparatus.","30","15/247333","2016-08-25","2018-0055569","2018-03-01","10835318","2020-11-17","SYNTHES GMBH | DEPUY SYNTHES PRODUCTS, INC.","Michael  Wahl | Bernd  Gutmann | Kevin  Clancy | Dana  Heavey | Tina  Corey | Todd  Kent","","","","A61B-0034/10","A61B-0034/10 | A61B-0034/25 | G06F-0003/04847 | G06T-0007/70 | A61B-0017/62 | A61B-0017/66 | A61B-2034/104 | A61B-2034/105 | A61B-2034/107 | A61B-2034/252 | A61B-2034/254 | A61B-2090/367 | A61B-2090/3966 | G06T-2207/10004 | G06T-2207/30008","A61B-034/10","A61B-034/10 | A61B-017/60 | A61B-034/00 | G06T-007/70 | G06F-003/0484 | A61B-090/00 | A61B-017/66 | A61B-017/62","","","","","","4920047001205"
"US","US","P","B2","Augmented and virtual reality for traversing group messaging constructs","In non-limiting examples of the present disclosure, systems, methods and devices for interacting with one or more electronic messages in a virtual space are presented. One or more avatars corresponding to the senders of a plurality electronic messages may be displayed within a virtual space. A user may navigate within the virtual space and execute one or more actions associated with an electronic message and/or its sender from the virtual space. In some examples, each of a plurality of electronic messages may be spatially arranged in the virtual space according to a corresponding message thread. In additional examples, each of a plurality of electronic messages may be spatially arranged in the virtual space based on a time that each message was sent or received.","1. A method for interacting with one or more electronic messages, the method comprising: receiving a message query comprising one or more search terms;determining that a first electronic message thread is more relevant to the message query than a second electronic message thread;causing the first electronic message thread to be displayed on a display of a computing device, the first electronic message thread comprising a first plurality of electronic messages displayed in association with a first plurality of avatars, wherein each of the first plurality of avatars represents a sender of one of the first plurality of electronic messages;causing the second electronic message thread to be displayed on the display of the computing device, the second electronic message thread comprising a second plurality of electronic messages displayed in association with a second plurality of avatars, wherein each of the second plurality of avatars represents a sender of one of the second plurality of electronic messages, and wherein the avatars corresponding to the second electronic message thread are displayed further away from a virtual instance of a user of the computing device than the avatars corresponding to the first electronic message thread based on their relative relevance to the message query;receiving a first indication that the virtual instance of the user of the computing device has crossed a first virtual threshold distance to one of the avatars;causing, based on the received first indication, a first set of information associated with the one of the avatars to be displayed on the display of the computing device;receiving a second indication that the virtual instance of the user of the computing device has crossed a second virtual threshold distance to the one of the avatars;causing, based on the received second indication, a second set of information associated with the one of the avatars to be displayed on the display of the computing device;causing, in association with the one of the avatars, a selectable option to have a corresponding one of the first plurality of electronic messages presented in a virtual space by the computing device to be displayed on the display of the computing device;receiving an indication to present the corresponding electronic message in the virtual space; andcausing the corresponding electronic message to be presented by the computing device in the virtual space.","18","15/860343","2018-01-02","2019-0204994","2019-07-04","10838587","2020-11-17","Microsoft Technology Licensing, LLC","Sreevani  Tippana","","","","G06F-0003/0482","G06F-0003/0482 | G06F-0003/048 | G06F-0003/04842 | G06F-0003/167 | G06Q-0010/10 | H04L-0051/16 | H04L-0051/22 | H04L-0067/38 | A61B-0005/744 | G06F-0003/165 | G06T-0011/60 | G06T-2200/24 | H04L-0051/046","G06F-003/0482","G06F-003/0482 | H04L-012/58 | G06F-003/048 | G06F-003/0484 | G06Q-010/10 | H04L-029/06 | A61B-005/00 | G06F-003/16 | G06T-011/60","","","","","","4920047004449"
"US","US","P","B2","Methods, apparatuses, and systems for radio-frequency imaging sensors for advanced fingerprint biometrics and medical imaging","Methods, apparatuses, systems, and implementations of an ultra-compact RF (30 GHz-10 THz) imaging sensor topology that provides a new insight into the human skin are disclosed. The skin tissue is the largest organ in the body?both in weight and surface area?and stores valuable information that can revolutionize security biometrics and mobile health monitoring. The proposed compact sensor enables, for the first time, portable and wearable devices to perform superior biometric authentication compared to current fingerprint methods. Additionally, these devices could probe into the skin to monitor vital signs in real-time and enable mobile health monitoring.","1. A radio-frequency (RF) imaging apparatus comprising: a substrate;at least one RF source;at least one RF detector;at least one linear imaging array comprising: at least one transmission line; andone or more antennas; andone or more RF switches, each of the one or more RF switches being coupled to at least one of the one or more antennas and comprising: a plurality of electrically tunable impedance sheets;a metal layer; andat least one insulating layer disposed between the plurality of electrically tunable impedance sheets;where the at least one RF source, the at least one RF detector, and the at least one linear imaging array are monolithically integrated on the substrate, andwhere the RF imaging apparatus is configured to operate in a frequency range of 30 GHz-10 THz.","20","16/309188","2017-06-14","2019-0318146","2019-10-17","10839189","2020-11-17","ARIZONA BOARD OF REGENTS ON BEHALF OF ARIZONA STATE UNIVERSITY","Georgios  Trichopoulos | Panagiotis  Theofanopoulos","","","","G06K-0009/0002","G06K-0009/0002 | A61B-0005/0507 | A61B-0005/1172 | G06F-0003/04886 | G06K-0009/00087 | G06T-0007/0014 | H01Q-0015/24 | A61B-2562/028 | G06T-2207/30088 | H01Q-0001/368 | H01Q-0021/062 | H01Q-0021/064","G06F-003/0481","G06F-003/0481 | G06K-009/00 | A61B-005/05 | A61B-005/1172 | G06T-007/00 | H01Q-015/24 | G06F-003/0488 | H01Q-001/36 | H01Q-021/06","","","","","","4920047005049"
"US","US","P","B2","Facial expression detection for screening and treatment of affective disorders","Embodiments of the present disclosure provide a system and method for using facial recognition and mimicry workflows to train cognitive and emotional empathy. The system and methods comprise the use of physiological measurements (e.g., EEG, etc.) in combinations with facial recognition to detect user affect and modify one or more cognitive screening instruments to further promote a user affect. One or more specific emotions associated with one or more specific negative cognitive bias are targeted to influence affect. One or more specific psychopathology may be treated using an emotional recognition training component within a computerized cognitive-bias modification regimen. The regimen may comprise the identification, targeting, and modification of emotions and may utilize one or more facial inputs, cognitive tasks, facial recognition and facial mimicry protocols to adaptively modify one or more attributes of one or more computerized stimuli or interactions within a computerized platform or platform-product.","1. A computer-implemented method for facial image processing, comprising: presenting, with a computing device comprising a user interface, a first instance of a computerized cognitive-bias modification regimen comprising a computerized stimuli or interaction to a user, wherein the computerized stimuli or interaction comprises an emotional expression prompt comprising an image or icon representative of at least one face displaying an emotional expression, wherein the emotional expression prompt is configured to prompt the user to distinguish a positive or negative valence for the at least one face and generate a facial expression according to the emotional expression prompt;receiving in real-time, with a camera operably engaged with the computing device, a digital image of the facial expression of the user in response to the emotional expression prompt;processing, with at least one processor, the digital image of the facial expression of the user to determine a valence input and an intensity or arousal input corresponding to the facial expression of the user in response to the emotional expression prompt;comparing, with the at least one processor, the valence input and the intensity or arousal input to a predetermined valence and intensity or arousal range associated with the emotional expression prompt;determining, with the at least one processor, a measure of concordance between the facial expression of the user and the emotional expression prompt;analyzing, with the at least one processor, the measure of concordance between the facial expression of the user and the emotional expression prompt to identify one or more cognitive bias in the user, wherein the one or more cognitive bias comprises at least one negatively biased perception of a neutral or ambiguous expression of the at least one face; andpresenting, with the computing device via the user interface, one or more targeted or modified emotional expression prompt configured to target one or more specific emotions in the user,wherein the computerized cognitive-bias modification regimen is configured to positively improve the at least one negatively biased perception in the user.","19","16/681711","2019-11-12","2020-0151439","2020-05-14","10839201","2020-11-17","AKILI INTERACTIVE LABS, INC.","Jason  Johnson | Jason  Trees | Elena Canadas  Espinosa","","","","G06K-0009/00315","G06K-0009/00315 | A61B-0005/163 | A61B-0005/165 | G06K-0009/66 | G06Q-0030/02 | G16H-0050/20","G06K-009/00","G06K-009/00 | A61B-005/16 | G06K-009/66 | G06Q-030/02 | G16H-050/20","","","","","","4920047005061"
"US","US","P","B2","Method and system for predicting audience viewing behavior","The present invention is directed to a method and system for predicting the behavior of an audience based on the biologically based responses of the audience to a presentation that provides a sensory stimulating experience and determining a measure of the level and pattern of engagement of that audience to the presentation. In particular, the invention is directed to a method and system for predicting whether an audience is likely to view a presentation in its entirety. In addition, the present invention may be used to determine the point at which an audience is likely to change their attention to an alternative sensory stimulating experience including fast forwarding through recorded content, changing the channel or leaving the room when viewing live content, or otherwise redirecting their engagement from the sensory stimulating experience.","1. An apparatus comprising: a biometric sensor to measure a biometric response of an audience member while exposed to media during a time period, the time period divided into time intervals; anda processor to: determine engagement scores for respective ones of the time intervals based on the biometric response;generate an engagement curve based on the engagement scores and the time period;identify a segment of the engagement curve having ascending engagement;calculate an area above a threshold engagement score and below the engagement curve for the segment by: determining a first engagement value at a start of the segment,determining a second engagement value at an end of the segment,calculating a first difference between the first engagement value and the second engagement value,determining a first time value at the start of the segment,determining a second time value at the end of the segment,calculating a second difference between the first time value and the second time value, andcalculating the area as half of the product of the first difference and the second difference;determine a positive buildup value for the media based on a ratio of the area to the time period; andpredict viewership based on the positive buildup value.","19","16/264220","2019-01-31","2019-0164130","2019-05-30","10839350","2020-11-17","CITIBANK, N.A","Carl D.  Marci | Brian  Levine | Ravi Kanth V  Kothuri | Caleb J.  Siefert","","","","G06Q-0010/10","G06Q-0010/10 | G06Q-0030/0201 | H04N-0021/252 | H04N-0021/25883 | H04N-0021/42201 | H04N-0021/4532 | H04N-0021/4662 | H04N-0021/84 | A61B-0005/0002 | A61B-0005/02405 | A61B-0005/0476 | A61B-0005/0533 | A61B-0005/08 | A61B-0005/11 | A61B-0005/163 | A61B-0005/225 | A61B-0005/6897 | H04H-0060/33","G06Q-010/10","G06Q-010/10 | G06Q-030/02 | H04N-021/25 | H04N-021/258 | H04N-021/422 | H04N-021/45 | H04N-021/466 | H04N-021/84 | A61B-005/024 | A61B-005/11 | A61B-005/22 | A61B-005/00 | A61B-005/08 | A61B-005/0476 | A61B-005/053 | H04H-060/33 | A61B-005/16","","","","","","4920047005210"
"US","US","P","B2","Method for noninvasive imaging of cardiac electrophysiological based on low rank and sparse constraints","The present invention discloses a method for noninvasive imaging of cardiac electrophysiological based on low rank and sparse constraints. This method decomposes the spatio-temporal distribution of endocardial and epicardial potentials into a low-rank matrix representing smooth potential components and a sparse matrix representing the details of potential salience according to the prior condition of spatio-temporal correlation of the endocardial and epicardial potential distribution of the heart. By introducing low rank and sparse constraints, the solution of the ill-conditioned inverse problem of ECG is constrained to the unique optimal solution. The invention combines the individualized three-dimensional heart model of the subject to obtain a three-dimensional dynamic distribution image of the cardiac endocardial and epicardial potential of the subject, which has important practical application value.","1. A method for noninvasive imaging of cardiac electrophysiology, comprising the following steps: (1) recording a subject'ss surface potential data and thoracic tomography image data;(2) based on the thoracic tomographic image data, establishing a 3D torso geometric model of the object and a 3D cardiac geometry model, respectively, then unifying the 3D torso geometry model and the 3D cardiac geometry model into the same coordinate system to obtain a 3D heart-torso model;(3) establishing a quasi-static electric field model of the subject'ss heart-torso based on the geometric relationship between heart and trunk of the subject, wherein the boundary element method is used to solve an electric field model to calculate a positive problem of an electrocardiogram, and a mapping relationship between endocardial and epicardial potential of the heart and body surface potential is obtained as Φ=HU, H is a transfer matrix, U is a cardiac endocardial and epicardial potential matrix, and Φ is a body surface potential matrix;(4) pretreating a 64-lead body surface potential data; and(5) according to the transfer matrix H, establishing an inverse problem solving model of the body surface potential to the cardiac potential, and then performing an inverse operation of a pre-processed body surface potential data to solve an inverse problem of the electrocardiogram; finally, reconstructing a distribution of cardiac endocardial and epicardial potential in the geometric model of the three-dimensional heart.","8","15/983546","2018-05-18","2019-0209035","2019-07-11","10827937","2020-11-10","ZHEJIANG UNIVERSITY","Huafeng  Liu | Lin  Fang","2018-10027389","CN","2018-01-11","A61B-0005/04007","A61B-0005/04007 | A61B-0005/0035 | A61B-0005/0044 | A61B-0005/04085 | G06F-0017/148 | G06N-0007/00 | A61B-0005/05 | A61B-2562/046 | A61B-2576/023","A61B-005/00","A61B-005/00 | A61B-005/04 | G06N-007/00 | G06F-017/14 | A61B-005/0408 | A61B-005/05","","","","","","4920046001003"
"US","US","P","B2","Electrocardiographic biometric authentication","Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for obtaining an electrocardiographic (ECG) signal of a user; obtaining a feature vector of the ECG signal of the user with neural network based feature extraction. Comparing the feature vector of the ECG signal with a stored feature vector of a registered user. Authenticating the user in response to determining that a similarity of the ECG feature vector of the ECG signal and the stored ECG feature vector of the registered user exceeds a pre-defined threshold value.","1. A wearable device comprising: an authentication circuit configured to perform electrocardiographic authentication of a user, the authentication circuit comprising: an input configured to receive an electrocardiographic (ECG) signal of the user;noise reduction circuitry configured to: filter the ECG signal with a finite impulse response filter to provide a filtered ECG signal,detect R-peaks in the filtered ECG signal, andalign segments of the ECG signal based on the detected R-peaks in the filtered ECG signal;feature extraction circuitry configured to implement multiple parallel neural networks to obtain a feature vector of the ECG signal that represents features extracted from the ECG signal by the neural networks;similarity evaluation circuitry configured to determine a cosine similarity of the feature vector of the ECG signal with a stored feature vector of a registered user; andauthentication circuitry configured to authenticate the user in response to determining the cosine similarity exceeds a pre-defined threshold value;at least one processor; anda data store coupled to the at least one processor having instructions stored thereon which, when executed by the at least one processor, cause the at least one processor to perform operations comprising: permitting the user to access features in response to receiving an indication that the user is authenticated from the authentication circuit,wherein the noise reduction circuitry is configured to provide sets of aligned segments of the ECG signal to the feature extraction circuitry, andwherein the feature extraction circuitry is configured to: process each set of aligned segments of the ECG signal by a respective one of the multiple parallel neural networks,extract features from the sets of aligned segments using the multiple parallel neural networks to obtain respective feature vectors, particular to each of the neural networks, andconcatenate the respective feature vectors to provide the feature vector of the ECG signal.","17","16/097552","2017-04-28","2019-0150794","2019-05-23","10827952","2020-11-10","ARIZONA BOARD OF REGENTS ON BEHALF OF ARIZONA STATE UNIVERSITY","Shihui  Yin | Jae-sun  Seo | Sang Joon  Kim | Chisung  Bae","","","","A61B-0005/117","A61B-0005/117 | A61B-0005/0452 | A61B-0005/0456 | A61B-0005/04525 | A61B-0005/7203 | A61B-0005/7246 | G06F-0021/32 | G06K-0009/00885 | G06N-0003/0454 | G06N-0003/084 | H04L-0029/06 | H04W-0012/0605 | G06K-2009/00939 | H04L-0063/0861","G06K-009/00","G06K-009/00 | A61B-005/117 | G06F-021/32 | H04L-029/06 | A61B-005/0452 | A61B-005/00 | H04W-012/06 | A61B-005/0456 | G06N-003/04 | G06N-003/08","","","","","","4920046001018"
"US","US","P","B2","Emotional/behavioural/psychological state estimation system","The present invention concerns a human emotional/behavioural/psychological state estimation system comprising a group of sensors and devices and a processing unit. The group of sensors and devices includes: a video-capture device; a skeletal and gesture recognition and tracking device; a microphone; a proximity sensor; a floor pressure sensor; user interface means; and one or more environmental sensors. The processing unit is configured to: acquire or receive a video stream captured by the video-capture device and data items provided by the skeletal and gesture recognition and tracking device, the microphone, the proximity sensor, the floor pressure sensor, the environmental sensor(s), and also data items indicative of interactions of a person under analysis with the user interface means; detect one or more facial expressions and a position of eye pupils, a body shape and features of voice and breath of the person under analysis; and estimate an emotional/behavioural/psychological state of the person on the basis of the acquired/received data items, of the detected facial expression(s), position of the eye pupils, body shape and features of the voice and the breath of the person, and of one or more predefined reference mathematical models modelling human emotional/behavioural/psychological states.","1. Emotional/behavioral/psychological state estimation system comprising a group of sensors and devices and a computing device, wherein the group of sensors and devices includes: a video camera configured to capture a video stream of a person under analysis;a skeletal and gesture recognition tracker configured to provide data items indicative of gestures of a body of the person under analysis;a microphone configured to provide data items indicative of a voice of the person under analysis;a proximity sensor configured to provide data items indicative of a distance of the person under analysis;a floor pressure sensor configured to provide data items indicative of position and movements of feet of the person under analysis;an user interface including one or more input peripherals and one or more output peripherals, the user interface designed to be used by the person under analysis; andone or more environmental sensors configured to provide data items indicative of parameters related to an environment surrounding the person under analysis;and wherein the computing device is configured to: acquire or receive the video stream captured by the video camera, the data items indicative of the gestures of the body of the person under analysis provided by the skeletal and gesture recognition tracker, the data items indicative of the voice of the person under analysis provided by the microphone, the data items indicative of the distance of the person under analysis provided by the proximity sensor, the data items indicative of the position and movements of the feet of the person under analysis provided by the floor pressure sensor, data items indicative of interactions of the person under analysis provided by the user interface, and the data items indicative of the parameters related to the environment surrounding the person under analysis provided by the environmental sensor(s);detect one or more facial expressions and a position of eye pupils of the person under analysis on the basis of the acquired/received video stream;detect a body shape of the person under analysis on the basis of the acquired/received video stream and the acquired/received data items indicative of the gestures of the body of said person;detect features of voice and breath of the person under analysis on the basis of the acquired/received data items indicative of the voice of said person; andestimate an emotional/behavioral/psychological state of the person under analysis on the basis of the acquired/received data items,the detected facial expression(s) of said person,the detected position of the eye pupils of said person,the detected body shape of said person,the detected features of the voice and the breath of said person, andone or more predefined reference mathematical models modelling human emotional/behavioral/psychological stateswherein said predefined reference mathematical model(s) comprise(s) one or more neuro-linguistic programming models that is/are such that to model human emotional, behavioral or psychological states according to the following response modes: a ""Rational Growth"" response mode, a ""Non-rational Growth"" response mode, a ""Rational Trouble"" response mode, a ""Non-rational Trouble"" response mode, a ""Rational Even Keel"" response mode, a ""Non-Rational Even Keel"" response mode, a ""Rational Overconfident"" response mode, and a ""Non-rational Overconfident"" response mode.","12","15/764695","2015-09-30","2018-0263545","2018-09-20","10827967","2020-11-10","CENTRO STUDI S.R.L.","Alberto  Camporesi | Vito  Santarcangelo","","","","A61B-0005/165","A61B-0005/165 | A61B-0005/1114 | A61B-0005/7267 | G06N-0003/08 | H04L-0067/04 | H04L-0067/12 | H04L-0067/22 | A61B-0005/163 | A61B-0005/168 | G06N-0005/022 | G06N-0007/005","A61B-005/16","A61B-005/16 | H04L-029/08 | A61B-005/00 | A61B-005/11 | G06N-003/08 | G06N-005/02 | G06N-007/00","","","","","","4920046001033"
"US","US","P","B2","Sound signal controlling apparatus, sound signal controlling method, and recording medium","An information processing apparatus includes: an estimator configured to estimate, based on biological information of a human subject, a sleep indicator indicative of a depth of sleep of the human subject; and a volume controller configured to control a volume adjuster that generates a second playback sound signal by adjusting an amplitude of a first playback sound signal, such that the first playback sound signal is adjusted based on the sleep indicator and a volume of an ambient sound in an environment in which the human subject is situated.","1. A sound signal controlling apparatus comprising: a memory storing instructions; anda processor that implements the instructions to: estimate, based on biological information of a human subject, a sleep indicator indicative of a depth of sleep of the human subject;generate a playback sound signal for outputting playback sound;generate an ambient sound signal indicative of ambient sound based on the generated playback sound signal and a sound signal output from a microphone disposed in an environment where the human subject is situated;determine a volume of the ambient sound obtained from the generated ambient sound signal; andcontrol a volume of the playback sound obtained from the generated playback sound signal based on the estimated sleep indicator and the determined ambient sound volume.","5","15/950338","2018-04-11","2018-0232197","2018-08-16","10831437","2020-11-10","YAMAHA CORPORATION","Atsushi  Ishihara | Morito  Morishima | Kiyoshi  Yamaki | Takehiko  Kawahara","2015-205263","JP","2015-10-19","G06F-0003/165","G06F-0003/165 | A61B-0005/4812 | A61B-0005/4836 | A61M-0021/02 | G06K-0009/0053 | G06K-0009/00543 | G06K-0009/00892 | H04R-0001/028 | H04R-0003/04 | A61B-0005/024 | A61B-0005/0816 | A61B-0005/6892 | A61B-0005/7415 | A61B-2560/0242 | A61M-2021/0027 | A61M-2205/332 | A61M-2205/3303 | A61M-2205/3306 | A61M-2205/3331 | A61M-2205/3375 | A61M-2205/3553 | A61M-2205/3569 | A61M-2205/3584 | A61M-2205/3592 | A61M-2205/502 | A61M-2205/505 | A61M-2205/52 | A61M-2230/06 | A61M-2230/10 | A61M-2230/30 | A61M-2230/42 | A61M-2230/63 | G06K-2009/00939 | H04R-2430/01","A61M-021/02","A61M-021/02 | G06F-003/16 | G06K-009/00 | H04R-003/04 | H04R-001/02 | A61B-005/00 | A61B-005/024 | A61B-005/08 | A61M-021/00","","","","","","4920046004479"
"US","US","P","B1","Eye tracking using optical coherence methods","A system tracks eye movement using optical coherence in a head mounted display. The system includes an illumination source configured to project low coherence interference light onto a portion of a user's eye. The system includes a scanning system to select an axial position within the illuminated portion of the user's eye. The system includes a detector configured to collect light reflected from the illuminated portion of the user's eye at the selected axial position, and the reflected light includes measurement data characterizing the illuminated portion of the user's eye. The system includes a controller configured to compare the measurement data with a trained baseline, and determine an eye position based the comparison.","1. An eye tracking device comprising: an illumination source configured to project low coherence interference light onto a portion of a user'ss eye via a scanning system, wherein the portion of the user'ss eye is a portion of the user'ss sclera, cornea, or limbus;the scanning system configured to scan an illuminated portion of the user'ss eye with the low coherence interference light from the illumination source at one or more different depths below a surface of the user'ss eye, wherein the scanning of the one or more different depths is performed along a longitudinal axis that intersects the illuminated portion of the user'ss eye;a detector configured to collect, for each of the one or more different depths, reflected low coherence interference light from the illumination source reflected from the illuminated portion of the user'ss eye, the reflected low coherence interference light from the illuminated portion of the user'ss eye at each of the one or more different depths of a plurality of different depths; anda controller configured to: determine, for each of the one or more different depths, measurement data characterizing the illuminated portion of the user'ss eye based on the reflected low coherence interference light collected for each of the one or more different depths,compare the measurement data with a trained baseline, anddetermine an eye position based on the comparison.","20","15/593555","2017-05-12","","","10832051","2020-11-10","FACEBOOK TECHNOLOGIES, LLC","Nicholas Daniel  Trail | Robert Dale  Cavin","","","","G06K-0009/00604","G06K-0009/00604 | G01B-0009/02091 | G01B-0011/002 | G06F-0003/013 | G06K-0009/0061 | G06T-0007/75 | G06T-2207/30201","A61B-005/00","A61B-005/00 | A61B-003/15 | G06K-009/00 | G06F-003/01 | G06T-007/73 | G01B-009/02 | G01B-011/00","","","","","","4920046005089"
"US","US","P","B1","Authentication method and system","A method for authenticating an object, comprising determining a physical dispersion pattern of a set of elements, determining a physical characteristic of the set of elements which is distinct from a physical characteristic producible by a transfer printing technology, determining a digital code associated with the object defining the physical dispersion pattern, and authenticating the object by verifying a correspondence of the digital code with the physical dispersion pattern, and verifying the physical characteristic.","1. An authentication device, comprising: a first interface configured to communicate over a digital data network;a second interface configured to receive information from an imager, defining at least one feature of an object within a captured image, having a unique variation between different examples of the object; andat least one processor, configured to: perform user authentication, and restrict use of authentication data for authentication of the object, received through the first interface, dependent on successful user authentication;control a communication over the first interface to receive authentication data in at least a first mode of operation;store the authentication data in a memory in at least a second mode of operation; andreliably authenticate the object, based on the authentication data, an identification of the object, and the information received through the second interface defining at least one feature of the object.","20","16/398247","2019-04-29","","","10832072","2020-11-10","CoPilot Ventures III LLC","Jay  Fraser","","","","G06K-0009/209","G06K-0009/209 | G06K-0007/10722 | G06K-0007/1413 | G06K-0009/00046 | G06K-0009/00288 | G06K-0009/00442 | G06K-0009/00483 | G06K-0009/00577 | G06K-0009/18 | G06K-0009/6201 | G06K-0009/74 | G07D-0007/0043 | G07D-0007/2008 | G07D-0007/2033 | H04L-0009/3236 | H04L-0009/3247 | A61B-0005/1172 | G07D-0007/12 | G07D-0007/1205 | H04L-2209/72","H04N-007/18","H04N-007/18 | G06K-009/20 | G06K-009/62 | G06K-009/18 | G06K-009/00 | G06K-007/14 | G06K-007/10 | H04L-009/32 | G06K-009/74 | G07D-007/20 | G07D-007/0043 | G07D-007/2033 | G07D-007/1205 | G07D-007/12 | A61B-005/1172","","","","","","4920046005110"
"US","US","P","B2","Continuous decoding direct neural interface which uses a markov mixture of experts","A method of continuous decoding of motion for a direct neural interface. The method of decoding estimates a motion variable from an observation variable obtained by a time-frequency transformation of the neural signals. The observation variable is modelled using a HMM model whose hidden states include at least an active state and an idle state. The motion variable is estimated using a Markov mixture of experts where each expert is associated with a state of the model. For a sequence of observation vectors, the probability that the model is in a given state is estimated, and from this a weighting coefficient is deduced for the prediction generated by the expert associated with this state. The motion variable is then estimated by combination of the estimates of the different experts with these weighting coefficients.","1. A method of continuous decoding of motion for a direct neural interface which acquires neural signals using a plurality of electrodes, wherein a command variable, y(t), is estimated which represents kinematic motion variables, using a mixture of experts, each expert being associated with one of the hidden states of a HMM model which models an observation variable represented by an observation vector, x(t), where the HMM model comprises at least one active state and one idle state, said method comprising: a calibration phase for estimating parameters of the HMM model and of a linear prediction parameter of each expert;pre-treatment of neural signals, said treatment including a time-frequency transformation over a moving observation window, in order to obtain a sequence of observation vectors x[1:t];estimating the mixture coefficients (gk(t),k=1, . . . , K) of the various experts from the probability of said sequence of observation vectors (P(x[1:t])) and from the probability of the respective states associated with these experts, given said sequence (P(zk(t)=1|x[1:t]));estimating by each expert, Ek, said motion variable from the running observation vector (x(t)) and the linear prediction parameter of said expert;combining estimates of the various experts using mixing coefficients in order to provide an estimate of the command variable; andwherein the mixture coefficient gk(t) associated with the expert Ek is obtained by where (P(x[1:t]) is the observation probability of the sequence of observation vectors and (P(zk,x[1:t]) is the state probability associated with the expert, given the sequence observed, with the probabilities (P(x[1:t]) and (P(zk,x[1:t]) being obtained using a forward algorithm.","13","15/615080","2017-06-06","2018-0005105","2018-01-04","10832122","2020-11-10","COMMISSARIAT A L'ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES","Marie-Caroline  Schaeffer | Tetiana  Aksenova","2016-056246","FR","2016-06-30","G06N-0003/0427","G06N-0003/0427 | A61F-0002/72 | G06F-0003/015 | G06K-0009/6297 | G06N-0003/063 | G06T-0007/277","G06N-003/04","G06N-003/04 | A61F-002/72 | G06F-003/01 | G06T-007/277 | G06K-009/62 | G06N-003/063","","","","","","4920046005159"
"US","US","P","B1","Dynamic beat optimization","Aspects of the present invention provide an approach for dynamically optimizing a beat. In an embodiment, a current movement rate and biometric data for each user in a group performing a physical activity are collected. An upcoming movement rate for each user is predicted based on the collected current movement rates and biometric data. Music having an optimized beat is then generated based on a lowest upcoming movement rate among the predicted upcoming movement rates.","1. A computer-implemented method comprising: capturing a current movement rate and biometric data for each user among a plurality of users performing a physical activity;predicting, based on the current movement rate and biometric data, an upcoming movement rate for each user; andgenerating, using a music generation system, music having an optimized beat based on a lowest upcoming movement rate among the predicted upcoming movement rates.","20","16/445735","2019-06-19","","","10832643","2020-11-10","INTERNATIONAL BUSINESS MACHINES CORPORATION","Craig M.  Trim | Martin G.  Keen | Michael  Bender | Sarbajit K.  Rakshit","","","","G10H-0001/0066","G10H-0001/0066 | A61B-0005/1127 | G06N-0020/00 | G10G-0001/00 | H04L-0067/22 | G10H-2220/371","G10H-001/00","G10H-001/00 | G10G-001/00 | H04L-029/08 | A61B-005/11 | G06N-020/00","","","","","","4920046005676"
"US","US","P","B2","System and method for holographic image-guided percutaneous endovascular percutaneous procedures","Holographic image-guidance can be used to track an interventional device during an endovascular percutaneous procedure. The holographic image guidance can be provided by a head-mounted device by transforming tracking data and vasculature image data to a common coordinate system and creating a holographic display relative to a patient's vasculature to track the interventional device during the endovascular percutaneous procedure. The holographic display can also include graphics to provide guidance for the physical interventional device as it travels through the patient's anatomy (e.g., the vasculature).","1. A method comprising: receiving, by a head-mounted device comprising a processor, tracking data for a physical interventional device in a tracking coordinate system, wherein the physical interventional device is used during an endovascular percutaneous medical procedure;transforming, by the head-mounted device, the tracking data for the physical interventional device in the tracking coordinate system into a headset coordinate system;accessing, by the head-mounted device, image data from a pre-operative image of a patient'ss anatomy comprising a physical operative site in an imaging coordinate system;transforming, by the head mounted device, the image data in the imaging coordinate system into the headset coordinate system;registering, by the head-mounted device, a 3D holographic representation of the interventional device based on the tracking data for the physical interventional device in the headset coordinate system to 3D anatomical holographic projections of the patient'ss anatomy based on the imaging data in the headset coordinate system;displaying, by the head mounted device, the 3D anatomical holographic projections providing a visualization of a holographic version of the patient'ss anatomy including a physical operative site within the patient'ss anatomy; andnavigating, by the head mounted device, the 3D holographic representation of the interventional device in the 3D anatomical holographic projections based on the tracking data for the interventional device in the headset coordinate system.","20","16/593374","2019-10-04","2020-0038117","2020-02-06","10820948","2020-11-03","THE CLEVELAND CLINIC FOUNDATION","Karl  West | Jeffrey H.  Yanof","","","","A61B-0034/20","A61B-0034/20 | A61B-0005/062 | A61B-0005/6852 | A61B-0005/745 | A61B-0005/7405 | A61B-0034/25 | A61B-0090/361 | A61B-0090/37 | A61M-0005/00 | G06F-0003/012 | G06K-0009/00671 | G06K-0009/3216 | G06T-0003/0006 | G06T-0003/20 | G06T-0007/344 | G06T-0017/20 | A61B-0005/064 | A61B-2034/102 | A61B-2034/107 | A61B-2034/2051 | A61B-2034/2057 | A61B-2034/2068 | A61B-2090/363 | A61B-2090/365 | A61B-2090/366 | A61B-2090/367 | A61B-2090/368 | A61B-2090/372 | A61B-2090/3762 | A61B-2090/3983 | A61B-2090/502 | A61M-2205/507 | G02B-2027/0174 | G06K-2009/3225 | G06K-2209/05 | G06T-0019/006","A61B-034/20","A61B-034/20 | A61B-005/06 | A61B-005/00 | G06T-017/20 | G06T-003/00 | G06T-003/20 | G06F-003/01 | G06T-007/33 | A61B-090/00 | G06K-009/32 | G06K-009/00 | A61M-005/00 | A61B-034/00 | A61B-034/10 | A61B-090/50 | G02B-027/01 | G06T-019/00","","","","","","4920045001206"
"US","US","P","B2","Surgical optical system with heads up display","Methods and systems are provided herein for a surgical optical system having a heads up display including, in accordance with various embodiments, an optical device, an image sensor optically coupled to the optical device to acquire image data from a field of view of the optical device, and a display device configured to display an acquired image representing the image data acquired by the image sensor.","1. A beam splitting apparatus comprising: a cylindrical housing defining an interior volume and having a first surface at a first end of the housing, a second surface at a second end of the housing, the second surface parallel to the first surface, and a third surface perpendicular to and extending between the first surface and the second surface, andan inlet defined in the first surface of the housing and defining an optical input path for receiving an optical input;a beam splitter positioned within the interior volume and optically coupled to the inlet for receiving the optical input, the beam splitter configured to split the optical input into a first optical output and a second optical output;a first outlet, defined in the second surface of the housing and defining a first optical output path for emitting the first optical output; anda second outlet, defined in the third surface of the housing and defining a second optical output path for emitting the second optical output.","11","15/870424","2018-01-12","2018-0235723","2018-08-23","10820962","2020-11-03","TSME, LLC","Tom C.  Pagonis | Simon  Beylin | Michael J.  Kang | Eric W.  Young","","","","A61B-0090/37","A61B-0090/37 | A61B-0001/24 | A61B-0005/0077 | A61B-0005/01 | A61B-0005/021 | A61B-0006/032 | A61B-0006/5294 | A61B-0090/20 | A61B-0090/361 | G02B-0021/0012 | G02B-0021/20 | G02B-0021/361 | G02B-0021/364 | G02B-0021/365 | G06F-0003/14 | G06T-0007/0012 | A61B-0005/7425 | A61B-2090/372 | A61B-2090/373 | A61B-2090/3762 | G06T-2207/10081","A61B-090/20","A61B-090/20 | G02B-021/20 | A61B-090/00 | G02B-021/36 | A61B-001/24 | A61B-005/00 | A61B-005/01 | A61B-005/021 | A61B-006/03 | A61B-006/00 | G02B-021/00 | G06F-003/14 | G06T-007/00","","","","","","4920045001220"
"US","US","P","B2","Reference interval generation","Described herein are systems and methods for generating health or risk parameter reference intervals for use in healthcare or any other application of risk/attribute measurement. The reference intervals generated by the systems and methods described herein are based on direct analysis and evidence-based models of human and/or other living organism data from a population of individuals including shared feature(s) and outcome data such as vital status. The direct analysis and evidence-based models of human and/or other living organisms data utilize shared common risk parameter feature(s) and outcome data and identify relationships of two or more health or risk parameters relative to one another. These methods also apply to the measurement of risk and/or other attributes of any living organism or nonliving objects.","1. A method for treating an individual based on a two-dimensional lookup table comprising one or more reference intervals of joint first and second risk parameters, the method comprising: (a) selecting the individual for laboratory testing and evaluation using the two-dimensional lookup table comprising the one or more reference intervals, wherein a first health parameter value and a second health parameter value determined from the laboratory testing are compared to the one or more reference intervals to determine a health status indicating a risk of disease incidence or mortality of the individual; and(b) receiving results of the laboratory testing and evaluation of a patient sample using the two-dimensional lookup table comprising the one or more reference intervals, wherein said results comprise the health status indicating the risk of disease incidence or mortality of the individual; and(c) providing treatment to the individual based at least on said results comprising the health status indicating the risk of disease incidence or mortality of the individual, wherein the one or more reference intervals in the two-dimensional lookup table were generated by: (i) importing data, the data comprising health parameter data comprising first risk parameter data, second risk parameter data, and disease incidence or mortality data from a population having at least one shared feature;(ii) grouping the first risk parameter data into a first plurality of data groups and the second risk parameter data into a second plurality of data groups;(iii) joining the first plurality of data groups with the second plurality of data groups generating a plurality of joint risk parameters;(iv) comparing the disease incidence or mortality data with the plurality of joint risk parameters thereby generating joint disease incidence or mortality data;(v) determining a distribution of the plurality of joint risk parameters;(vi) determining whether an overlap is present between the distribution of the plurality of risk joint parameters and the joint disease incidence or mortality data;(vii) generating the one or more reference intervals based on the overlap, wherein when the overlap is present, the distribution of the plurality of joint risk parameters is relatively high and a disease incidence or mortality risk represented by the joint risk outcome data is relatively low; and(viii) generating the two-dimensional lookup table comprising the one or more reference intervals, wherein said two-dimensional lookup table is configured to allow determination of the health status of the individual based on lab test results corresponding to the first and second risk parameters.","10","16/701042","2019-12-02","2020-0105417","2020-04-02","10825102","2020-11-03","VFD CONSULTING, INC.","Vera  Dolan","","","","G06Q-0040/08","G06Q-0040/08 | A61B-0005/742 | G06F-0001/03 | G06N-0020/00 | G16H-0010/60 | G16H-0050/30","G16H-050/30","G16H-050/30 | G16H-010/60 | A61B-005/00 | G06Q-040/08 | G06N-020/00 | G06F-001/03","","","","","","4920045005320"
"US","US","P","B2","Verified social media content","There is disclosed in one example a social media server, including: a processor; a trusted input/output (IO) interface to communicatively couple to a consumer device; a network interface to communicatively couple to an enterprise; and a memory having stored thereon executable instructions to instruct the processor to provide a data loss prevention (DLP) engine to: receive via the trusted IO interface a signed and encrypted user posting for the social media service, the user posting including a signed user state report verifying that the user has passed a biometric screening; transmit content of the user posting to the enterprise via the network interface for DLP analysis; receive from the enterprise a notification that the user posting has passed DLP analysis; and accept the user posting.","1. A social media server, comprising: a processor;a trusted input/output (IO) interface to communicatively couple to a consumer device;a network interface to communicatively couple to an enterprise; anda memory having stored thereon executable instructions to instruct the processor to provide a data loss prevention (DLP) engine to: receive via the trusted IO interface a signed and encrypted user posting for the social media service, the user posting including a signed user state report verifying that the user has passed a biometric screening;transmit content of the user posting to the enterprise via the network interface for DLP analysis;receive from the enterprise a notification that the user posting has passed DLP analysis; andaccept the user posting.","20","16/236087","2018-12-28","2019-0139156","2019-05-09","10825111","2020-11-03","McAfee, LLC","Kunal  Mehta | Carl D.  Woodward | Steven  Grobman | Ryan  Durand | Simon  Hunt","","","","G06Q-0050/01","G06Q-0050/01 | A61B-0005/117 | A61B-0005/165 | A61B-0005/4845 | A61B-0005/6898 | G06F-0021/316 | G06F-0021/552 | G06Q-0010/06395 | H04L-0063/0861 | H04W-0012/0609 | G06F-0021/53 | G06F-2221/2133 | H04L-0067/10","H04L-029/00","H04L-029/00 | G06Q-050/00 | G06Q-010/06 | G06F-021/31 | G06F-021/55 | H04L-029/06 | A61B-005/00 | A61B-005/117 | A61B-005/16 | H04W-012/06 | H04L-029/08 | G06F-021/53","","","","","","4920045005329"
"US","US","P","B1","Apparatus and method for informed personal well-being decision making","An apparatus and method for informed personal-well-being decision making that provides a user with alerts and information, focused on health and wellness, on items they choose for possible consumption. Some embodiments include optical, sonic, smell and other sensors, communications with databases that identify ingredients and effects on health and well-being, as well as user inputs. From user input, GPS, local conditions and alerts, some embodiments determine information specific to the user and their environment. By using established, and creating new, databases, some embodiments compile, compare, transmit and store data on various consumables. Some embodiments provide access to information on the companies, manufacturers, and various other components in an item's trip from dirt to table. Some embodiments establish methods and procedures to ascertain both the point-of-origin and where the consumable has traveled. Some embodiments provide a score for the specified consumable to show the quality of health provided by the consumable.","1. A method comprising: providing a personal computing device (PCD) for a first user, wherein the PCD includes a plurality of sensors including a camera;receiving, into the PCD, image data from the camera;identifying a boundary of a chosen consumable item in the image data;generating histogram data based on at least saturations and hues of pixels within the boundary of the chosen consumable item in the image data;using the histogram data, identifying a plurality of at least three selected from the group consisting of: the chosen consumable item, the chosen consumable item'ss components, the chosen consumable item'ss current age, and the chosen consumable item'ss condition;communicating, to a database server, the identifications of the plurality of at least three selected from the group consisting of: the chosen consumable item, the chosen consumable item'ss components, the chosen consumable item'ss current age, and the chosen consumable item'ss condition;identifying, in the database server, a plurality of the set consisting of ingredients, allergens, and toxins in the chosen consumable item based on the communicated identifications of the plurality of at least three selected from the group consisting of: the chosen consumable item, the chosen consumable item'ss components, the chosen consumable item'ss current age, and the chosen consumable item'ss condition;looking up, in the database server, a plurality of known detrimental, beneficial and health-quality effects on the first user'ss health for each of the plurality of the set consisting of ingredients, allergens, and toxins in the chosen consumable item;determining an effect on biological aging of the first user resulting from consumption of the chosen consumable item, wherein the effect is determined by starting with a score at a neutral point in a range of values, incrementing the score based on the looked-up beneficial effects of at least some of the chosen consumable item'ss ingredients, and decrementing the score based on the looked-up detrimental effects of at least some of the chosen consumable item'ss ingredients; andpresenting to the first user, from the first user'ss PCD, a comparison of a plurality of parameters of the chosen consumable item to at least one alternative consumable item based on the effect on the biological aging of the first user.","20","15/243945","2016-08-22","","","10825567","2020-11-03","FOOD2LIFE, LLC","Fazal  Wala | Alexander B.  Lemaire | Charles A.  Lemaire","","","","G16H-0050/20","G16H-0050/20 | G06Q-0030/0627 | G16H-0010/60","G16H-050/20","G16H-050/20 | G06N-020/00 | G16H-010/60 | G16H-020/00 | G16H-040/67 | G16H-010/20 | A61B-005/145 | G06F-019/00 | G06Q-030/06","","","","","","4920045005784"
"US","US","P","B2","Evaluation device, market research device, and learning evaluation device","An estimation device includes at least one of a facial skin temperature acquisition unit and a facial photographic image acquisition unit, and an evaluation unit. The facial skin temperature acquisition unit acquires, in time-series, facial skin temperature data of a facial surface of a subject to which brain function activation information is provided. The facial photographic image acquisition unit obtains, in time-series, facial photographic image data obtained by imaging the facial surface of the subject to which the brain function activation information is provided. The evaluation unit evaluates a degree of interest of the subject based on at least one of the facial skin temperature data acquired by the facial skin temperature acquisition unit and the facial surface photographic image data acquired by the facial surface photographic image data acquisition unit.","1. An estimation device, comprising: at least one of a facial skin temperature acquisition unit acquiring, in time-series, facial skin temperature data of a facial surface of a subject to which brain function activation information is provided, anda facial photographic image acquisition unit obtaining, in time-series, facial photographic image data obtained by imaging the facial surface of the subject to which the brain function activation information is provided; andan evaluation unit evaluating a degree of interest of the subject based on a change in an amount of brain activity based on at least one of the facial skin temperature data acquired by the facial skin temperature acquisition unit and the facial surface photographic image data acquired by the facial surface photographic image data acquisition unit.","11","15/767959","2016-10-17","2018-0303350","2018-10-25","10813556","2020-10-27","DAIKIN INDUSTRIES, LTD. | TOKYO INSTITUTE OF TECHNOLOGY","Junichiro  Arai | Takashi  Gotou | Makoto  Iwakame | Kenichi  Hino | Tomoya  Hirano | Yasunori  Kotani | Yoshimi  Ohgami | Taro  Tomatsu","2015-203356","JP","2015-10-15","A61B-0005/01","A61B-0005/01 | G06Q-0030/02 | G06Q-0030/0203 | G06Q-0030/0245 | G06T-0007/0012 | G06T-2207/10048 | G06T-2207/30088","A61B-005/01","A61B-005/01 | G06Q-030/02 | G06T-007/00","","","","","","4920044001029"
"US","US","P","B2","Touch-type blood pressure measurement apparatus and method","A touch-type blood pressure measurement apparatus is provided. The touch-type blood pressure measurement apparatus include: a touch sensor configured to generate a contact area signal when a finger of a user is in contact with the touch sensor; at least one photoplethysmogram (PPG) sensor configured to generate a PPG signal of the user while the finger is in contact with the touch sensor; a force sensor configured to generate a touch force signal of the finger in contact with the touch sensor; and a controller configured to obtain a blood pressure of the user based on the contact area signal, the PPG signal, and the touch force signal.","1. A touch-type blood pressure measurement apparatus comprising: a touch sensor configured to generate a contact area signal indicating a size of a contact area between the touch sensor and a finger of a user, when the finger of the user is in contact with the touch sensor;at least one photoplethysmogram (PPG) sensor configured to generate a PPG signal of the user while the finger is in contact with the touch sensor;a force sensor provided separately from the touch sensor and configured to generate a touch force signal of the finger in contact with the touch sensor, the touch force signal comprising a value of a force exerted by the finger to the force sensor; anda controller configured to determine a contact pressure based on the size of the contact area and the value of the force, and obtain a blood pressure of the user based on a change of the PPG signal according to the contact pressure, wherein the at least one PPG sensor is disposed between the touch sensor and the force sensor in a vertical direction of the touch-type blood pressure measurement apparatus.","20","15/680821","2017-08-18","2018-0177413","2018-06-28","10813561","2020-10-27","SAMSUNG ELECTRONICS CO., LTD.","Yong Joo  Kwon | Jae Min  Kang | Youn Ho  Kim | Seung Woo  Noh | Sang Yun  Park | Young Zoon  Yoon","10-2016-0180132","KR","2016-12-27","A61B-0005/02108","A61B-0005/02108 | A61B-0005/0053 | A61B-0005/022 | A61B-0005/02055 | A61B-0005/0261 | A61B-0005/1172 | A61B-0005/6826 | A61B-0005/6843 | A61B-0005/6898 | A61B-0005/7278 | A61B-0005/742 | G06F-0003/044 | A61B-0005/02427 | A61B-2090/065 | A61B-2562/0238 | A61B-2562/0247 | A61B-2562/0252 | A61B-2562/046 | A61B-2562/063 | G06F-0003/0416 | G06F-2203/04105 | G06K-0009/0002","A61B-005/021","A61B-005/021 | G06F-003/044 | A61B-005/0205 | A61B-005/00 | A61B-005/1172 | A61B-005/022 | A61B-005/026 | G06F-003/041 | G06K-009/00 | A61B-005/024 | A61B-090/00","","","","","","4920044001034"
"US","US","P","B2","Method for automatically selecting and providing sunscreen for users","One variation of a method includes: accessing a skin type of a user; predicting a first set of locations occupied by the user during a first future time interval; based on historical ultraviolet irradiance data and the first future time interval, calculating a first predicted unprotected ultraviolet radiation exposure of the user during the first future time interval; calculating a maximum allowable ultraviolet radiation exposure for periods within the first future time interval based on the skin type of the user; calculating a first minimum sun protection factor predicted to reduce the first predicted unprotected ultraviolet radiation exposure to less than the maximum allowable ultraviolet radiation exposure; selecting a first sunscreen formula characterized by a first sun protection factor greater than the first minimum sun protection factor; and shipping the first volume of the first sunscreen formula to the user prior to the first future time interval.","1. A method comprising: accessing a skin type of a user;predicting a first set of locations occupied by the user during a first future time interval;based on historical ultraviolet radiation irradiance data and the first future time interval, calculating a first predicted unprotected ultraviolet radiation exposure of the user during the first future time interval;selecting a first sunscreen formula based on the first predicted unprotected ultraviolet radiation exposure and the skin type of the user; andsupplying a first volume of the first sunscreen formula to the user.","20","16/171327","2018-10-25","2019-0060678","2019-02-28","10814148","2020-10-27","Sunborn Outdoors, LLC","Andrew  Poutiatine","","","","A61Q-0017/04","A61Q-0017/04 | A61B-0005/0077 | A61B-0005/1032 | A61B-0005/441 | A61B-0005/442 | A61B-0005/443 | A61B-0005/7275 | G06T-0007/0012 | G16H-0040/63 | G16H-0050/30 | A61B-0005/448 | A61Q-0019/004 | G06Q-0030/0269 | G06T-2207/10024 | G06T-2207/30088","A61Q-017/04","A61Q-017/04 | A61B-005/00 | G06T-007/00 | A61B-005/103 | G16H-040/63 | G16H-050/30 | G06Q-030/02 | A61Q-019/00","","","","","","4920044001617"
"US","US","P","B2","Advanced medical image processing wizard","An automatic medical image processing system includes a series of operation stages, each automating specifying the image processing parameters for processing medical images. In response to an image processing indicator, a first medical image is automatically identified, including determining a first image operation and image processing parameters, without user intervention. The first image operation is performed on the first medical image based on the image processing parameters. A second medical image is generated and transmitted to the client device to be presented therein. The client device displays a message prompting the user whether the user is satisfied with the second medical image. In response to a user input from the client device indicating that the user is unsatisfied with the second medical image, one or more remedial options are presented to allow the user selecting a remedial action to reprocess the first medical image.","1. An image processing system, comprising: a processor;an image storage system that stores medical data including medical images used in medical diagnoses;an image processing engine, the image processing engine processing the medical images in response to image processing commands, the processing on the medical images including changing image processing parameters used to display the medical images, the parameters including parameters that specify updated views of the medical images;an advanced image processing system that allows the user to directly input desired values of the image processing parameters, the advance image processing system receiving input from the user indicating the desired values and the advanced image processing system generating commands that are sent to the image processing engine causing the image process engine to change the image processing parameters to match the desired values of the image processing parameters to produce updated medical images; and,an automatic image processing system that processes a series of medical images to obtain preliminary medical results, the preliminary medical results including preliminary result medical images based on the series of medical images and the preliminary results including identification of anatomical features of interest and measured values of the anatomical features of interest, the automatic image processing system including: a graphical user interface, the graphical user interface presenting the user with a series of interactive questions pertaining to the anatomical features of interest and measured values of the anatomical features of interest within the preliminary medical results, answers from the user being used by the automatic image processing system to adjust selection or measurement of the anatomical features of interest within the preliminary result medical images to produce the updated medical images;wherein commands sent based on calculated values of the image processing parameters are sent to the image processing engine directly by the automatic image processing system or through the advanced image processing system.","20","16/029570","2018-07-07","2018-0330525","2018-11-15","10818048","2020-10-27","TERARECON, INC.","Tiecheng T.  Zhao | Akio  Iwase | Nobuyuki  Kihara","","","","G06T-0011/008","G06T-0011/008 | A61B-0001/31 | A61B-0005/055 | A61B-0005/7435 | A61B-0006/032 | A61B-0006/14 | A61B-0006/504 | A61B-0034/10 | G06F-0003/04847 | G06F-0019/321 | G06Q-0010/1095 | G06T-0011/60 | G16H-0010/60 | G16H-0030/20 | G16H-0030/40 | G16H-0040/20 | G06F-0003/0484 | G06Q-0050/22 | G06T-2200/24","G06F-003/0484","G06F-003/0484 | G06T-011/00 | G06F-019/00 | A61B-034/10 | G16H-030/20 | G16H-040/20 | G16H-010/60 | G16H-030/40 | A61B-001/31 | A61B-005/055 | A61B-005/00 | A61B-006/03 | A61B-006/14 | A61B-006/00 | G06Q-010/10 | G06T-011/60 | G06Q-050/22","","","","","","4920044005495"
"US","US","P","B2","Computer-aided dispatch systems and methods utilizing biometrics to assess responder condition and suitability","A Computer-Aided Dispatch (CAD) system is specially configured to account for the physical condition of emergency personnel, which can affect their ability to effectively handle a particular incident. The CAD system tracks health, stress, and biometric status of each available emergency responder automatically and in real-time based on a wide range of collected information and to assess the suitability of available emergency responders to respond to a given emergency incident based upon such status information. Based on such status information, the CAD system can make intelligent recommendations to the emergency dispatcher by taking into account such things as the emergency responder's past experiences with a particular type of emergency incident, the current and cumulative status of the emergency responder, and projections as to the future condition of the emergency responder if dispatched to handle the emergency incident.","1. A computer-aided dispatch (CAD) system comprising: a CAD database; anda CAD server subsystem configured to: store, in the CAD database, incident type information for each of a plurality of incident types, the incident type information specifying personnel qualifications for the incident type;receive, for each of a plurality of responders, biometric sensor data generated by a biometric sensor device worn by the responder;store, in the CAD database, the received biometric sensor data;store, in the CAD database, past performance evaluation information for each of a plurality of responders, the past performance evaluation information characterizing how the responder has performed when responding to past instances of each of the plurality of incident types based on the biometric sensor data;receive information for an incident including an incident type;identify a set of available responders qualified to respond to the incident based on the stored personnel qualifications for the incident type;evaluate relative suitability of the identified responders for the incident based on the past performance evaluation information characterizing how the identified responders have performed when responding to past instances of the incident type to determine a most suitable responder for handling the incident; andproduce a dispatch recommendation identifying the most suitable responder for handling the incident.","20","16/437633","2019-06-11","2019-0297399","2019-09-26","10820069","2020-10-27","Intergraph Corporation","Edward Michael  Sieja | Renz Angelo  Santos | Andrew James  England","","","","H04Q-0009/00","H04Q-0009/00 | A61B-0005/0022 | G06Q-0010/063114 | G06Q-0010/103 | G06Q-0010/1091 | G06Q-0050/22 | G08B-0021/0453 | G08B-0027/001 | H04B-0001/0343 | H04L-0067/02 | H04Q-2209/40 | H04Q-2209/70 | H04Q-2209/826 | H04Q-2209/84 | H04W-0004/80 | H04W-0004/90","G06Q-010/06","G06Q-010/06 | H04Q-009/00 | G06Q-010/10 | G06Q-050/22 | G08B-021/04 | G08B-027/00 | A61B-005/00 | H04L-029/08 | H04B-001/034 | H04W-004/80 | H04W-004/90","","","","","","4920044007501"
"US","US","P","B2","Electronic device and method for measuring heart rate based on infrared rays sensor using the same","A method for determining a heart rate (HR) using an infrared rays (IR) sensor and an electronic device is provided. An image is received using an IR sensor, at least one region of interest (ROI) for measuring the HR is determined in the received image, and the HR is determined based on the at least one determined ROI.","1. An electronic device comprising: an infrared rays (IR) sensor;a memory; anda processor electrically connected to the IR sensor and the memory,wherein the memory stores instructions which, when executed, cause the processor to:receive an image using the IR sensor,recognize, in response to a request for user authentication, an iris of a user using the IR sensor,detect an object from the received image,extract features of the detected object,determine at least one region of interest (ROI) for measuring a heart rate (HR) based on the extracted features of the object,identify whether measurement of the HR is possible in the ROI, andcomplete the user authentication based on information of the iris if the measurement of the HR is possible even if the surroundings are darkened.","15","15/682971","2017-08-22","2018-0055392","2018-03-01","10806356","2020-10-20","SAMSUNG ELECTRONICS CO., LTD.","Donghyun  Lee | Dongwook  Kim | Jinhee  Won | Jaesung  Lee | Jongmin  Choi | Taeho  Kim | Jeongmin  Park | Seungeun  Lee","10-2016-0109101","KR","2016-08-26","A61B-0005/02433","A61B-0005/02433 | A61B-0005/0077 | A61B-0005/024 | G06F-0021/32 | G06K-0009/00906 | G06T-0007/0012 | A61B-2576/00","A61B-005/024","A61B-005/024 | G06F-021/32 | G06T-007/00 | A61B-005/00 | G06K-009/00","","","","","","4920043001055"
"US","US","P","B2","User identification by biometric monitoring device","Techniques for user identification by a biometric monitoring device are disclosed. In one aspect, a method of operating a biometric monitoring device may involve measuring a weight of a user in response to detecting that the user is standing on a platform, determining, based on sensor data generated by a sensor, a user parameter indicative of the user's identification, identifying one of a plurality of user profiles as corresponding to the user based on a comparison of the user parameter to parameter values and a comparison of the measured weight of the user to weight values, and updating the identified user profile based on at least one of the measured weight and the user parameter.","1. A method of operating a biometric monitoring device, the device comprising a platform configured to receive at least one foot of a user, a plurality of sensors, a memory, and processing circuitry, the method comprising: detecting that the user is standing on the platform;measuring, in response to detecting that the user is standing on the platform and based on body-weight data generated by a first one of the sensors, a weight of the user;determining, in response to detecting that the user is standing on the platform and based on sensor data generated by a second one of the sensors, a user parameter indicative of the user'ss identification, wherein the second sensor comprises a wireless communication transceiver, and wherein the determining the user parameter comprises determining that a device associated with the user is in the proximity of the wireless communication transceiver;comparing the user parameter to a plurality of parameter values respectively associated with a plurality of user profiles stored in the memory;comparing the measured weight of the user to a plurality of weight values respectively associated with each of the user profiles;identifying the one of the user profiles as corresponding to the user based on the comparison of the user parameter to the parameter values and the comparison of the measured weight of the user to the weight values; andupdating the identified user profile based on at least one of the measured weight and the user parameter.","20","16/829658","2020-03-25","2020-0260999","2020-08-20","10806379","2020-10-20","FITBIT, INC.","Eric  Foxlin | Molly  Glauberman | Erick  Fuentes","","","","A61B-0005/1171","A61B-0005/1171 | A61B-0005/0531 | A61B-0005/117 | A61B-0005/6829 | G01G-0019/50 | G06K-0009/00892 | H04L-0067/306 | G06F-0003/048 | H04L-0067/12","A61B-005/1171","A61B-005/1171 | A61B-005/00 | G01G-019/50 | H04L-029/08 | A61B-005/053 | A61B-005/117 | G06K-009/00 | G06F-003/048","","","","","","4920043001077"
"US","US","P","B2","Systems and methods for utilizing wireless physiological sensors","Physiological sensors may be utilized to obtain physiological data for a user. The sensor data may be utilized in predicting a user's outcome to a medical intervention using one or more models. The models may be automatically executed in response to receiving certain types and/or amount of data, such as data received from one or more physiological remote sensors, such as Internet of Things sensors. The sensors may include heart rate sensors, arterial pressure sensors, glucose sensors, temperature sensors, weight sensors, blood oxygen sensors, urine sensors, saliva sensors, skin conduction sensors, muscle sensors, brain signal sensors, and/or other sensors. A sensor may communicate over the 2360-2400 MHz and/or the 30-37.5 MHz radio frequency (RF) band. The data may be received from a networked data store. Execution of the models may identify health issues in substantially real time, and the operation of one or more medical devices may be modified and/or a communication may be generated.","1. A system, comprising; a sensor interface configured to receive sensor signals from one or more physiological wireless sensors;one or more computing devices;a non-transitory memory medium that stores instructions that when executed by the one or more computing devices causes the system to perform operations comprising: register a plurality of physiological sensors configured to be worn by or implanted in a user via a device registry service, wherein respective physiological sensor Internet Protocol (IP) addresses are stored;associate in memory respective identifiers, comprising respective IP addresses, of the plurality of physiological sensors with the user;receive over a network sensor data from the plurality of physiological sensors associated with the user, the plurality of physiological sensors comprising at least a first physiological sensor of a first type and a second physiological sensor of a second type,store the received sensor data in a medical information data store;encrypt Protected Health Information contained within the network sensor data using a symmetric or asymmetric-key block cipher unique to the user;receive in association with the network sensor data at least one unique identifier, comprising at least one physiological sensor IP address;utilize the at least one unique identifier to locate information regarding treatment information for the user;access, by a rules execution engine, rules and respective rule data quantity thresholds, including at least two quantity thresholds comprising:a first quantity threshold for sensor data from the first physiological sensor, anda second quantity threshold for sensor data from the second physiological sensor,wherein the first quantity threshold is different than the second quantity threshold;perform unit conversions, normalization, formatting, and data filtering on sensor data from at least one physiological sensor;evaluate, by the rules execution engine, the accessed rules and data quantity thresholds, including: the first quantity threshold for sensor data from the first physiological sensor, andthe second quantity threshold for sensor data from the second physiological sensor to determine:which biological event predictive models, in a data store of biological event predictive models, are to be used to predict respective future user outcomes to respective medical interventions or respective failures to provide respective medical interventions, andwhether the determined biological event predictive models in the data store of biological event predictive models to respective medical interventions or respective failures to provide respective medical interventions are to be executed,wherein a given biological event predictive model predicts a future user outcome at least one year in the future to a medical intervention or a failure to provide a medical intervention, and the given biological event predictive model is based at least in part on medical survey data for a plurality of patients, and comprises at least one of:a linear model,a logistic model,a cumulative logit model,a multinomial model, ora proportional hazard model;at least partly in response to the rule execution engine determining that a given biological event predictive model is to be executed, execute the given biological event predictive model using at least a portion of the received sensor data to provide a biological prediction of a first future user outcome for the user at least one year in the future to a potential first medical intervention or a failure to provide the potential first medical intervention for the user;based at least in part on the biological prediction for the user made by the executed given biological event predictive model, determine whether a first action is to be taken, the first action comprising transmission of an electronic notification and/or a modification of an operation of a first medical device; at least partly in response to determining that the first action is to be taken, transmit the electronic notification and/or cause the operation of a first medical device of the user to be modifiedutilize the medical data store, storing received sensor data, to update at least one biological prediction model;wherein the first physiological sensor and the second physiological sensor are configured to communicate with each other over a body area network, and at least one of the physiological sensors comprises a biomedical microelectromechanical (MEMs) system configured to perform sample preconditioning and wirelessly communicate preconditioned sample data over: a 2360-2400 MHz radio frequency band, a 30-37.5 MHz radio frequency band, and/or Bluetooth.","14","15/194215","2016-06-27","2016-0354039","2016-12-08","10806404","2020-10-20","HEALTH OUTCOMES SCIENCES, INC.","Gabriel Enrique  Soto | John Albert  Spertus","","","","A61B-0005/7275","A61B-0005/7275 | A61B-0005/0022 | A61B-0005/01 | A61B-0005/02055 | A61B-0005/14532 | A61B-0005/14542 | A61B-0005/4836 | A61B-0005/6824 | A61B-0005/6831 | A61B-0005/6846 | A61B-0005/74 | G06N-0005/046 | G06Q-0040/08 | G06Q-0050/24 | G16H-0010/20 | G16H-0015/00 | G16H-0050/20 | G16H-0050/30 | G16H-0050/50 | G16H-0050/70 | A61B-0005/021 | A61B-0005/02444 | A61B-2560/0214 | A61B-2560/0475 | A61B-2562/028","A61B-005/00","A61B-005/00 | A61B-005/0205 | A61B-005/145 | A61B-005/01 | G06Q-040/08 | G06Q-050/24 | G16H-015/00 | G16H-010/20 | G16H-050/50 | G16H-050/30 | G16H-050/70 | G16H-050/20 | G06N-005/04 | A61B-005/024 | A61B-005/021","","","","","","4920043001101"
"US","US","P","B2","Wearable device and control method therefor","A wearable device according to an embodiment of the present disclosure of the present inventive concept, which is worn on a user's head to apply an electrical stimulation to a brain or measure brain waves from the brain, comprises: a wearing identification unit for identifying a worn state of the wearable device using a first sensor module detecting the worn state of the wearable device of a user; an electrode unit for applying an electrical stimulation to a user's brain or measuring brain waves from the user's brain; and a control unit for controlling the electrode unit to start the electrical stimulation or a brain wave measurement on the basis of the identification result by the wearing identification unit.","1. A wearable device, which is worn on a head of a user and applies an electrical stimulation to a brain of the user or measures brain waves from the brain of the user, the wearable device comprising: a first sensor module configured to sense a wearing state of the wearable device by the user;a wearing identification unit configured to check the wearing state of the wearable device based on information sensed from the first sensor module;a second sensor module configured to sense an identification of the user;a user identification unit having an input module and a storage unit storing information on a user account that is previously registered, and configured to identify the user based on the sensed identification of the user and the stored information on the user account;an electrode unit configured to apply an electrical stimulation to the brain of the user and measure brain waves from the brain of the user; anda control unit configured to control the electrode unit to start the electrical stimulation or the brain wave measurement,wherein when a corresponding user account stored in the storage unit is identified based on the sensed identification of the user from the second sensor and the wearable device is worn in predetermined correct direction based on the information sensed from the first sensor module, the control unit controls the electrode unit to start the electrical stimulation or the brain wave measurement, andwherein the first sensor module comprises at least one of an impedance measurement sensor for sensing impedance through the electrode unit, a decompression sensor for measuring pressure applied to the wearable device, an acceleration sensor for measuring acceleration of the wearable device, an illuminance sensor for measuring skin contact of the wearable device, a proximity sensor for measuring a skin distance of the wearable device, and a camera sensor for capturing an image of the user wearing the wearable device, andthe wearing identification unit checks a wearing position or direction of the wearable device based on at least one of a measured impedance, a measured pressure, a measured acceleration, a measured illuminance, a measured distance, and a captured image.","8","15/500262","2015-07-06","2017-0215753","2017-08-03","10799133","2020-10-13","Y-BRAIN INC.","Kiwon  Lee","10-2014-0101639","KR","2014-08-07","A61B-0005/04001","A61B-0005/04001 | A61B-0005/0476 | A61B-0005/6803 | A61N-0001/0456 | A61N-0001/20 | A61N-0001/36025 | G06F-0003/015 | A61B-0005/0531 | A61B-0005/117 | A61B-0005/1172 | A61B-0005/1176 | A61B-0005/6814 | A61B-0005/6843 | A61B-0005/6844 | A61B-0005/7405 | A61N-0001/04 | A61N-0001/0484","A61B-005/04","A61B-005/04 | A61N-001/20 | A61N-001/04 | A61B-005/0476 | A61B-005/00 | A61N-001/36 | A61B-005/117 | A61B-005/053 | A61B-005/1172 | A61B-005/1171 | G06F-003/01","","","","","","4920042001034"
"US","US","P","B2","Tendon device for suit type robot for assisting human with physical strength","A tendon device for a suit type robot which includes: a first wire and a second wire respectively fixed on a front portion and a rear portion of a joint of a user, and moving in a lengthwise direction thereof according to flexion-extension of the joint; a tendon driver including a first tendon module including a first pulley, and a second tendon module including a second pulley; a first pulley encoder measuring a rotary angle of the first pulley; a second pulley encoder for measuring a rotary angle of the second pulley; a controller configured to calculate tensions of the first wire and the second wire based on the rotary angle of the first and second pulleys in order to generate a control signal; and a driver configured to provide the first tendon module and the second tendon module with a driving power.","1. A tendon device for a wearable suit robot, the tendon device comprising: a first wire and a second wire respectively adapted to be fixed on a front portion and a rear portion of a joint of a user, and varying in length thereof according to flexion-extension of the joint;a tendon driver comprising a first tendon module including a first pulley on which the first wire is wound, and a second tendon module including a second pulley on which the second wire is wound;a first pulley encoder included in the first tendon module for measuring a rotary angle of the first pulley;a second pulley encoder included in the second tendon module for measuring a rotary angle of the second pulley;a controller configured to calculate tensions of the first wire and the second wire based on the rotary angle of the first pulley measured by the first pulley encoder and the rotary angle of the second pulley measured by the second pulley encoder, in order to generate a control signal;a driver configured to provide the first tendon module and the second tendon module with a driving power via a rotary shaft based on the control signal transferred from the controller;a housing having an internal space;a driving axis member crossing the internal space of the housing, the driving axis member coaxially coupled to the first tendon module and the second tendon module as penetrating therethrough, and wherein the driving axis member is connected to the rotary shaft of the driver and configured to transfer the driving power to the first tendon module and the second tendon module from the driver;a first torsion spring provided at the first pulley and the driving axis member to generate torsion; anda second torsion spring provided at the second pulley and the driving axis member to generate torsion.","10","15/796145","2017-10-27","2018-0116851","2018-05-03","10799381","2020-10-13","DAEGU GYEONGBUK INSTITUTE OF SCIENCE AND TECHNOLOGY","Hee Don  Lee","10-2016-0141606","KR","2016-10-28","A61F-0005/0102","A61F-0005/0102 | A61H-0003/00 | G06F-0003/016 | A61B-0005/1071 | A61B-0005/224 | A61B-0005/4528 | A61F-2002/5093 | A61H-0001/0259 | A61H-0001/0262 | A61H-2201/1671 | A61H-2201/5007 | A61H-2201/5012 | A61H-2201/5061 | A61H-2201/5097","A61F-005/01","A61F-005/01 | G06F-003/01 | A61H-003/00 | A61B-005/107 | A61B-005/22 | A61B-005/00 | A61F-002/50 | A61H-001/02","","","","","","4920042001281"
"US","US","P","B2","Computer system integration","A system and method of integrating a first computer and a second computer is disclosed. The first computer executes a software application having a graphical user interface. The second computer renders the graphical user interface, receives an identification of an event that has occurred in the software application, and identifies an action to be performed by the second computer in response to the occurrence of the event, the action being identified from a predefined sequence of actions. The second computer performs the identified action to modify the rendering of the graphical user interface.","1. A method of controlling a device for generating radiation, for use in a radiotherapy system comprising a first computer and a second computer, the first computer executing a treatment control program for controlling the device for generating radiation, the treatment control program having a first graphical user interface, the method being performed at the second computer and comprising: rendering the first graphical user interface, in a screen displayed on a display device, such that the treatment control program remains visible during a radiotherapy session, wherein the screen includes one or more display areas;receiving an identification of an event that has occurred in the treatment control program;identifying an action to be performed by the second computer in response to the occurrence of the event, wherein the action is identified from a predefined sequence of actions; andperforming the identified action to modify the rendering of the first graphical user interface so that the treatment control program is displayed on a largest of the one or more display areas of the screen.","20","15/053973","2016-02-25","2016-0243380","2016-08-25","10799718","2020-10-13","ELEKTA LIMITED","Adrian Maxwell  Smith","2015003170","GB","2015-02-25","A61N-0005/1048","A61N-0005/1048 | G06F-0003/0481 | G06F-0003/04845 | G06F-0003/1454 | G06F-0009/452 | G06F-0009/542 | G09G-0005/12 | G09G-0005/14 | H04N-0007/18 | A61N-2005/1059 | A61N-2005/1074 | G06F-2209/545 | G09G-2380/08","G06F-003/048","G06F-003/048 | A61N-005/10 | G06F-009/451 | G06F-009/54 | G06F-003/0481 | G06F-003/0484 | G06F-003/14 | G09G-005/12 | G09G-005/14 | H04N-007/18","","","","","","4920042001615"
"US","US","P","B2","Training scripts","A training script device is described that conveniently allows a user to create a training script defining one or more steps of a workout routine, where each step may include an activity, a duration for performing that activity, and an intensity at which the activity is to be performed. Further, one or more steps of the training script can be self-starting in response to performance data detected by sensors of training script device executing the training script. This conveniently frees the athlete from having to continuously monitor the status of his or her workout activities. Still further, the training script device conveniently allows a user to transfer training scripts to other training script devices, so that athletes can share successful training scripts.","1. A device for creating a training script for a workout, comprising a user interface module that prompts a user to input data specifying a step in a training script;a control module that creates training steps to operate a user computing device to display a prompt for the training steps and to compile the training steps into the training script;a script database that receives and stores the training script; anda device interface module that synchronizes one or more training scripts in the script database with the user computing device, wherein the user interface module allows the user to define a user profile, the user profile having a group of training scripts relating to favorite workouts, and wherein the group of training scripts relating to the favorite workouts are synchronized with the user computing device by the device interface module during a synchronization operation.","13","15/341290","2016-11-02","2017-0136300","2017-05-18","10799762","2020-10-13","NIKE, INC.","James W.  Clark | Theodore H.  Helprin | Albert  Shum","","","","A63B-0024/0075","A63B-0024/0075 | A61B-0005/021 | A61B-0005/02438 | A61B-0005/1112 | A61B-0005/1118 | A61B-0005/486 | A61B-0005/681 | A63B-0024/00 | A63B-0069/00 | A63B-0071/0619 | G06Q-0010/06311 | G06Q-0010/109 | G09B-0005/02 | G09B-0019/00 | G09B-0019/0038 | G09B-0023/303 | G16H-0020/30 | A61B-0005/145 | A61B-2503/10 | A61B-2562/0219 | A63B-2024/0078 | A63B-2071/0663 | A63B-2220/12 | A63B-2220/17 | A63B-2220/34 | A63B-2220/40 | A63B-2225/20 | A63B-2225/50 | A63B-2230/04 | A63B-2230/207 | A63B-2230/30 | A63B-2230/50 | H04L-0067/306 | Y10S-0482/901","G16H-020/30","G16H-020/30 | G09B-005/02 | G09B-019/00 | G06Q-010/10 | G06Q-010/06 | G09B-023/30 | H04L-029/08 | A63B-024/00 | A61B-005/021 | A61B-005/024 | A61B-005/11 | A61B-005/00 | A63B-069/00 | A63B-071/06 | A61B-005/145","","","","","","4920042001659"
"US","US","P","B2","Calculating pace and energy expenditure from athletic movement attributes","Systems and methods configured to process motion data associated with a user. The systems and methods are configured to receive motion data from a sensor, calculate motion attributes from the data, and classify the motion data using one or more mathematical models. Attributes may be calculated without classifying the motion data into an activity. Attributes may be compared to mathematical models. Motion data within the models and attributes of the user may be independent of any activity type. Attributes may be compared to select an energy expenditure model from one or more energy expenditure models, or an activity classification model, from the one or more activity classification models. An energy expenditure, or a classification of received data as a linear travel motion, may then be calculated.","1. A unitary apparatus configured to be worn on a user, comprising: a processor;a sensor configured to capture motion data of the user;a non-transitory computer-readable medium comprising computer-executable instructions that when executed by the processor perform at least: receiving, from the sensor and via one or more wireless networks, while being worn by the user, a data stream comprising one or more data points generated as a result of a motion of the user;transforming the one or more data points into a dataset representing a motion of the user;without classifying the one or more data points into an activity type, calculating a first set of one or more motion attributes from the dataset;determining, for each model of one or more models, a probability that each model is a best-match to the first set of one or more motion attributes based on a regression function and a comparison of the first set of one or more motion attributes from the dataset to a second set of one or more motion attributes in each model of the one or more models, wherein the second set of one or more motion attributes and the first set of one or more motion attributes are independent of any activity type, and wherein the first set and the second set have a same number of motion attributes;selecting, based on the regression function and a result of the comparison of the first set of one or more motion attributes from the dataset to the second set of one or more motion attributes of the one or more models, a first model, from the one or more models, as a best-match to the first set of one or more motion attributes from the dataset, wherein the first model is selected as the best-match based on a determination that the first model is associated with a highest probability of each of the probabilities; andinputting, into the first model, the first set of one or more motion attributes from the dataset;receiving, from the first model, an output indicating one or more characteristics associated with the motion of the user.","20","14/514093","2014-10-14","2016-0213974","2016-07-28","10802038","2020-10-13","NIKE, INC.","Santoshkumar  Balakrishnan | Manan  Goel | Bradley W.  Wilkins | Corey  Dow-Hygelund | Jeff  Hazel | John  Schmitt","","","","G01P-0013/00","G01P-0013/00 | A61B-0005/0022 | A61B-0005/024 | A61B-0005/0205 | A61B-0005/02438 | A61B-0005/1118 | A61B-0005/1123 | A61B-0005/4866 | A61B-0005/6823 | A61B-0005/7235 | A61B-0005/7246 | A61B-0005/7278 | A63B-0024/0006 | A63B-0024/0062 | G01B-0021/00 | G01P-0015/00 | G01P-0015/18 | G06F-0001/163 | G06F-0003/011 | G06F-0003/014 | G06F-0003/017 | G06K-0009/00348 | G06K-0009/00543 | G06N-0005/04 | G06N-0020/00 | G16H-0040/67 | A61B-0005/002 | A61B-0005/0024 | A61B-0005/0059 | A61B-0005/01 | A61B-0005/0833 | A61B-0005/1112 | A61B-0005/4806 | A61B-0005/681 | A61B-0005/6804 | A61B-0005/6807 | A61B-0005/6898 | A61B-2562/0219 | A61B-2562/0247 | A63B-2024/0015 | A63B-2024/0068 | A63B-2230/06 | G06F-0019/3481 | G16H-0020/30","A61B-005/00","A61B-005/00 | G01P-013/00 | G01B-021/00 | G01P-015/00 | G06N-020/00 | A61B-005/0205 | A61B-005/024 | A61B-005/11 | G16H-040/67 | G06F-003/01 | G06K-009/00 | G01P-015/18 | A63B-024/00 | G06F-001/16 | G06N-005/04 | G16H-020/30 | A61B-005/01 | A61B-005/083 | G06F-019/00","","","","","","4920042003922"
"US","US","P","B2","Technologies for enhancing contrast of an illumination marker","An illumination marker includes a light source and an optical attenuation cover coupled to the light source. The optical attenuation cover is configured to attenuate an intensity of light that passes through the optical attenuation cover based on a length of an optical path of the light through the optical attenuation cover. In some embodiments, the optical attenuation cover may be embodied as a physical barrier cover and include light-blocking structures. Additionally, in some embodiments, the illumination maker may include a diffusive or retro-reflective core rather than the light source.","1. An illumination marker comprising: a light source to generate light; andan optical attenuation cover coupled to the light source, wherein the optical attenuation cover is to attenuate an intensity of light that passes through the optical attenuation cover based on a length of an optical path of the light through the optical attenuation cover and wherein the optical attenuation cover is to attenuate an intensity of background light that passes through the optical attenuation cover at a greater amount than the optical attenuation cover attenuates an intensity of the light generated by the light source.","23","15/787695","2017-10-18","2019-0113662","2019-04-18","10802182","2020-10-13","INTEL CORPORATION","Nizan  Horesh","","","","G02B-0005/126","G02B-0005/126 | A61B-0005/1127 | F21K-0009/64 | F21V-0003/02 | F21V-0019/006 | G02B-0005/003 | G02B-0005/0236 | G02B-0005/12 | G02B-0005/22 | G06F-0003/0304 | G02B-0001/04 | G02B-2207/123 | G06K-0009/2054","G02B-005/12","G02B-005/12 | G02B-005/126 | F21V-003/02 | F21K-009/64 | G02B-005/02 | F21V-019/00 | A61B-005/11 | G06F-003/03 | G02B-005/22 | G02B-005/00 | G06K-009/20 | G02B-001/04","","","","","","4920042004065"
"US","US","P","B2","Assigning a tool to a pick-up gesture","A method includes determining a first position of a thumb and a first position of an index finger at a first time; calculating a first distance between the thumb and the index finger at the first time based upon the first position of the thumb and index finger; determining a second position of the thumb and index finger at a second time, the second time being relatively later in time than the first time; calculating a second distance between the thumb and the index finger at the second time, based upon the second position of the thumb and index finger; identifying a pick-up gesture based upon the first distance and the second distance; selecting a first tool from a set of tools based upon a tool position of the first tool, the first tool being a real tool; and assigning the first tool to the pick-up gesture.","1. A method for assigning a first tool to a pick-up gesture, comprising: determining via a first position detector, as a first determination, a first position of a thumb of a hand of a person at a first time and a first position of an index finger of the hand at the first time;calculating via processing circuitry, as a first calculation, a first distance between the thumb and the index finger at the first time, the first distance based upon the first position of the thumb and the first position of the index finger;determining via the first position detector, as a second determination, a second position of the thumb at a second time and a second position of the index finger at the second time, the second time being later in time than the first time;calculating via the processing circuitry, as a second calculation, a second distance between the thumb and the index finger at the second time, the second distance based upon the second position of the thumb and the second position of the index finger;identifying via the processing circuitry, the pick-up gesture based upon the first distance and the second distance;selecting via the processing circuitry, the first tool from a set of tools based upon a tool position of the first tool, the first tool being a real tool;assigning via the processing circuitry, the first tool to the pick-up gesture; andproviding via an interface, a sequence table including at least one data set representing the first tool and at least one time of the pick-up gesture.","29","16/039445","2018-07-19","2019-0033977","2019-01-31","10802597","2020-10-13","SIEMENS HEALTHCARE GMBH","Cynthia  Von Wendorff | Barbara  Laermann | Nitin  Bagrecha | Anton  Ebert","2017-183006","EP","2017-07-25","G06F-0003/017","G06F-0003/017 | A61B-0034/30 | A61B-0034/74 | G06F-0003/011 | G06F-0003/0485 | G06F-0003/04815 | G06F-0003/04845 | G06K-0009/00355 | G06K-0009/00389 | A61B-2017/00207 | A61B-2034/741 | G06K-0009/00671 | G06T-0019/006","G06F-003/01","G06F-003/01 | G06F-003/0485 | G06F-003/0484 | G06F-003/0481 | G06K-009/00 | A61B-034/00 | A61B-034/30 | G06T-019/00 | A61B-017/00","","","","","","4920042004476"
"US","US","P","B2","Photosensitive component, display device and fingerprint identification method","The present application discloses a photosensitive component, a display device and a fingerprint identification method. The photosensitive component comprises a first electrode layer, a first photosensitive material layer arranged on the first electrode layer, a second electrode layer arranged on the first photosensitive material layer, a second photosensitive material layer arranged on the second electrode layer, and a third electrode layer arranged on the second photosensitive material layer. The first electrode layer is made of an opaque material, and the third electrode layer is made of a transparent material.","1. A photosensitive component, comprising: a first electrode layer;a first photosensitive material layer arranged on the first electrode layer;a second electrode layer arranged on the first photosensitive material layer;a second photosensitive material layer arranged on the second electrode layer; anda third electrode layer arranged on the second photosensitive material layer,wherein the first electrode layer is made of an opaque material, and the third electrode layer is made of a transparent material,wherein the first photosensitive material layer is connected with the second photosensitive material layer,wherein a top portion of the first photosensitive material layer comprises a first part and a second part, wherein the first part is covered by the second electrode layer, and the second part is not covered by the second electrode layer, and is connected with the second photosensitive material layer,wherein the photosensitive component further comprises: a first connection line arranged in close contact with a first side surface of the first photosensitive material layer, and a second connection line arranged in close contact with a second side surface of the second photosensitive material layer, andwherein the second electrode layer is connected with the first connection line, and the third electrode layer is connected with the second connection line.","14","16/163670","2018-10-18","2019-0122019","2019-04-25","10803279","2020-10-13","BOE TECHNOLOGY GROUP CO., LTD. | ORDOS YUANSHENG OPTOELECTRONICS CO., LTD.","Hao  Zhang","2017-11000631","CN","2017-10-24","G06K-0009/0002","G06K-0009/0002 | A61B-0005/1172 | G06F-0003/0421","A61B-005/1172","A61B-005/1172 | G06K-009/00 | G06F-003/042","","","","","","4920042005149"
"US","US","P","B2","Sessions and groups","Athletic activity may be tracked while providing encouragement to perform athletic activity. For example, energy expenditure values and energy expenditure intensity values may be calculated and associated with a duration and type of activity performed by an individual. These values and other movement data may be displayed on an interface in a manner to motivate the individual and maintain the individual's interest. The interface may track one or more discrete ""sessions"". The sessions may be associated with energy expenditure values during a duration that is within a second duration, such as a day, that is also tracked with respect to variables, such as energy expenditure. Other individuals (e.g., friends) may also be displayed on an interface through which a user's progress is tracked. This may allow the user to also view the other individuals' progress toward completing an activity goal and/or challenge.","1. A computer-implemented method comprising: receiving movement data from a sensor of a first device worn by a first user and from a plurality of individual body worn sensors worn by a plurality of users,automatically initiating an athletic activity measurement session during a predetermined first time period;calculating energy expenditure values for the first user and the plurality of users for the predetermined first time period, based on the received movement data;receiving locational data for the first user from a location-determining sensor of the first device, and for the plurality of users during a second time period within the first time period;determining an activity type of the first user and an at least one of the plurality of users, based on the received movement data and locational data, wherein the first user and the at least one of the plurality of users are within a predetermined distance of one another;determining, based on the received locational data that the first user and the at least one of the plurality of users have remained stationary during the second time period and pausing the session;determining that the first user and the at least one of the plurality of users are interested in participating in a common athletic activity, based on the calculated energy expenditure values; andtransmitting a request to the first user and the at least one of the plurality of users, to form or join a group participating in the common athletic activity.","15","15/608529","2017-05-30","2017-0262699","2017-09-14","10803305","2020-10-13","NIKE, INC.","Kristen L.  White | Michael L.  Orenstein | Jenny  Campbell | Christina S.  Self | Elizabeth  Walker","","","","G06K-0009/00348","G06K-0009/00348 | A61B-0005/0022 | A61B-0005/1118 | A61B-0005/4866 | A61B-0005/7435 | G04F-0010/00 | G06F-0016/487 | G06F-0019/00 | G06F-0019/3481 | G06Q-0050/01 | G16H-0020/30 | A61B-0005/681 | A61B-0005/6802 | A61B-0005/6807 | G06F-0016/489 | G06F-0019/3418 | G16H-0040/63 | Y02A-0090/26","G06K-009/00","G06K-009/00 | G06F-016/487 | A61B-005/00 | G06F-019/00 | A61B-005/11 | G04F-010/00 | G06Q-050/00 | G16H-020/30 | G06F-016/48 | G16H-040/63","","","","","","4920042005175"
"US","US","P","B2","Emotion estimating apparatus","Provided is an. emotion. estimating apparatus capable of precisely estimating an emotion and mental state of a measurement subject by using a non-contact pulse detection technology. The emotion estimating apparatus forcibly performs re-sampling processing of digital biometric data generated by converting a heart rate signal to digital data after extracting data for one cycle at an RR interval, and obtains coefficients of harmonic components by a DCT conversion processing unit. From the coefficients of the harmonic components, AC components are removed by LPFs, whereby a coefficient data array is obtained.. The coefficient data array is compared to a dictionary data group, in which dictionary data is a characteristic quantity indicating an emotion or mental state, and a similarity therebetween is calculated, whereby an emotion or mental state of a subject is estimated on the basis of the heart rate signal of the subject.","1. An emotion estimating apparatus comprising: a re-sampling processing unit that extracts data for one cycle based on an RR interval from digital biometric data converted from a heart rate signal to digital data and converts the data to a predetermined number of samples;a DCT conversion processing unit that performs discrete cosine transform on normalized digital biometric data whose number of samples is fixed by the re-sampling processing unit;a low pass filter group that reduces an AC component for each coefficient data for a coefficient data array output from the DCT conversion processing unit; andan estimating processing unit that estimates a most similar emotion or mental state by comparing the coefficient data array obtained from the low pass filter group with a dictionary data group that is an aggregation of dictionary data created for each emotion. or mental state.","2","16/497846","2018-03-08","2020-0250446","2020-08-06","10803335","2020-10-13","KYUSHU INSTITUTE OF TECHNOLOGY","Yasushi  Sato","2017-063539","JP","2017-03-28","G06K-0009/00845","G06K-0009/00845 | A61B-0005/18 | G06F-0003/011","G06K-009/00","G06K-009/00 | G06F-003/01 | A61B-005/18","","","","","","4920042005205"
"US","US","P","B2","Apparatus and method for determining user's mental state","An apparatus for determining a user's mental state in a terminal is provided. The apparatus includes a data collector configured to collect sensor data; a data processor configured to extract feature data from the sensor data; and a mental state determiner configured to provide the feature data to an inference model to determine the user's mental state.","1. A terminal system, comprising: one or more processors configured to:collect sensor data generated as a user is using a terminal to compose a message;determine a pictorial representation for the user, based on extracted feature data from the sensor data, the extracted feature data reflecting an observed emotion of the user; andcontrol an implementation of one or more measures based on the pictorial representation for the user.","36","15/882135","2018-01-29","2018-0150751","2018-05-31","10803389","2020-10-13","Samsung Electronics Co., Ltd.","Ho-Sub  Lee","10-2012-0126804","KR","2012-11-09","G06N-0005/02","G06N-0005/02 | A61B-0005/165 | G06N-0007/005 | G06N-0099/005 | A61B-0005/6898 | A61B-0005/7267 | H04L-0051/20","G06F-003/041","G06F-003/041 | G06N-005/02 | A61B-005/16 | G06N-007/00 | G06N-099/00 | A61B-005/00 | H04L-012/58","","","","","","4920042005259"
"US","US","P","B2","Presenting geographic search results using location projection and time windows","Users within transit in a vehicle may initiate location queries to fulfill a set of interests, such as stops for food, fuel, and lodging. A device may fulfill the queries according to various factors, such as the distance of nearby locations to the user or to another location specified by the user, and the popularity of various locations. However, the user may not have specified or even chosen a route, and may wish to have interests fulfilled at a later time (e.g., stopping for food in 30 minutes), and a presentation of search results near the user's current location may be unhelpful. Presented herein are techniques for fulfilling location queries that involve predicting a route of the user, and identifying a timing window for the query results (e.g., locations that are likely to be near the user's projected location when the wishes to stop for food in 30 minutes).","1. A method, comprising: identifying a transit contingency corresponding to historic times and frequencies at which a user has performed an action;predicting a route of a vehicle and a projected location of the vehicle along the route during a time window corresponding to the transit contingency and a location query for locations;identifying a list of locations that satisfy the location query and that are within a proximity range of the projected location;preferentially sorting and filtering the list of locations based upon one or more factors to generate a sorted and filtered list of locations, wherein a first location is excluded from the list of locations based upon a first factor indicating that the user dislikes an aspect of the first location;generating query results comprising the sorted and filtered list of locations that excludes the first location; andpresenting the query results, as the sorted and filtered list of locations, for the location query.","20","16/509571","2019-07-12","2019-0340926","2019-11-07","10803747","2020-10-13","INRIX, Inc.","David  DiMeo | Andreas  Hecht","","","","G08G-0001/096791","G08G-0001/096791 | A61B-0005/02055 | A61B-0005/0476 | A61B-0005/4845 | B60R-0016/0236 | B60W-0030/143 | B60W-0040/08 | B60W-0040/09 | B64C-0039/024 | G01C-0021/3415 | G01C-0021/3469 | G01C-0021/3617 | G01C-0021/3655 | G01C-0021/3667 | G01C-0021/3682 | G05D-0001/0011 | G05D-0001/0088 | G05D-0001/021 | G06F-0016/29 | G06N-0020/00 | G06Q-0020/102 | G06Q-0030/0283 | G06Q-0040/08 | G07B-0015/00 | G07B-0015/063 | G07C-0005/008 | G08G-0001/012 | G08G-0001/0112 | G08G-0001/0129 | G08G-0001/0141 | G08G-0001/0145 | G08G-0001/065 | G08G-0001/07 | G08G-0001/093 | G08G-0001/097 | G08G-0001/0962 | G08G-0001/0965 | G08G-0001/0967 | G08G-0001/096725 | G08G-0001/096741 | G08G-0001/096775 | G08G-0001/096811 | G08G-0001/096822 | G08G-0001/096838 | H04B-0001/3822 | H04B-0007/18504 | H04L-0009/3247 | H04L-0067/02 | H04L-0067/306 | H04M-0015/60 | H04W-0004/024 | H04W-0004/029 | H04W-0004/40 | H04W-0004/42 | H04W-0004/50 | H04W-0012/08 | A61B-0005/024 | A61B-0005/0531 | B60W-2040/0809 | B60W-2040/0872 | B60W-2540/22 | B60W-2552/00 | B60W-2555/20 | B60W-2710/1044 | B60W-2710/18 | B60W-2720/10 | B64C-2201/123 | G01C-0021/3608 | G06Q-0050/30 | G06Q-2240/00 | H04W-0004/48","B60W-040/00","B60W-040/00 | G08G-001/0967 | H04W-004/50 | G06N-020/00 | G06F-016/29 | H04W-004/024 | H04W-004/029 | G08G-001/01 | B60W-040/08 | B60W-040/09 | G08G-001/09 | G07B-015/06 | G08G-001/0968 | G08G-001/097 | B60W-030/14 | G05D-001/00 | G07C-005/00 | A61B-005/0205 | A61B-005/0476 | A61B-005/00 | G05D-001/02 | H04B-001/3822 | H04L-029/08 | B64C-039/02 | H04B-007/185 | G06Q-020/10 | G06Q-030/02 | H04W-012/08 | H04M-015/00 | G06Q-040/08 | H04L-009/32 | B60R-016/023 | G07B-015/00 | G08G-001/065 | G01C-021/36 | H04W-004/42 | H04W-004/40 | G01C-021/34 | G08G-001/07 | G08G-001/0962 | G08G-001/0965 | H04W-004/48 | A61B-005/024 | A61B-005/053 | G06Q-050/30","","","","","","4920042005614"
"US","US","P","B2","Information processing device, information processing method, and program for decreasing reduction of visibility","There is provided an information processing device, an information processing method, and a program that make it possible to decrease reduction in a recognition rate corresponding to the amount of exercise of a user wearing a wearable device. Acceleration information is acquired as exercise state information, and movement speed is calculated. If the movement speed exceeds certain speed, a plurality of pieces of information is displayed in a time-division manner for a certain amount of information each with which amount a recognition rate is not decreased, whereby a plurality of pieces of information is displayed while reduction in the recognition rate is controlled. The present technology can be applied to a wearable device.","1. An information processing device comprising: an activity state information acquisition unit configured to acquire activity state information, wherein the activity state information includes a user'ss exercise intensity; anda display mode setting unit configured to set a display mode from among a plurality of display modes on the basis of the activity state information acquired by the activity state information acquisition unit,wherein the plurality of display modes includes a first display mode of simultaneously displaying first information and second information different from the first information, anda second display mode of displaying the first information and the second information at different timing,wherein the display mode setting unit sets the first display mode of simultaneously displaying the first information and the second information in a case where the exercise intensity is weaker than a first threshold value, and sets the second display mode of displaying the first information and the second information at different timing in a case where the exercise intensity is stronger than the first threshold value,wherein, in a case where the second display mode of displaying the first information and the second information at different timing is set, the display mode setting unit sets a display switching time during which the first information is displayed and switched to the second information,wherein the display switching time is set based on the activity state information,wherein the display switching time is set to a first time based on the user'ss exercise intensity being a first level, and the display switching time is set to a second time longer than the first time based on the user'ss exercise intensity being a second level stronger than the first level, andwherein the activity state information acquisition unit and the display mode setting unit are each implemented via at least one processor.","19","15/762896","2016-09-16","2018-0234661","2018-08-16","10805574","2020-10-13","SONY CORPORATION","Tsubasa  Tsukahara | Jun  Kimura | Katsuya  Hyodo | Daisuke  Nakata","2015-193420","JP","2015-09-30","H04N-0007/007","H04N-0007/007 | A61B-0005/1118 | A61B-0005/6803 | A61B-0005/7445 | G02B-0027/01 | G06F-0003/011 | G06F-0003/0481 | G06F-0003/0487 | G06K-0009/00671 | G06T-0019/006 | H04N-0005/64 | A61B-0005/01 | A61B-0005/02438 | A61B-0005/0476 | A61B-0005/0488 | A61B-0005/1113 | A61B-0005/4266 | G02B-2027/0178","A61B-005/00","A61B-005/00 | A61B-005/11 | G02B-027/01 | H04N-007/00 | H04N-005/64 | G06F-003/0487 | G06F-003/01 | G06F-003/0481 | G06K-009/00 | G06T-019/00 | A61B-005/024 | A61B-005/01 | A61B-005/0476 | A61B-005/0488","","","","","","4920042007428"
"US","US","P","B2","Portable apparatus and method of changing screen of content thereof","A portable apparatus and a method of changing a content screen of the portable apparatus are provided. The portable apparatus includes changing a displayed content in response to an increase in a visual fatigue and a method of changing a content screen of the portable apparatus. Some of disclosed various embodiments provide a portable apparatus that calculates a visual fatigue by using user electroencephalogram (EEG) information received from a wearable apparatus and changing a displayed content into another content in response to an increase in the calculated visual fatigue, and a method of changing a content screen of the portable apparatus.","1. A method of changing a content screen of a portable apparatus, the method comprising: displaying content;determining whether a value of a visual fatigue is higher than a threshold value using a model trained by machine learning;based on the determining that the value of the visual fatigue is higher than the threshold value, displaying a user interface (UI) indicating an increase of the visual fatigue and a guide for changing a layout of the content on the content; andbased on a user request being input while the UI is displayed, changing the layout of the content.","18","16/728482","2019-12-27","2020-0129083","2020-04-30","10791954","2020-10-06","Samsung Electronics Co., Ltd.","Sun-ho  Moon | Jong-ho  Choi | Se-jin  Kwak | Sung-soo  Kim | Hwa-kyung  Kim | Jong-youb  Ryu | Sang-hyup  Lee","10-2015-0061725","KR","2015-04-30","A61B-0005/0482","A61B-0005/0482 | A61B-0005/0002 | A61B-0005/0478 | A61B-0005/6803 | A61B-0005/6898 | A61B-0005/742 | A61B-0005/7475 | G06F-0003/013 | G06F-0003/015 | G06F-0003/04886 | G06K-0009/00496 | G06K-0009/00597 | G16H-0040/63 | A61B-0003/00 | A61B-0003/113 | A61B-0005/048 | G06F-2203/04806","A61B-005/0482","A61B-005/0482 | G06F-003/01 | A61B-005/00 | G06F-003/0488 | A61B-005/0478 | G06K-009/00 | G16H-040/63 | A61B-003/00 | A61B-005/048 | A61B-003/113","","","","","","4920041001037"
"US","US","P","B2","Dynamically controlled treatment protocols for autonomous treatment systems","Systems, and methods relate to a medical device receiving a treatment parameter operating point within a first operating region defined by a first set of operating points for which automatic incremental adjustment of a parameter in the current operation is permitted. In an illustrative example, incremental adjustment may use artificial intelligence based on patient feedback and sensor measurement of outcomes. Some exemplary devices may receive a request to alter the current treatment parameter operating point to a second treatment parameter operating point outside the first operating region and in a second operating region in a known safe operation zone, bounded by a known unsafe zone unavailable to the user. In the second operating region, some examples may restrict the step size of incremental adjustments requested by the user. Data may be collected for cloud-based analysis, for example, to facilitate discovery of more effective treatment protocols.","1. A therapeutic delivery apparatus comprising: a therapy module operably coupled to a processor, the therapy module comprising a compression garment, wherein the therapy module is adapted to deliver a predetermined compression therapy to a patient according to a treatment parameter operating point defined by a set of parameters associated with the delivery of the therapy in response to receiving a command signal transmitted by the processor;a communication interface configured for communicating information about the patient to a remote or local server, the communicated information including information about a result of the therapy applied to the patient by the therapy module;the processor operably coupled to control the therapy module according to the treatment parameter operating point, and operably coupled to the communication interface to generate a message that includes the result of the therapy applied to the patient by the therapy module; and,a memory device operably coupled to the processor and containing instructions, that when executed by the processor, cause the processor to perform operations to dynamically adjust the treatment parameter operating point, the operations comprising: receive a current treatment parameter operating point that lies within a first predetermined operating region defined by a first set of operating points for which automatic incremental adjustment of a parameter in the current operation is permitted;receive a request to alter the current treatment parameter operating point to a second treatment parameter operating point that lies outside of the first predetermined operating region and in a second predetermined operating region defined by a second set of operating points for which authorization is required, wherein the second predetermined operating region lies outside of the first predetermined operating region in a space of operating points;request authorization to alter the treatment parameter operating point from the first predetermined operating region to the second predetermined operating region;if the requested authorization is received, then generate a second command signal to the therapy module for delivering therapy to the patient according to the second treatment operating point; and,if the requested authorization is denied, then generate a first command signal to the therapy module for delivering therapy to the patient according to the first treatment operating point,wherein in response to the first command signal being received at the therapy module, the therapy module delivers a first predetermined compression therapy to the patient, the first predetermined compression therapy being associated with the first treatment operating point,wherein in response to the second command signal being received at the therapy module, the therapy module delivers a second predetermined compression therapy to the patient, the second predetermined compression therapy being associated with the second treatment operating point.","20","14/936462","2015-11-09","2016-0129186","2016-05-12","10792422","2020-10-06","WHITE BEAR MEDICAL LLC","Ryan  Douglas | Steven M  Gigl","","","","A61M-0005/1723","A61M-0005/1723 | A61H-0009/0085 | G06Q-0010/0639 | G06Q-0010/10 | G06Q-0050/22 | G16H-0020/10 | G16H-0020/30 | G16H-0040/63 | G16H-0050/20 | G16H-0050/30 | A61H-0009/0092 | A61H-2201/1207 | A61H-2201/1635 | A61H-2201/5005 | A61H-2201/5007 | A61H-2201/5012 | A61H-2201/5043 | A61H-2201/5046 | A61H-2201/5071 | A61H-2201/5089 | A61H-2201/5097 | A61H-2230/00 | A61H-2230/065 | A61H-2230/203 | A61H-2230/208 | A61H-2230/255 | A61H-2230/305 | A61H-2230/505 | A61H-2230/655 | A61M-0001/0031 | A61M-0001/0088 | A61M-0016/0051 | A61M-2205/3553 | A61M-2205/3561 | A61M-2205/52 | A61M-2230/005 | A61M-2230/06 | A61M-2230/205 | A61M-2230/30 | A61M-2230/50","G16H-050/20","G16H-050/20 | G06Q-050/22 | G06Q-010/10 | G16H-040/63 | G16H-050/30 | G16H-020/10 | G16H-020/30 | A61M-005/172 | A61H-009/00 | G06Q-010/06 | A61M-001/00 | A61M-016/00","","","","","","4920041001502"
"US","US","P","B2","Motion sickness monitoring and application of supplemental sound to counteract sickness","Methods, systems, and computer programs are presented for managing motion sickness of a user while the user is wearing a head-mounted device (HMD). One method includes an operation for monitoring the physical characteristics of the user while wearing the HMD that is presenting a virtual reality with multimedia content, where the physical characteristics including motions of the user. The multimedia content includes audio and video for presentation on a display of the HMD. Additionally, the method includes an operation for determining if the user is experiencing motion sickness based on the monitoring of the physical characteristics of the user while the virtual reality is being presented. When the user is experiencing motion sickness, supplemental sound is delivered to the user, where the supplemental sound is combined with sound from the multimedia content for delivery to the user, and the supplemental sound is defined to decrease the motion sickness experienced by the user.","1. A method executed by a processor, comprising: monitoring physical characteristics of a user while the user is wearing a headmounted display (HMD) and the HMD is presenting a virtual reality with multimedia content, the multimedia content including video for presentation on a display of the HMD and audio, the physical characteristics including motions of the user;determining if the user is experiencing motion sickness based on the monitoring of the physical characteristics of the user while the virtual reality is being presented, the physical characteristics include user head motion that is not expected based on presentation of the multimedia content, the user head motion is one of the physical characteristics used to determine that the user is experiencing motion sickness; andwhen the user is experiencing motion sickness, delivering supplemental sound to the user, wherein the supplemental sound is combined with sound from the multimedia content for delivery to the user, the supplemental sound is transferred via bone conduction of the user only to influence reduction in the motion sickness experienced by the user, the sound for the multimedia content and the supplemental sound are delivered via separate devices.","20","16/012719","2018-06-19","2018-0296921","2018-10-18","10792569","2020-10-06","Sony Interactive Entertainment Inc.","Brian  Watson","","","","A63F-0013/57","A63F-0013/57 | A61B-0003/112 | A61B-0003/113 | A61B-0005/0036 | A61B-0005/1128 | A61B-0005/4023 | A61B-0005/4836 | A63F-0013/212 | A63F-0013/213 | A63F-0013/26 | A63F-0013/285 | A63F-0013/424 | A63F-0013/428 | A63F-0013/54 | A63F-0013/67 | A63F-0013/79 | G06F-0003/011 | G06F-0003/012 | G06F-0003/013 | G06K-0009/00671 | G06T-0019/006 | A61B-2503/12 | A61M-2021/0038","G06F-003/01","G06F-003/01 | A63F-013/57 | A63F-013/428 | A63F-013/26 | A63F-013/212 | A63F-013/285 | A63F-013/424 | A61B-005/00 | A63F-013/213 | A63F-013/54 | A63F-013/67 | A63F-013/79 | A61B-003/11 | A61B-003/113 | A61B-005/11 | G06K-009/00 | G06T-019/00 | A61M-021/00","","","","","","4920041001647"
"US","US","P","B2","Magnetic resonance fingerprinting data collection and analysis system","A method of employing a central computer database (18) for supporting a characterization of tissue by magnetic resonance fingerprinting measurements, includes: exciting nuclei of a subject of interest by applying (50) a radio frequency excitation field B1 generated according to a magnetic resonance fingerprinting sequence (38), acquiring (52) magnetic resonance imaging signal data from radiation emitted by excited nuclei of the subject of interest, transferring (54) a magnetic resonance fingerprinting data set (42) to the central computer database (18), retrieving (56) a predefined dictionary from the central computer database (18), matching (60) the acquired magnetic resonance imaging signal data to the retrieved dictionary by applying a pattern recognition algorithm to determine a value (40) or a set of values (40) for at least one physical quantity (T1, T2), adding (62) at least the determined value (40) or the determined set of values (40) as a new entry of an associated medical data set (36) to the central computer database (18), and making (64) the new entry of an associated medical data set (36) accessible to users of the central computer database (18). A magnetic resonance fingerprinting data collection and analysis system (10) includes a central computer database, a data receiving unit (20), a data output unit (22) and a data analysis device (26) configured to carry out the method.","1. A method of employing a central computer database for supporting a characterization of tissue by magnetic resonance fingerprinting measurements, the central computer database being configured to receive the magnetic resonance fingerprinting measurements from each of a plurality of distinct magnetic resonance imaging systems employed by a plurality of clinicians to perform magnetic resonance examination and to provide magnetic resonance fingerprinting data to the clinicians and other users, the central computer database comprising: a plurality of associated medical data sets, each associated medical data set of the plurality of associated medical data sets including at least an associated value or an associated set of values for at least one physical quantity (T1, T2), anda plurality of predefined dictionaries, wherein each predefined dictionary of the plurality of predefined dictionaries is dedicated to a specific magnetic resonance fingerprinting sequence and includes a plurality of possible magnetic resonance signal evolutions of nuclei having been excited according to the specific magnetic resonance fingerprinting sequence, each magnetic resonance signal evolution of the plurality of possible magnetic resonance signal evolutions being based on a different value or a different set of values for the at least one physical quantity (T1, T2),the method comprising:arranging at least a portion of a subject of interest in an examination space of a magnetic resonance imaging system in which a static magnetic field B0 is being generated,exciting nuclei of or within at least the portion of the subject of interest by applying a radio frequency excitation field B1 generated according to a magnetic resonance fingerprinting sequence,acquiring magnetic resonance imaging signal data from radiation emitted by excited nuclei of or within at least the portion of the subject of interest,transferring a magnetic resonance fingerprinting data set comprising at least the acquired magnetic resonance imaging signal data and the magnetic resonance fingerprinting sequence used to obtain the magnetic resonance imaging signal data, to the central computer database,searching for a predefined dictionary of the plurality of predefined dictionaries corresponding to the magnetic resonance fingerprinting sequence that has been used to obtain the magnetic resonance imaging signal data,if a dictionary that is based on the magnetic resonance fingerprinting sequence is unavailable in the central computer database: creating a new dictionary and adding the new dictionary to the plurality of predefined dictionaries in the central computer database, the new dictionary being dedicated to the magnetic resonance fingerprinting sequence that has been used to obtain the corresponding magnetic resonance imaging signal data and including a plurality of possible magnetic resonance signal evolutions of nuclei having been excited according to the magnetic resonance fingerprinting sequence, wherein each possible magnetic resonance signal evolution of the plurality of possible magnetic resonance signal evolutions is based on a different value or a different set of values for the at least one physical quantity (T1, T2),if a corresponding dictionary that corresponds to the magnetic resonance fingerprinting sequence already exists in the central computer database: matching the acquired magnetic resonance imaging signal data to the corresponding dictionary by applying a pattern recognition algorithm to determine a value or a set of values for the at least one physical quantity (T1, T2) from a possible magnetic resonance signal evolution of the plurality of possible magnetic resonance signal evolutions that forms the closest match with the acquired magnetic resonance imaging signal data with regard to a predefined mathematical measure function that is indicative of a difference between the magnetic resonance signal evolution based on the determined value or the determined set of values of the at least one physical quantity (T1, T2) and the acquired magnetic resonance imaging signal data,adding at least the determined value or the determined set of values for the at least one physical quantity (T1, T2) as a new entry of an associated medical data set to the plurality of associated medical data sets in the corresponding dictionary,wherein each physical quantity of the at least one physical quantity (T1, T2) is either related to a physical property of a tissue type of at least the portion of the subject of interest or to a physical property of the magnetic resonance imaging system, andmaking the added magnetic resonance fingerprinting data set accessible to users of the central computer database.","17","15/527028","2015-11-16","2017-0328973","2017-11-16","10794976","2020-10-06","KONINKLIJKE PHILIPS N.V.","Thomas Erik  Amthor | Sascha  Krueger | Mariya Ivanova  Donevea | Peter  Koken | Julien  Senegas | Jochen  Keupp | Peter  Boernert","2014-195174","EP","2014-11-27","G01R-0033/5608","G01R-0033/5608 | G01R-0033/4828 | G16H-0050/20 | G16H-0050/70 | G01R-0033/50 | G06F-0021/32 | G06K-0009/6232 | G06K-2209/05","A61B-005/00","A61B-005/00 | A61B-005/055 | G01R-033/56 | G16H-050/70 | G16H-050/20 | G01R-033/48 | G06F-021/32 | G01R-033/50 | G06K-009/62","","","","","","4920041004043"
"US","US","P","B2","Material analysis of anatomical items","A computer-implemented method for medical device modeling includes accessing an electronic definition for a model of a three-dimensional item and an electronic definition of a three-dimensional spline relating to an internal anatomical volume; determining, with a computer-based finite element analysis system and using the electronic definitions, stresses created by the three-dimensional item along the three-dimensional spline, for different points along the three-dimensional spline; and displaying stress data generated by the finite element analysis system with a visualization system, the display of the stress data indicating levels of stress on portions of the three-dimensional item at particular locations along the three-dimensional spline.","1. A computer-implemented method for medical device modeling, the method comprising: accessing an electronic definition for a model of a three-dimensional item, an electronic definition of a three-dimensional anatomical item having an internal anatomical volume, and a plurality of electronic definitions of three-dimensional splines representing paths through a portion of the internal anatomical volume, wherein each spline in the plurality of splines has a different shape;determining, with a computer-based finite element analysis system and using the electronic definitions, stresses created by the three-dimensional item on the anatomical item, for a plurality of locations of the three-dimensional item along each of the plurality of three-dimensional splines;displaying, with a visualization system, a visual representation of the stresses created on the anatomical item by the three-dimensional item; andwherein each spline in the plurality of splines is generated by: generating a plurality of points;fitting a preliminary spline to the plurality of points;generating a plurality of rays around each point in the plurality of points;generating each spline in the plurality of splines by fitting a final spline to the plurality of points such that each point in the plurality of points is positioned equidistant from the final spline in a plane positioned perpendicular to an axis of the final spline at each relevant point along the final spline.","18","15/857389","2017-12-28","2018-0137690","2018-05-17","10796495","2020-10-06","Boston Scientific Scimed, Inc. | Regents of the University of Minnesota","Dane  Coffey | Daniel F.  Keefe | Arthur G.  Erdman | Benjamin  Bidne | Gregory Ernest  Ostenson | David M.  Flynn | Kenneth Matthew  Merdan | Chi-Lun  Lin","","","","G06T-0019/20","G06T-0019/20 | A61B-0034/10 | G06K-0009/4604 | G06T-0007/0012 | G06T-0013/20 | G06T-0015/00 | G06T-0017/00 | G06T-0019/006 | A61B-2017/00243 | A61B-2017/00778 | A61B-2034/102 | A61B-2034/104 | A61B-2034/105 | A61B-2034/107 | A61B-2034/2055 | A61B-2090/368 | G06F-0003/01 | G06F-0003/011 | G06K-2009/4666 | G06T-2207/10076 | G06T-2207/30004 | G06T-2207/30048 | G06T-2207/30101 | G06T-2211/40 | G06T-2219/00","A61B-017/00","A61B-017/00 | A61B-034/10 | A61B-034/20 | A61B-090/00 | G06F-003/01 | G06K-009/46 | G06T-013/20 | G06T-015/00 | G06T-017/00 | G06T-019/00 | G06T-019/20 | G06T-007/00","","","","","","4920041005551"
"US","US","P","B2","Closed-loop intervention control system","Described is a closed-loop intervention control system for memory consolidation in a subject. During operation, the system simulates memory changes of a first memory in a subject during waking encoding of the memory, and then while the subject is sleeping and coupled to an intervention system. Based on the simulated memory changes, the system predicts behavioral performance for the first memory, the behavioral performance being a probability that the first memory can be recalled on cue. The system can be used to control operation (e.g., turn on or off) of the intervention system with respect to the first memory based on the behavioral performance of the first memory determined by the simulation.","1. A closed-loop intervention control system for memory consolidation in a subject, the system comprising: one or more processors and a memory, the memory being a non-transitory computer-readable medium having executable instructions encoded thereon, such that upon execution of the instructions, the one or more processors perform operations of: recording biometric data during waking encoding of a first memory, the biometric data simulating a memory change of the first memory and representing at least one of attention, stress, and mental fatigue;based on the simulated memory change, predicting behavioral performance for the first memory, the predicted behavioral performance being a probability that the first memory can be recalled on cue;controlling operation of the intervention system with respect to the first memory based on the predicted behavioral performance of the first memory determined by the simulation, such that if the predicted behavioral performance is less than a predetermined level, activating electrodes to apply a target memory cue to a subject during a slow wave sleep state of the subject and ceasing activation of the electrodes when the predicted behavioral performance exceeds the predetermined level; andcorrelating the subject'ss performance of a skill after activation of the electrodes with the biometric data, wherein the correlation between biometric data and the subject'ss performance of the skill is updated every m trials based on a rolling mean biometric and rolling mean performance metric.","21","15/798325","2017-10-30","2018-0068581","2018-03-08","10796596","2020-10-06","HRL LABORATORIES, LLC","Steven W.  Skorheim | Michael D.  Howard | Praveen K.  Pilly","","","","G09B-0019/00","G09B-0019/00 | A61B-0005/0476 | A61B-0005/165 | A61B-0005/4812 | A61B-0005/4836 | A61M-0021/00 | A61M-0021/02 | A61N-0001/36025 | G05B-0017/02 | G05B-0019/048 | A61B-0005/0402 | A61B-0005/0488 | A61B-0005/486 | A61B-0005/7275 | A61M-2021/0016 | A61M-2021/0027 | A61M-2021/0072 | A61M-2205/502 | A61M-2230/04 | A61M-2230/10 | A61M-2230/18 | A61M-2230/60 | G05B-0013/0265 | G05B-2219/23026 | G06Q-0010/06398","A61N-001/36","A61N-001/36 | G09B-019/00 | G05B-019/048 | G05B-017/02 | A61B-005/0476 | A61B-005/16 | A61M-021/00 | A61B-005/00 | A61M-021/02 | G06Q-010/06 | A61B-005/0488 | A61B-005/0402 | G05B-013/02","","","","","","4920041005652"
"US","US","P","B2","Recording dose data from drug injection devices using optical character recognition (OCR)","A method of recording a medicament dose using a data collection device comprises capturing, by a video camera of said data collection device, a video showing a medicament dose indicator of a medicament delivery device, adjusting a scale of an image of said medicament dose indicator in said video, adjusting said image for skew of one or more characters displayed on a component of the medicament delivery device in said video, determining the position of at least one of said one or more characters in the image, identifying the at least one character using optical character recognition and determining a medicament dose shown by the medicament dose indicator based on a result of said optical character recognition. The method may include determining whether more than one delivery of medicament is recorded in the video and, if so, whether said more than one delivery includes one or more prime shots, so that an overall dosage delivered to a user may be determined based on multiple determined medicament doses. A wearable electronic device comprising a video camera may be used to obtain and analyze the video, for example, using software provided in an ""app"". The wearable electronic device may be configured to be worn on the head of a user, to capture the video from the user's point of view.","1. A method of recording a medicament dose using a data collection device, comprising: capturing, by a video camera of the data collection device, a video showing a medicament dose indicator of an injector pen;determining a position of at least one of one or more characters in an image in said video;identifying the at least one character using optical character recognition software;determining a medicament dose indicated by the medicament dose indicator based on a result of said identifying using said optical character recognition software; anddetermining whether more than one delivery of medicament is recorded in said video, wherein the injector pen comprises a movable component for selecting said medicament dose to be dispensed.","13","16/165838","2018-10-19","2019-0057764","2019-02-21","10796791","2020-10-06","SANOFI-AVENTIS DEUTSCHLAND GMBH","Stephan  Riedel | Till  Gerken","2014-189706","EP","2014-10-21","G16H-0020/13","G16H-0020/13 | A61M-0005/24 | A61M-0005/31 | A61M-0005/315 | A61M-0005/31525 | G06F-0019/00 | G06F-0019/321 | G06F-0019/3468 | G06K-0009/32 | G06K-0009/3258 | G06T-0005/50 | G06T-0007/12 | G06T-0007/136 | G06T-0007/73 | G16H-0015/00 | G16H-0020/17 | G16H-0030/20 | G16H-0040/63 | H04N-0005/235 | A61M-2005/3126 | A61M-2205/3306 | A61M-2205/505 | A61M-2205/52 | A61M-2205/6081 | G06K-2209/03 | G06T-2207/10016 | G06T-2207/20068 | G06T-2207/20076 | H04N-0005/23222","G06K-007/10","G06K-007/10 | G16H-020/13 | G06K-009/32 | A61M-005/24 | A61M-005/315 | G06F-019/00 | G16H-040/63 | G06T-007/73 | G06T-007/12 | G06T-007/136 | A61M-005/31 | G06T-005/50 | H04N-005/235 | G16H-020/17 | G16H-030/20 | G16H-015/00 | H04N-005/232","","","","","","4920041005847"
"US","US","P","B2","Vision protection method and systems thereof","A vision protection method is provided to ensure a viewer to rest his/her eyes after viewing on an electronic device for a certain period, wherein the eyesight protection method includes the steps of detecting at least one of eye activities of the viewer and working parameter of the electronic device in a working mode of the electronic device during the viewer is working on a current work displaying by the electronic device; switching the working mode of the electronic device to a resting mode when an abnormal eye activity of the viewer is detected; and switching the electronic device from the resting mode back to the working mode to resume the display of the current work of the electronic device. Therefore, the viewer is enforced to rest his/her eyes after every certain period.","1. A system for eyesight protection of a viewer of an electronic device, comprising: a display;a camera mounted relative to the display for imaging a viewer in front of the display;a control module coupled to the display and the camera to: (a) detect a viewer in front of the display;(b) initiate a working mode wherein: i) the display presents working information to the viewer;ii) the control module triggers a timer counting down a predetermined working time period for the working mode;iii) the control module monitors one or more parameters of an eye of the viewer using the camera, the one or more parameters comprising monitoring blinks of the eye of the viewer;iv) the control module analyzes images from the camera to detect a sitting posture of the viewer; andv) the control module monitors ambient light intensity of the electronic device;(c) during the working mode, if the control module determines that the blinks indicate potential dry eye problems, the control module detects an improper sitting posture of the viewer, or the ambient light intensity is detected below a preset ambient light threshold, a warning is presented on the display.","16","16/723947","2019-12-20","2020-0237219","2020-07-30","10786154","2020-09-29","EYES4LIVES, INC.","Roger  Wu","","","","A61B-0003/18","A61B-0003/18 | A61B-0003/112 | A61B-0003/113 | A61B-0003/12 | A61B-0003/14 | A61B-0005/1075 | A61B-0005/1103 | A61B-0005/1116 | A61B-0005/1128 | A61B-0005/486 | A61B-0005/489 | A61H-0005/00 | A61M-0021/02 | G06F-0003/013 | G06K-0009/00597 | G06Q-0010/109 | G09G-0005/00 | A61B-0005/1176 | A61B-2503/20 | A61B-2560/0266 | A61B-2560/0271 | A61H-2201/5007 | A61H-2201/5043 | A61H-2201/5064 | A61H-2201/5092 | A61M-2021/005 | A61M-2021/0027 | A61M-2205/056 | A61M-2205/3303 | A61M-2230/62 | A63F-2300/8094 | G06F-2203/011 | G09G-2354/00 | G09G-2356/00 | G09G-2360/144 | G09G-2360/145","A61B-003/18","A61B-003/18 | G06K-009/00 | A61B-005/107 | A61B-005/11 | A61B-005/00 | A61B-003/11 | A61B-003/14 | A61B-003/12 | A61B-003/113 | A61H-005/00 | G09G-005/00 | A61M-021/02 | G06F-003/01 | G06Q-010/10 | A61B-005/1171 | A61M-021/00","","","","","","4920040000854"
"US","US","P","B2","Analyte sensor and apparatus for insertion of the sensor","An apparatus for insertion of a medical device in the skin of a subject is provided.","1. A sensor insertion assembly comprising: an inserter device comprising: an analyte sensor at least a portion of which is configured to be positioned under a skin surface of a subject,a sharp coupled with a sharp support; anda cap removably attached to a distal portion of the inserter device by a plurality of threads, the cap including a first interior space, wherein the at least a portion of the analyte sensor and at least a portion of the sharp are housed within the first interior space.","20","16/736728","2020-01-07","2020-0138353","2020-05-07","10786190","2020-09-29","ABBOTT DIABETES CARE INC.","Phillip  Yee | Christopher A.  Thomas | Udo  Hoss | Lei  He | Michael R.  Love","","","","A61B-0005/14865","A61B-0005/14865 | A61B-0005/002 | A61B-0005/0004 | A61B-0005/0022 | A61B-0005/0024 | A61B-0005/02055 | A61B-0005/14503 | A61B-0005/14532 | A61B-0005/6849 | A61B-0005/6898 | A61B-0005/72 | A61B-0005/742 | A61B-0005/7405 | A61B-0005/7425 | A61B-0005/7455 | A61M-0005/158 | A61M-0005/1723 | G06K-0007/10366 | A61B-2560/0214 | A61B-2560/0412 | A61B-2560/0475 | A61B-2560/0487 | A61B-2562/0295 | A61M-0005/3286 | A61M-2005/1726 | A61M-2205/33 | A61M-2205/3584 | A61M-2205/502 | A61M-2230/201","A61B-005/00","A61B-005/00 | A61B-005/1486 | A61B-005/0205 | G06K-007/10 | A61B-005/145 | A61M-005/158 | A61M-005/172 | A61M-005/32","","","","","","4920040000889"
"US","US","P","B2","Methods and systems for modifying bioactive agent use","Methods, computer program products, and systems are described that include measuring at least one effect of a combined bioactive agent and artificial sensory experience on an individual and/or modifying at least one of the bioactive agent or the artificial sensory experience at least partially based on the at least one effect.","1. A method, comprising: measuring, via one or more processors, at least one effect of a combined bioactive agent and artificial sensory experience on an individual; andmodifying, via the one or more processors, at least one of the bioactive agent or the artificial sensory experience at least partially based on the at least one effect, comprising: modifying, via the one or more processors, a bioactive agent dosage; andtransmitting, via the one or more processors, a modified bioactive agent dosage signal based on the modified bioactive agent dosage to an administration unit configured to administer the modified bioactive agent dosage to the individual.","19","15/349974","2016-11-11","2017-0100540","2017-04-13","10786626","2020-09-29","THE INVENTION SCIENCE FUND I, LLC","Roderick A.  Hyde | Muriel Y.  Ishikawa | Eric C.  Leuthardt | Royce A.  Levien | Robert W.  Lord | Mark A.  Malamud | Elizabeth A.  Sweeney | Lowell L.  Wood, Jr. | Victoria Y. H.  Wood","","","","A61M-0005/1723","A61M-0005/1723 | A61B-0005/024 | A61B-0005/04 | A61B-0005/05 | A61B-0005/08 | A61B-0005/16 | A61B-0005/411 | A61B-0005/415 | A61B-0005/418 | A61B-0005/4266 | A61B-0005/48 | A61B-0005/4839 | G06F-0019/325 | A61B-0005/416 | A61M-2205/50 | A61M-2205/502 | A61M-2205/52 | A61M-2205/581 | A61M-2230/04 | A61M-2230/10 | A61M-2230/30 | A61M-2230/65 | G06F-0003/011 | G06F-0016/24575","A61B-005/024","A61B-005/024 | A61B-005/04 | A61B-005/05 | A61B-005/08 | A61B-005/16 | A61M-005/172 | A61B-005/00 | G06F-019/00 | G06F-016/2457 | G06F-003/01","","","","","","4920040001323"
"US","US","P","B2","Human behavior recognition apparatus and method","Disclosed herein are a human behavior recognition apparatus and method. The human behavior recognition apparatus includes a multimodal sensor unit for generating at least one of image information, sound information, location information, and Internet-of-Things (IoT) information of a person using a multimodal sensor, a contextual information extraction unit for extracting contextual information for recognizing actions of the person from the at least one piece of generated information, a human behavior recognition unit for generating behavior recognition information by recognizing the actions of the person using the contextual information and recognizing a final action of the person using the behavior recognition information and behavior intention information, and a behavior intention inference unit for generating the behavior intention information based on context of action occurrence related to each of the actions of the person included in the behavior recognition information.","1. A human behavior recognition apparatus, comprising: a multimodal sensor unit for generating at least one information of image information, sound information, location information, and Internet-of-Things (IoT) information relating to a person using a multimodal sensor;a contextual information extraction unit for extracting contextual information for recognizing actions of the person from the at least one information;a human behavior recognition unit for generating behavior recognition information by recognizing the actions of the person using the contextual information and recognizing a final action of the person using the behavior recognition information and behavior intention information; anda behavior intention inference unit for generating the behavior intention information based on context of action occurrence related to each of the actions of the person included in the behavior recognition information,wherein the behavior intention inference unit checks actions previous and subsequent to a current action of the person using the behavior recognition information in order to define the context of action occurrence, andwherein the behavior intention information includes possible actions that are capable of occurring subsequent to the actions of the person for whom the context of action occurrence is defined,wherein the human behavior recognition unit determines any one of subsequent actions that are predicted from the context of action occurrence included in the behavior intention information, among actions of the person, and then recognizes the final action of the person based on the determined action.","12","16/213833","2018-12-07","2020-0074158","2020-03-05","10789458","2020-09-29","ELECTRONICS AND TELECOMMUNICATIONS RESEARCH INSTITUTE","Do-Hyung  Kim | Jin-Hyeok  Jang | Jae-Hong  Kim | Sung-Woong  Shin | Jae-Yeon  Lee | Min-Su  Jang","10-2018-0101630","KR","2018-08-28","G06K-0009/00342","G06K-0009/00342 | A61B-0005/1118 | G06K-0009/00275 | G06K-0009/00375 | G06K-0009/66 | A61B-0005/1114 | G06F-0003/01 | G06N-0005/047 | G06T-2200/08","G06K-009/66","G06K-009/66 | G06K-009/00 | A61B-005/11 | G06F-003/01 | G06N-005/04","","","","","","4920040004133"
"US","US","P","B2","Apparatus and method for predicting/recognizing occurrence of personal concerned context","Disclosed is technology for providing a proper UI/UX through various devices or services when occurrence of registered concerned context is predicted or recognized in order to predict or recognize the circumstances that require attention or emotion control with regard to a change in his/her biological information With this, a user designates his/her own biological information range or emotional state with regard to circumstances which catch his/her attention, and registers concerned context by selectively designating attributes of circumstantial elements. Further, a user registers feedback desired to be given and an external device/service desired to interface with when the occurrence of the concerned context is predicted or recognized. According to the attributes of the circumstances designated in the registered concerned context, points in time for collecting and managing UX data are automatically determined, thereby processing and managing the UX data as useful information.","1. An apparatus for predicting/recognizing occurrence of personal concerned context, the apparatus comprising: a user interface device comprising a concerned context definer through which a user designates biological information, emotions, and circumstances and registers concerned context about the user'ss own biological information change or emotional state; andan emotion-biological information model management module comprising an emotion-biological information model manager which reflects information about the concerned context registered by the user in an emotion-biological information model, makes the emotion-biological information model learn from a user voice/biological information feature and reference statistics of the user voice/biological information feature depending on user behavior and atmospheric temperature, and manages the emotion-biological information model, and a concerned-context event generator which generates a concerned-context occurrence prediction event or a concerned-context occurrence recognition event by predicting or recognizing the occurrence of the concerned context registered in the concerned context definer of the user interface device.","19","16/219443","2018-12-13","2019-0371344","2019-12-05","10789961","2020-09-29","ELECTRONICS AND TELECOMMUNICATIONS RESEARCH INSTITUTE","Kyoung Ju  Noh | Ji Youn  Lim | Ga Gue  Kim | Seung Eun  Chung | Hyun Tae  Jeong","10-2018-0062753","KR","2018-05-31","G10L-0017/26","G10L-0017/26 | A61B-0005/0533 | G06K-0009/00302 | A61B-0005/0205 | A61B-0005/165 | G10L-2015/228 | H04W-0088/18","G10L-017/26","G10L-017/26 | G06F-003/00 | G06F-009/00 | A61B-005/053 | G06K-009/00 | G10L-015/22 | A61B-005/0205 | H04W-088/18 | A61B-005/16","","","","","","4920040004631"
"US","US","P","B2","Alignment of three-dimensional data collected in dental sessions, and applications thereof","Disclosed embodiments integrate a camera into an intraoral mirror. Integrating a camera into an intraoral mirror provides an efficient way to record and display what is visible to the healthcare provider in the mirror.","1. A computer-implemented method for aligning three-dimensional dental data from a plurality of dental sessions, comprising: (a) receiving a plurality of point clouds, each point cloud (i) representing three-dimensional locations in a dental room of a dental mirror including an interior of a patient'ss mouth, and (ii) collected during a different dental session when the patient'ss mouth is in a different position in the dental room, the dental mirror configured to enable a healthcare provider to view a reflection of the interior of the patient'ss mouth when observing the reflective surface;(b) aligning the plurality of point clouds to represent a common volume element within the patient'ss mouth; and(c) generating, based on the aligned plurality of point clouds, a three-dimensional model of the interior of a patient'ss mouth.","20","16/253931","2019-01-22","2019-0150724","2019-05-23","10779719","2020-09-22","DENTAL SMARTMIRROR INC.","Gidon Oded  Elazar | Dan Zidkiahu  Harkabi | Joshua Israel  Wachspress | Yael Miriam  Harkabi","","","","A61B-0001/247","A61B-0001/247 | A61B-0001/00006 | A61B-0001/00009 | A61B-0001/00016 | A61B-0001/00032 | A61B-0001/00034 | A61B-0001/00041 | A61B-0001/00045 | A61B-0001/00087 | A61B-0001/00105 | A61B-0001/00195 | A61B-0001/045 | A61B-0001/05 | A61B-0001/06 | A61B-0001/063 | A61B-0001/0607 | A61B-0001/0676 | A61B-0001/24 | A61B-0005/0079 | A61B-0005/0086 | A61B-0005/0088 | A61B-0005/061 | A61B-0005/065 | A61B-0005/067 | A61B-0005/1176 | A61C-0003/00 | A61C-0009/0073 | A61C-0013/0004 | A61C-0013/34 | A61C-0019/004 | F21V-0033/0068 | G02B-0027/144 | G06F-0003/023 | G06F-0003/0334 | G06F-0019/00 | G06K-0009/00255 | G06T-0003/40 | G06T-0003/4038 | G06T-0003/60 | G06T-0005/009 | G06T-0007/0012 | G06T-0007/0016 | G06T-0007/11 | G06T-0017/20 | G16H-0020/40 | G16H-0030/20 | G16H-0040/63 | H04N-0005/2252 | H04N-0005/2253 | H04N-0005/2254 | H04N-0005/2256 | H04N-0005/2257 | H04N-0005/2354 | H04N-0005/23238 | H04N-0005/23241 | H04N-0007/183 | H05B-0045/00 | H05B-0045/22 | H05B-0047/105 | A61B-0001/0684 | A61B-0005/0022 | A61B-2560/0456 | A61B-2576/02 | F21W-2131/202 | G06T-0007/337 | G06T-2200/32 | G06T-2207/10048 | G06T-2207/10116 | G06T-2207/20208 | G06T-2207/20212 | G06T-2207/30036 | G06T-2210/22 | G06T-2210/41 | G10L-0015/265 | H04N-2005/2255","A61B-001/247","A61B-001/247 | A61B-001/00 | A61B-001/05 | A61B-001/06 | A61B-005/06 | A61B-005/00 | H04N-005/225 | H04N-005/235 | A61B-001/045 | A61C-003/00 | A61B-001/24 | G16H-030/20 | G16H-040/63 | G16H-020/40 | A61B-005/1171 | H05B-045/00 | H05B-045/22 | H05B-047/105 | G06F-003/023 | G06F-003/033 | G06T-003/40 | G06T-003/60 | H04N-007/18 | G06K-009/00 | H04N-005/232 | F21V-033/00 | G02B-027/14 | G06T-007/00 | G06T-017/20 | A61C-013/15 | G06T-005/00 | G06T-007/11 | A61C-009/00 | A61C-013/00 | A61C-013/34 | G06F-019/00 | G10L-015/26 | F21W-131/202 | G06T-007/33","","","","","","4920039000896"
"US","US","P","B2","Contactless-type sport training monitor method","The present invention provides a contactless-type sport training monitor method, comprising: selecting at least an image database to recognize a plurality of expressions in the image database; making pre-processing for the plurality of expressions: using a convolutional neural network as a feature point extraction model; acquiring a human image; tracking a first target region and a second target region in the human image; making chrominance-based rPPG trace extraction; using the deep level model to compare the second target region image; and to calculate a post-exercise heart rate recovery achievement ratio, to judge the Rating of Perceived Exertion, and judging whether the human body is under overtraining status or not.","1. A contactless-type sport training monitor method by using a human image and a physiological signal, comprising: selecting at least an image database to recognize a plurality of expressions in an image database, respectively, in order to train a facial expression feature extraction model;acquiring a sequence of human images;tracking a first target region and a second target region in said human image, and acquiring a first target region image in said first target region and a second target region image in said second target region, respectively, wherein the first target region image comprises a palm skin image or a face skin image of said human image, and said second target region image comprises a facial expression image;making a rPPG trace extraction for said first target region image:making a time-frequency transform for said first target region images;using a signal processing for said first target region image, to obtain some physiological signals, wherein said signal processing uses a motion noise spectrum stability value that is lower than a stability threshold, or a difference between a largest frequency and a motion frequency that is smaller than a frequency threshold, wherein said motion noise spectrum stability value comprises and wherein E1 is a largest frequency energy, and E2 is a total signal energy minus E1, and wherein said physiological signals comprise a heart rate, a heart rate recovery, and a post-exercise heart rate recovery achievement ratio comprising wherein HRRlowest comprises a lowest heart rate value, E[HRex] comprises an average exercising heart rate value, and HRrest comprises an average resting heart rate value; using said facial expression feature extraction model to extract the facial expression features on the said second target region images; andusing said facial features and said physiological signals to obtain an index for judging whether said human body is under overtraining status or not.","5","16/040721","2018-07-20","2019-0246921","2019-08-15","10779739","2020-09-22","NATIONAL CHIAO TUNG UNIVERSITY","Bing-Fei  Wu | Chun-Hsien  Lin | Po-Wei  Huang | Tzu-Min  Lin | Meng-Liang  Chung","","","","A61B-0005/02416","A61B-0005/02416 | A61B-0005/0013 | A61B-0005/0077 | A61B-0005/024 | A61B-0005/02125 | A61B-0005/7203 | A61B-0005/726 | A61B-0005/7257 | A61B-0005/7264 | A61B-0005/7275 | A61B-0005/7278 | A61B-0005/7485 | G06F-0003/017 | G06K-0009/00302 | A61B-0005/0402 | A61B-0005/725 | A61B-0005/7207 | A61B-2576/00 | G06T-0007/20 | G06T-0007/246","A61B-005/024","A61B-005/024 | A61B-005/00 | G06K-009/00 | G06F-003/01 | A61B-005/021 | G06T-007/246 | A61B-005/0402 | G06T-007/20","","","","","","4920039000916"
"US","US","P","B2","Elongate implant containing a structurally encoded pin, carrier and reading system therefor","A carrier for retaining a plurality of implants each comprising a structurally encoded pin, the structurally encoded pin having a shape or surface characteristics discernable by an imaging modality such as x-ray, fluoroscopy, computed tomography, electromagnetic radiation, ultrasound, visible light, UV light, magnetic resonance imaging, positron emission tomography and neutron imaging, from outside the carrier, the shape or surface characteristics representing structurally encoded data. The invention further discloses a carrier for viewing a plurality of implants, and associated reading systems for reading a plurality of implants. Finally, the invention discloses methods for reading a plurality of implantable devices retained within a carrier.","1. A system for reading a plurality of elongate implants comprising: the plurality of elongate implants;a carrier comprising a front surface defining a front axis and an upper surface, said upper surface comprising a plurality of apertures arrayed in one or more series and wherein the plurality of elongate implants extend through said plurality of apertures in said series; anda source of reading illumination located external to and directable at said plurality of elongate implants along a vector orthogonal to said front axis, wherein said source of reading illumination reads all of said plurality of elongate implants retained within said carrier in a single image.","13","15/806482","2017-11-08","2018-0064506","2018-03-08","10779907","2020-09-22","Brian Kieser | Thomas Zink | Nicholas M. Cordaro","Brian  Kieser | Thomas  Zink | Nicholas M.  Cordaro","","","","A61B-0090/90","A61B-0090/90 | A61B-0017/70 | A61B-0017/7002 | A61B-0017/7032 | A61B-0017/864 | A61B-0017/865 | A61B-0017/866 | A61B-0017/8685 | A61B-0050/20 | A61B-0050/22 | A61B-0050/30 | A61B-0050/33 | A61B-0050/34 | A61B-0090/39 | A61B-0090/96 | A61B-0090/98 | B33Y-0080/00 | G06K-0007/1413 | G06K-0019/06 | A61B-0005/06 | A61B-0006/12 | A61B-0008/0841 | A61B-2017/00526 | A61B-2050/3008 | A61B-2050/3011 | A61B-2090/373 | A61B-2090/374 | A61B-2090/378 | A61B-2090/3762 | A61B-2090/3925 | A61B-2090/3937 | A61B-2090/3954 | A61B-2090/3966 | A61F-2250/0086 | A61F-2250/0089 | B29K-2995/0056 | B29L-2031/7532 | G06K-2019/06271","A61B-090/90","A61B-090/90 | A61B-090/96 | A61B-017/86 | A61B-090/00 | G06K-007/14 | A61B-090/98 | B33Y-080/00 | A61B-017/70 | A61B-050/33 | A61B-050/30 | A61B-050/20 | G06K-019/06 | A61B-050/22 | A61B-050/34 | A61B-008/08 | B29L-031/00 | A61B-005/06 | A61B-006/12 | A61B-017/00","","","","","","4920039001084"
"US","US","P","B2","Transcranial stimulation device and method based on electrophysiological testing","The present method and system provides for the clinical application of neurostimulation and/or neuromodulation to a patient. The method and system includes receipt and acquisition of patient data, processing of that data relative to one or more known data sets, and determination of a good-fit trigger specific treatment protocol. The method and system provides for application of the protocol to the patient, including delivery of neuromodulation and biofeedback. Based thereon, the method and system re-iterates the goodness of fit determination for further treatment to the patient.","1. A transcranial stimulation method comprising: measuring an electroencephalography anomaly in a brain region of a patient;determining a treatment protocol based on the electroencephalography anomaly; andapplying a transcranial current stimulation based on the treatment protocol to the patient via: a plurality of spaced-apart removable and replaceable at least one of:electrodes and sensors, arranged in a piece of headgear based on the treatment protocol;an electroencephalography device wired to one or more of said at least one of: electrodes and sensors; anda trans cranial current stimulation device wired to one or more of said electrodes providing the transcranial stimulation based on the treatment protocol.","20","14/578764","2014-12-22","2015-0112409","2015-04-23","10780268","2020-09-22","EVOKE NEUROSCIENCE, INC.","David W  Hagedorn","","","","A61N-0001/36014","A61N-0001/36014 | A61B-0005/0006 | A61B-0005/0478 | A61B-0005/0482 | A61B-0005/0484 | A61B-0005/6803 | A61N-0001/0484 | A61N-0001/37247 | A61N-0002/02","G06F-017/30","G06F-017/30 | A61N-001/36 | A61B-005/0484 | A61N-001/04 | A61N-001/372 | A61N-002/02 | A61B-005/0478 | A61B-005/00 | A61B-005/0482","","","","","","4920039001443"
"US","US","P","B2","Cadence and media content phase alignment","Systems, devices, apparatuses, components, methods, and techniques for cadence and media content phase alignment are provided. An example media-playback device includes a content output device that operates to output media content, a cadence-acquiring device, a phase-delay calibration engine, a cadence-based media content selection engine, and a phase-aligned media playback engine. The cadence-acquiring device includes a movement-determining device and a cadence-determination engine configured to determine a cadence based on movement data captured by the movement-determining device. The phase-delay calibration engine configured to determine phase delay values for at least one cadence value. The cadence-based media content selection engine configured to identify a media content item based on the cadence determined by the cadence-acquiring device. The phase-aligned media playback engine configured to align the identified media content item to the repetitive-motion activity and cause the media-output device to output the aligned media content item.","1. A media-playback device for aligning play back of media content for a user performing a repetitive motion activity, the repetitive-motion activity including a repetitive cycle of motion having a repetitive action point, the media-playback device comprising: a content output device that operates to output media content;a cadence-acquiring device comprising a movement-determining device and a cadence-determination engine configured to determine a cadence based on movement data captured by the movement-determining device;a phase-delay calibration engine configured to determine phase delay values for at least one cadence value, wherein the phase-delay calibration engine determines the phase delay values based at least in part on a time required to detect the repetitive action point within the repetitive motion activity; anda phase-aligned media playback engine configured to: align a media content item to the repetitive motion activity using at least one of the determined phase-delay values; andcause the media-output device to output the aligned media content item so that a beat of the media content item is output coincidentally with an expected repetitive action point.","17","16/368319","2019-03-28","2019-0332348","2019-10-31","10782929","2020-09-22","SPOTIFY AB","Tristan  Jehan","","","","G06F-0003/165","G06F-0003/165 | A61B-0005/024 | A63B-0071/00 | A63B-0071/0622 | G06F-0003/011 | G06F-0016/632 | G06F-0016/636 | A63B-2071/0625 | A63B-2230/062","G06F-017/00","G06F-017/00 | G06F-003/16 | G06F-016/632 | G06F-016/635 | A61B-005/024 | A63B-071/00 | G06F-003/01 | A63B-071/06","","","","","","4920039004088"
"US","US","P","B2","Headset with motion sensor","A headset including a speaker, a motion sensor, a transceiver, and a processor is provided. The speaker plays audio data. The motion sensor senses a posture of a user to generate first sensing data. The transceiver performs data transmission with an external device. The processor is coupled to the motion sensor and the transceiver. The processor determines whether the posture is correct according to the first sensing data to generate an output result and transmits the output result through the transceiver.","1. A headset, comprising: a speaker, playing audio data;a motion sensor, sensing a posture of a user to generate first sensing data;a transceiver, performing data transmission with an external device; anda processor, coupled to the motion sensor and the transceiver, the processor determines whether the posture is correct according to the first sensing data to generate an output result and transmits the output result through the transceiver,wherein the output result indicates that the posture is correct or the posture is incorrect, and the headset comprises the following modes:a general mode, the transceiver does not transmit any data other than the output result; anda training mode, the transceiver transmits the first sensing data to the external device.","12","16/293660","2019-03-06","2020-0169802","2020-05-28","10783359","2020-09-22","MERRY ELECTRONICS(SHENZHEN) CO., LTD.","Meng-Wei  Lin | Mao-Hung  Lin | Hung-Chi  Lin | Sheng  Chen","107142162 A","TW","2018-11-27","G06K-0009/00335","G06K-0009/00335 | A61B-0005/1116 | A61B-0005/4561 | A63B-0023/0244 | G06F-0003/011 | G06F-0003/012 | G06F-0003/167 | A63B-2208/02 | A63B-2230/62 | G08B-0021/0446 | H04R-0001/1016 | H04R-0005/033 | H04R-0005/0335 | H04R-2430/01","G06K-009/00","G06K-009/00 | G06F-003/16 | G06F-003/01 | A61B-005/11 | A63B-023/02 | A61B-005/00 | H04R-001/10 | H04R-005/033 | G08B-021/04","","","","","","4920039004514"
"US","US","P","B2","System and method for combining what-if and goal seeking analyses for prescriptive time series forecasting","A computer-implemented method for prescriptive time-series forecasting, which combines both what-if analysis and goal-seeking analysis. The method comprises building a model for a target metric with a set of predictors, based on historical time-series data, and computing, using the model, a set of forecast values. Using the set of forecast values with respect to a forecasting period, both a set of goals for the target metric and a set of constraints for the predictors are analyzed. A set of updated forecasts based on the analyses with respect to the forecasting period is determined to meet the goals within the set of constraints. The updated set of forecasts is presented with respect to the forecasting period, e.g., using a table, a visualization, and/or an interactive user interface.","1. A computer-implemented method for prescriptive time-series forecasting, the method being performed by a system including at least one computer processor and comprising: automatically identifying a set of predictors for a target metric by obtaining historical time-series data for the target metric and building an autoregression model using the historical time-series data, wherein each predictor of the set of predictors is identified at least in part based on an effect of the predictor on the target metric, wherein the historical time-series data is automatically obtained, via a webcrawler, from one or more remote online data sources;building, based on the historical time-series data, a forecasting model for the target metric with the set of predictors;computing, using the forecasting model, a set of forecast values for each predictor of the set of predictors and for the target metric;displaying, in an interactive user interface, the set of forecast values, the target metric, and a user-selectable scenario creation field;displaying, in an interactive user interface in response to a user'ss selection of the scenario creation field, the set of predictors identified by the system and user-selectable controls for defining whether or not a constraint is imposed on each predictor and a type of constraint imposed;receiving from the user, via the interactive user interface, a set of constraints for the set of predictors;analyzing, using the set of forecast values with respect to a forecasting period, both a set of goals for the target metric and the set of constraints for the set of predictors, wherein the set of constraints are applied to the forecast values computed using the forecasting model;updating, to meet the set of goals for the target metric within the set of constraints for the set of predictors, the set of forecast values dynamically with respect to the forecasting period; andpresenting, with respect to the forecasting period, the updated set of forecast values.","9","15/832001","2017-12-05","2018-0158079","2018-06-07","10783536","2020-09-22","INTERNATIONAL BUSINESS MACHINES CORPORATION","Yea-Jane  Chu | Richard J.  Oswald | Jean-Francois  Puget | Jing-Yun  Shyr","","","","G06Q-0030/0202","G06Q-0030/0202 | G06N-0005/022","A61M-005/172","A61M-005/172 | G06Q-030/02 | G06N-005/02","","","","","","4920039004690"
"US","US","P","B2","Method and system for robust image detection for automatic detection of symptoms","A system and method for automatic detection of symptoms of peritonitis during peritoneal dialysis, such as using a mobile device with an image capturing system.","1. A system for automatic detection of symptoms of peritonitis during peritoneal dialysis, comprising: an image capturing device in communication with a processor;an effluent bag for receiving effluent fluid during peritoneal dialysis, the bag having a clear window for visual inspection of the effluent fluid; anda visual signal disposed on a surface of the effluent bag for being inspected by the image capturing device through the effluent fluid, the visual signal being a computer-readable signal when no distortions are present and wherein the quality of the visual signal through the effluent fluid on a captured image of the image capturing device determines the presence of an infection.","20","16/353900","2019-03-14","2019-0295256","2019-09-26","10783635","2020-09-22","GRAFTY, INC.","Allen Yang  Yang | Manish  Mukherjee","","","","G06T-0007/0014","G06T-0007/0014 | A61J-0001/10 | A61M-0001/28 | G06K-0007/10722 | G06K-0007/1413 | G06K-0007/1417 | G06T-0003/40 | G06T-0003/60 | G06T-0005/002 | A61M-2205/3306 | A61M-2205/6072 | G06T-2207/30092","G06T-007/00","G06T-007/00 | A61M-001/28 | A61J-001/10 | G06T-005/00 | G06T-003/40 | G06K-007/14 | G06K-007/10 | G06T-003/60","","","","","","4920039004789"
"US","US","P","B2","Motion sensor using cross coupling","Techniques for performing one or both of gesture recognition and biometric monitoring with an electronic device are disclosed, where the electronic device has a wireless communications capability using beamforming techniques and includes a plurality of millimeter wave antenna modules. Each module includes at least one transmit antenna and at least one receive antenna, operable in one or more frequency ranges not less than 20 GHz, the receive antenna coupled with a first branch configured to receive H-polarized signals and a second branch configured to receive V-polarized signals. Performing one or both of gesture recognition and biometric monitoring includes detecting a presence and motion of a reflective object or anatomical feature by determining a relationship between received H-polarized signals and received V-polarized signals for two or more receive antennas as a function of time.","1. A method comprising: performing one or both of gesture recognition and biometric monitoring with an electronic device, the electronic device having a wireless communications capability using beamforming techniques and including a plurality of millimeter wave antenna modules, each module including at least one transmit antenna and at least one receive antenna, operable in one or more frequency ranges not less than 20 GHz, the receive antenna coupled with a first branch configured to receive H-polarized signals and a second branch configured to receive V-polarized signals; wherein:the performing one or both of gesture recognition and biometric monitoring includes detecting a presence and motion of a reflective object or anatomical feature by determining a relationship between received H-polarized signals and received V-polarized signals for two or more receive antennas as a function of time.","30","15/981558","2018-05-16","2019-0350465","2019-11-21","10772511","2020-09-15","QUALCOMM INCORPORATED","Mustafa Emin  Sahin | Udara  Fernando | Seunghwan  Kim","","","","A61B-0005/0205","A61B-0005/0205 | A61B-0005/1102 | A61B-0005/113 | A61B-0005/6897 | G06F-0003/017 | G06K-0009/00355 | H01Q-0021/24 | H04B-0007/10 | H04W-0052/0216 | H04W-0064/006 | H04W-0074/0833 | H01Q-0021/062 | H01Q-0021/065","A61B-005/0205","A61B-005/0205 | A61B-005/11 | A61B-005/113 | A61B-005/00 | G06F-003/01 | G06K-009/00 | H01Q-021/24 | H04B-007/10 | H04W-052/02 | H04W-064/00 | H04W-074/08 | H01Q-021/06","","","","","","4920038000847"
"US","US","P","B2","Rehabilitation system and method","The present invention relates to a rehabilitation system (10) for a patient (24) suffering from a damaged muscle and/or nerve, said system (10) comprising: a brain activity sensor (14) for measuring a patient's brain activity related to controlling the damaged muscle and/or nerve; ?a muscle sensor (18) for measuring a muscular activity of the damaged muscle and/or a neural activity of the damaged nerve; a display (22) for displaying a representation (34) of an affected body part of the patient (24); and a control unit (20) for determining an intended movement of the affected body part in which the damaged muscle and/or nerve is arranged, and for controlling the display (22) to display a representation (36) of the intended movement, wherein the control unit (20) is configured to determine the intended movement based on the patient's brain activity measured by the brain activity sensor (14) and based on the muscular and/or neural activity of the damaged muscle and/or nerve measured by the muscle sensor (18).","1. A rehabilitation system for a patient suffering from a damaged muscle, said rehabilitation system comprising: a brain activity sensor configured to measure a patient'ss brain activity related to controlling the damaged muscle;a muscle sensor configured to measure a muscular activity of the damaged muscle;a display configured to display a representation of an affected body part of the patient;a control unit configured to determine an intended movement of the affected body part with the damaged muscle,control the display to display a representation of the intended movement, anddetermine the intended movement based on both the patient'ss brain activity measured by the brain activity sensor and the muscular activity of the damaged muscle measured by the muscle sensor; andan evaluation unit configured to compare a plurality of measurement results of the patient'ss brain activity measured by the brain activity sensor and the muscular activity of the damaged muscle measured by the muscle sensor over time to determine a recovery progress of the patient and a difference between the brain activity signals and the muscle signals over time;generate a statistic including a trend of brain activity signals and muscle signals over time, wherein a decrease in the difference between the brain activity signals and the muscle signals over time indicates a positive effect of a therapy; anddisplay the statistic to the patient with a graphical item to provide feedback to the patient regarding recovery.","18","15/310301","2015-05-27","2017-0143229","2017-05-25","10772528","2020-09-15","KONINKLIJKE PHILIPS N.V.","Mirela Alina  Weffers-Albu | Raymond  Van Ee","2014-170891","EP","2014-06-03","A61B-0005/0482","A61B-0005/0482 | A61B-0005/0488 | A61B-0005/4041 | A61B-0005/4519 | A61B-0005/6814 | A61B-0005/6828 | A61B-0005/6831 | A61B-0005/744 | A61F-0007/00 | A61H-0023/02 | A61N-0001/36003 | G06F-0003/015 | G09B-0005/06 | A61B-2505/09 | A61H-2201/02","A61B-005/0482","A61B-005/0482 | A61B-005/00 | A61B-005/0488 | G06F-003/01 | A61N-001/36 | A61F-007/00 | A61H-023/02 | G09B-005/06","","","","","","4920038000864"
"US","US","P","B2","Method and apparatus for displaying medical image","A method and an apparatus are provided for displaying a medical image. The method includes displaying a first medical image on a screen, based on a first input that zooms in on or zooms out from a first object in the first medical image, determining first geometry information comprising either one or both of position information and size information of the first object, and displaying the first geometry information on a predetermined fixed region of the screen.","1. A method of displaying a medical image, the method comprising: displaying a first medical image on a screen, based on a first input that zooms in on or zooms out from a first object in the first medical image;determining first geometry information comprising either one or both of position information and size information of the first object;determining whether an adjacent region located adjacent to the first object and large enough to display the first geometry information exists in the first medical image;displaying the first geometry information as text information on the adjacent region exist in the first medical image; anddisplaying the first geometry information on the predetermined fixed region of the screen in response to the adjacent region being determined not to exist in the first medical image,wherein the displaying of the first geometry information comprises, in response to the first input that zooms in on or zooms out from the first object in the first medical image, continuously displaying the first geometry information on the predetermined fixed region while a zoom level of the first medical image changes.","19","15/831628","2017-12-05","2018-0160996","2018-06-14","10772595","2020-09-15","SAMSUNG ELECTRONICS CO., LTD.","Gi-tae  Lee | Dong-jin  Yang","10-2016-0170406","KR","2016-12-14","A61B-0006/5247","A61B-0006/5247 | A61B-0006/463 | A61B-0008/463 | G06F-0003/04845 | G06F-0003/04886 | G16H-0030/20 | G16H-0030/40 | A61B-0005/7264 | A61B-0034/10 | A61B-2034/107 | G01R-0033/546 | G01R-0033/5608","G06K-009/00","G06K-009/00 | A61B-006/00 | G06F-003/0484 | G06F-003/0488 | G16H-030/40 | G16H-030/20 | A61B-008/00 | A61B-034/10 | A61B-005/00 | G01R-033/56 | G01R-033/54","","","","","","4920038000930"
"US","US","P","B2","Neuro-adaptive body sensing for user states framework (NABSUS)","Described is a system for personalizing a human-machine interface (HMI) device based on a mental and physical state of a user. During performance of a task in a simulation environment, the system extracts biometric features from data collected from body sensors, and extracts brain entropy features from electroencephalogram (EEG) signals. The brain entropy features are correlated with the biometric features to generate a mental-state model. The mental-state model is deployed in a HMI device during performance of the task in an operational environment for continuous adaptation of the HMI device to its user's mental and physical states.","1. A system for personalizing a human-machine interface (HMI) device, the system comprising: one or more processors and a non-transitory memory having instructions encoded thereon such that when the instructions are executed, the one or more processors perform operations of: during performance of a task in a simulation environment, extracting a first set of biometric features from data collected from one or more body sensors; andextracting a set of brain entropy features from electroencephalogram (EEG) signals;correlating the set of brain entropy features with the first set of biometric features, resulting in a correlation of features;generating a mental-state model as a function of the correlation of features, where in generating the mental-state model, the set of brain entropy features are further correlated with a set of performance metrics, wherein the set of performance metrics are obtained during the task performance in the simulation environment; anddeploying the mental-state model in an HMI device during performance of the task in an operational environment for continuous adaptation of the HMI device.","17","16/252247","2019-01-18","2019-0227626","2019-07-25","10775887","2020-09-15","HRL LABORATORIES, LLC","Iman  Mohammadrezazadeh | Rajan  Bhattacharyya","","","","G06F-0003/015","G06F-0003/015 | A61B-0005/0476 | A61B-0005/165 | A61B-0005/7275 | A61N-0001/36031 | G06N-0020/00","A61B-005/04","A61B-005/04 | G06F-003/01 | G06N-020/00 | A61N-001/36 | A61B-005/0476 | A61B-005/00 | A61B-005/16","","","","","","4920038004207"
"US","US","P","B2","Typifying emotional indicators for digital messaging","The present disclosure provides computing systems and techniques for indicating an emotional and/or environmental state of a user in a digital messaging application. A computing device can determine an emotional and/or environmental state of a first user responsive to reading or responding to a message and can convey the determined emotional and/or environmental state to a second computing device, to be transiently presented by the second computing device.","1. At least one non-transitory machine-readable storage medium comprising instructions that when executed by a processor at an apparatus, cause the processor to: receive, from a messaging device, a first information element including an indication of message content;determine a current usage of the apparatus;determine an emotional state based at least in part on the current usage of the apparatus;determine an environmental state, responsive in part, to receiving a message including the message content;generate a second information element, the second information element to include an indication of the determined emotional state, an indication of the determined environmental state, and an indication to transiently present the indications of the determined emotional and environmental states; andsend the second information element to the messaging device.","20","16/410042","2019-05-13","2020-0110804","2020-04-09","10776584","2020-09-15","CAPITAL ONE SERVICES, LLC","Jeremy  Phillips | Andrew  Beane","","","","G06F-0040/30","G06F-0040/30 | A61B-0005/0077 | A61B-0005/01 | A61B-0005/021 | A61B-0005/165 | A61B-0005/6898 | A61B-0005/7264 | G06F-0003/0484 | G06F-0003/04817 | G06F-0040/253 | G06K-0009/00302 | G08B-0021/18","G06F-040/30","G06F-040/30 | G06K-009/00 | G06F-003/0484 | G06F-003/0481 | G08B-021/18 | A61B-005/00 | A61B-005/01 | A61B-005/021 | A61B-005/16 | G06F-040/253","","","","","","4920038004896"
"US","US","P","B2","Characterizing states of subject","Among other things, a user of a browser is exposed simultaneously to three interfaces: A viewing interface for at least one image of a subject that is stored on a device on which the browser is running, a decision support interface that aids the user in determining the state of the subject based on the image, and a template interface that aids the user in capturing uniform descriptive information about the state of the subject. At least two of the viewing interface, the decision support interface, and the template interface operate cooperatively so that actions of the user with respect to one of the two interfaces causes changes in content exposed by the other of the two interfaces.","1. A computer based method comprising using a radiological image capture device to capture and store a digital radiological image of at least a part of a body of a patient associated with either the left side of the patient or the right side of the patient, the image being in an axial plane of the patient,on an electronic display device, displaying simultaneously to a user: (a) the image of the part of the body of the patient associated with either the left side of the patient or the right side of the patient, and, in connection with the image, an identifier of the left side of the patient or the right side of the patient in the image, and,(b) one or more displayed template elements of a particular template for the user to invoke to express findings about a medical state of the patient, each of the displayed template elements of the particular template including a single word or a phrase of two or more words, at least one of the displayed template elements of the particular template being potentially invocable by the user to include the single word or phrase of two or more words of the displayed template element in the expressed findings,the displayed template elements of the particular template including a side-specific displayed template element for potentially identifying that the part of the body of the patient shown in the image is associated with the right side of the patient or with the left side of the patient,if the identifier in the image is a left side identifier and the side-specific displayed template element identifies that the part of the body is associated with the right side of the patient, presenting the side-specific displayed template element in a manner to indicate that the side-specific displayed template element is not invocable, orif the identifier in the image is a right side identifier and the side-specific displayed template element identifies that the part of the body is associated with the left side of the patient, presenting the side-specific displayed template element in a manner to indicate that the side-specific displayed template element is not invocable,storing in an electronic storage at least part of the expressed findings about the medical state of the patient, andtreating the patient to improve the medical state of the patient based on the expressed findings.","15","14/979921","2015-12-28","2016-0210441","2016-07-21","10777307","2020-09-15","LIFETRACK MEDICAL SYSTEMS PRIVATE LTD.","Eric  Schulze | Brendan  Philip Rees | Dennis  Mejia","","","","G16H-0015/00","G16H-0015/00 | A61B-0005/0022 | A61B-0005/0035 | A61B-0005/7246 | A61B-0005/7282 | A61B-0005/742 | A61B-0005/748 | A61B-0005/7425 | A61B-0005/7475 | G06F-0003/0481 | G06F-0003/0484 | G06F-0003/0486 | G06F-0019/321 | G06F-0040/106 | G06F-0040/123 | G06F-0040/134 | G06F-0040/169 | G06T-0007/0014 | G06T-0011/60 | G16H-0030/20 | G16H-0050/20 | A61B-0005/0002 | A61B-0005/0013 | A61B-0005/055 | A61B-0005/7264 | A61B-0005/743 | A61B-0005/7435 | A61B-0005/7485 | A61B-2560/0475 | A61B-2576/02","A61B-005/00","A61B-005/00 | G16H-015/00 | G06F-003/0484 | G16H-050/20 | G06F-019/00 | G06F-040/106 | G06F-040/123 | G06F-040/134 | G06F-040/169 | G16H-030/20 | G06F-003/0481 | G06F-003/0486 | G06T-007/00 | G06T-011/60 | A61B-005/055","","","","","","4920038005608"
"US","US","P","B2","System and method for insulin pump medical device including a slider assembly wherein images on display allow for highlighting and magnifying images","A medical system includes an input assembly for receiving one or more user inputs. The input assembly includes at least one slider assembly for providing an input signal. Processing logic receives the input signal from the input assembly and provides a first output signal and a second output signal. A display assembly is configured to receive, at least in part, the first output signal from the processing logic and render information viewable by the user. The second output signal is provided to one or more medical system components. The information rendered on the display assembly may be manipulatable by the user and at least a portion of the information rendered may be magnified.","1. A medical system comprising: a first medical device comprising: a pump assembly configured to pump fluid out of a reservoir for delivery;a feedback system configured to indicate the dosage of fluid delivered;a display assembly for rendering information; andan input assembly comprising at least one slider assembly, for manipulating the information rendered on the display assembly and for providing an input signal in response to an input; anda second medical device configured to communicate with the first medical device, the second medical device comprising: telemetry circuitry for communication with the first medical device;a display assembly for rendering information;an input assembly comprising at least one slider assembly for manipulating the information rendered on the display assembly and for providing an input signal in response to an input;a computer program product residing on a computer readable medium having a plurality of instructions stored thereon which, when executed by a processor, cause the processor to perform operations comprising: selecting information on the display assembly,highlighting the selected information on the display assembly,magnifying the highlighted selected information with respect to the nonhighlighted information on the display assembly.","10","16/679443","2019-11-11","2020-0069869","2020-03-05","10765802","2020-09-08","DEKA PRODUCTS LIMITED PARTNERSHIP","Kevin L.  Grant | Douglas J.  Young | Matthew C.  Harris","","","","A61M-0005/14244","A61M-0005/14244 | A61M-0005/1723 | G06F-0003/03547 | G06F-0003/0482 | G06F-0003/04847 | G06K-0009/2054 | G06T-0003/40 | G16H-0010/60 | G16H-0020/17 | A61M-2005/14208 | A61M-2205/502 | A61M-2205/505 | A61M-2205/52 | A61M-2205/58 | A61M-2230/201 | G06F-0003/03548 | G06F-0003/044 | G06F-2203/0339","A61M-005/142","A61M-005/142 | G06F-003/0482 | G06F-003/0354 | G06F-003/0484 | G06K-009/20 | G06T-003/40 | A61M-005/172 | G16H-020/17 | G16H-010/60 | G06F-003/044","","","","","","4920037001474"
"US","US","P","B2","Systems and methods for using a transcutaneous electrical stimulation device to deliver titrated therapy","The disclosed electrical stimulation system generates interventions to assist patients in complying with a diet. The wearable device includes a microprocessor, electrical stimulator and at least one electrode configured to deliver electrical stimulation to the epidermis, through a range of 0.1 mm to 10 mm or a range of 0.1 mm to 20 mm of the dermis, of a T2 dermatome to a T12 dermatome or meridian of the patient, a C5 to a T1 dermatome across the hand and/or arm, and/or the upper chest regions. The device is adapted to provide electrical stimulation as per stimulation protocols and to communicate wirelessly with a companion control device configured to monitor and record appetite patterns of the patient and deliver titrated therapy. The control device is also configured to monitor, record, and modify stimulation parameters of the stimulation protocols.","1. A method of enabling a patient to achieve a weight loss objective using an electrical dermal patch secured to the patient'ss skin comprising a housing, an electrical pulse generator positioned within the housing, and at least one electrode attached to said housing and in electrical communication with the electrical pulse generator, wherein said electrical pulse generator is configured to deliver electrical pulses having a pulse amplitude in a range of 1 mA to 65 mA, the method comprising: using a plurality of programmatic instructions configured to execute on a device external to the electrical dermal patch, receiving data indicative of at least one of weight, well-being, hunger, appetite, calories consumed by the patient, or calories expended by the patient;applying a plurality of stimulation sessions to the patient'ss skin using said electrical dermal patch over a duration of one week, wherein each of the plurality of stimulation sessions comprises said electrical pulses, wherein at least some of the plurality of stimulation sessions have a duration of at least 15 minutes, and wherein the plurality of stimulation sessions comprises at least two occurring on different days in the week;repeatedly applying said plurality of stimulation sessions over a predefined period of time; andafter the predefined period of time, using the plurality of programmatic instructions configured to execute on the device external to the electrical dermal patch to modify said plurality of stimulation sessions based on at least one of the data indicative of weight, the data indicative of well-being, the data indicative of hunger, the data indicative of appetite, the data indicative of calories consumed by the patient, or the data indicative of calories expended by the patient.","75","15/728413","2017-10-09","2018-0085580","2018-03-29","10765863","2020-09-08","ELIRA, INC.","Raul E.  Perez | Peter I.  Hong | Steven  Diianni | Luis Jose  Malave | Brad  Stengel","","","","A61N-0001/36031","A61N-0001/36031 | A61N-0001/0456 | A61N-0001/0484 | A61N-0001/0492 | A61N-0001/0496 | A61N-0001/36007 | A61N-0001/36014 | A61N-0001/37247 | G09B-0019/0092 | A61B-0005/1118 | A61B-0005/14532 | A61B-0005/4866 | A61B-0005/681 | A61N-0001/0502 | G06Q-0010/1093","A61N-001/36","A61N-001/36 | A61N-001/04 | G09B-019/00 | A61N-001/372 | A61B-005/11 | A61B-005/00 | A61B-005/145 | G06Q-010/10 | A61N-001/05","","","","","","4920037001534"
"US","US","P","B2","Wearable computing device","The present disclosure describes a wearable computing device (WCD) in the form of a ring that can be worn on the finger of a human user.","1. An intelligent ring computing device configured for fitting around a finger of a wearer and adapted for unlocking a client computing device, the intelligent ring comprising: a housing, the housing having an outer bounding member and an inner bounding member, the outer and inner bounding members configured for being coupled together in a manner so as to form an interior portion, the interior portion retaining a plurality of components of the intelligent ring;a curved rechargeable battery positioned within the interior portion of the housing;one or more sensors, the one or more sensors comprising at least one of an accelerometer, a gyroscope, or a motion sensor, the one or more sensors being configured to sense a change in a condition of the wearer of the intelligent ring so as to produce sensed data;a memory, the memory storing one or more instructions, the instructions pertaining to remotely unlocking the client computing device;a flexible printed circuit board positioned proximate the outer bounding member, the flexible printed circuit board comprising: a processor, the processor configured for receiving the sensed data and implementing the one or more instructions in response thereto; anda communication module, the communication module comprising a near field communication device configured for communicating authorization data to the client computing device to unlock the client computing device.","20","16/224686","2018-12-18","2019-0384354","2019-12-19","10768666","2020-09-08","MOTIVE (ABC), LLC | PROXY, INC.","Curt C.  von Badinski | Michael J.  Strasser | Peter  Twiss","","","","G06F-0001/163","G06F-0001/163 | A61B-0005/01 | A61B-0005/021 | A61B-0005/0205 | A61B-0005/02416 | A61B-0005/0404 | A61B-0005/0452 | A61B-0005/1118 | A61B-0005/1455 | A61B-0005/14532 | A61B-0005/681 | A61B-0005/6826 | G01P-0015/00 | G02B-0019/0052 | G02B-0019/0061 | G04G-0021/02 | G04G-0021/025 | G06F-0001/1635 | G06F-0003/014 | G06F-0003/017 | G06F-0003/14 | G06F-0021/32 | G06K-0009/00885 | G06K-0009/00892 | G06K-0009/6202 | G08B-0005/36 | G08B-0021/02 | G08C-0017/02 | H02J-0007/0044 | H02J-0007/0047 | H02J-0007/35 | H02S-0040/22 | H02S-0099/00 | A61B-2560/0214 | A61B-2560/0412 | A61B-2562/146 | A61B-2562/164 | A61B-2562/166 | G02B-0019/0042 | G06K-2009/00939 | G08C-2201/30 | Y02E-0010/52","G06F-001/16","G06F-001/16 | A61B-005/00 | H02J-007/35 | G01P-015/00 | G04G-021/02 | G06F-003/01 | G06K-009/00 | G08B-021/02 | G08C-017/02 | G06F-003/14 | G08B-005/36 | H02J-007/00 | H02S-040/22 | G02B-019/00 | H02S-099/00 | A61B-005/01 | A61B-005/021 | A61B-005/024 | A61B-005/0452 | A61B-005/11 | A61B-005/145 | A61B-005/1455 | G06F-021/32 | G06K-009/62 | A61B-005/0205 | A61B-005/0404","","","","","","4920037004316"
"US","US","P","B2","Information processing apparatus, information processing system, and computer program product","According to one embodiment, an information processing apparatus includes an input receiver, a template selector, and a tracker. The input receiver receives an input operation of a user. The template selector specifies at least one template out of a plurality of templates that are related to a shape of an object based on the input operation received by the input receiver. The tracker tracks the object in an image including the object by using the at least one template specified by the template selector.","1. An information processing apparatus comprising: a processor configured to: control to display, on a display, two or more templates included in a plurality of templates that are related to a shape of a marker inside a subject;control to receive an input operation of a user which is a user'ss selection operation of selecting one or more templates out of the two or more templates displayed on the display;control to specify at least one template out of the plurality of templates based on the input operation; andcontrol to track the marker in an image including the marker by using the at least one template.","19","15/894271","2018-02-12","2019-0026584","2019-01-24","10769467","2020-09-08","KABUSHIKI KAISHA TOSHIBA","Ryusuke  Hirai | Yasunori  Taguchi | Wataru  Watanabe","2017-141230","JP","2017-07-20","G06K-0009/2081","G06K-0009/2081 | A61N-0005/1049 | A61N-0005/1067 | G06K-0009/00208 | G06K-0009/6202 | G06K-0009/6215 | A61N-2005/1061 | A61N-2005/1074 | G06F-0003/0482 | G06F-0003/0488 | G06F-0003/04845 | G06K-2009/3291","G06K-009/00","G06K-009/00 | G06K-009/20 | G06K-009/62 | A61N-005/10 | G06F-003/0482 | G06F-003/0488 | G06K-009/32 | G06F-003/0484","","","","","","4920037005111"
"US","US","P","B2","Information processing device, information processing method, and program","[Object] To provide an information processing device, an information processing method, and a program capable of providing property transactions with a higher degree of satisfaction by generating certain property information using a happiness score based on user information. [Solution] The information processing device includes: a computation unit that computes a happiness score on a basis of sensed user information; and a generation unit that generates certain property information using the computed happiness score.","1. An information processing device including a real estate search and presentation system, comprising: a data collection device configured to collect resident input information from a plurality of residents;the resident input information including blood pressure data of a resident and GPS position data of the resident and address location of the resident;a blood pressure sensor configured to sense and provide the blood pressure data of the resident;a Global Positioning System (GPS) sensor configured to sense and provide the GPS position data of the resident;a resident input device configured to receive the address location of the resident;happiness computation circuitry configured to generate a happiness score indicating an emotional happiness assessment associated with the resident in connection with the GPS position data of the resident, and the happiness score generated on the basis of positive emotion data including positive emotion data estimated from biological information including the blood pressure data of the resident;the happiness score memory configured to store the happiness score in association with the GPS position data of the resident and the address location of the resident, for each of the plurality of residents;property information memory configured to store a plurality of real estate property information including address location data for each of the plurality of real estate property information;property information generation circuitry configured to: detect when a search request was submitted,generate one or more resultant real estate property information including the resultant address location data for each of the resultant real estate property information, wherein each of the resultant real estate property information met criteria of the search request, the criteria including a happiness score criteria, andprovide a resultant happiness score associated with each resultant address location for each of the resultant real estate property information which met the happiness score criteria of the search request, wherein each of the resultant happiness scores were generated based upon resultant positive emotion data estimated from resultant biological information including the resultant blood pressure data of the resultant resident and the associated resultant retrieved GPS position data; andinformation presentation circuitry configured to cause a display to present the resultant real estate property information which met the happiness score criteria of the search request;wherein the information presentation circuitry is further configured to arrange the resultant real estate property information in an order based upon each of their associated resultant happiness scores.","20","15/558601","2016-02-24","2018-0082387","2018-03-22","10769737","2020-09-08","SONY CORPORATION","Yasushi  Tsuruta","2015-107821","JP","2015-05-27","G06Q-0050/16","G06Q-0050/16 | A61B-0005/1118 | G06F-0016/00 | G06F-0016/29 | G06K-0009/00302 | G10L-0025/63","G06Q-050/16","G06Q-050/16 | G06F-016/29 | G06F-016/00 | G10L-025/63 | A61B-005/11 | G06K-009/00","","","","","","4920037005381"
"US","US","P","B2","Method for increasing reading efficiency in medical image reading process using gaze information of user and apparatus using the same","According to one embodiment, a method for increasing the reading efficiency of a medical image is provided. The method of increasing the reading efficiency of a medical image comprises of: receiving the gaze information of a user, acquiring a gaze tracking device, during a medical image reading process; determining a region of interest of the user with respect to the medical image by using the gaze information; determining a type of service corresponding to the region of interest; and providing the determined service.","1. A method for increasing medical image reading efficiency, comprising: acquiring gaze information of a user including change of gaze and fixation time of gaze during a reading process of the medical image by the user by using a gaze tracking unit coupled with the medical image reading apparatus;generating, by the medical image reading apparatus, information on a region of interest (ROI) of the user based on the gaze information wherein the information on the region of interest includes the region of interest which is extracted from regions included in the medical image;determining, by the medical image reading apparatus, a type of service corresponding to the region of interest, using the gaze information which includes the change of gaze and the fixation time of gaze; andproviding, by the medical image reading apparatus, the determined service, and wherein the type of service is determined to be adapted for reading efficiency of the region of interest, based on characteristics of the region of interest including the dimension of the medical image, the modality of the medical image and the morphology of the medical image, and a department in which the user is specialized,wherein the providing the type of service includes:in the event that the region of interest is a tissue or a lesion, providing, by the medical image reading apparatus, a three-dimensional model of the tissue or the lesion,wherein the three-dimensional model is generated based on reconstructing regions of the tissue or a lesion into a three-dimension.","17","15/760803","2015-09-24","2019-0340751","2019-11-07","10769779","2020-09-08","VUNO, INC.","Sangki  Kim | Hyun-Jun  Kim | Kyuhwan  Jung | Yeha  Lee","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0003/113 | G06F-0003/013 | G16H-0030/20 | A61B-0005/055 | A61B-0006/032 | G06F-0003/012 | G06F-0003/048","G06F-003/01","G06F-003/01 | G06T-007/00 | G16H-030/20 | A61B-003/113 | A61B-005/055 | A61B-006/03 | G06F-003/048","","","","","","4920037005423"
"US","US","P","B2","Methods and apparatus to adjust content presented to an individual","Methods, apparatus, systems and articles of manufacture to adjust content presented to an individual are disclosed. An example system includes a first modality sensor to measure a first response of an individual to first content during a first time frame and a second modality sensor to measure a second response of the individual to the first content during the first time frame. The first modality sensor is to measure a third response of the individual to first content during a second time frame, and the second modality sensor is to measure a fourth response of the individual to the first content during the second time frame. The example system also includes a mental classifier executing instructions to determine a first mental classification of the individual based on a first comparison of the first response to a first threshold and a second comparison of the second response to a second threshold. The mental classifier also is to determine a second mental classification of the individual based on a third comparison of the third response to a third threshold and a fourth comparison of the fourth response to a fourth threshold. In addition, the mental classified is to determine a mental state of the individual based on a degree of similarity between the first mental classification and the second mental classification. The example system also includes a content modifier to at least one of modify the first content to include second content or replace the first content with second content based on the mental state.","1. A system comprising: a first sensor to measure a first response of an individual to first content during a first time frame and a second response of the individual to the first content during a second time frame, the first sensor including a pupil dilation sensor;a second sensor to measure a third response of the individual to the first content during the first time frame and a fourth response of the individual to the first content during the second time frame; anda processor to: generate a cognitive load index based on data from the pupil dilation sensor, the cognitive load index representative of how much of an information processing capacity of the individual is being used;determine a first mental classification of the individual based on (1) a first comparison of the first response to a first threshold and (2) a second comparison of the third response to a second threshold;determine a second mental classification of the individual based on (1) a third comparison of the second response to a third threshold and (2) a fourth comparison of the fourth response to a fourth threshold;determine a mental state of the individual based on a degree of similarity between the first mental classification and the second mental classification; andat least one of modify the first content to include second content or replace the first content with the second content based on the mental state.","18","15/908436","2018-02-28","2018-0192126","2018-07-05","10771844","2020-09-08","CITIBANK, N.A","Carl D.  Marci | Brian  Levine | Brendan  Murray","","","","H04N-0021/44218","H04N-0021/44218 | A61B-0003/112 | A61B-0003/113 | A61B-0005/0064 | A61B-0005/0533 | A61B-0005/165 | A61B-0005/7282 | G06F-0003/01 | G06K-0009/00221 | G06K-0009/00362 | G06Q-0030/0201 | H04N-0021/4223 | H04N-0021/42201 | H04N-0021/4415 | H04N-0021/44204 | H04N-0021/44213 | H04N-0021/458 | H04N-0021/812 | A61B-0005/7278 | A61B-2503/12","H04N-021/442","H04N-021/442 | A61B-005/053 | A61B-003/11 | A61B-003/113 | A61B-005/16 | H04N-021/81 | G06Q-030/02 | H04N-021/4415 | G06K-009/00 | H04N-021/458 | G06F-003/01 | H04N-021/422 | H04N-021/4223 | A61B-005/00","","","","","","4920037007475"
"US","US","P","B2","Orientation independent sensing, mapping, interface and analysis systems and methods","The disclosure relates generally to applications of Orientation Independent Sensing (OIS) and Omnipolar mapping Technology (OT) to various system, device and method embodiments as recited herein. Similarly, systems and methods suitable for supporting OIS and OT systems and methods are disclosed. Further, OIS and OT implementations that provide end user interfaces, diagnostic indicia and visual displays generated, in part, based on measured data or derived from measured data are also disclosed. Embodiments also describe applying optimization techniques to determine the greatest voltage difference of a local electric field associated with an electrode-based diagnostic procedure and a vector representation thereof. Various graphic user interface related features are also described to facilitate orientation and electrode clique signal display.","1. A method of reducing one or more error types in cardiac system data obtained from a subject using a plurality of electrodes, the method comprising: defining an error reducing vector {circumflex over (m)} by normalizing a differential electric field vector using a magnitude, wherein the differential electric field vector is a difference of a first electric field vector E(tj) and a second electric field vector E(ti), wherein ti and tj are electric field measurements in time, wherein tj>ti and wherein the magnitude is |E(tj)?E(ti)|;determining a cardiac system parameter by performing a vector operation comprising operating, using an operator, upon (i) {circumflex over (m)} or a vector perpendicular thereto {circumflex over (m)}⊥ and(ii) a diagnostic vector, wherein the diagnostic vector is generated using measured cardiac electrogram signalsto generate an output, wherein the output is a scalar output or a vector output; anddisplaying the output or information correlated with the output.","24","15/953155","2018-04-13","2018-0296111","2018-10-18","10758137","2020-09-01","ST JUDE MEDICAL CARDIOLOGY DIVISION, INC | ST JUDE MEDICAL, CARDIOLOGY DIVISION, INC.","Don Curtis  Deno | Dennis J.  Morgan | Joshua C.  Bush | Kumaraswamy  Nanthakumar | Stephane  Masse | Karl  Magtibay","","","","A61B-0005/04011","A61B-0005/04011 | A61B-0005/044 | A61B-0005/046 | A61B-0005/04017 | A61B-0005/0422 | A61B-0005/0432 | A61B-0005/7203 | A61B-0005/746 | G06F-0003/0482","A61B-034/20","A61B-034/20 | A61B-018/14 | A61B-005/04 | G06F-003/0482 | A61B-005/042 | A61B-005/00 | A61B-005/044 | A61B-005/046 | A61B-005/0432","","","","","","4920036001022"
"US","US","P","B2","Method for operating an image system of a medical imaging modality and medical imaging modality","A method operates an image system of a medical imaging modality in which a patient data record of a patient is processed. A workflow for an examination is selected from a set of workflows on the basis of an examination specification of the patient data record. Wherein each workflow contains comprises a selection from a set of functions which are carried out in a specific temporal sequence.","1. A method for operating an image system of a medical imaging modality in which a patient data record of a patient is processed, which comprises the steps of: selecting a workflow for examination from a set of workflows for user guidance on a basis of an examination specification of the patient data record, each of the workflows having a selection from a set of functions which are carried out in a specific temporal sequence, and the workflow having a function block with functions that are freely selectable by a user, the function block being terminated by means of user input or by means of carrying out a specific function;wherein the function block enables the user to select all of the functions of the function block to be part of the workflow and the function block enables a user to select less than all of the functions of the function block to be part of the workflow; andwherein the functions in the function block are initially defined in the function block, and at least some functions in the workflow are temporally located before the function block.","9","15/381381","2016-12-16","2017-0177387","2017-06-22","10758154","2020-09-01","SIEMENS HEALTHCARE GMBH","Clemens  Joerger | Gudrun  Roth-Ganter","10-2015-225543","DE","2015-12-17","A61B-0005/055","A61B-0005/055 | A61B-0005/742 | A61B-0005/7475 | A61B-0006/032 | A61B-0006/4441 | A61B-0006/487 | G06F-0003/0482 | G06F-0003/0484 | G06F-0003/04847 | G06F-0009/453 | G06F-0019/321 | A61B-0006/461 | A61B-0006/467","A61B-008/00","A61B-008/00 | A61B-005/055 | G06F-009/451 | G06F-003/0484 | A61B-005/00 | A61B-006/03 | A61B-006/00 | G06F-003/0482 | G06F-019/00","","","","","","4920036001039"
"US","US","P","B2","Adjusting alarms based on sleep onset latency","In some implementations, a mobile device can adjust an alarm setting based on the sleep onset latency duration detected for a user of the mobile device. For example, sleep onset latency can be the amount of time it takes for the user to fall asleep after the user attempts to go to sleep (e.g., goes to bed). The mobile device can determine when the user intends or attempts to go to sleep based on detected sleep ritual activities. Sleep ritual activities can include those activities a user performs in preparation for sleep. The mobile device can determine when the user is asleep based on detected sleep signals (e.g., biometric data, sounds, etc.). In some implementations, the mobile device can determine recurring patterns of long or short sleep onset latency and present suggestions that might help the user sleep better or feel more rested.","1. A method, comprising: receiving, by a computing device, indication of a desired sleep duration;calculating, by the computing device, a sleep onset latency duration based on a difference between an intended sleep time and an actual sleep time;setting, by the computing device, an alarm timer in response to the actual sleep time being determined, the alarm timer being set to correspond to the desired sleep duration added to the sleep onset latency duration; andtriggering, by the computing device, an alarm in response to expiration of the alarm timer.","21","16/212502","2018-12-06","2019-0104985","2019-04-11","10758173","2020-09-01","Apple Inc.","Roy J.  Raymann | Wren N.  Dougherty | Divya  Nag | Deborah M.  Lambert | Stephanie  Greer | Thomas R.  Gruber","","","","A61B-0005/4809","A61B-0005/4809 | G06Q-0010/109 | G08B-0021/06 | H04L-0067/22 | H04M-0001/72566 | H04W-0004/70 | A61B-0005/01 | A61B-0005/02416 | A61B-0005/0816 | A61B-0005/11 | A61B-0005/4815 | A61B-0005/742 | A61B-2560/0242","H04M-001/725","H04M-001/725 | A61B-005/00 | H04W-004/70 | G06Q-010/10 | G08B-021/06 | H04L-029/08 | A61B-005/01 | A61B-005/024 | A61B-005/08 | A61B-005/11","","","","","","4920036001058"
"US","US","P","B2","Method for cross-diagnostic identification and treatment of neurologic features underpinning mental and emotional disorders","A system and method for diagnosing mental or emotional disorders is disclosed. An affective BCI component is incorporated into a closed loop, symptom?responsive psychiatric DBS system. A series of input data related to a brain of the patient is acquired while the patient performs a battery of behavioral tasks. From the patient's performance on the task battery, the system identifies what is abnormal for that individual patient in terms of functional domains. Patient-specific behavioral measurements are then linked to patterns of activation and de-activation across different brain regions, identifying specific structures that are the source of the patient's individual impairment.","1. A method for diagnosing mental or emotional disorders comprising: a) administering, using a computer interface, a transdiagnostic assessment to a patient, the transdiagnostic assessment including at least one psycho-physical task;b) receiving a series of input data related to a brain of the patient acquired while the patient performs the at least one psycho-physical task;c) determining an impairment corresponding to the patient along a set of functional domains;d) recording, using a signal recorder, at least one of electrical, magnetic, optical, bio-acoustic, brain derived or body derived activity from the patient;e) identifying, from the at least one psycho-physical task, a deviation in the set of functional domains as compared to a predetermined control that indicates a mental or emotional disorder;f) identifying brain regions and signal characteristics corresponding to the identified deviation, using the input data;g) applying, using at least one stimulation device, stimulation to the identified brain regions to alter the at least one of electrical, magnetic, optical, bio-acoustic, brain derived or body derived activity in the brain regions; andwherein the functional domains include at least one of fear, reward motivation, emotion regulation, decision making/impulsivity, or attention/preservation.","26","15/305551","2015-04-22","2017-0042474","2017-02-16","10758174","2020-09-01","THE GENERAL HOSPITAL CORPORATION | MASSACHUSETTS INSTITUTE OF TECHNOLOGY","Alik S.  Widge | Thilo  Deckersbach | Darin  Dougherty | Emad  Eskandar | Kristen  Ellard","","","","A61B-0005/4836","A61B-0005/4836 | A61B-0003/112 | A61B-0003/113 | A61B-0005/0008 | A61B-0005/0075 | A61B-0005/024 | A61B-0005/0205 | A61B-0005/0402 | A61B-0005/04008 | A61B-0005/0488 | A61B-0005/053 | A61B-0005/165 | A61B-0005/4064 | A61B-0006/037 | A61B-0008/0808 | A61N-0001/0531 | A61N-0001/0534 | A61N-0001/36096 | A61N-0001/36132 | A61N-0001/36135 | A61N-0001/36139 | A61N-0001/3787 | G06F-0003/015 | G16H-0020/40 | G16H-0020/70 | A61B-0005/055 | A61B-0005/0816","A61N-001/37","A61N-001/37 | A61B-005/00 | A61N-001/378 | A61N-001/05 | A61N-001/36 | G16H-020/40 | G16H-020/70 | A61B-005/024 | A61B-005/053 | A61B-005/16 | G06F-003/01 | A61B-003/11 | A61B-003/113 | A61B-005/0205 | A61B-005/04 | A61B-005/0402 | A61B-005/0488 | A61B-006/03 | A61B-008/08 | A61B-005/055 | A61B-005/08","","","","","","4920036001059"
"US","US","P","B2","Methods and apparatus for neuromodulation","A neuromodulator accurately measures?in real time and over a range of frequencies?the instantaneous phase and amplitude of a natural signal. For example, the natural signal may be an electrical signal produced by neural tissue, or a motion such as a muscle tremor. The neuromodulator generates signals that are precisely timed relative to the phase of the natural signal. For example, the neuromodulator may generate an exogenous signal that is phase-locked with the natural signal. Or, for example, the neuromodulator may generate an exogenous signal that comprises short bursts which occur only during a narrow phase range of each period of an oscillating natural signal. The neuromodulator corrects distortions due to Gibbs phenomenon. In some cases, the neuromodulator does so by applying a causal filter to a discrete Fourier transform in the frequency domain, prior to taking an inverse discrete Fourier transform.","1. An apparatus comprising: (a) one or more sensors that are configured to measure a physiological signal;(b) one or more computers that are programmed (i) to calculate a discrete signal that consists of samples of the physiological signal,(ii) to calculate a second signal, which second signal is a discrete Fourier transform of the discrete signal,(iii) to calculate a smoothed signal, by performing calculations that include (A) applying a causal filter to the second signal, which causal filter deforms a front-segment but not an end-segment of the second signal in such a way that the start point of the smoothed signal is equal in value to the endpoint of the smoothed signal, and (B) removing negative frequency components,(iv) to calculate an analytic signal, which analytic signal is equal to an inverse discrete Fourier transform of the smoothed signal,(v) to calculate, based on the analytic signal, instantaneous phase of the physiological signal, and(vi) to output instructions, based on the instantaneous phase; and(c) one or more transducers that are configured to output, based on the instructions, a neuromodulation signal.","20","16/571845","2019-09-16","2020-0008743","2020-01-09","10758175","2020-09-01","ELEMIND TECHNOLOGIES, INC. | NUVU, LLC | MASSACHUSETTS INSTITUTE OF TECHNOLOGY","Nir  Grossman | David  Wang | Edward  Boyden","","","","A61B-0005/4836","A61B-0005/4836 | A61B-0005/04001 | A61B-0005/0476 | A61B-0005/1101 | A61B-0005/7253 | A61B-0005/7257 | A61N-0005/0622 | A61N-0007/00 | G06F-0017/14 | A61N-2005/063 | A61N-2007/0021","A61B-005/00","A61B-005/00 | A61B-005/0476 | G06F-017/14 | A61B-005/04 | A61B-005/11 | A61N-005/06 | A61N-007/00","","","","","","4920036001060"
"US","US","P","B2","Systems and methods for selecting, activating, or selecting and activating transducers","A graphical representation may be displayed including at least a plurality of transducer graphical elements, each transducer graphical element of the plurality of transducer graphical elements representative of a respective transducer of a plurality of transducers of a transducer-based device. A set of user input may be received including an instruction set to reposition a first transducer graphical element in a state in which the first transducer graphical element is located at a first location in the graphical representation and a second transducer graphical element is located at a second location in the graphical representation, the second location closer to a predetermined location in the graphical representation than the first location. In response to conclusion of receipt of the set of user input, the first transducer graphical element may be repositioned from the first location in the graphical representation to the predetermined location in the graphical representation.","1. A medical device system comprising: a data processing device system;an input-output device system communicatively connected to the data processing device system; anda memory device system communicatively connected to the data processing device system and storing a program executable by the data processing device system, the program comprising:communication instructions configured to cause the data processing device system to communicate, via the input-output device system, with an electrode-based device system comprising a structure and a plurality of electrodes arrangeable in a three dimensional distribution on the structure, the structure and the plurality of electrodes locatable within a bodily cavity;first display instructions configured to cause the input-output device system to display information regarding at least the electrode-based device system, the displayed information including a graphical representation of at least a portion of the electrode-based device system, the graphical representation comprising a map of at least the three dimensional distribution, the map of the three dimensional distribution portraying the three dimensional distribution distorted onto a two dimensional plane, the graphical representation including a plurality of graphical elements arranged according to the map of the three dimensional distribution, each graphical element of the plurality of graphical elements corresponding to a respective electrode of the plurality of electrodes, the plurality of graphical elements including a first set of graphical elements and a second set of graphical elements, the first set of graphical elements located relatively further, as compared to the second set of graphical elements, from a central region of the map of the three dimensional distribution, each particular graphical element in the first set of graphical elements appearing enlarged with respect to each particular graphical element in the second set of graphical elements;activation instructions configured to cause activation, via the input-output device system, of at least some electrodes of the plurality of electrodes; andsecond display instructions configured to cause the input-output device system to update the displayed information based at least on a result of the activation.","40","16/139772","2018-09-24","2019-0029608","2019-01-31","10758191","2020-09-01","KARDIUM INC.","Saar  Moisa | Michael Hermann  Weber","","","","A61B-0005/743","A61B-0005/743 | A61B-0005/015 | A61B-0005/02 | A61B-0005/042 | A61B-0005/0422 | A61B-0005/6859 | A61B-0005/6869 | A61B-0005/72 | A61B-0005/748 | A61B-0005/7435 | G06F-0003/0482 | G06F-0003/04815 | G06F-0003/04842 | G06F-0003/04847 | A61B-0005/157 | A61B-0005/150022 | A61B-0005/150969 | A61B-0018/1492 | A61B-2018/00214 | A61B-2018/00267 | A61B-2018/00357 | A61B-2018/00577 | A61B-2018/00642 | A61B-2018/00702 | A61B-2018/00791 | A61B-2018/00839 | A61B-2018/00875 | A61B-2018/1467 | A61B-2034/107 | A61B-2560/0475 | G16H-0040/63","A61B-005/00","A61B-005/00 | A61B-005/01 | A61B-005/042 | G06F-003/0484 | A61B-005/02 | G06F-003/0482 | G06F-003/0481 | A61B-018/00 | A61B-005/15 | A61B-005/157 | A61B-018/14 | A61B-034/10 | G16H-040/63","","","","","","4920036001076"
"US","US","P","B2","Dialysis system with artificial intelligence","Constraining adaptive optimizations of a state of an operation module of a medical device includes determining if a new state has at least one operational parameter that is outside a constraint that has been provided to the medical device in a non-repudiable manner, accepting the new state if no operational parameters are outside any of the constraints, and reverting the medical device to a previous valid state if at least one operational parameter is outside at least one of the constraints. The adaptive optimizations may be provided using artificial intelligence along with relevant inputs thereto. The medical device may be a dialysis system. Constraint data may be provided to the medical device along with a one-way hash value of the constraint data using, for example, a SHA 256 hash. The one-way hash value may be digitally signed using a private key that is part of a public/private key pair.","1. A method of constraining adaptive optimizations of operational parameters of an operation module of a medical device, comprising: determining if a new state corresponding to an adjustment of values of at least one of the operational parameters results in at least one of the operational parameters being outside at least one of a plurality of constraints that have been provided to the medical device, the constraints being non-repudiable;accepting the new state if none of the operational parameters are outside any of the constraints; andreverting the medical device to a previous valid state if at least one of the operational parameters is outside at least one of the constraints, wherein the constraints are provided to the medical device along with a one-way hash value of the constraints that is digitally signed.","18","16/228863","2018-12-21","2020-0197592","2020-06-25","10758660","2020-09-01","FRESENIUS MEDICAL CARE HOLDINGS, INC.","Norbert  Leinfellner | Joseph  Manakkil","","","","A61M-0001/287","A61M-0001/287 | A61M-0001/3403 | B01D-0061/32 | A61M-0001/282 | A61M-2205/3584 | A61M-2205/502 | A61M-2205/52 | A61M-2205/6009 | G06F-0003/04847 | G06F-0009/451","A61M-001/28","A61M-001/28 | B01D-061/32 | A61M-001/34 | G06F-003/0484 | G06F-009/451","","","","","","4920036001543"
"US","US","P","B2","Decision support tool for choosing treatment plans","Patient data can be used to determine input values to different estimation functions for different treatment types. The estimation functions can each be used to estimate one or more outcome values for the respective treatment. A quality score can be determined using the outcome value(s). A first treatment plan having an optimal quality score can be identified, e.g., by displaying the treatment plans with the quality scores, which may correspond to the outcome values.","1. A method of selecting among a plurality of treatment plan types for treating a tumor of a first patient, the method comprising: for each of the plurality of treatment plan types: creating, by a computer system, an estimation function associated with the treatment plan type by: receiving previous outcome values of one or more types of outcome values for previous patients treated using the treatment plan type,receiving previous input values of input variables for the previous patients, for each of the one or more types of outcome values: using the previous input values and the previous outcome values corresponding to the type of outcome value to determine an estimation subfunction of the estimation function;receiving, by the computer system, information about the first patient;analyzing, by the computer system, the information to determine a set of input values, the input values including characteristics of the tumor;for each of the plurality of treatment plan types: identifying an estimation function associated with the treatment plan type, andpredicting a quality of the treatment plan type by using the set of input values with the identified estimation function to calculate, by the computer system, one or more outcome values, and determining a quality score based on the one or more outcome values, the set of input values including the one or more dose input values;identifying, by the computer system, a first treatment plan type having an optimal quality score to a user of the computer system, the first treatment plan type including providing radiation to the first patient;generating, by the computer system, a first treatment plan of the first treatment plan type based on the set of input values and the plurality of outcome values, the first treatment plan including instructions for controlling a treatment head in order to treat the tumor of the first patient; andproviding, by the treatment head coupled with a radiation source, radiation at pre-defined angles and pre-defined doses to specific portions of a treatment area of the first patient according to the first treatment plan, wherein the treatment head is controlled by a control unit according to the instructions in the first treatment plan.","18","14/040479","2013-09-27","2015-0095044","2015-04-02","10762167","2020-09-01","VARIAN MEDICAL SYSTEMS, INTERNATIONAL AG","Joona  Hartman | Maria Isabel  Cordero Marcos | Esa  Kuusela | Jarkko Yrjana  Peltola | Janne Ilmari  Nord","","","","G06F-0019/00","G06F-0019/00 | A61N-0005/103 | G16H-0050/20 | A61N-2005/1041","G06Q-050/00","G06Q-050/00 | G06F-019/00 | A61N-005/10 | G16H-050/20 | G06Q-010/00","","","","","","4920036005026"
"US","US","P","B1","Secure authentication using biometric factors","In general, the techniques of this disclosure describe a computing device in a secure domain that is configured to receive, via a guard device, an authentication factor from a biometric authentication device in a non-secure domain. The biometric authentication device is in a non-secure domain, and the authentication factor comprises an identifier of a prospective user of the biometric authentication device. The computing device may then determine, based on the received authentication factor, whether the prospective user is a trusted user of the computing device based on the authentication factor. Responsive to determining that the prospective user of the biometric authentication device is the trusted user, the computing device may enable access to one or more applications on the computing device.","1. A method comprising: receiving, by a computing device in a secure domain, via a guard device, a first authentication factor from a biometric authentication device in a non-secure domain, wherein the first authentication factor comprises an identifier of a first prospective user of the biometric authentication device;determining, by the computing device, whether the first prospective user is a trusted user of the computing device based on the first authentication factor;determining, by the computing device, that the trusted user has a medic credential based on information stored in a user database stored on the computing device; andresponsive to determining that the first prospective user of the biometric authentication device is the trusted user that has the medic credential, enabling, by the computing device, access to one or more applications on the computing device;after enabling the access to the one or more applications on the computing device, receiving, by the computing device, via the guard device, a second authentication factor from a secondary authentication device in the non-secure domain, wherein the second authentication factor comprises an identifier of a second prospective user, wherein the second prospective user comprises a user of the secondary authentication device;determining, by the computing device, an identity of the second prospective user based on the received second authentication factor and the information stored in the user database; anddetermining, by the computing device, medical treatment information about the second prospective user based on the identity of the second prospective user.","15","15/866046","2018-01-09","","","10762183","2020-09-01","ARCHITECTURE TECHNOLOGY CORPORATION","Deborah K.  Charan | Ranga  Ramanujan","","","","G06F-0021/32","G06F-0021/32 | A61B-0005/0402 | G06K-0009/00221 | G06K-0009/00557","G06F-021/32","G06F-021/32 | A61B-005/0402 | G06K-009/00","","","","","","4920036005042"
"US","US","P","B2","Emotional/cognitive state presentation","Emotional/cognitive state presentation is described. When two or more users, each using a device configured to present emotional/cognitive state data, are in proximity to one another, each device communicates an emotional/cognitive state of the user of the device to another device. Upon receiving data indicating an emotional/cognitive state of another user, an indication of the emotional/cognitive state of the user is presented.","1. A method comprising: detecting, at a first device associated with a first user, a second device associated with a second user that is in viewing proximity to the first device;determining, by the first device, an emotional or cognitive state of the first user;accessing a parameter, stored in association with the second user, to verify that the first user has previously selected the second user as a specific person with which the emotional or cognitive state of the first user can be shared;at least partly in response to detecting the second device is in viewing proximity to the first device, communicating, to the second device, an indication of the emotional or cognitive state of the first user;at least partly in response to detecting the second device is in viewing proximity to the first device, receiving, from the second device, an indication of an emotional or cognitive state of the second user; andpresenting a virtual indicator of the emotional or cognitive state of the second user based on a position of the second user within a virtual reality environment or mixed reality environment visible to the first user.","18","15/158409","2016-05-18","2017-0337476","2017-11-23","10762429","2020-09-01","MICROSOFT TECHNOLOGY LICENSING, LLC","John C.  Gordon | Cem  Keskin","","","","G06N-0005/022","G06N-0005/022 | A61B-0005/165 | G06F-0003/011 | G06F-0003/013 | G06F-0003/015 | G06F-0003/017 | G06K-0009/00302 | G06K-0009/00671 | G06T-0019/006 | H04N-0021/4223 | H04N-0021/42201 | H04N-0021/42202 | H04N-0021/4334 | H04N-0021/43637 | H04N-0021/44231 | H04N-0021/8456 | A61B-0005/0205 | G06F-0001/1613 | G06F-2203/011 | G06K-0009/00597 | G06T-2219/012","G06N-005/02","G06N-005/02 | G06F-003/01 | A61B-005/16 | H04N-021/4223 | G06K-009/00 | H04N-021/845 | H04N-021/433 | H04N-021/4363 | H04N-021/442 | G06T-019/00 | G06F-001/16 | H04N-021/422 | A61B-005/0205","","","","","","4920036005287"
"US","US","P","B2","Machine learning system for assessing heart valves and surrounding cardiovascular tracts","A machine learning system for evaluating at least one characteristic of a heart valve, an inflow tract, an outflow tract or a combination thereof may include a training mode and a production mode. The training mode may be configured to train a computer and construct a transformation function to predict an unknown anatomical characteristic and/or an unknown physiological characteristic of a heart valve, inflow tract and/or outflow tract, using a known anatomical characteristic and/or a known physiological characteristic the heart valve, inflow tract and/or outflow tract. The production mode may be configured to use the transformation function to predict the unknown anatomical characteristic and/or the unknown physiological characteristic of the heart valve, inflow tract and/or outflow tract, based on the known anatomical characteristic and/or the known physiological characteristic of the heart valve, inflow tract and/or outflow tract.","1. A computer-implemented machine learning method for evaluating at least one characteristic of a heart valve, an inflow tract, an outflow tract or a combination thereof the method comprising: (a) predicting, with a transformation function on a computer, at least one of an unknown anatomical characteristic or an unknown physiological characteristic of at least one of a heart valve, an inflow tract or an outflow tract, using at least one of a known anatomical characteristic or a known physiological characteristic of the at least one heart valve, inflow tract or outflow tract, wherein said at least one of said heart valve, said inflow tract, and said outflow tract includes at least one of said heart valve, a heart ventricle, and a heart atrium; and(b) using a production mode of a machine learning system on the computer to direct the transformation function and one or more feature vectors, to predict at least one of unknown anatomical characteristic or unknown physiological characteristic of at least one production heart valve, production inflow tract or production outflow tract, based on at least one of patient specific patient known anatomical characteristic or patient known physiological characteristic of the at least one production heart valve, production inflow tract or production outflow tract, wherein said at least one of said production heart valve, said production inflow tract, said production outflow tract includes at least one of said production heart valve, a production heart ventricle, and a production heart atrium, to generate at least one or more quantities of interest.","55","15/588317","2017-05-05","2017-0337488","2017-11-23","10762442","2020-09-01","STENOMICS, INC.","Michael A.  Singer","","","","G06N-0020/00","G06N-0020/00 | A61B-0005/7253 | A61B-0005/7267 | A61B-0005/7275 | A61B-0034/10 | G06F-0017/11 | G06F-0019/00 | G06N-0005/04 | G16H-0050/20 | G16H-0050/50","G06N-020/00","G06N-020/00 | A61B-005/00 | G06N-005/04 | A61B-034/10 | G16H-050/50 | G16H-050/20 | G06F-017/11 | G06F-019/00","","","","","","4920036005300"
"US","US","P","B2","Risk detection and peer corrective assistance for risk mitigation within a work environment","Methods and systems for predicting injury risk include generating state sequences that precede a hazard event based on information regarding a user's state. A cognitive suite of workplace hygiene and injury predictors (WHIP) is generated based on the state sequences using a processor. The cognitive WHIP predicts a degree of risk correlated with each particular user state sequence. An advantageous relationship between the user and one or more socially connected users is determined. An ameliorative action is triggered when a user enters a high-risk state based on the advantageous relationship to the one or more connected users and proximity of the user to one or more other users.","1. A method for predicting injury risk, comprising: generating state sequences that precede a hazard event that poses a risk of workplace injury based on information regarding user states by embedding a relatively high-dimensional measurement of the user states in a relatively low-dimensional feature space;generating a cognitive suite of workplace hygiene and injury predictors (WHIP) based on the state sequences using a processor, wherein the cognitive WHIP predicts a degree of risk of workplace injury correlated with each particular user state sequence;determining an advantageous relationship between a user and one or more socially connected users;determining an outcome of a previous ameliorative action;triggering an ameliorative action responsive to the user entering a high-risk area determined based on the user'ss state including an indication of user drowsiness, based on the advantageous relationship to the one or more socially connected users, the outcome of the previous ameliorative action, and proximity of the user to one or more other users, including providing an incentive to the one or more socially connected users to reduce the degree of risk; andtriggering an automatic change in a setting of a device in a vicinity of the user in the high-risk state to reduce a degree of risk.","20","14/984417","2015-12-30","2017-0193623","2017-07-06","10762459","2020-09-01","INTERNATIONAL BUSINESS MACHINES CORPORATION","Rahil  Garnavi | James R.  Kozloski | Timothy  Lynar | John  Wagner","","","","G06Q-0010/0635","G06Q-0010/0635 | G06N-0005/045 | G06Q-0050/01 | G06Q-0050/265 | A61B-0005/681 | A61B-0005/7275 | G05B-0019/406 | G06F-0001/163","G06Q-010/06","G06Q-010/06 | G06Q-050/26 | G06Q-050/00 | G06N-005/04 | A61B-005/00 | G06F-001/16 | G05B-019/406","","","","","","4920036005317"
"US","US","P","B2","Predictive alerts for individual risk of injury with ameliorative actions","Methods and systems for predicting injury risk include generating state sequences that precede a hazard event based on information regarding a user's state. A cognitive suite of workplace hygiene and injury predictors (WHIP) is generated based on the state sequences using a processor, wherein the cognitive WHIP predicts a degree of risk correlated with each particular user state sequence. A risk heat map of a workplace is generated based on the cognitive WHIP that encodes regions of greater and lesser risk. An ameliorative action is triggered when a user moves into an area of high risk based on the heat map.","1. A method for predicting injury risk, comprising: generating state sequences that precede a hazard event that poses a risk of workplace injury based on information regarding a user'ss state by embedding a relatively high-dimensional measurement of the user'ss state in a relatively low-dimensional feature space;generating a cognitive suite of workplace hygiene and injury predictors (WHIP) based on the state sequences using a processor, wherein the cognitive WHIP predicts a degree of risk of workplace injury correlated with each particular user state sequence;generating a risk heat map of a workplace based on the cognitive WHIP that encodes regions with gradations of risk intensities that include at least low-risk, intermediate-risk, and high risk, wherein the risk intensity of a region is based on an absolute risk level of the region and at least one contextual factor based on the user'ss state, including an indication of drowsiness; andtriggering an ameliorative action when a user moves into an area of high risk based on the heat map that includes automatically changing a setting of a device in the area of high risk to reduce a degree of risk.","20","14/984530","2015-12-30","2017-0193379","2017-07-06","10762460","2020-09-01","INTERNATIONAL BUSINESS MACHINES CORPORATION","Rahil  Garnavi | James R.  Kozloski | Timothy M.  Lynar | John M.  Wagner","","","","G06Q-0010/0635","G06Q-0010/0635 | G06N-0005/045 | G06Q-0050/265 | G09B-0029/007 | A61B-0005/681 | A61B-0005/7275 | G05B-0019/406 | G06F-0001/163","G06Q-010/06","G06Q-010/06 | G06N-005/04 | G09B-029/00 | G06Q-050/26 | G06F-001/16 | A61B-005/00 | G05B-019/406","","","","","","4920036005318"
"US","US","P","B2","System and method for automatically generating a facial remediation design and application protocol to address observable facial deviations","Described are various embodiments of a computerized method and system for automatically developing a facial remediation protocol for a user based on an input facial image of the user, wherein facial remediation design or plan comprises a combination of one or more of a surgical plan to shift or change the size of various facial anatomical features, a makeup plan to change the apparent size or apparent position of various facial anatomical features and other techniques, such as hair design, to reduce the actual and perceived difference between the subject's face and a standard face, for example.","1. A computerized method for automatically developing a facial remediation protocol for a user based on an input facial image of the user, the method comprising: defining a digital user facial structure of the user based on the input facial image;retrieving a designated digital standard facial structure from accessible data storage;computing structural deviations between said digital user facial structure and said designated standard facial structure;retrieving preset digital facial remediation protocol fixes corresponding to at least some of said computed deviations from said accessible data storage, wherein one or more preset facial remediation protocol fixes have been pre-established to at least partially reduce a visual appearance of corresponding structural deviations; andoutputting a digital remediation protocol according to said preset digital facial remediation protocol fixes,wherein said defining said digital user facial structure comprises automatically identifying a user set of preset structural landmarks from the input facial image and defining a digital user landmark representation thereof, said designated digital standard facial structure comprises a corresponding standard landmark representation of a corresponding standard set of preset structural landmarks, and said computing comprises computing deviations between said user landmark representation and said standard landmark representation.","24","16/221448","2017-05-16","2019-0254748","2019-08-22","10751129","2020-08-25","John Gordon Robertson","John Gordon  Robertson","2933799","CA","2016-06-21","A61B-0034/10","A61B-0034/10 | A61B-0005/0077 | G06K-0009/00281 | G06T-0007/0014 | G06T-0011/60 | A61B-2034/105 | G06F-0003/0482 | G06T-2200/24 | G06T-2207/30201","A61B-034/10","A61B-034/10 | A61B-005/00 | G06T-007/00 | G06T-011/60 | G06K-009/00 | G06F-003/0482","","","","","","4920035001217"
"US","US","P","B2","Information processing apparatus, information processing method, and information processing system for status recognition","Provided is an information processing apparatus including a status recognition unit that recognizes a status of a reference apparatus on the basis of information on a status of an apparatus corresponding to the reference apparatus, the reference apparatus serving as a reference when a behavior recognition mode for deciding a status of behavior is set and a behavior-recognition-mode setting unit that sets the behavior recognition mode for a setting target apparatus for which the behavior recognition mode is to be set on the basis of the recognized status of the reference apparatus.","1. An information processing apparatus, comprising: a processor configured to: acquire, from at least one sensor, first information associated with a status of a reference apparatus;recognize the status of the reference apparatus based on the first information;determine a relative distance between the reference apparatus and each of a plurality of setting target apparatuses; andcontrol the plurality of setting target apparatuses to set a first behavior recognition mode of a first setting target apparatus of the plurality of setting target apparatuses and to set a second behavior recognition mode of a second setting target apparatus of the plurality of setting target apparatuses, wherein the first behavior recognition mode and the second behavior recognition mode correspond to recognition of different user behaviors, and the plurality of setting target apparatuses is controlled based on: the recognized status of the reference apparatus,the relative distance between the reference apparatus and each of the first setting target apparatus and the second setting target apparatus, andtransmission of information indicating a respective behavior recognition mode from the reference apparatus to one of the plurality of setting target apparatuses in case the relative distance to the one of the plurality of setting target apparatuses is longer than a threshold.","16","15/103984","2014-09-22","2016-0314401","2016-10-27","10755181","2020-08-25","SONY CORPORATION","Masatomo  Kurata | Masanori  Katsu | Sota  Matsuzawa","2013-265274","JP","2013-12-24","G06N-0005/04","G06N-0005/04 | A61B-0005/11 | G06F-0001/163 | G06F-0003/01 | G06F-0003/011 | G06F-0011/30 | H04M-0001/7253 | H04M-0001/72569 | A61B-0005/68 | A61B-2560/0223 | H04M-0001/72522 | H04M-0001/72563 | H04M-2250/06 | H04M-2250/10","G06N-005/04","G06N-005/04 | G06F-003/01 | G06F-011/30 | A61B-005/11 | H04M-001/725 | G06F-001/16 | A61B-005/00","","","","","","4920035005240"
"US","US","P","B2","Medical scan comparison system","A medical scan comparison system is operable to receive a medical scan via a network and to generate similar scan data. The similar scan data includes a subset of medical scans from a medical scan database and is generated by performing an abnormality similarity function to determine that a set of abnormalities included in the subset of medical scans compare favorably to an abnormality identified in the medical scan. At least one cross-sectional image is selected from each medical scan of the subset of medical scans for display on a display device associated with a user of the medical scan comparison system in conjunction with the medical scan.","1. A medical scan comparison system, comprising: a medical scan database that includes a plurality of medical scans;a processing system that includes a processor; anda memory that stores executable instructions that, when executed by the processing system, facilitate performance of operations comprising: receiving a first medical scan via a network;generating similar scan data that includes a subset of medical scans from the medical scan database by performing an abnormality similarity function to determine that a set of abnormalities included in the subset of medical scans compare favorably to an abnormality identified in the first medical scan;retrieving a set of patient records corresponding to the subset of medical scans from the medical scan database;calculating a set of longitudinal quality scores corresponding to longitudinal data of each patient record in the set of patient records based on a review of whether or not each patient record includes biopsy data;generating a ranking of the set of patient records based on the set of longitudinal quality scores;generating a set of remaining patent records by removing at least one patient record from the set of patient records that corresponds to at least one lowest ranking;generating an updated subset of medical scans by removing at least one medical scan corresponding to the at least one patient record;generating medical scan report data for display on a display device associated with a user of the medical scan comparison system in conjunction with the first medical scan, wherein the medical scan report data includes the longitudinal data from each patient record of the set of remaining patient records; andtransmitting, via the network, the medical scan report data and at least one selected cross-sectional image from each medical scan of the updated subset of medical scans to a client device for display on the display in conjunction with the first medical scan.","20","16/420634","2019-05-23","2019-0279761","2019-09-12","10755811","2020-08-25","ENLITIC, INC.","Devon  Bernard | Kevin  Lyman | Li  Yao | Anthony  Upton | Ben  Covington | Jeremy  Howard","","","","G16H-0030/40","G16H-0030/40 | A61B-0005/002 | A61B-0005/0022 | A61B-0006/032 | A61B-0006/4233 | A61B-0006/463 | A61B-0006/468 | A61B-0006/50 | A61B-0006/503 | A61B-0006/5217 | A61B-0006/5288 | A61B-0006/5294 | A61B-0006/563 | A61B-0008/468 | A61B-0008/5223 | A61B-0008/565 | G01T-0001/247 | G06F-0003/048 | G06F-0003/167 | G06F-0019/321 | G06F-0019/328 | G06F-0040/169 | G06F-0040/197 | G06F-0040/247 | G06F-0040/279 | G06F-0040/30 | G06F-0040/56 | G06K-0009/03 | G06K-0009/6215 | G06K-0009/6267 | G06N-0003/04 | G06N-0003/0454 | G06N-0003/084 | G06Q-0010/10 | G06Q-0010/103 | G06Q-0050/22 | G06T-0007/0012 | G06T-0007/0016 | G06T-0007/11 | G16H-0010/60 | G16H-0015/00 | G16H-0030/20 | G16H-0040/20 | G16H-0040/63 | G16H-0050/20 | G16H-0050/30 | G16H-0050/70 | H04N-0005/32 | A61B-0006/505 | G06F-0003/0485 | G06F-0003/04842 | G06F-0019/3418 | G06K-0009/6202 | G06K-0009/6256 | G06K-2209/05 | G06N-0007/005 | G06N-0020/10 | G06T-0011/003 | G06T-0011/60 | G06T-2200/24 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/10104 | G06T-2207/10116 | G06T-2207/10132 | G06T-2207/20081 | G06T-2207/30004 | G06T-2207/30061 | G06T-2207/30068 | G16H-0050/50 | H04L-0067/12 | H04L-0067/42","G16H-030/40","G16H-030/40 | G06F-019/00 | G06F-003/048 | G06T-007/00 | G06Q-050/22 | G16H-050/20 | A61B-006/00 | A61B-008/00 | A61B-008/08 | G16H-050/70 | G06N-003/04 | G06F-040/30 | G06F-040/56 | G06F-040/169 | G06F-040/197 | G06F-040/247 | G06F-040/279 | G16H-030/20 | G16H-010/60 | G16H-015/00 | G16H-050/30 | A61B-006/03 | G06F-003/16 | G06K-009/03 | G06K-009/62 | A61B-005/00 | G06N-003/08 | G16H-040/20 | G06Q-010/10 | G06T-007/11 | G01T-001/24 | H04N-005/32 | G16H-040/63 | G06T-011/60 | G06N-020/10 | G06N-007/00 | G16H-050/50 | H04L-029/08 | H04L-029/06 | G06F-003/0484 | G06F-003/0485 | G06T-011/00","","","","","","4920035005865"
"US","US","P","B2","Eye tracking using video information and electrooculography information","Disclosed are an apparatus and a method of low-latency, low-power eye tracking. In some embodiments, the eye tracking method operates a first sensor having a first level of power consumption that tracks positions of an eye of a user. In response to detection that the eye does not change position for a time period, the method stops operation of the first sensor and instead operates a second sensor that detects a change of position of the eye. The second sensor has a level of power consumption lower than the level of power consumption of the first sensor. Once the eye position changes, the second sensor resumes operation.","1. A method of eye tracking, comprising: operating a video oculography (VOG) sensor to track a position of an eye of a user;stopping operation of the VOG sensor in response to a first detection, based on VOG signals from the VOG sensor, that the eye does not change position for a time period;operating an electrooculography (EOG) sensor to track the position of the eye responsive to stopping the operation of the VOG sensor, wherein the EOG sensor has a lower power consumption than the VOG sensor; andresuming operation of the VOG sensor in response to a second detection, based on EOG signals from the EOG sensor, of a change of the position of the eye.","19","15/390410","2016-12-23","2018-0184002","2018-06-28","10757328","2020-08-25","MICROSOFT TECHNOLOGY LICENSING, LLC","Vaibhav  Thukral | Chris  Aholt | Christopher Maurice  Mei | Bill  Chau | Nguyen  Bach | Lev  Cherkashin | Jaeyoun  Kim","","","","H04N-0005/23241","H04N-0005/23241 | A61B-0003/0025 | A61B-0003/113 | A61B-0003/145 | A61B-0005/0496 | G06F-0001/163 | G06F-0001/1686 | G06F-0001/3203 | G06F-0001/325 | G06F-0003/011 | G06F-0003/013 | G06F-0003/015 | G06F-0003/0304 | G06K-0009/00604 | G06T-0007/0014 | G06T-0007/248 | G06T-0007/292 | G06T-0007/74 | G06T-2207/30041","A61B-003/00","A61B-003/00 | A61B-003/113 | A61B-003/14 | A61B-005/0496 | G06F-003/01 | G06K-009/00 | G06T-007/00 | G06T-007/246 | G06T-007/292 | G06T-007/73 | H04N-005/232 | G06F-001/16 | G06F-001/3234 | G06F-003/03 | G06F-001/3203","","","","","","4920035007367"
"US","US","P","B2","Anomaly detection by self-learning of sensor signals","Accurate detection of anomaly in sensor signals is critical and can have an immense impact in the health care domain. Accordingly, identifying outliers or anomalies with reduced error and reduced resource usage is a challenge addressed by the present disclosure. Self-learning of normal signature of an input sensor signal is used to derive primary features based on valley and peak points of the sensor signals. A pattern is recognized by using discrete nature and strictly rising and falling edges of the input sensor signal. One or more defining features are identified from the derived features based on statistical properties and time and frequency domain properties of the input sensor signal. Based on the values of the defining features, clusters of varying density are identified for the input sensor signal and based on the density of the clusters, anomalous and non-anomalous portions of the input sensor signals are classified.","1. A processor implemented method (200) for anomaly detection in an input sensor signal, comprising: deriving primary features associated with the input sensor signal based on discrete nature of the input sensor signal, the primary features being minima points, maxima points, next minima points and three consecutive extrema points (204), wherein the input sensor signal comprises a non-anomalous portion thereof;detecting a pattern associated with the input sensor signal based on selective derived features obtained from the primary features (206, 208) and representing the detected pattern in the form of a function of the derived features;identifying, using a semi-supervised approach, at least one defining feature from the derived features based on statistical properties and time and frequency domain properties of the input sensor signal (210), wherein the identified defining features are the derived features that satisfy conditions including: (i) difference between mean values of the derived features of the non-anomalous portion of the input sensor signal and the mean values of the derived features of complete portion of the input sensor signal is larger than at least a pre-defined first threshold, the pre-defined first threshold being based on the type of the input sensor signal; and(ii) standard deviation of the derived features of the non-anomalous portion of the input sensor signal is smaller than the standard deviation of the derived features of complete portion of the input sensor signal by at least a pre-defined second threshold, the pre-defined second threshold being based on the type of the input sensor signal;performing self-learning of the input sensor signal based on the derived features and the at least one defining feature of the non-anomalous portion of the input sensor signal (212);clustering portions of the input sensor signal based on values of the at least one defining feature associated thereof into clusters of varying density (214); andautomatically classifying the portions of the input sensor signal as anomalous portions and non-anomalous portions based on the density of the clusters (216) and ground truth, wherein most dense clusters correspond to non-anomalous portions and least dense clusters correspond to anomalous portions of the input sensor signal,wherein self-learning of the input sensor signal encompasses dynamic variation in pattern recognition to classify the anomalous portions and non-anomalous portions.","11","15/456199","2017-03-10","2018-0110471","2018-04-26","10743821","2020-08-18","TATA CONSULTANCY SERVICES LIMITED","Soma  Bandyopadhyay | Arijit  Ukil | Rituraj  Singh | Chetanya  Puri | Arpan  Pal | C A  Murthy","201621036139","IN","2016-10-21","A61B-0005/7267","A61B-0005/7267 | A61B-0005/021 | A61B-0005/0468 | A61B-0005/14551 | G06F-0017/18 | G06K-0009/0053 | G06N-0020/00","G06N-003/08","G06N-003/08 | G06F-011/22 | G06N-003/02 | A61B-005/00 | A61B-005/021 | G06N-020/00 | G06F-017/18 | G06K-009/00 | A61B-005/0468 | A61B-005/1455","","","","","","4920034001103"
"US","US","P","B2","Control method for a medical imaging system","In a control method for a screen display of a medical imaging system, an image data set of a patient is acquired and a comparison of the acquired image data set is made with a number of pre-stored image data sets, each of which is stored with layout parameters for the screen display associated therewith. Display of the acquired image data set take place with the layout parameters of the pre-stored image data set that has the greatest similarity with the acquired image data set.","1. A control method for presenting an acquired medical image data set at a display screen, said method comprising: with a computer, acquiring an image data set representing an image of a patient;in said computer, comparing the acquired image data set with a plurality of pre-stored image data sets, each of said pre-stored image data sets being stored with respective layout parameters associated therewith, the respective layout parameters identifying a manner in which each respective one of the pre-stored image data sets is presented on the display screen;in said computer, identifying one of said pre-stored image data sets having a greatest similarity to said acquired image data set based upon the act of comparing the acquired image data set with the plurality of pre-stored image data sets; andfrom said computer, presenting the acquired image data set at the display screen, which is in communication with said computer, in accordance with the layout parameters of said one of said pre-stored image data sets having said greatest similarity to the acquired image data set.","20","15/950565","2018-04-11","2018-0293773","2018-10-11","10748315","2020-08-18","SIEMENS HEALTHCARE GMBH","Sven  Kohle | Andreas  Prause | Maria  Kroell","2017-166063","EP","2017-04-11","G06T-0011/60","G06T-0011/60 | A61B-0005/055 | A61B-0006/032 | A61B-0006/463 | A61B-0006/5211 | G06K-0009/6215 | G16H-0030/20 | G16H-0030/40 | G16H-0040/63 | G16H-0050/50 | A61B-0006/467 | A61B-0006/56 | G06F-0003/0486 | G06F-0003/04845 | G06T-2200/24 | G06T-2210/41","G06K-009/00","G06K-009/00 | G06T-011/60 | G06K-009/62 | G16H-030/20 | A61B-005/055 | A61B-006/03 | G16H-040/63 | A61B-006/00 | G16H-030/40 | G16H-050/50 | G06F-003/0486 | G06F-003/0484","","","","","","4920034005553"
"US","US","P","B2","Modification of behavior or physical characteristics through visual stimulation","A system and a process are provided for evaluating subliminal pixel patterns and identifying trigger patterns, which are pixel patterns that trigger a response in subjects exposed to the pattern. Each pixel pattern is embedded in a digital video or a digital still image. Pixel patterns that are found to induce reactions in subjects are identified as trigger patterns and are flagged for re-testing. Re-tested trigger patterns that repeatably induce reactions are identified as positive trigger patterns and are studied further. Variations are made to a positive trigger pattern to determine whether small changes can affect how a subject responds when exposed to that positive trigger pattern. A positive trigger pattern is evaluated to determine whether it can induce an emotional, a physical, and/or a behavioral change in the subjects and, if so, the positive trigger pattern is applied to a real-world situation.","1. A method for evaluating a video to determine whether or not a pattern of pixels embedded in the video induces a change in at least one viewer of the video, the method comprising steps of: monitoring a plurality of viewers during a session to produce a recording of the session;displaying to the viewers, during the session, the video that includes a sequence of images containing the embedded pattern of pixels therein, the pixels of the embedded pattern being consciously unnoticeable by the viewers from other pixels in the sequence of images;determining whether or not a change occurs in any of the viewers while the viewers are viewing the video;correlating a determined change in at least one of the viewers to an occurrence of the embedded pattern during the session based on a timing of the sequence of images in the video and a timing of the change in the at least one of the viewers in the recording of the session; anddetermining whether a variation in the embedded pattern induces a change in at least one of the viewers.","21","15/475723","2017-03-31","2017-0281067","2017-10-05","10736526","2020-08-11","VDYNAMICS LLC","Adam  Hanina","","","","A61B-0005/0402","A61B-0005/0402 | A61B-0003/032 | A61B-0005/0476 | G06K-0009/00255 | G06Q-0030/02 | G06Q-0050/00 | A61B-0003/113 | A61B-0005/021 | A61B-0005/02438 | A61B-0005/1114 | A61B-0005/165","A61B-005/0205","A61B-005/0205 | A61B-005/0402 | G06K-009/00 | A61B-005/0476 | G06Q-030/02 | A61B-003/032 | G06Q-050/00 | A61B-003/113 | A61B-005/021 | A61B-005/11 | A61B-005/024 | A61B-005/16","","","","","","4920033001012"
"US","US","P","B2","Wearable mood and activity monitoring system","The present invention is a wearable mood and activity monitoring system comprising a wrist worn device, further comprising an adjustable wrist band and a health monitoring assembly further comprising a faceplate with an interactive touchscreen display, a microchip processor in wired communication via a plurality of circuitry cables with a health sensor for detecting real-time physiological data of the user, an accelerometer, a tracking system for tracking a relative location of the user, an information receiver and transmitter unit, and a power source, a plate securer, and a backplate; and a remote monitoring device. The user selects a user-reported mood using the interactive touchscreen display. The health sensor generates the real-time physiological data of the user. The microchip processor is configured to evaluate the real-time physiological data with the user-reported mood to provide an overall mental health of the user.","1. A health monitoring system comprising: a wrist worn device and a remote monitoring device, wherein the wrist worn device comprises: an adjustable wrist band configured to attach to a wrist of a user; a health monitoring assembly comprising, in functional combination, a faceplate including an interactive touchscreen display; a microchip processor in wired communication via a plurality of circuitry cables with at least one health sensor configured to detect real-time physiological data of the user; at least one accelerometer;at least one tracking system configured to track a relative location of the user;at least one information receiver and transmitter unit; andat least one power source;wherein the health monitoring assembly is configured to couple to a backplate using at least one plate securer;wherein the at least one health sensor is installed to the backplate and configured to contact a radial artery of the user from which the at least one health sensor detects the real-time physiological data;wherein the health monitoring assembly is further configured to prompt the user to select a user-reported mood input by using the interactive touchscreen display;wherein the at least one microchip processor comprises a data processing means for evaluating the real-tiome physiological data and the user-reported mood to provide an overall mental health of the user; andwherein the at least one remote monitoring device is configured to receive the user-reported mood and the real-time physiological data to alert a care provider of the overall mental health of the user; andwherein the caregiver is able to input at least one instruction or feedback to the user into the remote monitoring device which is configured to send the at least one instruction or feedback to the health monitoring assembly.","19","16/148771","2018-10-01","2019-0029584","2019-01-31","10736555","2020-08-11","Erin Marie Carr-Jordan | Annissa D. Furr","Erin Marie  Carr-Jordan | Annissa D.  Furr","","","","A61B-0005/165","A61B-0005/165 | A61B-0005/1118 | A61B-0005/167 | A61B-0005/6824 | A61B-0005/6831 | G06F-0001/163 | G06F-0003/014 | G06F-0003/015 | G06F-0003/03547 | G06F-0003/04817 | G06N-0005/00 | G06Q-0010/101 | G06Q-0050/01 | G16H-0020/70 | G16H-0040/63 | G16H-0040/67 | G16H-0080/00 | H04W-0004/029 | A61B-0005/0022 | A61B-0005/16 | A61B-0005/486 | A61B-0005/4806 | A61B-0005/681 | G06F-0003/0482 | G06F-2203/011","A61B-005/00","A61B-005/00 | A61B-005/16 | H04W-004/029 | G16H-080/00 | G06F-001/16 | G06Q-010/10 | G06Q-050/00 | A61B-005/11 | G06F-003/0354 | G16H-040/67 | G06N-005/00 | G16H-040/63 | G06F-003/0481 | G06F-003/01 | G16H-020/70 | G06F-003/0482","","","","","","4920033001041"
"US","US","P","B2","Feedback device and method for providing thermal feedback using the same","A method for providing a thermal feedback performed by a feedback device is disclosed. The method includes: applying an operating power to a thermoelectric element to start a thermoelectric operation for outputting a thermal feedback; stopping the application of the operating power to terminate the thermoelectric operation; and when the application of the operating power is stopped, applying a buffering power to the thermoelectric element to reduce a temperature returning speed of a contact surface so that a thermal inversion illusion is prevented. The thermal inversion illusion is a sensation felt by the user when a temperature of the contact surface returns to an initial temperature due to the termination of the thermoelectric operation, the thermal inversion illusion being opposite to the outputted thermal feedback.","1. A method for providing a thermal feedback, performed by a feedback device, comprising: applying an operating power to a thermoelectric element to start a thermoelectric operation for outputting the thermal feedback;stopping the application of the operating power to terminate the thermoelectric operation; andin response to stopping the application of the operating power, applying a buffering power to the thermoelectric element to reduce a temperature returning speed of a contact surface as compared to if the operating power were stopped without applying the buffering power, wherein the feedback device comprises a heat outputting module which is provided as the thermoelectric element and performs the thermoelectric operation including at least one of a heat generating operation and a heat absorbing operation and the contact surface which is configured to contact with a body of a user and transmit a heat generated by the thermoelectric operation.","37","15/633501","2017-06-26","2018-0116602","2018-05-03","10736576","2020-08-11","TEGWAY CO., LTD.","Kyoungsoo  Yi | Ookkyun  Oh","10-2016-0157732 | 10-2016-0157733 | 10-2016-0157734 | 10-2016-0157735 | 10-2016-0157736 | 10-2016-0157737","KR | KR | KR | KR | KR | KR","2016-11-24 | 2016-11-24 | 2016-11-24 | 2016-11-24 | 2016-11-24 | 2016-11-24","A61B-0005/7271","A61B-0005/7271 | A61B-0005/01 | A61B-0005/015 | A61B-0018/1477 | F25B-0021/02 | G05D-0023/192 | G05D-0023/20 | G06F-0003/011 | G06F-0003/016 | H05B-0001/0227 | F25B-2321/0212 | Y02B-0030/765","H04B-003/36","H04B-003/36 | A61B-005/00 | G06F-003/01 | H05B-001/02 | A61B-005/01 | A61B-018/14 | F25B-021/02 | G05D-023/19 | G05D-023/20","","","","","","4920033001062"
"US","US","P","B2","Systems, devices, and/or methods for wristbands","Certain exemplary embodiments can provide an attachment coupled to a hand of a user. The attachment can comprise a laser sensor. The attachment can be constructed to cause a signal to be transmitted via the wireless transmitter responsive to motion of a finger of the user determined by the laser sensor. The attachment can comprise wireless transceiver.","1. A system comprising: an attachment coupled to a hand of a user, the attachment comprising a laser sensor, the attachment constructed to cause a first signal to be transmitted via a first wireless transmitter responsive to motion of a finger of the user determined by the laser sensor, the attachment comprising wireless transceiver;a wristband, the wristband constructed to receive the first signal from the attachment, the wristband constructed to analyze the first signal from the attachment to determine that characters are being written by the user, the wristband constructed to cause an audio of characters written by the user to be played by a speaker/microphone or to an earpiece port; wherein the wristband comprises a cardiac monitor that is constructed to monitor a heart rate of the user;the wristband is constructed to determine a room of a structure responsive to an analysis of the heart rate of the user; andthe wristband is constructed to render a color of a plurality of colors, the color indicating the determined room in the structure.","7","16/517558","2019-07-20","2020-0209964","2020-07-02","10739852","2020-08-11","Logan Amstutz","Logan  Amstutz","","","","G06F-0003/014","G06F-0003/014 | A61B-0005/02438 | A61B-0005/681 | G06F-0003/038 | G06F-0003/167 | G06K-0009/00402 | G08B-0021/22 | G06F-2203/0331 | G06K-0009/00624","G06F-003/01","G06F-003/01 | G06F-003/038 | G06F-003/16 | G06K-009/00 | A61B-005/024 | A61B-005/00 | G08B-021/22","","","","","","4920033004317"
"US","US","P","B1","Meta data management system for a multi-user CAx environment","A software agnostic multi-user CAx environment system includes a host computer with a processor and a memory. The processor and memory are configured to operate a multi-user CAx environment. The host computer is configured to communicate with a plurality of local computers. Each of the local computers includes at least one CAx software package and is configured to operate a local CAx environment of the multi-user CAx environment. A part database is configured to store multiple part files. Each of the part files includes at least one component having multiple features. At least one meta data file is stored within the part database. The meta data file is linked to at least one of the plurality of features.","1. A system for executing software agnostic multi-user CAx environments comprising: a host computer including a processor and a memory, the processor and memory being configured to operate a multi-user CAx environment;said host computer configured to communicate with a plurality of local computers, each of said local computers including at least one CAx software package and being configured to operate a local CAx environment of said multi-user CAx environment;a part database configured to store a plurality of part files, each of said part files including at least one component having a plurality of features; andat least one meta data file stored within said part database, the meta data file being linked to at least two of said plurality of features via direct links, wherein the direct links are architectural connections between the meta data file and the at least two of said plurality of features.","15","14/825496","2015-08-13","","","10740500","2020-08-11","RAYTHEON TECHNOLOGIES CORPORATION","Joshua Daniel  Winn | William A.  Sowa","","","","G06F-0030/00","G06F-0030/00 | A61B-0005/72 | H04L-0067/10","A61B-005/04","A61B-005/04 | G06F-017/50 | G06F-030/00 | H04L-029/08 | A61B-005/00","","","","","","4920033004961"
"US","US","P","B2","Long-tail large scale face recognition by non-linear feature level domain adaption","A computer-implemented method, system, and computer program product are provided for facial recognition. The method includes receiving, by a processor device, a plurality of images. The method also includes extracting, by the processor device with a feature extractor utilizing a convolutional neural network (CNN) with an enlarged intra-class variance of long-tail classes, feature vectors for each of the plurality of images. The method additionally includes generating, by the processor device with a feature generator, discriminative feature vectors for each of the feature vectors. The method further includes classifying, by the processor device utilizing a fully connected classifier, an identity from the discriminative feature vector. The method also includes control an operation of a processor-based machine to react in accordance with the identity.","1. A surveillance system with facial recognition, the surveillance system comprising: one or more cameras;a processor device and memory coupled to the processor device, the processing system programmed to: receive a plurality of images from the one or more cameras;extract, with a feature extractor utilizing a convolutional neural network (CNN) with an enlarged intra-class variance of long-tail classes, feature vectors from each of the plurality of images;generate, with a feature generator, discriminative feature vectors for each of the feature vectors;classify, with a fully connected classifier, an identity from the discriminative feature vectors; andcontrol an operation of a processor-based device to react in accordance with the identity.","20","16/145578","2018-09-28","2019-0095699","2019-03-28","10740595","2020-08-11","NEC CORPORATION","Xiang  Yu | Xi  Yin | Kihyuk  Sohn | Manmohan  Chandraker","","","","G06K-0009/00288","G06K-0009/00288 | G06K-0009/00261 | G06K-0009/00268 | G06K-0009/6247 | G06K-0009/6256 | G06K-0009/6262 | G06K-0009/6269 | G06K-0009/6271 | G06N-0003/08 | G06N-0003/084 | G06Q-0020/40145 | G06Q-0030/0281 | G08B-0013/196 | G08B-0015/007 | H04N-0007/183 | H04N-0007/185","A61B-005/00","A61B-005/00 | G06K-009/00 | G06N-003/08 | G06K-009/62 | G06Q-020/40 | G06Q-030/02 | G08B-013/196 | G08B-015/00 | G06F-003/00 | H04N-007/18","","","","","","4920033005055"
"US","US","P","B2","System and method for identifying features of a friction ridge signature based on information representing a topography of friction ridges","One or more features of a friction ridge signature of a subject may be identified based on information representing a three-dimensional topography of friction ridges of the subject. Information representing the three-dimensional topography of the friction ridges of the subject may be received. One or more level-three features of the friction ridge signature of the subject may be identified based on the information representing the three-dimensional topography of the friction ridges of the subject. The one or more level-three features may include one or more topographical ridge peaks, topographical ridge notches, topographical ridge passes, pores, and/or other information.","1. A system configured to identify features of a friction ridge signature of a subject based on information representing a three-dimensional topography of friction ridges of the subject, the system comprising: one or more processors configured by computer readable instructions to: receive information representing a three-dimensional topography of friction ridges of a subject, wherein the information representing the three-dimensional topography of the friction ridges is embedded in individual ones of one or more two-dimensional images captured by a total internal reflection based imaging system; andidentify one or more level-three features of the friction ridge signature of the subject based on the information representing the three-dimensional topography of the friction ridges of the subject.","26","15/724054","2017-10-03","2019-0164292","2019-05-30","10740902","2020-08-11","IDENTIFICATION INTERNATIONAL, INC.","Richard K.  Fenrich | Bryan D.  Dickerson","","","","G06T-0007/13","G06T-0007/13 | A61B-0005/0077 | A61B-0005/1079 | A61B-0005/1172 | A61B-0005/7239 | B42D-0025/313 | G06F-0021/32 | G06K-0009/0008 | G06T-0001/0007 | G06T-0007/0012 | G06T-0007/64 | A61B-0005/01 | A61B-2562/028 | A61B-2562/0247 | G06T-2200/04 | G06T-2207/30088","A61B-005/1172","A61B-005/1172 | G06K-009/00 | G06F-021/32 | G06T-007/00 | G06T-007/13 | A61B-005/00 | A61B-005/107 | B42D-025/313 | G06T-007/64 | G06T-001/00 | A61B-005/01","","","","","","4920033005362"
"US","US","P","B2","Information processing apparatus, method, system, and storage medium for image display","An information processing apparatus acquires, for each of a plurality of three-dimensional images, information about a position where a two-dimensional image included in the three-dimensional image is present, identifies, based on an instruction about a position of a two-dimensional image to be displayed at a display unit, a three-dimensional image to be a target of the instruction, and identifies, based on information about the position specified by the instruction, and the information about the position where the two-dimensional image is present for each of the plurality of three-dimensional images, a two-dimensional image which is included in the identified three-dimensional image, and which is to be displayed at the display unit.","1. An information processing apparatus comprising: at least one memory storing instructions; andat least one processor that when executing the instructions, causes the information processing apparatus to:acquire, for each of a plurality of three-dimensional images, information about a position where a two-dimensional image included in the three-dimensional image is present;identify, based on an instruction about a position of a two-dimensional image to be displayed at a display unit, a three-dimensional image to be a target of the instruction; andidentify, based on information about the position specified by the instruction, and the information about the position where the two-dimensional image is present for each of the plurality of three-dimensional images, a two-dimensional image which is included in the identified three-dimensional image, and which is to be displayed at the display unit,wherein the information processing apparatus identifies a two-dimensional image at a position nearest to the position specified by the instruction, the identified two-dimensional image being included in a three-dimensional image, which has a smallest spacing of the positions at each of which the two-dimensional image included in the three-dimensional image is present, among the identified three-dimensional images.","11","15/940726","2018-03-29","2018-0301215","2018-10-18","10741277","2020-08-11","CANON KABUSHIKI KAISHA","Yoshio  Iizuka | Yukari  Nakashoji","2017-079435","JP","2017-04-13","G16H-0030/40","G16H-0030/40 | A61B-0005/7425 | G06F-0003/0484 | G06F-0003/0485 | G06T-0007/0012 | G16H-0030/20 | G16H-0040/63 | A61B-0005/055 | A61B-0006/461 | G06T-2207/10072","G16H-030/40","G16H-030/40 | G06T-007/00 | G06F-003/0485 | A61B-005/00 | G16H-040/63 | G06F-003/0484 | G16H-030/20 | A61B-006/00 | A61B-005/055","","","","","","4920033005730"
"US","US","P","B2","Mobile device with side-looking biometric sensor","A mobile device with a side-looking biometric sensor, a sensor and a method for sensing a biometric function of a user holding a mobile device a disclosed. In an embodiment, a mobile device has a generally flat rectangular shape with a relatively large front and rear surfaces and relatively small upper side, lower side, left side and right side surfaces, wherein the mobile device includes a sensor configured for capturing biometric data of a user holding the mobile device. The sensor includes a light source configured for emitting light towards a hand of the user and a photodetector configured for receiving light emitted from the light source and reflected back from the hand, wherein the sensor is a side-looking sensor.","1. A mobile device comprising: a generally flat rectangular shape with a relatively large front and rear surfaces and relatively small upper side, lower side, left side and right side surfaces, wherein the upper and lower side surfaces are smaller than the left and right side surfaces;at least one sensor located on the lower side surface, and configured for capturing first contact pressure data of a user holding the mobile device; andat least one sensor located on the upper side surface, and configured for capturing second contact pressure data of the user,wherein each sensor comprises: a light source configured for emitting light towards a hand of the user, anda photodetector configured for receiving light reflected from the hand that was emitted from the light source, andwherein each sensor is a side-looking sensor.","12","16/192595","2018-11-15","2020-0162592","2020-05-21","10742786","2020-08-11","OSRAM OPTO SEMICONDUCTORS GMBH","Christoph  Goeltner","","","","H04M-0001/026","H04M-0001/026 | A61B-0005/02 | A61B-0005/14552 | A61B-0005/6898 | G06F-0003/0304 | A61B-2560/0462 | G06K-0009/0004 | H04M-2250/12","G06K-009/00","G06K-009/00 | H04M-001/02 | A61B-005/1455 | A61B-005/00 | G06F-003/03 | A61B-005/02","","","","","","4920033007225"
"US","US","P","B2","Hearing assistance device with brain computer interface","The present disclosure relates to communication devices. Such devices may comprise input for receiving sound signal to be processed and presented to a user, and output for outputting the processed signal to a user perceivable as sound. Such processing may be performed by use of a processor for processing the sound signal in dependence of a setting or a set of setting to compensate a hearing loss profile. Further, the communication device may comprise a bio-signal acquisition and amplifier component in communication with a user interface for providing the bio-signals as input to the user interface, the user interface controlling the setting or set of setting for operation of the communication device.","1. A hearing aid device comprising: an input for receiving a sound signal to be processed and presented to a user, and an output for outputting a signal to a user perceivable as sound,a processor for processing the sound signal in dependence of a setting or a set of settings to compensate a hearing loss profile, anda bio-signal acquisition and amplifier component comprising at least one of the following for acquiring an EEG signal: an ear EEG electrode configured to be inserted into an ear canal or on a skin-part of the head of a wearer,an implantable EEG electrode configured to be placed under the skin at the head and/or skull of a wearer, andan implantable EEG electrode configured to be placed on the ear canal, andwherein the bio-signal acquisition and amplifier component is configured to extract an EOG signal based on the EEG signal for identifying eye movements of the wearer,wherein the bio-signal acquisition and amplifier component is in communication with a user interface for providing the bio-signals as input to the user interface, the user interface using the inputted bio-signals to control the setting or set of settings for operation of the hearing aid device by performing at least one of: changing a current program for sound processing,enabling or ending a music processing program, andcontrolling a directionality pattern of a microphone beamformer of the hearing aid device.","7","16/504060","2019-07-05","2019-0327570","2019-10-24","10743121","2020-08-11","OTICON A/S","Niels Henrik  Pontoppidan | Thomas  Lunner | Michael Syskind  Pedersen | Lars Ivar  Hauschultz | Povl  Koch | Graham  Naylor | Eline Borch  Petersen","2013-172066","EP","2013-06-14","H04R-0025/606","H04R-0025/606 | A61B-0005/0478 | A61B-0005/04845 | A61B-0005/121 | A61B-0005/165 | A61B-0005/4836 | A61B-0005/6817 | A61B-0005/746 | G06F-0003/013 | G06F-0003/015 | G06K-0009/00604 | H04R-0025/00 | H04R-0025/305 | H04R-0025/505 | A61B-0005/048 | A61B-0005/0482 | A61B-0005/6868 | H04R-0025/40 | H04R-0025/453 | H04R-0025/552 | H04R-0025/70 | H04R-2225/41 | H04R-2225/43 | H04R-2225/61 | H04R-2225/67","H04R-025/00","H04R-025/00 | G06K-009/00 | A61B-005/0478 | A61B-005/0484 | A61B-005/12 | A61B-005/00 | G06F-003/01 | A61B-005/16 | A61B-005/048 | A61B-005/0482","","","","","","4920033007557"
"US","US","P","B2","Depicting force","A force exerted on a distal end of an elongate medical device can be determined. A graphical representation of the distal end of the elongate medical device and a graphical representation of the force exerted on the distal end of the elongate medical device can be computed. The graphical representation of the force can emanate from the graphical representation of the distal end of the elongate medical device. A first dimension of the graphical representation of the force can be increased in response to a longitudinal force being exerted on the distal end of the elongate medical device. A second dimension of the graphical representation of force can be increased in response to a lateral force being exerted on the distal end of the elongate medical device.","1. A non-transitory computer readable medium storing instructions for depicting a force exerted on a distal end of an elongate medical device, the instructions executable by a processing resource to cause a computer to: determine the force exerted on the distal end of the elongate medical device;compute a graphical representation of the distal end of the elongate medical device and a graphical representation of the force exerted on the distal end of the elongate medical device, wherein the graphical representation of the force emanates from the graphical representation of the distal end of the elongate medical device, wherein the force is determined from a signal received from a force sensor included in the elongate medical device;increase a first dimension of the graphical representation of the force in response to a longitudinal force being exerted on the distal end of the elongate medical device; andincrease a second dimension of the graphical representation of the force in response to a lateral force being exerted on the distal end of the elongate medical device, wherein the first dimension is different than the second dimension, and wherein: the first dimension relates to a longitudinal length of the graphical representation of the force;the first dimension of longitudinal length is altered based on a change in magnitude of a longitudinal force being exerted on the distal end of the elongate medical device;the second dimension relates to a lateral width of the graphical representation of the force; andthe second dimension of lateral width is altered based on a change in lateral force being exerted on the distal end of the elongate medical device; andcause the graphical representation of the distal end of the elongate medical device and a graphical representation of the force exerted on the distal end of the elongate medical device to be displayed to a user.","12","14/699737","2015-04-29","2015-0313547","2015-11-05","10729500","2020-08-04","ST. JUDE MEDICAL, CARDIOLOGY DIVISION, INC.","Michael A.  Quinn | Daniel R.  Starks","","","","A61B-0034/20","A61B-0034/20 | A61B-0005/042 | A61B-0005/6852 | A61B-0005/6885 | A61B-0005/7445 | A61B-0018/1492 | A61B-0090/06 | A61B-0090/37 | A61B-0090/92 | A61M-0025/0105 | G06F-0003/016 | A61B-2018/00577 | A61B-2018/00839 | A61B-2034/2046 | A61B-2090/064 | A61B-2090/065 | A61M-2025/0166","A61B-034/20","A61B-034/20 | A61B-005/00 | A61B-005/042 | A61B-018/14 | G06F-003/01 | A61B-090/00 | A61B-090/92 | A61M-025/01 | A61B-018/00","","","","","","4920032001176"
"US","US","P","B2","Apparatus and methods for monitoring objects in a surgical field","Apparatus and methods for identifying and counting objects having identifiers entering and exiting a surgical field are provided. In one embodiment, the apparatus has an entry scanner, a hand held scanner and an exit scanner for generating a detection field and for receiving data which identifies said objects. In another embodiment, the apparatus has a plurality of lower antennas and an upper antenna for generating a detection field and for receiving data which identifies said objects. Various surgical devices with identifiers and methods for preventing electromagnetic coupling between and protecting objects and identifier are also provided. The invention further provides apparatus and methods comprising a handheld scanner and a mat adapted to underlie a patient during a surgical procedure.","1. A package of surgical sponges, comprising: a plurality of sponges, each of the plurality of sponges comprising an absorbent material and an RFID tag attached to the absorbent material; andpackaging for containing the plurality of sponges,wherein the RFID tags of the adjacent ones of the plurality of sponges are not aligned with one another.","20","15/957131","2018-04-19","2018-0243044","2018-08-30","10729510","2020-08-04","STRYKER CORPORATION","Steven J.  Fleck | David  Szakelyhidi | Gautam  Gandhi","","","","A61B-0090/08","A61B-0090/08 | A61B-0005/742 | A61B-0005/746 | A61B-0046/00 | A61B-0050/10 | A61B-0050/13 | A61B-0050/30 | A61B-0050/36 | A61B-0050/37 | A61B-0090/37 | A61B-0090/90 | A61B-0090/98 | A61F-0013/36 | A61F-0013/44 | A61G-0013/10 | G06K-0007/01 | G06K-0007/10316 | G06K-0007/10366 | G06K-0007/10386 | G06K-0007/10425 | G06K-0007/10475 | G06Q-0010/087 | G06Q-0010/0875 | H01Q-0001/2216 | A61B-2017/00199 | A61B-2050/0056 | A61B-2050/0065 | A61B-2090/0805 | A61G-0007/0502 | A61G-0013/12 | A61G-2205/10","G06K-007/01","G06K-007/01 | A61B-090/00 | A61B-050/10 | A61B-050/13 | A61B-050/30 | A61B-050/36 | A61B-050/37 | A61B-046/00 | A61B-090/90 | A61B-090/98 | A61G-013/10 | G06K-007/10 | H01Q-001/22 | G06Q-010/08 | A61B-005/00 | A61F-013/44 | A61F-013/36 | A61B-050/00 | A61B-017/00 | A61G-007/05 | A61G-013/12","","","","","","4920032001186"
"US","US","P","B2","System and method for improving bowling shot performance","A system and method for improving bowling shot performance based on bowling shot metrics calculated from the analysis of bowling shot sensor data from the user are disclosed. The system comprises a motion sensor/computer device integrated with a bowling glove, a microcomputer system, wireless data communications coupled to methods for data capture from the sensorized glove, and a mobile electronic device for accessing and displaying a bowler's current and historical performance data using the Internet. The performance metrics include ball revolutions rate at release, ball speed, force, backswing duration, front swing duration and shot tempo. Comparing the current and historical performance data allows the user to adjust his or her bowling swing accordingly.","1. A system for improving bowling shot performance, comprising: a bowling motion sensor device, wearable by a user, for obtaining bowling shot data, said bowling motion sensor comprising; sensors for detecting bowling shot motions, an integrated sensor/computing platform configured to recognize a bowling shot while it is being made by using the steps comprising, i. capturing said bowling shot data generated by said bowling motion sensor device for said bowling shot, said bowling shot data comprising accelerometer data and gyroscope data,ii. calculating magnitudes for said accelerometer and gyroscope data,iii. measuring a time duration of said bowling shot from initiation of a bowler'ss backswing, front swing and point of ball release,iv. determining a backswing start time of said bowling shot as measured from the point of ball release, andv. determining whether said point of ball release coincides with a maximum magnitude of said gyroscope data, and whether a time duration of said backswing as measured from said point of ball release coincides with a bowling shot recognition pattern,said integrated sensor/computing platform being further configured to capture said bowling shot data generated by said bowling shot if a bowling shot is recognized and to wirelessly transmit said bowling shot data;a mobile device for wirelessly receiving said bowling shot data transmitted from said bowling motion sensor device, said mobile device comprising; a microcomputer system configured to wirelessly receive said bowling shot data, and to further wirelessly transmit said bowling shot data, and said mobile device further having a touch-capable user interface display;an Internet-connected Web server computer; said Web server computer configured to wirelessly receive and store said bowling shot data transmitted from said mobile device, to calculate bowling shot metrics from said received bowling shot data, and to wirelessly communicate said calculated bowling shot metrics back to said mobile device for display to the user;whereby said user adjusts a bowling shot in accordance with the bowling shot metrics displayed on said mobile device.","20","15/923706","2018-03-16","2018-0264337","2018-09-20","10729960","2020-08-04","Kevin Logan","Kevin  Logan","","","","A63B-0069/0046","A63B-0069/0046 | A61B-0005/11 | A61B-0005/1124 | A61B-0005/6806 | A63B-0024/0006 | A63B-0071/148 | G06F-0001/163 | G06F-0001/1694 | G06F-0003/014 | G06K-0009/00342 | G06K-0017/0022 | A61B-2503/10 | A61B-2562/0219 | A63B-2220/803 | G06F-2200/1637","A63B-069/00","A63B-069/00 | A63B-024/00 | G06K-017/00 | G06F-001/16 | G06F-003/01 | G06K-009/00 | A63B-071/14 | A61B-005/11 | A61B-005/00","","","","","","4920032001635"
"US","US","P","B2","Methods, systems, and apparatuses for accurate measurement and real-time feedback of solar ultraviolet exposure","System and methods for accurate measurement and real-time feedback of solar ultraviolet exposure for management of ultraviolet dose. The systems can include a wearable device and a mobile device, the system performing accurate measurement of UV exposure.","1. A wearable UV sensing device, comprising: a sensing housing that includes a back surface,a front surface with, in a side view of the housing, an outwardly curved configuration relative to the back surface, the front surface having a central region disposed further away from the back surface than a periphery of the front surface,the front surface made of a material adapted to block visible light,the front surface including an aperture formed therein allowing UV light to travel therethrough,a UV sensor positioned under the aperture so that UV light passing through the aperture can be sensed by the UV sensor,a wireless communication module configured to wirelessly communicate with an external device,a printed circuit board disposed within the sensing housing; anda releasable securing member, wherein the sensing housing also includes a securing surface, and the releasable securing member is configured to interact with the securing surface to releasably secure the sensing housing to the releasable securing member,wherein the releasable securing member has a curved configuration where it interacts with the securing surface.","13","16/245701","2019-01-11","2019-0145820","2019-05-16","10732034","2020-08-04","THE JOAN AND IRWIN JACOBS TECHNION-CORNELL INNOVATION INSTITUTE","Emmanuel  Dumont | Shayak  Banerjee | Mauricio  Contreras","","","","G01J-0001/429","G01J-0001/429 | A61N-0005/06 | G01J-0001/0204 | G01J-0001/0228 | G01J-0001/0271 | G01J-0001/0437 | G01J-0001/0492 | G01J-0001/4204 | G01J-0001/4209 | G06F-0001/163 | G06F-0001/1632 | G06F-0001/1684 | G06F-0001/1694 | G06F-0001/3206 | G06F-0001/3287 | G06F-0003/0481 | G06F-0003/0482 | G06F-0003/0484 | G06F-0003/04847 | H01R-0013/15 | H01R-0013/6205 | H05K-0005/0247 | A61B-0005/445 | A61B-2560/0242 | A61N-2005/0628 | A61N-2005/0657 | G01J-2001/4266","G06F-001/16","G06F-001/16 | H05K-005/00 | H05K-007/00 | G01J-001/42 | A61N-005/06 | G01J-001/02 | G01J-001/04 | G06F-001/3206 | G06F-003/0484 | G06F-001/3287 | G06F-003/0481 | G06F-003/0482 | H01R-013/15 | H01R-013/62 | H05K-005/02 | A61B-005/00","","","","","","4920032003700"
"US","US","P","B2","Multi-function thermostat with health monitoring features","A multi-function thermostat for a building includes a sensor configured to measure an environmental condition of a building space, a communication interface, and a processing circuit. The communications interface is configured to communicate with an emergency server and receive occupant health data from a health sensor configured to monitor an occupant. The processing circuit is configured to determine a health metric associated with the occupant based on the occupant health data and cause the communications interface to send a distress message to the emergency server when the health metric associated with the occupant indicates a medical emergency.","1. A multi-function thermostat for a building, the thermostat comprising: a sensor configured to measure an environmental condition of a building space;a communications interface configured to: provide at least one signal to HVAC equipment based on a measurement from the sensor to control the environmental condition of the building space;communicate with an emergency server; andreceive occupant health data from a health sensor configured to monitor an occupant, wherein the occupant health data comprises a health value indicating a measured biological condition of the occupant; anda processing circuit configured to: calculate a health metric associated with the occupant based on the health value, wherein the health metric is a function of the health value and indicates health of the occupant; andcause the communications interface to send a medical distress message to the emergency server when the health metric associated with the occupant indicates a medical emergency of the occupant.","20","16/450027","2019-06-24","2019-0310598","2019-10-10","10732600","2020-08-04","JOHNSON CONTROLS TECHNOLOGY COMPANY","Sudhi  Sinha | Joseph R.  Ribbich | Michael L.  Ribbich | Charles J.  Gaidish | John P.  Cipolla","","","","G05B-0019/048","G05B-0019/048 | A61B-0005/02055 | A61B-0005/681 | A61M-0005/1723 | F24F-0011/30 | F24F-0011/62 | G06F-0003/167 | G06Q-0020/10 | G06Q-0020/382 | G06Q-0020/383 | G06Q-0020/405 | G06Q-0050/12 | G06Q-0050/30 | G07F-0017/0057 | G07G-0005/00 | G08B-0007/066 | G08B-0021/0453 | H04L-0067/12 | H04W-0064/003 | A61B-0005/02405 | A61B-0005/02438 | A61B-0005/117 | A61B-0005/1113 | A61M-0005/14 | A61M-2209/088 | F24F-0011/52 | F24F-0011/63 | F24F-2110/10 | F24F-2120/10 | F24F-2120/12 | F24F-2120/14 | F24F-2120/20 | G05B-2219/15117 | G05B-2219/2614 | G05B-2219/2642 | G06F-0003/04883 | G06F-0016/24575 | G08B-0019/00 | G08B-0027/00 | H04W-0064/00 | H05B-0047/105 | H05B-0047/11","G08C-019/22","G08C-019/22 | H04Q-009/00 | G05B-019/048 | F24F-011/30 | F24F-011/62 | G08B-007/06 | G06Q-020/38 | H04W-064/00 | A61B-005/0205 | A61B-005/00 | A61M-005/172 | G08B-021/04 | H04L-029/08 | G06F-003/16 | G06Q-020/10 | G06Q-020/40 | G06Q-050/12 | G06Q-050/30 | G07F-017/00 | G07G-005/00 | G06F-016/2457 | A61M-005/14 | F24F-110/10 | F24F-120/10 | F24F-120/12 | F24F-120/14 | F24F-120/20 | F24F-011/63 | F24F-011/52 | G08B-019/00 | G08B-027/00 | A61B-005/11 | A61B-005/117 | H05B-047/11 | H05B-047/105 | A61B-005/024 | G06F-003/0488","","","","","","4920032004263"
"US","US","P","B1","Detecting emotions from micro-expressive free-form movements","Computerized methods and systems, including computer programs encoded on a computer storage medium, may adaptively predict expression of emotions based on collected biometric data. For example, a computing system may receive first data indicative of a first time-evolving movement of a portion of a body during a collection period, and may obtain second data identifying predictive models that correlate default emotions with second feature values that characterize body movements during prior collection periods. Based on an outcome of the application of the least one pattern recognition algorithm or machine learning algorithm to portions of the first and second data, the system may determine a corresponding one of the default emotions represented by the first time-evolving movement, and may transmit data indicative of the corresponding one of the default emotions to the communications device for presentation to a user.","1. A system, comprising: one or more computers; andone or more storage devices storing instructions that are operable, when executed by the one or more computers, to cause the one or more computers to perform operations comprising: at a first time, presenting, on a touchscreen display unit of a communications device, a user interface of a plurality of predictive models configured to determine emotions that are experienced by users, the user interface including representations of a plurality of default emotions;receiving, through the user interface, (i) one or more first contacts on the touchscreen display unit, and (ii) data correlating the one or more first contacts with the plurality of default emotions;training the plurality of predictive models using the one or more first contacts and the data, to identify one or more default emotions of the plurality of default emotions upon being provided with data corresponding to contacts made with the touchscreen display unit;at a second time, receiving first data indicative of a first time-evolving movement of a portion of a body of the user of the communications device during a collection period, wherein the first time-evolving movement comprises a plurality of contacts established sequentially between the portion of the body of the user and a surface of the touchscreen display unit at corresponding first contact times during the collection period;determining, using the first data, first values of features that characterize the contacts during the collection period, wherein the features comprise an X coordinate of the portion of the body, a Y coordinate of the portion of the body, an area of contact of the portion of the body, a contact force of the portion of the body, and a time of movement of the portion of the body;accessing second data about the plurality of predictive models that have been trained at the first time, wherein one or more of the plurality of predictive models correlates ranges of second values of one or more of the features obtained during prior collection periods to default emotions of the plurality of default emotions;comparing, using at least one of a pattern recognition algorithm or a machine learning algorithm, the first values of the features determined using the first data to the second data;in response to the comparing, determining that one or more first values of the features are within ranges of second values of one or more features that correlate with a particular default emotion of the plurality of default emotions;in response to the determination, associating the one or more first values with a predictive model that corresponds to the particular default emotion;based on the associating, determining that the first time-evolving movement of the portion of the body of the user during the collection period indicates that the particular default emotion is experienced by the user during the collection period; andtransmitting data indicative of the particular default emotion to the communications device to present a representation of the particular default emotion.","23","15/669316","2017-08-04","","","10732722","2020-08-04","EMAWW","Alicia  Heraz","","","","G06F-0003/017","G06F-0003/017 | G06F-0003/0414 | G06F-0040/30 | G06K-0009/00355 | G06K-0009/00885 | G06K-0009/66","G06F-003/01","G06F-003/01 | A61B-005/00 | G06F-003/16 | G06F-003/14 | H04N-021/00 | G06F-003/041 | G06K-009/00 | G06K-009/66 | G06F-040/30","","","","","","4920032004382"
"US","US","P","B2","Biometric sensor","A biometric sensing apparatus is employed by a person in order to obtain biometric data. Transmitting and receiving antennas are used in order to transmit and receive signals. Measurements of the received signals are correlated with biological activity in order to provide biometric data.","1. A biometric sensing apparatus comprising: a first antenna supported by a first component, the first component configured to be worn by a subject and to maintain the first antenna in proximity to the subject when the first component is worn;a plurality of second antennas supported by a second component, the second component configured to be worn by the subject and to maintain the plurality of second antennas in proximity to the subject when the second component is worn;a signal generator operatively connected to the first antenna, the signal generator being configured to generate a first frequency signal on the first antenna;a signal processor operatively connected to the plurality of second antennas, the signal processor being configured to process a receive signal received on each of the second antennas during a plurality of integration periods, and for each of the plurality of integration periods and for each of the second antennas to determine a measurement of an amount of the receive signal received corresponding to the first frequency signal using a fast fourier transform; andwherein the measurements corresponding to the first frequency signal taken during the plurality of integration periods provides data regarding a biometric of the subject.","25","16/102185","2018-08-13","2019-0050082","2019-02-14","10732778","2020-08-04","Tactual Labs Co.","David  Holman","","","","G06F-0003/044","G06F-0003/044 | A61B-0005/0507 | A61B-0005/681 | A61B-0005/6802 | G06F-0003/0416 | A61B-0005/6806 | G06F-2203/04102 | G06F-2203/04104 | G06K-0009/00885 | G06K-2009/00939","G06F-003/044","G06F-003/044 | A61B-005/00 | G06F-003/041 | A61B-005/05 | G06K-009/00","","","","","","4920032004437"
"US","US","P","B2","Device and method for automation of mean axis of rotation (mar) analysis","A computer readable storage medium for determining a normalized mean axis of rotation (MAR) of a cervical spine in a patient is provided, having stored thereon instructions executable by a processor to perform steps of providing a flexion trace and an extension trace of each of cervical spine vertebrae C2 to C7 by detecting a start position, drawing a line concurrently as the pointing device follows the margin from the start position to a finish position and detecting the finish position; superimposing the flexion trace on the extension trace; providing for a user to correct an error in a trace; determining a MAR datum; and normalizing the MAR datum.","1. An image analysis apparatus for determining a normalized mean axis of rotation (MAR) of a cervical spine of a patient using a flexion medical image and an extension medical image of each of cervical spine vertebrae two to seven (C2 to C7), the apparatus comprising: an image output device that is a Digital Imaging and Communications in Medicine (DICOM) viewer configured to display the flexion medical image and the extension medical image; a pointing device configured to trace a margin of each of C2 to C7 vertebrae of the cervical spine as a continuous line; a processor, the processor in electronic communication with the pointing device; and a memory; the memory including instructions for the processor: to provide a flexion trace and an extension trace of C2 to C7 vertebrae by detecting a start position, drawing a line concurrently as the pointing device follows the margin from the start position to a finish position and to detect the finish position; to superimpose the flexion trace of a selected vertebra on the extension trace of the selected vertebra; to allow a user to remove or correct an error in a trace; to determine the MAR; and to normalize the MAR.","18","16/302509","2016-05-30","2019-0172201","2019-06-06","10733728","2020-08-04","KKT INTERNATIONAL LTD","Mayar  Abbasi | Aslam  Khan","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/1071 | A61B-0005/4566 | G06F-0003/0486 | G06F-0003/04845 | G06T-0011/203 | G06T-0011/60 | G06T-2207/30012 | G16H-0050/50","G06K-009/00","G06K-009/00 | A61B-006/00 | G06T-007/00 | A61B-005/107 | A61B-005/00 | G06F-003/0484 | G06F-003/0486 | G06T-011/20 | G06T-011/60 | G16H-050/50","","","","","","4920032005376"
"US","US","P","B2","Method and system for computer-aided triage","A system for computer-aided triage can include a router, a remote computing system, and a client application. A method for computer-aided triage can include determining a parameter associated with a data packet, determining a treatment option based on the parameter, and transmitting information to a device associated with a second point of care.","1. A method for computer-aided triage, the method comprising, at a remote computing system remote from a first point of care: receiving, at the remote computing system, a set of Digital Imaging and Communications in Medicine (DICOM) images associated with the patient and taken at the first point of care, wherein the set of DICOM images is concurrently sent to a standard radiology workflow operating in parallel with the method, wherein, in the standard radiology workflow, a radiologist analyzes the set of DICOM images at the first point of care and notifies a specialist based on a visual assessment of the set of DICOM images at a workstation, wherein the standard radiology workflow takes a first amount of time;at the remote computing system, automatically detecting a potential pathology from the set of DICOM images based on an automated processing of the set of DICOM images;upon detecting the potential pathology from the set of DICOM images, automatically: performing a first process, wherein the first process comprises: determining, at the remote computing system, a specialist associated with a second point of care;notifying the specialist at a first mobile device associated with the specialist, wherein the specialist is notified in a second amount of time shorter than the first amount of time;displaying a compressed version of the set of DICOM images on the first mobile device;performing a second process, wherein the second process comprises: determining, at the remote computing system, a clinical trial associated with the potential pathology;determining, at the remote computing system, a research coordinator associated with the clinical trial;notifying the research coordinator on a second mobile device associated with the research coordinator, wherein the research coordinator is notified in a third amount of time shorter than the first amount of time;displaying a compressed version of the set of DICOM images on the second mobile device;receiving a first input from the specialist;receiving a second input from the research coordinator; andestablishing a communication between the specialist and the research coordinator via a first client application executing on the first mobile device and a second client application executing on the second mobile device.","19","16/688721","2019-11-19","2020-0090331","2020-03-19","10733730","2020-08-04","VIZ.AI, INC.","Christopher  Mansi | David  Golan","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/4064 | G06T-0007/11 | G16H-0030/20 | G16H-0030/40 | G16H-0040/20 | G16H-0050/20 | G16H-0080/00 | H04L-0067/12 | A61B-0005/002 | A61B-0005/02007 | A61B-0005/7264 | G06T-2207/10016 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/20072 | G06T-2207/20076 | G06T-2207/20081 | G06T-2207/30016 | G06T-2207/30101 | G06T-2207/30172","G06K-009/00","G06K-009/00 | G06T-007/00 | G16H-080/00 | G16H-030/40 | G16H-050/20 | G16H-030/20 | G16H-040/20 | H04L-029/08 | G06T-007/11 | A61B-005/00 | A61B-005/02","","","","","","4920032005378"
"US","US","P","B2","Augmented reality planning and viewing of dental treatment outcomes","In an embodiment, a processing device receives image data of a face from an image capture device associated with an augmented reality (AR) display. The processing device processes the image data to a) identify a mouth in the image data, b) identify a dental arch in the mouth, and c) determine a position of the dental arch relative to a position of the AR display. The processing device determines a treatment outcome for the dental arch, generates a visual overlay comprising an indication of the treatment outcome at the determined position of the dental arch, and outputs the visual overlay to the AR display, wherein the visual overlay is superimposed over a view of the dental arch on the AR display.","1. A method comprising: receiving image data of a user'ss face from an image capture device associated with an augmented reality (AR) display used by the user, wherein the image data of the user'ss face is received from the image capture device while the user views their face through the AR display;processing, by a processing device, the image data to a) identify a mouth in the image data, b) identify a dental arch in the mouth, and c) determine a position of the dental arch relative to a position of the AR display;determining, by the processing device, a treatment outcome for the dental arch;generating, by the processing device, a visual overlay comprising an indication of the treatment outcome at the determined position of the dental arch; andoutputting the visual overlay to the AR display while the user views their face through the AR display, wherein the visual overlay is superimposed over a view of the dental arch on the AR display such that the visual overlay is visible to the user rather than a true depiction of the dental arch, wherein a remainder of the user'ss face that is not covered by the visual overlay is visible to the user.","33","16/583058","2019-09-25","2020-0020170","2020-01-16","10733805","2020-08-04","ALIGN TECHNOLOGY, INC.","Pavel  Pokotilov | Anton  Lapshin | Evgeniy  Malashkin | Sergei  Ozerov | Yury  Slynko | Andrey Sergeevich  Nekrasov | Leonid Vyacheslavovich  Grechishnikov | Anna  Orlova","","","","G06T-0019/006","G06T-0019/006 | A61B-0034/10 | A61B-0090/36 | A61C-0007/002 | A61C-0009/008 | G02B-0027/0093 | G02B-0027/017 | G06F-0003/011 | G06K-0009/00268 | A61B-2017/00216 | A61B-2034/105 | A61B-2034/2048 | A61B-2034/2065 | A61B-2090/365 | A61B-2090/3612 | A61B-2090/371 | A61B-2090/372 | A61B-2090/502 | G02B-2027/014 | G02B-2027/0138 | G02B-2027/0141 | G02B-2027/0178 | G02B-2027/0181","G06T-019/00","G06T-019/00 | G06K-009/00 | A61C-007/00 | A61C-009/00 | A61B-034/10 | G06F-003/01 | A61B-090/00 | G02B-027/01 | G02B-027/00 | A61B-017/00 | A61B-034/20 | A61B-090/50","","","","","","4920032005453"
"US","US","P","B1","Systems and methods for reaction measurement","This disclosure relates to systems, media, and methods for quantifying and monitoring visual acuity, motor skill, and cognitive ability of a user through measuring user activities while the user responds to prompts on an electronic device. Disclosed embodiments may receive image data from a user-facing camera, motion data from a sensor device attached to the user, location data from a touchscreen, and time data measuring a user's response times. Disclosed embodiments may provide graphical user interfaces to which the user responds and calculate health metrics based on characteristics of the user's response. Disclosed embodiments may calculate visual acuity, motor skill, and cognitive ability metrics based on data measured while the user responds to the graphical user interfaces. Disclosed embodiments may include comparing the metrics to respective baseline values and providing an alert when the metrics deviate from threshold values indicating a change in user health.","1. A system for measuring reaction times of a user, comprising: an electronic device comprising a touchscreen, a user-facing camera, at least one memory storing operation instructions, and at least one processor;a first sensor device attached to the user, the first sensor device comprising an inertial measurement unit;the at least one processor executing the operation instructions to perform operations comprising: providing, on the touchscreen, a graphical user interface with at least one selection region;updating, at an interval, the graphical user interface to provide at least one object related to the at least one selection region;receiving a user selection on the graphical user interface of the touchscreen;recording, between the updating and the receiving, data comprising: image data, from the user-facing camera, including at least a portion of a face of the user;first motion data, from the first sensor device, representing first motions of the user;location data, from the touchscreen, representing a location of the user selection within the graphical user interface; andtime data, indicating a time period between the updating and the receiving;determining, based on the location data, if the user performed reaction test instructions comprising selecting one of the at least one selection region on the touchscreen when at least one corresponding object appears;calculating, based on the image data, a visual acuity metric as an average percent of a field of view of the camera that includes the user'ss face;calculating, based on the first motion data, a motor skill metric as an average amount of time the user moves between the updating and the receiving;calculating, based on the time data, a cognitive ability metric as an average time period between the updating and the receiving,comparing the visual acuity metric, the motor skill metric, and the cognitive ability metric to a visual acuity threshold, a motor skill threshold, and a cognitive ability threshold, respectively; andproviding, based on the comparing, an alert based on at least one of the following occurring:the visual acuity metric exceeding the visual acuity threshold,the motor skill metric exceeding the motor skill threshold, orthe cognitive ability metric exceeding the cognitive ability threshold.","22","16/588596","2019-09-30","","","10722165","2020-07-28","BIOMECH SENSOR LLC","John Douglas | Igor Peri? | Frank Fornari","","","","A61B-0005/162","A61B-0005/162 | A61B-0005/1124 | A61B-0005/163 | A61B-0005/6825 | A61B-0005/746 | A61B-0005/748 | G06F-0003/013 | G06F-0003/04842 | G06K-0009/00281 | G09B-0019/00 | A61B-2562/0219","G09B-019/00","G09B-019/00 | A61B-005/16 | G06F-003/01 | G06F-003/0484 | A61B-005/11 | A61B-005/00 | G06K-009/00","","","","","","4920031001047"
"US","US","P","B2","Method and system of utilizing ECG signal for central venous catheter tip positioning","Disclosed herein are a method and a medical system for utilizing of an intravascular ECG signal for central venous catheter placement. The medical system is capable of detecting the position of a catheter tip and assessing its location relative to the cavoatrial junction. The detection and assessment are performed by a multiscale analysis of the complexity of the intravascular signal data points.","1. A medical system for placement of a central venous catheter comprising: a placement unit including an electrode usable to acquire intravascular ECG (ivECG) signal data;a multiscale complexity analysis module including software programmed for processing the ivECG signal data acquired by the electrode, wherein the processing uses Multiscale Complexity Analysis (MSCA) of dynamics of the ivECG signal data using a Complementary Probability Cumulative Distributive Function; anda visualization device configured to provide a visual indication of a location of the central venous catheter relative to a target location.","19","16/011409","2018-06-18","2018-0296796","2018-10-18","10722686","2020-07-28","C. R. Bard, Inc.","Vladislav  Bukhman","","","","A61M-0025/01","A61M-0025/01 | A61B-0005/042 | A61B-0005/065 | A61B-0005/6852 | A61B-0005/7221 | A61B-0034/20 | G06F-0017/18 | A61B-2505/03 | A61B-2505/05 | A61M-2025/0166 | A61M-2205/13 | A61M-2205/18 | A61M-2205/50 | A61M-2210/125 | A61M-2230/005 | A61M-2230/04 | Y02E-0010/549","A61B-005/00","A61B-005/00 | A61M-025/01 | A61B-005/06 | A61B-034/20 | A61B-005/042 | G06F-017/18","","","","","","4920031001566"
"US","US","P","B2","Vibration-based secure side channel for medical devices","According to some embodiments, a system for securing communications between an implantable wearable medical device (IWMD) and an external device (ED) is disclosed. The system includes a wireless radio frequency (RF) channel configured for communication between the IWMD and the ED. The system further includes a vibration-based side channel configured for verifying communication between the IWMD and the ED such that the RF channel is activated only when the IWMD detects a vibration signal generated by an ED.","1. A system for securing communications between an implantable or wearable medical device (IWMD) and an external device (ED), the system comprising: a wireless radio frequency (RF) channel configured to communicate medical information between the IWMD and the ED; anda vibration-based side channel configured to verify the communication of medical information between the IWMD and the ED;the RF channel being activated when the IWMD detects a vibration signal generated by the ED via a motion sensing device of the IWMD and determines an amplitude gradient and amplitude mean of the vibration signal are above respective thresholds via a demodulator of the IWMD.","17","15/552180","2016-02-12","2018-0043168","2018-02-15","10722719","2020-07-28","THE TRUSTEES OF PRINCETON UNIVERSITY","Younghyun  Kim | Woo Suk  Lee | Vijay  Raghunathan | Niraj K.  Jha | Anand  Raghunathan","","","","A61N-0001/37217","A61N-0001/37217 | A61B-0005/0028 | A61B-0005/0031 | A61B-0005/686 | H04L-0063/18 | H04W-0012/02 | H04W-0012/04 | H04W-0012/06 | A61B-0005/002","A61N-001/372","A61N-001/372 | A61B-005/00 | H04L-029/06 | H04W-012/04 | H04W-012/02 | H04W-012/06","","","","","","4920031001598"
"US","US","P","B2","Methods and apparatus for recognition of a plurality of gestures using roll pitch yaw data","Described are apparatus and methods for reconstructing a plurality of gestures using roll pitch and yaw data, typically in combination with data for recognition of start and/or stop portions of the gesture using an auxiliary sensor, such as a capacitive touch sensor or a MEMS sensor.","1. An apparatus capable of interacting with at least one controllable device based upon a pose of at least a portion of a human body, the apparatus comprising: one or more sensors that are sized for wearing on the human body, each of the one or more sensors emitting sensor data; anda detection unit that operates upon the sensor data to determine the pose of at least the portion of the human body and is capable of interacting with the at least one controllable device, the detection unit including: a memory that stores at least one or more characteristics of human anatomy that are associated with the human body using at least a partial skeletal rendering of a human; anda detection processor, automatically operating under software control, that inputs, aggregates and fuses the sensor data from each of the one or more sensors using the at least one or more characteristics of human anatomy stored in the memory to determine the pose of at least the portion of the human body based upon a locality of said one or more sensors, and wherein the pose is determined using at least a comparison of which one of an absolute value of a change in roll, a change in pitch and a change in yaw is greatest when compared to each other during a period of time.","20","14/637352","2015-03-03","2015-0241985","2015-08-27","10725550","2020-07-28","NOD, INC.","Anusankar  Elangovan | Harsh  Menon","","","","G06F-0003/017","G06F-0003/017 | G06F-0001/3259 | G06F-0003/011 | G06F-0003/014 | G06F-0003/016 | G06F-0003/044 | G06K-0009/00355 | G06K-0009/00375 | A61B-0005/1123 | A61B-2562/0219 | Y02D-0010/155","G06F-003/01","G06F-003/01 | G06F-003/044 | G06K-009/00 | G06F-001/3234 | A61B-005/11","","","","","","4920031004408"
"US","US","P","B2","Physiological control based upon media content selection","A media-playback device includes: a media-output device that plays media content items; a physiological measurement device programmed to measure at least one physiological measurement of a user of the media-output device; and a physiological control engine configured to: identify a current physiological measurement for the user; and cause the media-output device to modify playback of the media content items based upon the current physiological measurement.","1. A method for playing media content items based on a physiological measurement, the method comprising: receiving at least one physiological measurement of a user, the physiological measurement associated with a level of exertion of the user during performance of a repetitive-motion activity;identifying a current physiological measurement of the user;estimating a future physiological measurement of the user from a workout plan that involves one or more changes in the physiological measurement of the user, the workout plan requiring the user to maintain a first heart rate for a first predetermined interval, and to change the first heart rate to a second heart rate for a second predetermined interval; andtransmitting a signal configured to cause a media-playback device to modify playback of media content items based on the estimated future physiological measurement.","18","16/241634","2019-01-07","2019-0243602","2019-08-08","10725730","2020-07-28","SPOTIFY AB","Owen  Smith | Sten  Garmark | Gustav  Soderstrom","","","","G06F-0003/165","G06F-0003/165 | A61B-0005/0022 | A61B-0005/01 | A61B-0005/024 | A61B-0005/02438 | A61B-0005/0816 | A61B-0005/0833 | A61B-0005/1112 | A61B-0005/4266 | A61B-0005/6898 | A63B-0071/00 | A63B-0071/0622 | A63B-0071/0686 | G01S-0019/19 | G06F-0003/011 | G06F-0003/015 | G16H-0040/67 | A61B-0005/02055 | A61B-0005/681 | A61B-0005/6831 | A63B-2071/0625 | A63B-2220/12 | A63B-2230/062","G06F-017/00","G06F-017/00 | G06F-003/16 | G06F-003/01 | A61B-005/024 | A63B-071/00 | G01S-019/19 | A61B-005/00 | A61B-005/08 | A61B-005/11 | G16H-040/67 | A61B-005/01 | A61B-005/083 | A63B-071/06 | A61B-005/0205","","","","","","4920031004585"
"US","US","P","B2","Biometrics system, biologic information storage, and portable device","In a biometrics system for a building entrance unlocking or a bank account authentication, reference information registered under administration by the system is transmitted to a room or mobile-phone for private storage, with the original reference information deleted from the system. Biologic information gotten upon authentication is transmitted through wireless system to the room or mobile-phone for comparison with the reference, the result being returned to the system. Or, the reference is tentatively sent back to the system for comparison with the gotten biologic information. The biologic information sent to mobile-phone also includes health control information for storage and display. Mobile-phone also can receive blood pressure information at a waiting lounge of medical institution though wireless local communication even if the main power shut down. The communication between the biometrics system and the mobile-phone is encrypted. The system includes sensor unit and protection unit, the abnormality thereof being separately checked.","1. A structural sphere of activity for persons having a main entrance commonly utilized by the persons to go into an area in the structural sphere, and an authentication system for authorizing by authentication of one of the persons who is to access the main entrance for reaching one of sub areas within the area, the structural sphere of activity for the persons comprising: an information sensor, which is provided at the main entrance, arranged to sense information of the one of the persons to be authorized by the authentication;an administrator, which is provided in the authentication system, arranged to administrate the authentication system;a transmitter, which is provided in the authentication system, arranged to transmit in advance information of success in the authentication at the main entrance to the one of the sub areas to which the one of the persons is going to reach after going through the main entrance; anda lock control system for the main entrance commonly utilized by the persons, the lock control system being arranged to unlock the main entrance in accordance with the authentication, wherein the one of the sub areas is not unlocked by the information of success in the authentication at the main entrance in advance, but is to be unlocked in response to the one of the persons who actually reaches the one of the sub areas,wherein the transmitter is arranged not to transmit the information of the success in the authentication of the one of the persons at the main entrance to another one of the sub areas other than the one of the sub areas to which the one of the persons is going to reach, andwherein the one of the sub area is unique destination of the one of the persons and receives the information of success in the authentication at the main entrance before the one of the persons comes to the unique destination.","20","16/240895","2019-01-07","2019-0138706","2019-05-09","10726116","2020-07-28","NL GIKEN INCORPORATED","Masahide  Tanaka | Tohru  Matsui","2006-026393 | 2006-026401","JP | JP","2006-02-02 | 2006-02-02","G06F-0021/32","G06F-0021/32 | A61B-0005/117 | G06F-0019/3418 | G06K-0009/00906 | G06Q-0020/40 | G07C-0009/257 | G16H-0010/60 | A61B-0005/002 | A61B-0005/021 | A61B-0005/1455 | A61B-2560/0242 | G06K-2009/00932 | G16H-0050/20","G06F-021/32","G06F-021/32 | G06K-009/00 | G16H-010/60 | G07C-009/25 | G06F-019/00 | G06Q-020/40 | A61B-005/117 | A61B-005/021 | A61B-005/1455 | A61B-005/00 | G16H-050/20","","","","","","4920031004967"
"US","US","P","B2","Finger vein authentication device","Provided is a device which performs vein authentication by using a downward irradiation-type thin module and selecting an image of a proper angle by varying the irradiation direction of near-infrared illumination. Realized are a photographing method and control method of a finger vein image suitable for thin devices such as a smartphone. Adopted is a finger vein authentication device comprising an imaging unit, an illumination unit which is disposed on a substantially same plane as the imaging unit, and irradiates a finger to be captured by the imaging unit with light in which an irradiation angle is variable, an image selection unit which selects an image according to the irradiation angle of the illumination unit, and an authentication processing unit which performs authentication processing using the image selected by the image selection unit.","1. A finger vein authentication device which takes a photograph of a blood vessel pattern of a finger of an individual, and authenticates the individual by matching the photographed blood vessel pattern with a registered blood vessel pattern, comprising: a plurality of imaging sensors;an illumination device which is disposed on a substantially same plane as the plurality of imaging sensors, the illumination device comprising a light source and a movable reflecting mirror in which an angle of reflection is variable, the illumination device irradiates a finger to be captured by the plurality of imaging sensors by directing light from the light source to the movable reflecting mirror in a direction parallel to the plane and reflecting light from the movable reflecting mirror at a variable angle;a processor in communication with the plurality of imaging sensors, the processor comprising: an image selection circuit which selects an image according to the angle of reflection of the light; andan authentication processing circuit which performs authentication processing using the image selected by the image selection circuit.","7","16/060830","2016-10-31","2018-0336428","2018-11-22","10726283","2020-07-28","HITACHI, LTD.","Kenji  Ichige","2015-239035","JP","2015-12-08","G06K-0009/00885","G06K-0009/00885 | A61B-0005/1171 | G01N-0021/01 | G06F-0021/32 | G06K-0009/00013 | G06T-0001/0007 | G01N-0021/4795 | G06K-2009/0006 | G06K-2009/00932 | G06T-2207/30101","G06K-009/00","G06K-009/00 | A61B-005/1171 | G01N-021/01 | G06F-021/32 | G06T-001/00 | G01N-021/47","","","","","","4920031005134"
"US","US","P","B2","Control method and recording medium","A control method includes: receiving, from a case search system, a plurality of data including a plurality of images corresponding to a plurality of similar medical images having a certain similarity with a target medical image to be interpreted; displaying on a display a display screen including a first display area that displays thumbnails of the plurality of similar medical images; sensing one similar medical image selected from among the plurality of similar medical images displayed as thumbnails in the first display area; if the one selected similar medical image is a diffuse lesion, displaying the other plurality of medical images in a second display area included on the display screen; and if the one selected similar medical image is a localized lesion, successively displaying, in the second display area and in a first direction, the plurality of medical images including the localized lesion.","1. A control method for an information terminal, the control method being executed by a computer of the information terminal, and comprising: receiving medical case data items for medical cases, the medical case data items including thumbnail images corresponding to medical images for the medical cases, the medical images being determined on the basis of a target medical image that is interpreted;displaying a display screen including the thumbnail images on a display;detecting a selected thumbnail image from among the thumbnail images; anddisplaying a first thumbnail image, a second thumbnail image, and a third thumbnail image in a first way or a second way, whereinthe medical case data items, the medical cases, the thumbnail images, and the medical images are in one-to-one relationship,the thumbnail images include the first thumbnail image, the second thumbnail image, and the third thumbnail image,each of the medical case data items includes first information indicating a corresponding medical image, second information indicating whether the corresponding medical case is diffuse or localized, and third information indicating first medical images for the medical case,the corresponding medical image and the first medical images are obtained through one medical examination performed on a subject,the corresponding medical image and the first medical images include a first image in a first tomographic plane of the subject, a second image in a second tomographic plane of the subject, and a third image in a third tomographic plane of the subject,the first tomographic plane is closest to a top of a head of the subject among the first tomographic plane, the second tomographic plane, and the third tomographic plane,the third tomographic plane is farthest away from the top among the first tomographic plane, the second tomographic plane, and the third tomographic plane,the first thumbnail image corresponds to the first image, the second thumbnail image corresponds to the second image, and the third thumbnail image corresponds to the third image,if the second information corresponding to the selected thumbnail image indicates that the medical case corresponding to the selected thumbnail image is diffuse, the first thumbnail image, the second thumbnail image, and the third thumbnail image are displayed in the first way,if the second information corresponding to the selected thumbnail image indicates that the medical case corresponding to the selected thumbnail image is localized, the first thumbnail image, the second thumbnail image, and the third thumbnail image are displayed in the second way,the first way is that the first thumbnail image, the second thumbnail image, and the third thumbnail image are displayed at a same time on the display, andthe second way is that (i) the second thumbnail image is displayed on the display after the first thumbnail image is displayed on the display and the third thumbnail image is displayed on the display after the second thumbnail image is displayed on the display, or (ii) the second thumbnail image is displayed on the display after the third thumbnail image is displayed on the display and the first thumbnail image is displayed on the display after the second thumbnail image is displayed on the display.","3","15/272277","2016-09-21","2017-0091582","2017-03-30","10726295","2020-07-28","PANASONIC INTELLECTUAL PROPERTY MANAGEMENT CO., LTD.","Kazutoyo  Takata | Kenji  Kondo | Kazuki  Kozuka | Hirohiko  Kimura | Toyohiko  Sakai","2015-193682","JP","2015-09-30","G06K-0009/6212","G06K-0009/6212 | A61B-0005/055 | A61B-0006/5217 | G06F-0019/321 | G16H-0030/40 | G16H-0040/63 | G16H-0050/70 | G06F-0003/0482 | G06K-2009/6213 | G06K-2209/051","G06F-016/30","G06F-016/30 | G06K-009/62 | G16H-040/63 | G16H-050/70 | G16H-030/40 | A61B-005/055 | A61B-006/00 | G06F-019/00 | G06F-003/0482","","","","","","4920031005146"
"US","US","P","B2","Method for treating a surface","Method for treating a surface includes: automatically evaluating at least one digital image which includes the target surface; determining the nature of the target surface according to the evaluation of the at least one digital image; determining at least one available treatment implement according to the evaluation of the at least one image; determining the nature of the surface treatment according to the evaluation of the at least one image; automatically determining a use of the determined treatment implement in the determined treatment of the determined surface; and providing information analogous to the determined use of the treatment implement.","1. A method for treating a target surface, the method comprising steps of: a. using machine learning in evaluating at least one digital image including the target surface;b. determining the nature of the target surface according to the evaluation of the at least one image;c. determining at least one available treatment implement according to the evaluation of the at least one image;d. determining the nature of the surface treatment according to the evaluation of the at least one image;e. using machine learning to determine a use of the determined implement in the determined treatment of the determined surface;f. altering performance characteristics of the implement or providing information analogous to the determined use.","18","16/015230","2018-06-22","2019-0005355","2019-01-03","10726301","2020-07-28","THE PROCTER & GAMBLE COMPANY","Jonathan Livingston  Joyce | Faiz Feisal  Sherman | Jennifer Theresa  Werner","","","","G06K-0009/6262","G06K-0009/6262 | A45D-0044/005 | A61B-0005/44 | G06K-0009/4628 | G06K-0009/6218 | G06K-0009/6267 | G06N-0020/00 | G06Q-0050/01 | A61B-0005/0077 | A61B-0005/441 | A61B-0005/448 | A61B-0005/7264 | A61B-0005/7275 | A61B-0005/74","G06K-009/62","G06K-009/62 | A45D-044/00 | A61B-005/00 | G06K-009/46 | G06N-020/00 | G06Q-050/00","","","","","","4920031005151"
"US","US","P","B2","Fundus image capturing","An apparatus for producing a fundus image includes: a processor and a memory; an illumination component including a light source and operatively coupled to the processor; a camera including a lens and operatively coupled to the processor, wherein the memory stores instructions that, when executed by the processor, cause the apparatus to capture fundus images and provide controls for re-imaging the fundus.","1. A method for imaging a fundus of a patient, comprising: receiving an eye input, the eye input including an indication of a given eye of the patient to image;receiving a focus input, the focus input indicating an image point focus of a portion of the given eye;capturing a first image of the given eye at the image point focus;presenting a control on a graphical user interface, the control configured to initiate an image acquisition sequence of the given eye;after receiving selection of the control, capturing a second image of the given eye at the image point focus;storing both the first image and the second image; anddisplaying an exam summary interface providing a summary of image captures, the summary of image captures providing an indication of a number of images captured for each given eye and the image point focus for each of the images captured.","20","15/981129","2018-05-16","2018-0336679","2018-11-22","10726547","2020-07-28","WELCH ALLYN, INC.","Richard M.  Farchione | Kristen L.  Stebbins | Corrie A.  Baum | Thomas A.  Myers","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0003/0033 | A61B-0003/0041 | A61B-0003/1208 | G06F-0003/013 | G16H-0010/60 | G16H-0030/20 | G16H-0030/40 | G16H-0040/60 | A61B-0003/00 | A61B-0005/14555 | G06T-2207/30041","G06K-009/00","G06K-009/00 | G06T-007/00 | G06F-003/01 | G16H-010/60 | G16H-030/20 | G16H-040/60 | A61B-003/12 | A61B-003/00 | G16H-030/40 | A61B-005/1455","","","","","","4920031005394"
"US","US","P","B2","Method for proposing personalized cosmetics","The present invention provides a method for proposing personalized cosmetics and a system for implementing the same, the method comprising the steps of: photographing the visible spectrum of the skin of a subject to be measured; mapping a personalized visible spectrum to the measured visible spectrum of the skin so as to generate a spectral comparison table; matching a personalized composition to the spectral comparison table; and displaying the matched personalized composition on an image display unit.","1. A method for proposing a personalized cosmetic composition, comprising the steps of: photographing a visible spectrum of a skin of a subject to be measured to prepare a measured visible spectrum of the skin;generating a spectral comparison table by mapping a personalized visible spectrum to the measured visible spectrum of the skin;matching a personalized cosmetic composition to the spectral comparison table; anddisplaying the matched personalized cosmetic composition on an image display unit,wherein the personalized visible spectrum is a preset obtained by performing a step of photographing a standard group of skin conditions preferred according to a fashion to calculate a mean intensity value for each wavelength,wherein the step of generating a spectral comparison table comprises storing a data pair comprising W and I in the spectral comparison table by comparing the measured visible spectrum of the skin with the personalized visible spectrum for each wavelength range thereof, wherein the W of the data pair refers to a wavelength range, andwherein the I of the data pair refers to a difference value between an intensity of the personalized visible spectrum and an intensity of the measured visible spectrum of the skin in the W,wherein the step of matching a personalized cosmetic composition to the spectral comparison table includes matching a component of the personalized cosmetic composition to at least one data pair stored in the spectral comparison table,wherein the step of matching a component of the personalized cosmetic composition includes matching a corresponding wavelength reinforcement material to the W of the at least one data pair stored in the spectral comparison table, andwherein the wavelength reinforcement material is one wavelength reinforcement powder or two or more wavelength reinforcement composite powders which selected from the group consisting of mica, synthetic mica, alumina, borosilicate powder, talc, and sericite.","13","15/563064","2016-03-30","2018-0342059","2018-11-29","10726550","2020-07-28","AMOREPACIFIC CORPORATION","Choon Bok  Jeong | Se Jun  Park | Yu Jin  Kang | Kyung Ho  Choi | Yeong Jin  Choi","10-2015-0045694","KR","2015-03-31","G06T-0007/0014","G06T-0007/0014 | A61B-0005/00 | A61B-0005/1032 | A61B-0005/441 | A61B-0005/7246 | A61K-0008/18 | G06K-0009/6215 | G06Q-0030/0621 | G06Q-0030/0631 | G06T-2207/30088","G06K-009/62","G06K-009/62 | G06T-007/00 | A61B-005/00 | G06Q-030/06 | A61B-005/103 | A61K-008/18","","","","","","4920031005397"
"US","US","P","B2","Image processing device and image processing method","Provided is an image processing device including an infrared image acquisition unit that acquires an infrared image of an imaged object, a visible light image acquisition unit that acquires a visible light image of the imaged object, a generation unit that generates cutaneous sensation control parameters on the basis of the infrared image acquired by the infrared image acquisition unit, and a data processing unit that associates the visible light image acquired by the visible light image acquisition unit with the cutaneous sensation control parameters generated by the generation unit.","1. An image processing device, comprising: an infrared image acquisition unit configured to acquire a plurality of infrared images at a plurality of infrared ray irradiation angles with respect to an imaged object;a visible light image acquisition unit configured to acquire a visible light image of the imaged object, wherein each pixel region of a plurality of pixel regions of an infrared image of the plurality of infrared images corresponds to a set of pixels of the visible light image;a generation unit configured to: estimate a surface roughness of the imaged object in each pixel region of the plurality of pixel regions based on a distribution of pixel values corresponding to each pixel region of the plurality of pixel regions at the plurality of infrared ray irradiation angles;generate a first parameter of a plurality of cutaneous sensation control parameters based on the estimated surface roughness of the imaged object and pixel values of the plurality of infrared images;estimate a density of texture boundaries on a surface of the imaged object based on a dispersion of the estimated surface roughness of the imaged object; andgenerate a second parameter of the plurality of cutaneous sensation control parameters based on the estimated density of the texture boundaries on the surface of the imaged object and the pixel values of the plurality of infrared images, wherein the plurality of cutaneous sensation control parameters includes tactile sensation control parameters, andthe tactile sensation control parameters include the first parameter to control a first tactile sensation corresponding to the surface roughness of the imaged object, and the second parameter to control a second tactile sensation corresponding to the density of the texture boundaries on the surface of the imaged object; anda data processing unit configured to assign the plurality of cutaneous sensation control parameters to the set of pixels of the visible light image.","7","15/540312","2015-10-09","2017-0352290","2017-12-07","10726740","2020-07-28","SONY CORPORATION","Toshiyuki  Sasaki | Takahiro  Nagano | Masatoshi  Yokokawa | Takefumi  Nagumo","2015-006041","JP","2015-01-15","G09B-0021/00","G09B-0021/00 | A61B-0005/0075 | A61B-0005/0077 | A61B-0005/01 | A61B-0005/015 | A61B-0005/486 | A61B-0005/7455 | G06F-0003/011 | G06F-0003/016 | G06F-0003/0304 | G06T-0007/13 | G06T-0007/40 | G09B-0021/003 | H04N-0005/247 | H04N-0005/33 | H04N-0005/332 | G06T-2207/10048","G09B-021/00","G09B-021/00 | A61B-005/01 | A61B-005/00 | H04N-005/33 | G06F-003/03 | G06F-003/01 | H04N-005/247 | G06T-007/13 | G06T-007/40","","","","","","4920031005587"
"US","US","P","B2","Medical system having plug and play function","A medical system is disclosed, which can be useable in particular for monitoring and/or controlling at least one bodily function of a user. The medical system comprises a control device and at least one medical user element embodied separately from the control device. The medical user element and the control device are designed to exchange data wirelessly. The medical system is designed to enable an automatic assignment step, wherein an exchange of personal data between the medical user element and the control device is enabled by the automatic assignment step. The medical system is furthermore designed to automatically initiate the automatic assignment step by means of an assignment coupling between the medical user element and the control device. The medical system is furthermore designed to enable a separation of the assignment coupling for medical operation of the medical system after the assignment step.","1. A medical system for monitoring and/or controlling at least one bodily function of a user, comprising: a blood glucose measuring device;at least one additional device, wherein either the blood glucose measuring device or the additional device or both serve as a control device; andat least one medical user element embodied separately from the control device and configured to perform a medical function,wherein the medical user element and the control device are configured to exchange data wirelessly,wherein the medical user element and the control device are configured to move with respect to each other,wherein the medical system is configured to perform an assignment coupling between the control device and the medical user element using a coupling interface and without physical contact between the control device and the medical user element;wherein the control device and the medical user element exchange personal data automatically via a wireless communication link, wherein the personal data is exchanged only in response to the assignment coupling;wherein a data exchange between the medical user element and the control device that are assigned to one another is effected upon establishment of proximity between the medical user element and the control device so that the data, including the personal data, is transmitted during a time period within which the medical user element moves past the control device.","19","15/688317","2017-08-28","2017-0357766","2017-12-14","10716504","2020-07-21","ROCHE DIABETES CARE, INC. | ROCHE DIAGNOSTICS INTERNATIONAL AG","Nicole  Bernini | Harvey B.  Buck, Jr. | Andreas  Eberhart | Sybille  Froech | Otto  Gaa | Michael  Marquant | Juergen  Rasch-Menges | Bernd  Roesicke | Joerg  Scherer","2009-155892","EP","2009-03-23","A61B-0005/4839","A61B-0005/4839 | A61B-0005/0015 | A61B-0005/0024 | A61B-0005/0031 | A61B-0005/14503 | A61B-0005/14532 | A61B-0005/14546 | A61B-0005/7271 | A61B-0005/74 | A61B-0090/98 | G06F-0019/00 | G06F-0021/32 | G06F-0021/445 | G16H-0040/63 | H04W-0004/70 | H04W-0004/80 | A61B-2560/045 | A61B-2560/0406 | A61N-0001/37235 | H04L-0067/12","A61B-005/00","A61B-005/00 | A61B-005/145 | A61N-001/372 | A61B-005/117 | G06F-021/44 | G06F-021/32 | A61B-090/98 | G16H-040/63 | H04W-004/80 | H04W-004/70 | G06F-019/00 | H04L-029/08","","","","","","4920030000845"
"US","US","P","B2","Automatic display of previously-acquired endoluminal images","Apparatus and methods are provided for use with an endoluminal data-acquisition device that acquires a set of endoluminal data-points of a lumen of a subject's body at respective locations inside the lumen, a second endoluminal device, and a display configured to display images. At least one processor includes location-association functionality that associates a given data point acquired by the endoluminal data-acquisition device with a given location within the lumen. Location-determination functionality determines, by means of image processing, in an extraluminal image of the second endoluminal device, a current location of at least a portion of the second endoluminal device. Display-driving functionality drives the display to display an indication of the endoluminal data point associated with the location, in response to determining that the portion of the second device is currently at the location. Other applications are also described.","1. A system for guiding an endoluminal therapeutic procedure, comprising: a display; andat least one computer processor in communication with the display and configured to: receive a plurality of endoluminal images obtained at a first time by an endoluminal imaging catheter at a plurality of locations, respectively, within a lumen of a subject;associate the plurality of endoluminal images with the plurality of locations within the lumen;receive a plurality of extraluminal images obtained at a later second time by an extraluminal imaging device, wherein the plurality of extraluminal images includes a representation of an endoluminal therapeutic device within the lumen;determine at the later second time, with image processing of the plurality of extraluminal images obtained at the later second time, a current location of the endoluminal therapeutic device within the lumen;associate, at the later second time, the current location of the endoluminal therapeutic device with a location of the plurality of locations;identify at the later second time, from the plurality of endoluminal images obtained at the first time, an endoluminal image corresponding to the location; andcause the display to simultaneously display: at least one extraluminal image of the plurality of extraluminal images, wherein the at least one extraluminal image includes the representation of the endoluminal therapeutic device; andthe identified endoluminal image corresponding to the location, wherein the endoluminal image is automatically updated based on the current location of the endoluminal therapeutic device.","14","13/228185","2011-09-08","2012-0004529","2012-01-05","10716528","2020-07-21","SYNC-RX, LTD.","David  Tolkowsky | Ran  Cohen | Eldad  Klaiman","","","","A61B-0006/5217","A61B-0006/5217 | A61B-0001/0005 | A61B-0006/12 | A61B-0006/461 | A61B-0006/463 | A61B-0006/541 | G06F-0003/14 | G06T-0001/00 | G06T-0007/00 | G06T-0019/20 | G09G-0005/363 | A61B-0005/0066 | A61B-0006/503 | A61B-0006/504 | A61B-0008/0891 | A61B-2017/00252 | A61B-2017/00694 | A61B-2017/00703 | A61B-2017/22044 | A61B-2017/22094 | A61B-2090/062 | A61F-0002/82 | A61F-0002/958 | A61F-2250/0096 | G06T-2219/2024","A61B-006/00","A61B-006/00 | G06F-003/14 | G06T-001/00 | G09G-005/36 | G06T-007/00 | G06T-019/20 | A61B-001/00 | A61B-006/12 | A61F-002/82 | A61B-017/22 | A61B-017/00 | A61F-002/958 | A61B-008/08 | A61B-005/00 | A61B-090/00","","","","","","4920030000869"
"US","US","P","B2","Method for pushing picture, mobile terminal, and storage medium","Provided are a method for pushing a picture, a terminal and a storage medium. The method includes the follows. An image containing a facial expression of a user is acquired, when a screen is lit; the image is analyzed to determine an emotion type of the user; and a target picture is pushed according to the emotion type of the user.","1. A method for pushing a picture, comprising: acquiring an image containing a facial expression of a user when a screen is lit;comparing the image with a template to determine locations of multiple facial features;analyzing shapes of the facial features to determine multiple candidate emotion types;determining an emotion type with the highest proportion among the candidate emotion types as the emotion type of the user; andpushing a target picture according to the emotion type of the user.","8","15/957360","2018-04-19","2018-0349686","2018-12-06","10719695","2020-07-21","GUANGDONG OPPO MOBILE TELECOMMUNICATIONS CORP., LTD.","Jian  Bai","2017-10401789","CN","2017-05-31","G06K-0009/00302","G06K-0009/00302 | A61B-0005/0077 | A61B-0005/165 | A61B-0005/6898 | A61B-0005/7264 | G06F-0003/011 | G06K-0009/6256 | G06F-2203/011","G06K-009/62","G06K-009/62 | G06K-009/00 | A61B-005/16 | G06F-003/01 | A61B-005/00","","","","","","4920030003992"
"US","US","P","B1","Aerial device including translation or rotation measurement","Disclosed is a system which uses one or more camera units with embedded processors to measure the relative translation and/or rotation between different members on an aerial device. Image data from each unit is processed and transmitted processing to the position control system of the aerial device, and used to determine the position of an aerial element of the device.","1. A position detection system, the system comprising: a first member configured to be movable relative to a second member;a motion-sensing device on either the first or the second member, the motion-sensing device being oriented to receive image data relevant to motion of the first member relative to the second member; anda processing component configured to determine a position of one of the first and second members using the image data.","20","16/725356","2019-12-23","","","10719941","2020-07-21","ALTEC INDUSTRIES, INC.","Aaron  Beck | Michael A.  Fleming","","","","G06T-0007/20","G06T-0007/20 | B66F-0017/006 | G05D-0003/20 | G06T-0007/70 | H04N-0005/2253 | H04N-0005/2256 | B66F-0011/046","A61B-005/00","A61B-005/00 | G06T-007/20 | G05D-003/20 | B66F-017/00 | H04N-005/225 | G06T-007/70 | G06F-003/00 | B66F-011/04","","","","","","4920030004237"
"US","US","P","B2","System and method for face position tracking and alerting user","Current technologies detect the alertness of a user using frontal face. However, there are no techniques to track the position of face from a side angle. A method and system for face position tracking of a user and alerting the user is disclosed. The method includes capturing images using a monocular camera and identifying a user's face from the images and storing the user's face as reference face. The user's face is divided into two regions and one or more corner points are identified. A centroid is created in the two regions and the corner points are joined using virtual lines to create a dual flexible spider model. One or more new corner points are created on fulfillment of pre-defined conditions. Angle and magnitude of flow vectors is determined using one or more new corner points and alerts are given to the user based on the angle and magnitude.","1. A method for face position tracking and alerting a user, the method comprising: capturing one or more images through a camera;identifying the user'ss face from one or more faces based on space occupied in the one or more images to store the user'ss face as a reference face;dividing the user'ss face into (i) a first region and (ii) a second region and identifying one or more corner points from the first region and the second region of the user'ss face;creating a centroid in each of the first region and the second region and joining the one or more corner points with the centroid created in each of the first region and the second region using a plurality of virtual lines to create a dual flexible spider model;creating a dense plurality of virtual lines in the dual flexible spider model, based on movement of the user'ss face for a predefined time period;tracking variations in the dual flexible spider model due to the movement of the user'ss face by computing one or more flow vectors based on a magnitude and a phase value of the one or more corner points;creating one or more new corner points and creating one or more additional flow vectors by subjecting the one or more new corner points to optical flow frame processing, wherein the one or more new corner points are created based on one or more predefined conditions;determining one or more valid motion vectors, one or more invalid motion vectors and one or more static motion vectors based on an angle and magnitude of the one or more flow vectors; andalerting the user if the angle and magnitude of the one or more flow vectors of the one or more valid motion vectors is greater than a threshold.","19","16/030559","2018-07-09","2019-0139233","2019-05-09","10719945","2020-07-21","TATA CONSULTANCY SERVICES LIMITED","Apurba  Das | Nithish  Chauhan | Hardik Jayesh  Sanghani","201721039668","IN","2017-11-07","G06T-0007/251","G06T-0007/251 | A61B-0005/18 | B60K-0028/02 | B60K-0028/06 | B60K-0028/066 | G06F-0003/012 | G06K-0009/00228 | G06K-0009/00248 | G06K-0009/00281 | G06K-0009/00288 | G06K-0009/00335 | G06K-0009/00362 | G06K-0009/468 | G06K-0009/4638 | G06K-0009/6211 | G06K-0009/6261 | G06T-0007/149 | G06T-0007/162 | G06T-0007/181 | G06T-0007/246 | G06T-0007/73 | G06T-0007/75 | G08B-0021/06 | G06K-0009/00845 | G06T-2207/20024 | G06T-2207/20164 | G06T-2207/20192 | G06T-2207/30201 | G06T-2207/30268","G06K-009/00","G06K-009/00 | G06T-007/246 | G08B-021/06 | G06T-007/149 | B60K-028/06 | G06K-009/46 | G06K-009/62 | G06T-007/73 | G06T-007/181 | B60K-028/02 | G06T-007/162 | A61B-005/18 | G06F-003/01","","","","","","4920030004241"
"US","US","P","B2","Method and a system for eye tracking","According to an aspect of the present inventive concept there is provided a method for eye tracking, comprising: capturing a sequence of digital images of an eye of a user; outputting data including said sequence of images to an image processing unit; processing said data by the image processing unit to determine a sequence of positions of the eye, each position being indicative of a gaze direction, acquiring biosignal data representing an activity of the eye; and in response to detecting closing of the eye based on the acquired biosignal data, pausing at least one of said capturing, said outputting and said processing. A system for implementing the method is also disclosed.","1. A method for eye tracking, the method comprising: capturing a sequence of digital images of an eye of a user;outputting data including said sequence of images to an image processing unit;processing said data by the image processing unit to determine a sequence of positions of the eye, each position being indicative of a gaze direction,acquiring biosignal data representing an activity of the eye;in response to detecting closing of the eye based on the acquired biosignal data, pausing said capturing; andreturning of said capturing to an active state from the paused state,wherein returning of said capturing to the active state includes transitioning said capturing from the paused state to a waiting state and transitioning said capturing from the waiting state to the active state.","16","15/651445","2017-07-17","2018-0027176","2018-01-25","10721392","2020-07-21","STICHTING IMEC NEDERLAND","Carlos  Agell | Pierluigi  Casale","2016-180066","EP","2016-07-19","H04N-0005/23219","H04N-0005/23219 | A61B-0003/113 | A61B-0005/0496 | G06F-0003/013 | G06F-0003/017 | G06K-0009/0061 | G06T-0007/20 | G06T-0007/74 | H04N-0005/23241 | A61B-0003/112 | G06T-2207/10016 | G06T-2207/30041","H04N-005/232","H04N-005/232 | A61B-003/113 | A61B-005/0496 | G06F-003/01 | G06T-007/73 | G06K-009/00 | G06T-007/20 | A61B-003/11","","","","","","4920030005674"
"US","US","P","B2","Method for providing physiological state information and electronic device for supporting the same","An apparatus and method for providing physiological state information are provided. The apparatus includes a wearable electronic device. The wearable electronic device includes a sensor module configured to measure motion of the wearable electronic device, a display configured to provide a user interface (UI) including movable particles displayed on the display, and a processor configured to reduce the number of the displayed movable particles based on the measured motion of the wearable device.","1. A wearable electronic device comprising: a plurality of sensors;a display; anda processor configured to: obtain physiological state information related to a plurality of physiological states of a user of the wearable electronic device through the plurality of sensors,control the display to provide a user interface (UI) including a plurality of movable display objects corresponding to each of the plurality of physiological states, wherein, based upon properties of the physiological state information, the plurality of moveable display objects varies in at least one of a number, a location, a shape, a color, or a size,change at least one of the number, the location, the shape, the color, or the size of the plurality of movable display objects upon analyzing the obtained physiological information, andchange a state of the UI such that a position of the plurality of movable display objects corresponds to a direction of a sensed motion of the wearable electronic device.","16","15/233233","2016-08-10","2017-0046052","2017-02-16","10712919","2020-07-14","SAMSUNG ELECTRONICS CO., LTD.","Eun Hye  Lee | Eun Ji  Ahn | Dok Shin  Lim | Tae Kyeung  Lim | Joon Ho  Ok","10-2015-0112878","KR","2015-08-11","G06F-0003/04845","G06F-0003/04845 | A61B-0005/02438 | A61B-0005/1118 | A61B-0005/1123 | A61B-0005/165 | A61B-0005/4809 | A61B-0005/6802 | A61B-0005/6898 | A61B-0005/742 | G04G-0009/0064 | G04G-0021/025 | G06F-0001/163 | G06F-0001/1684 | G06F-0001/1694 | G06F-0003/015 | G06F-0003/0346 | G06F-0003/0488 | G06F-0003/04817 | G06F-0003/04883 | G06K-0009/00342 | G16H-0020/30 | G16H-0020/60 | G16H-0040/63 | G16H-0050/20","G06F-003/0484","G06F-003/0484 | G06F-001/16 | G06F-003/0346 | G06F-003/01 | G06F-003/0488 | G04G-009/00 | G06F-003/0481 | G06K-009/00 | G04G-021/02 | A61B-005/11 | A61B-005/024 | G16H-050/20 | A61B-005/16 | G16H-020/60 | A61B-005/00 | G16H-040/63 | G16H-020/30","","","","","","4920029004578"
"US","US","P","B2","Non-contacting monitor for bridges and civil structures","A system for monitoring the movement of objects, structures, models of structures, cables and the like provides for the acquisition of images with an optical sensing device such as a video camera fixedly mounted at a selected distance from the item studied, in which the images are arranged into frames divided into pixels which are characterized by an intensity reflected or emitted over a selected time interval, and a data processing system to calculate a physical displacement as function of time of the item being studied or a portion of the item being studied based on an output from the video camera, and in some embodiments the system visually distinguishes one or more locations in the frame to indicate a difference in the phase of motion for multiple objects appearing in the frame.","1. A system for monitoring the motion of a first object having at least one surface that reflects light from an environment surrounding the first object and having the capacity to store heat from said environment, comprising: a video camera which can be stably positioned at a selected distance from the first object with an unobstructed view of at least a portion of the first object, wherein the video camera acquires images of the first object which are able to be divided into a plurality of pixels, wherein the pixels are characterized by an intensity associated with one or both of visible light energy from light reflected from the at least one surface of the first object or infra-red energy emitted from thermal heating of the at least one surface of the first object over a selected time interval, and wherein the images are arranged in a plurality of frames; anda data processing system configured to obtain a first measurement of an intensity of a first location of at least one frame comprising at least one pixel and a second measurement of an intensity of a second location of the frame comprising at least one pixel apart from the first location, determine a difference in the first measurement and the second measurement, and display at least one image from the frame,wherein the data processing system is further configured to modify the displayed image to indicate a difference in a phase of motion between the first object and at least a second object based on the difference in the first measurement and the second measurement.","22","16/679905","2019-11-11","2020-0073545","2020-03-05","10712924","2020-07-14","RDI TECHNOLOGIES, INC.","Jeffrey R.  Hay","","","","G06F-0003/04847","G06F-0003/04847 | A61B-0005/0077 | A61B-0005/01 | A61B-0005/024 | A61B-0005/0816 | A61B-0005/165 | A61B-0005/4815 | A61B-0005/7435 | G01N-0029/44 | G06F-0016/7335 | G06K-0009/00335 | G06K-0009/00771 | G06T-0007/0016 | G06T-0007/11 | G06T-0007/248 | G06T-0007/262 | G01N-2291/028 | G06T-2200/24 | G06T-2207/10016 | G06T-2207/20056 | G06T-2207/20216 | G06T-2207/30004 | G06T-2207/30164 | H04N-0007/18","G06K-009/00","G06K-009/00 | G06F-003/0484 | G06F-016/732 | A61B-005/00 | A61B-005/01 | A61B-005/024 | A61B-005/08 | A61B-005/16 | G06T-007/00 | G01N-029/44 | G06T-007/11 | G06T-007/246 | G06T-007/262 | H04N-007/18","","","","","","4920029004583"
"US","US","P","B2","Sensor systems and methods for activity evaluation","Systems and methods are discussed for providing sensor enhanced safety, recovery, and activity evaluation systems. Sensors that monitor user activity and behavior are worn by a user and/or placed in the user environment. Data from the sensors are processed to obtain a safety, recovery, and/or activity evaluation. Based on the evaluation, recommendations or adjustments to the terms of an insurance policy covering the user, the user's employer, or a facility providing health care to the user, aer generated, to accurately reflect the risks associated with the user, employer, and/or facility. In embodiments, an alert may be generated when a failure to conform with activity guidelines is detected.","1. An activity evaluation system, comprising: a communications device configured to receive remote sensor data based on at least one sensor proximate to an individual associated with and distinct from a covered entity;a data storage device storing at least one activity guideline associated with the individual;a computer hardware server, in communication with the communications device and the data storage device, and operated by a risk management entity remote from the at least one sensor, configured to: analyze the received sensor data to determine activity characteristics of the individual;output an activity evaluation based on the activity characteristics and the at least one stored activity guideline;adjust data corresponding to a parameter of a risk management policy covering the covered entity based on the sensor data and the activity evaluation, wherein the computer hardware server is configured to adjust the data corresponding to the parameter so as to provide an adjustment favorable to the covered entity responsive to the activity evaluation being indicative of conformance by the individual with the at least one activity guideline; andresponsive to the activity evaluation being indicative of non-conformance by the individual with the at least one activity guideline, transmit an alert to a computing device of the covered entity.","16","16/564703","2019-09-09","2019-0392529","2019-12-26","10713729","2020-07-14","HARTFORD FIRE INSURANCE COMPANY","Andrew J.  Amigo | Michael  Gingrave","","","","G06Q-0040/08","G06Q-0040/08 | A61B-0005/1038 | A61B-0005/112 | A61B-0005/1112 | A61B-0005/1115 | A61B-0005/1118 | A61B-0005/1121 | A61B-0005/1123 | A61B-0005/6804 | G06F-0019/00 | G06Q-0010/105 | G16H-0050/30 | A61B-0005/6807 | A61B-2503/20","G06Q-040/08","G06Q-040/08 | A61B-005/103 | A61B-005/11 | A61B-005/00 | G16H-050/30 | G06Q-010/10 | G06F-019/00","","","","","","4920029005378"
"US","US","P","B2","Hand sanitizer station","A system and method for detecting, using a sensor, an initiation event; capturing, using a camera, an image of a user's face responsive to the initiation event; activating, responsive to facial recognition and a determination based on one of exposure data associated with the user and the absence thereof that the user has not exceed a safe use standard for ultraviolet light, an ultraviolet source; the ultraviolet source and an activation duration sufficient to sanitize a surface located within a compartment. In one embodiment, visually presenting, by a display, a plurality of graphic elements associated with a plurality of potential content for presentation to the user; and presenting user selected content to the user when the ultraviolet source is activated and responsive to determining a user's selection, wherein the user's selection is made touch-lessly.","1. A system comprising: a sensor configured to detect an initiation event;a camera configured to capture an image of a user'ss face responsive to the initiation event, the camera communicatively coupled to the sensor;an ultraviolet source configured to be activated responsive to facial recognition and a determination based on one of exposure data associated with the user and an absence thereof that the user has not exceed a safe use standard for ultraviolet light; the ultraviolet source activated for an activation duration that sanitizes a surface located within a compartment; anda display configured to visually present a plurality of graphic elements associated with a plurality of potential content for presentation to the user, the display communicatively coupled to the ultraviolet source and presenting user selected content to the user when the ultraviolet source is activated and responsive to determining a user'ss selection, wherein the user'ss selection is made touch-lessly.","18","14/815993","2015-08-01","2016-0030766","2016-02-04","10702707","2020-07-07","CP STUDIOS LLC","George  Scritchfield | Nigel  Waites","","","","A61N-0005/0624","A61N-0005/0624 | G06F-0003/011 | G06K-0009/00228 | G06K-0009/00375 | A61N-2005/0627 | A61N-2005/0643 | A61N-2005/0661","A61N-005/06","A61N-005/06 | G06F-003/01 | G06K-009/00","","","","","","4920028001593"
"US","US","P","B2","Facilitating dynamic monitoring of body dimensions over periods of time based on three-dimensional depth and disparity","A mechanism is described for facilitating smart monitoring of body dimensions according to one embodiment. A method of embodiments, as described herein, includes receiving a first request to take a first picture of a user, wherein the first picture is taken at a first point in time using a depth-sensing camera; automatically computing first body dimensions relating to a body of the user based on at least one of a first image of the body and first depth information relating to one or more parts of the body, wherein the first image and the first depth information are obtained from the first picture; generate a first three-dimensional (3D) model of the body based on the first body dimensions; and communicating at least one of the first 3D model and the first body dimensions to a display device, wherein the display device to display at least one of the first 3D model and the first body dimensions.","1. An apparatus for analyzing a body part of a user, the apparatus comprising: a depth-sensing device including one or more sensors to generate first image data with respect to the body part of the user and to generate second image data with respect to the body part, the depth-sensing device to generate the first image data at a first time and to generate the second image data at a second time after the first time;at least one processor; anda storage device including instructions that, when executed by the at least one processor, cause the at least one processor to: generate a first image indicative of a first change in the body part between the first time and the second time based on the first image data and the second image data, the first image including a first portion based on the first image data and a second portion based on the second image data, the second portion to at least partially overlap the first portion in the first image to show a difference in body shape between the first time and the second time;generate a prediction with respect to a second change in the body part at a third time based on the first image data and the second image data, the third time to occur after the first time and after the second time; andgenerate a second image of the body part based on a target body dimension for the body part, the target body dimension defined by a user input; andcause a display device to display at least one of the first image, the second image, or the prediction.","21","15/883864","2018-01-30","2019-0022462","2019-01-24","10702745","2020-07-07","INTEL CORPORATION","Venkata Siva Varun Kumar  Nandimandalam | Jim Santiago  Baca | Neal P.  Smith | David W.  Baker","","","","A63B-0024/0075","A63B-0024/0075 | A41H-0003/00 | A61B-0005/00 | A61B-0005/1071 | A61B-0005/1072 | A61B-0005/1079 | G06F-0019/00 | G06K-0009/00214 | G06Q-0010/0639 | G06Q-0030/00 | G06T-0005/50 | G06T-0007/00 | G06T-0007/50 | G06T-0007/62 | G06T-0017/00 | G09B-0019/0092 | G16H-0010/60 | G16H-0020/30 | G16H-0020/60 | G16H-0040/67 | A61B-0005/0077 | A61B-0005/1114 | G06T-2207/10021 | G06T-2207/10028 | G06T-2207/20221","A63B-024/00","A63B-024/00 | G16H-010/60 | G06T-007/62 | A61B-005/107 | G16H-020/30 | G16H-020/60 | G06T-005/50 | G06T-017/00 | G06T-007/50 | A61B-005/00 | G06T-007/00 | G06K-009/00 | G16H-040/67 | G06Q-010/06 | G09B-019/00 | A41H-003/00 | G06Q-030/00 | G06F-019/00 | A61B-005/11","","","","","","4920028001631"
"US","US","P","B2","System and method for detecting invisible human emotion in a retail environment","A system for detecting invisible human emotion in a retail environment is provided. The system comprises a camera and an image processing unit. The camera is configured in a retail environment to capture an image sequence of a person before and during when a price of a product or service becomes visible. The image processing unit is trained to determine a set of bitplanes of a plurality of images in the captured image sequence that represent the hemoglobin concentration (HC) changes of the person, and to detect the person's invisible emotional states based on HC changes. The image processing unit is trained using a training set comprising a set of subjects for which emotional state is known.","1. A system for detecting invisible human emotion in a retail environment within which a product is displayed in a product display to a person, the system comprising: a price display device for selectively displaying at least one price of the product, pursuant to a point of sale event;a camera configured to capture an image sequence of the person before and during the point of sale event; anda processing unit trained to determine a set of bitplanes of a plurality of images in the captured image sequence that represent the hemoglobin concentration (HC) changes of the person, to detect the person'ss invisible emotional states based on the HC changes, and to output the detected invisible emotional states, the processing unit being trained using a training set comprising HC changes of subjects with known emotional states.","16","16/076472","2017-02-08","2019-0041984","2019-02-07","10705603","2020-07-07","NURALOGIX CORPORATION","Kang  Lee | Pu  Zheng","","","","G06F-0003/013","G06F-0003/013 | A61B-0003/113 | A61B-0005/0077 | A61B-0005/145 | A61B-0005/1455 | A61B-0005/16 | A61B-0005/165 | G06K-0009/4652 | G06K-0009/78 | G06N-0003/0445 | G06N-0003/08 | G06Q-0030/0201 | G06Q-0030/0238 | G06T-0007/20 | H04N-0007/188 | A61B-0005/0402 | A61B-0005/08 | A61B-2503/12 | G06F-2203/011 | G06K-0009/00228 | G06K-0009/00302 | G06T-2207/20081","G06F-003/01","G06F-003/01 | G06Q-030/02 | G06T-007/20 | H04N-007/18 | A61B-005/16 | A61B-003/113 | A61B-005/00 | A61B-005/145 | G06K-009/78 | A61B-005/1455 | G06K-009/46 | G06N-003/08 | G06N-003/04 | A61B-005/08 | A61B-005/0402 | G06K-009/00","","","","","","4920028004472"
"US","US","P","B2","Methods and apparatus to capture patient vitals in real time during an imaging procedure","Apparatus, systems, and methods to capture and combine patient vitals and image data are disclosed. An example apparatus includes a video capturing device or an audio receiving device, a vitals data manager, and a vitals aggregator. The video capturing device captures visual vital information of a patient from a vital monitor during an imaging procedure. The audio receiving device captures audible vital information of the patient during the imaging procedure. The vitals data manager receives the captured visual vital information or the captured audible vital information, the captured visual vital information or the captured audible vital information to be tagged with an identifier of the patient to form tagged vitals information. The vitals aggregator receives the tagged vitals information and the image associated with the patient, the vitals aggregator to organize the tagged vitals information with the image associated with the patient to form a composite image.","1. An apparatus to capture patient vitals in real time during an imaging procedure, the apparatus comprising: at least one of a video capturing device or an audio receiving device, the video capturing device configured to capture a visual vital information of a patient from a vital monitor during the imaging procedure and the audio receiving device configured to capture an audible vital information of the patient during the imaging procedure;a vitals data manager to: obtain at least one of the visual vital information or the audible vital information, the at least one of the visual vital information or the audible vital information tagged with an identifier of the patient;obtain a medical image of the patient, the medical image captured during the imaging procedure; anddetermine, utilizing the identifier of the patient, that the at least one of the visual vital information or the audible vital information correspond to the medical image of the patient; anda vitals aggregator to: when the at least one of the visual vital information or the audible vital information does not correspond to the medical image, trigger a recapture of the at least one of the visual vital information or the audible vital information; andembed the at least one of the visual vital information or the audible vital information with the medical image corresponding to the patient to form a composite image.","20","16/197795","2018-11-21","2020-0160574","2020-05-21","10706602","2020-07-07","GENERAL ELECTRIC COMPANY","Katelyn Rose  Nye | Gireesha  Rao","","","","G06T-0011/60","G06T-0011/60 | A61B-0005/0013 | A61B-0005/0077 | A61B-0005/7435 | A61B-0005/7475 | A61B-0007/04 | G06K-0009/00624 | G06K-0009/03 | G06K-0009/6201 | G16H-0030/20 | G16H-0040/63 | H04R-0001/028 | A61B-2576/00 | G06F-0003/0482 | G06K-2209/01 | G06K-2209/057 | H04N-0005/23206","G06T-011/60","G06T-011/60 | G06K-009/03 | H04R-001/02 | A61B-005/00 | A61B-007/04 | G16H-040/63 | G16H-030/20 | G06K-009/00 | G06K-009/62 | G06F-003/0482 | H04N-005/232","","","","","","4920028005465"
"US","US","P","B2","Wearable physiology monitor computer apparatus, systems, and related methods","A computer-implemented method of detecting physiological attributes of a wearer of a computerized wearable device having one or more sensors comprises (1) using the information from the one or more sensors to assess the physiology of the wearer; and (2) notifying the wearer of the wearer's physiology. In various embodiments, the method involves using the wearable device to determine the wearer's current posture, balance, alertness, and/or physical state and comparing the current posture, balance, alertness and/or physical state to at least one baseline measurement. For example, the system may measure a baseline posture to determine when the wearer's current posture deviates from the baseline posture, and notify the wearer so that the wearer may improve his or her posture. In other embodiments, the computerized wearable device may detect one or more of the wearer's physiological characteristics (e.g., oxygen levels, pulse rate, pupil size, etc.) and determine the wearer's alertness level.","1. A computerized eyewear comprising: at least one processor;one or more sensors operatively coupled to the at least one processor;a power source operatively coupled to the at least one processor; anda communication device operatively coupled to the at least one processor,wherein the computerized eyewear is configured to: at least partially in response to receiving at least one signal at a first time or a first period of time from the one or more sensors, determine a normal physiology of the wearer of the computerized eyewear;at least partially in response to receiving at least one signal at a second time or a second period of time, determine a current physiology of the wearer of the computerized eyewear;at least partially in response to determining the current physiology of the wearer, compare the current physiology of the wearer to the normal physiology of the wearer; andnotify the wearer when the current physiology of the wearer deviates from the normal physiology of the wearer.","20","16/429480","2019-06-03","2019-0298228","2019-10-03","10694981","2020-06-30","VISION SERVICE PLAN","Jay William  Sales | Richard Chester  Klosinski, Jr. | Matthew Allen  Workman | Meghan Kathleen  Murphy | Matthew David  Steen","","","","A61B-0005/112","A61B-0005/112 | A61B-0003/112 | A61B-0005/0002 | A61B-0005/0022 | A61B-0005/0077 | A61B-0005/0402 | A61B-0005/0476 | A61B-0005/1032 | A61B-0005/1103 | A61B-0005/117 | A61B-0005/1114 | A61B-0005/1116 | A61B-0005/1128 | A61B-0005/1176 | A61B-0005/14552 | A61B-0005/165 | A61B-0005/4076 | A61B-0005/4266 | A61B-0005/443 | A61B-0005/486 | A61B-0005/4884 | A61B-0005/6803 | A61B-0005/7246 | A61B-0005/7278 | A61B-0007/04 | A63B-0024/0062 | G06F-0021/35 | G06K-0009/00348 | G06K-0009/00597 | G06K-0009/00604 | G06K-0009/00617 | G06K-0009/00664 | G06K-0009/6201 | G07C-0009/37 | G08B-0021/02 | G08B-0021/0423 | G08B-0021/0461 | G08B-0021/0476 | G09B-0005/00 | G09B-0005/06 | G09B-0019/0092 | G16H-0020/40 | G16H-0040/63 | G16H-0050/20 | H04L-0063/0861 | A61B-0005/024 | A61B-0005/0205 | A61B-0005/0531 | A61B-0005/0816 | A61B-0005/1118 | A61B-0005/7282 | A61B-2560/0475 | A61B-2562/0219 | A61B-2562/0223 | A61B-2562/0257 | A61B-2576/00 | A61F-0002/76 | A61F-2002/7695 | G02C-0011/10","A61B-005/00","A61B-005/00 | A61B-005/1455 | A61B-005/16 | A61B-005/11 | A61B-003/11 | A61B-005/0402 | A61B-005/0476 | A61B-005/103 | A61B-005/1171 | A61B-007/04 | G06K-009/00 | G16H-040/63 | G16H-050/20 | A61B-005/117 | G07C-009/37 | G09B-005/00 | G06K-009/62 | G08B-021/04 | A63B-024/00 | G09B-005/06 | G09B-019/00 | G06F-021/35 | G08B-021/02 | H04L-029/06 | G16H-020/40 | A61F-002/76 | A61B-005/0205 | A61B-005/024 | A61B-005/053 | A61B-005/08 | G02C-011/00","","","","","","4920027001054"
"US","US","P","B2","System and method for tumor ablation treatment planning including core tumor, margin and healthy tissue coverage","A system for ablation planning and treatment includes a delineation module (124) configured to distinguish tissue types in an image, the tissue types including at least a core tissue and a margin zone encapsulating the core tissue. A treatment planning module (140) is configured to apply weightings in a cost function to prioritize ablation coverage of the tissue types including the core tissue and the margin zone to determine ablation characteristics that achieve an ablation composite in accordance with user preferences. A graphical user interface (122) is rendered on a display to indicate the core tissue, the margin zone, the ablation composite and permit module user selection of one or more treatment methods.","1. A system for ablation planning and treatment, comprising: a delineation module configured to distinguish tissue types in an image, the tissue types including at least a core tissue and a margin zone encapsulating the core tissue;a treatment planning module configured to apply each of at least two sets of weightings in a cost function to prioritize ablation coverage in and surrounding a planned treatment volume including the core tissue and in the margin zone to determine candidate treatment plan to achieve an ablation composite in accordance with user preferences; anda graphical user interface rendered on a display to indicate the core tissue, the margin zone, the ablation composite and permit user selection of one or more treatment method, the graphic user interface including a graphic representation representing a portion of the region covered by the ablation relative to collateral damage comprising a volume of the healthy tissue destroyed by ablation.","20","15/552384","2016-03-24","2018-0042679","2018-02-15","10695129","2020-06-30","KONINKLIJKE PHILIPS N.V.","Sandeep  Dalal | Jochen  Kruecker","","","","A61B-0034/10","A61B-0034/10 | A61B-0018/12 | A61B-0018/1477 | A61B-0034/25 | G06F-0019/3481 | A61B-2018/00577 | A61B-2018/1425 | A61B-2034/104 | A61B-2034/107 | G06F-0003/0482 | G06T-0007/0012 | G06T-0007/11 | G06T-2207/20104 | G06T-2207/30024 | G06T-2207/30096 | G16H-0040/63","A61B-034/10","A61B-034/10 | A61B-034/00 | A61B-018/14 | A61B-018/12 | G06F-019/00 | A61B-018/00 | G06T-007/11 | G16H-040/63 | G06F-003/0482 | G06T-007/00","","","","","","4920027001202"
"US","US","P","B2","Augmented reality enhancements for intraoral scanning","A system comprises a scanner, an augmented reality (AR) display and a computing device. The scanner generates intraoral images of a dental arch and the AR display generates additional image data representative of a view from a wearer of the AR display. The computing device receives the intraoral images from the intraoral scanner, generates a virtual three-dimensional model of at least a portion of the dental arch from the intraoral images, receives the additional image data from the AR display, determines, from the additional image data, a region of the view that is outside of the dental arch, generates a visual overlay comprising the virtual three-dimensional model, and sends the visual overlay to the AR display. The AR display displays the visual overlay such that the virtual three-dimensional model is shown in the region of the view that is outside of the dental arch.","1. A system comprising: an intraoral scanner to generate a plurality of intraoral images of a dental arch of a patient during an intraoral scanning procedure;an augmented reality (AR) display comprising an image capture device and one or more lenses, the image capture device of the AR display to generate additional image data representative of a field of view of a wearer of the AR display; anda computing device operatively coupled to the intraoral scanner and the AR display, the computing device to: receive the plurality of intraoral images from the intraoral scanner;generate a virtual three-dimensional model of at least a portion of the dental arch from the plurality of intraoral images during the intraoral scanning procedure;receive the additional image data from the AR display;determine, from the additional image data, a first region of the field of view that includes the dental arch and a second region of the field of view that does not include the dental arch;generate a visual overlay of the virtual three-dimensional model; andsend the visual overlay of the virtual three-dimensional model to the AR display, wherein the AR display is to superimpose the visual overlay of the virtual three-dimensional model over a real-world environment in the field of view of the wearer that the wearer sees through the one or more lenses such that the visual overlay of the virtual three-dimensional model is superimposed over the real-world environment in the second region of the field of view and the visual overlay of the virtual three-dimensional model is not superimposed over the real-world environment in the first region of the field of view that includes the dental arch.","20","15/841200","2017-12-13","2018-0168781","2018-06-21","10695150","2020-06-30","ALIGN TECHNOLOGY, INC.","Avi  Kopelman | Eric Paul  Meyer | Elad  Zeiri | Amir  Ashkenazi | Ron  Ganot | Partha  Dey | Sergei  Ozerov | Ran  Mizrahi | Ilya  Fomin | Sean M.  Nolen | Sergey  Valiev | Edi  Fridman | Sergey  Gagarin","","","","A61C-0009/0053","A61C-0009/0053 | A61B-0005/0088 | A61B-0034/10 | A61B-0034/20 | A61B-0034/25 | A61B-0090/36 | A61C-0001/0015 | A61C-0001/082 | A61C-0005/44 | A61C-0007/002 | A61C-0009/004 | A61C-0009/0046 | A61C-0019/04 | A61C-0019/05 | G06F-0003/011 | G06K-0009/00281 | G06K-0009/6212 | G06T-0017/00 | G06T-0019/006 | G09B-0023/283 | G16H-0020/40 | G16H-0030/20 | G16H-0030/40 | G16H-0040/60 | G16H-0050/20 | G16H-0050/50 | A61B-0001/00009 | A61B-0001/00045 | A61B-0001/00172 | A61B-0001/24 | A61B-0005/1032 | A61B-0005/4542 | A61B-0005/4547 | A61B-0005/4552 | A61B-0005/7455 | A61B-0006/14 | A61B-0006/466 | A61B-0006/5217 | A61B-0006/5247 | A61B-0034/76 | A61B-2017/00216 | A61B-2034/102 | A61B-2034/105 | A61B-2034/107 | A61B-2034/2048 | A61B-2034/2065 | A61B-2034/252 | A61B-2034/254 | A61B-2034/256 | A61B-2034/258 | A61B-2090/062 | A61B-2090/309 | A61B-2090/365 | A61B-2090/3612 | A61B-2090/371 | A61B-2090/372 | A61B-2090/373 | A61B-2090/502 | G02B-0027/0093 | G02B-0027/017 | G02B-2027/0178 | G06F-0003/013 | G06N-0003/08 | G06N-0020/10 | G06T-2207/30036 | G06T-2210/41 | Y02A-0090/26","A61C-009/00","A61C-009/00 | A61C-007/00 | G06T-019/00 | G06T-017/00 | A61B-005/00 | A61B-006/00 | A61B-090/00 | G16H-050/50 | A61B-034/10 | A61C-001/08 | A61B-034/00 | A61C-019/04 | A61B-034/20 | G16H-050/20 | G16H-020/40 | G16H-040/60 | A61C-005/44 | G06F-003/01 | G16H-030/20 | G16H-030/40 | G06K-009/62 | G06K-009/00 | A61C-001/00 | A61C-019/05 | G09B-023/28 | A61B-017/00 | G02B-027/01 | A61B-090/50 | G02B-027/00 | A61B-001/24 | A61B-005/103 | A61B-006/14 | A61B-001/00 | G06N-003/08 | A61B-090/30 | G06N-020/10","","","","","","4920027001223"
"US","US","P","B2","Determining implantation configuration for a prosthetic component or application of a resurfacing tool","Systems and methods for modifying a shoulder joint configuration exhibiting wear that take into account resultant of forces responsible for the wear of the glenoid surface from geometric characteristics of wear.","1. A method for determining a configuration in which a resurfacing tool is applied to a scapula of a patient, the method comprising: defining a spatial coordinate system of the scapula;providing mapping data relating to a glenoid surface of the scapula, the mapping data being defined in the spatial coordinate system;determining geometric characteristics of wear of the glenoid surface from the mapping data;determining the vector characteristics of a force resultant of forces responsible for wear of the glenoid surface from the geometric characteristics of wear; anddetermining an application of the resurfacing tool on the glenoid surface of the scapula from the vector characteristics of the force resultant by taking into account action of the force resultant on the articular cooperation between the scapula as resurfaced by the application of the resurfacing tool and the humerus of the patient.","10","16/226523","2018-12-19","2019-0117404","2019-04-25","10695185","2020-06-30","TORNIER","Yves-Alain  Ratron","2010-050541","FR","2010-01-27","A61F-0002/30942","A61F-0002/30942 | A61B-0005/103 | A61B-0005/4519 | A61B-0005/4528 | A61B-0090/36 | A61F-0002/4081 | A61F-0002/4657 | G06F-0017/16 | A61B-0005/0059 | A61B-0005/6878 | A61B-0034/10 | A61B-2034/105 | A61B-2034/2055 | A61F-0002/40 | A61F-2002/30884 | A61F-2002/30902 | A61F-2002/30943 | A61F-2002/4007 | A61F-2002/4632 | A61F-2002/4633 | A61F-2002/4666 | A61F-2002/488 | Y10T-0029/49718","A61F-002/30","A61F-002/30 | A61F-002/40 | A61B-005/103 | A61B-005/00 | A61B-090/00 | A61F-002/46 | G06F-017/16 | A61F-002/48 | A61B-034/10 | A61B-034/20","","","","","","4920027001258"
"US","US","P","B2","Sensory input through non-invasive brain stimulation","Systems, methods and techniques for providing sensory input to a subject through non-invasive brain stimulation are generally described. In some examples, an input signal related to an environment may be received. In various further examples, a communication to the subject may be determined in response to the input signal. In some examples, an output signal corresponding to the determined communication may be generated. Some further examples may comprise non-invasively stimulating a portion of the subject's brain with the output signal with a stimulation subsystem positioned outside of the subject's scalp. In various examples, the stimulation of the portion of the subject's brain may be effective in producing a sensory response perceivable by the subject.","1. A method for interacting with a virtual environment, the method comprising: receiving an input signal from the virtual environment;determining, in response to the input signal, a communication about the virtual environment;generating an output signal corresponding to the determined communication; andnon-invasively and transcranially stimulating a portion of a brain of a subject with the output signal with a stimulation subsystem positioned outside of a scalp of the subject to produce a sensory response perceivable by the subject, wherein the non-invasively and transcranially stimulating comprises transcranial ultrasound stimulation of the portion of the brain of the subject.","19","15/299875","2016-10-21","2017-0113056","2017-04-27","10695574","2020-06-30","UNIVERSITY OF WASHINGTON","Andrea  Stocco | Darby  Losey | Justin A.  Abernethy | Rajesh  Rao","","","","A61N-0002/006","A61N-0002/006 | A61B-0005/4005 | A61N-0001/0476 | A61N-0001/36025 | A61N-0002/02 | G06F-0003/015","A61N-002/00","A61N-002/00 | A61N-002/02 | A61N-001/36 | A61N-001/04 | A61B-005/00 | G06F-003/01","","","","","","4920027001642"
"US","US","P","B2","Configurable device switching mechanism that enables seamless interactions with multiple devices","Various embodiments are described herein for an assistive device and associated method for interacting with at least one electronic device. In one example embodiment, the assistive device can include at least one communication interface, a memory, and at least one processing unit. The memory can store a whitelist of the at least one electronic device; and a gesture-to-command map of input signals in linked association with commands, including a selection command and a control command. The processing unit can be configured for sustaining an electronic communication connection to a target electronic device; receiving an input signal generated from user manipulation of a physical interface; searching the gesture-to-command map based on the input signal to determine a command; and using the at least one communication interface to transmit the command to the at least one electronic device thereby allowing the user to use the same assistive device for selecting and/or controlling at least one electronic device.","1. An assistive device for interacting with at least one electronic device, the assistive device comprising: at least one communication interface;a memory to store: a whitelist having a list including the at least one electronic device; anda gesture-to-command map comprising a plurality of input signals, each input signal in linked association with one of a plurality of commands, the plurality of commands comprising at least one selection command and at least one control command; andat least one processing unit configured for: using the at least one communication interface to sustain an electronic communication connection to a target electronic device that is in the whitelist;receiving at least one input signal generated from user manipulation of at least one physical interface;searching the gesture-to-command map based on the at least one input signal to determine a target command; andusing the at least one communication interface to transmit the target command to the at least one electronic device.","26","16/204090","2018-11-29","2019-0163283","2019-05-30","10698498","2020-06-30","KOMODO OPENLAB INC.","Jorge  Silva Arce | Mauricio  Meza | Tom  Nantais | Lawrence  Kwok","","","","G06F-0003/017","G06F-0003/017 | G06F-0003/038 | G06F-0021/305 | G06K-0009/00389 | H01H-0013/00 | H04L-0063/101 | A61B-0005/74","G06F-003/01","G06F-003/01 | G06K-009/00 | G06F-021/30 | H04L-029/06 | H01H-013/00 | G06F-003/038 | A61B-005/00","","","","","","4920027004537"
"US","US","P","B2","Sensor assembly and terminal","A sensor assembly and a terminal having the sensor assembly are provided. The sensor assembly includes a fingerprint module and a proximity sensor. The fingerprint module includes a fingerprint panel and a fingerprint sensor located below the fingerprint panel. The proximity sensor is located below the fingerprint panel and includes a light emitter and a light receiver. Light emitted by the light emitter exits through the fingerprint panel, and is then reflected by an external object to form reflected light which is in turn received by the light receiver through the fingerprint panel.","1. A sensor assembly, comprising: a fingerprint module, comprising a fingerprint panel and a fingerprint sensor located below the fingerprint panel;a proximity sensor, located below the fingerprint panel and comprising a light emitter and a light receiver, wherein the light emitter is operable to emit light that exits through the fingerprint panel and is reflected by an external object to form reflected light, and the light receiver is operable to receive the reflected light;a first attached layer disposed on a surface of the fingerprint panel close to the light emitter and the light receiver;a second attached layer disposed on the first attached layer, and defining a first through hole and a second through hole;the light emitter being offset with respect to and partially facing the first through hole, and the light receiver being offset with respect to and partially facing the second through hole;a first light-guiding structure disposed between the second attached layer and the light emitter, wherein the first light-guiding structure comprises two parallel first light-guiding portions, wherein each of the first light-guiding portions is obliquely oriented relative to a top edge of the light emitter and extends from the top edge of the light emitter to an edge of the first through hole; anda second light-guiding structure disposed between the second attached layer and the light receiver, wherein the second light-guiding structure comprises two parallel second light-guiding portions, wherein each of the second light-guiding portions is obliquely oriented relative to a top edge of the light receiver and extends from the top edge of the light receiver to an edge of the second through hole whereby the first light guiding portions are parallel to the second light guiding portions.","18","15/865496","2018-01-09","2018-0260060","2018-09-13","10698514","2020-06-30","GUANGDONG OPPO MOBILE TELECOMMUNICATIONS CORP., LTD.","Haiping  Zhang","2017-10132063","CN","2017-03-07","G06F-0003/0412","G06F-0003/0412 | G01S-0017/08 | G01S-0017/88 | G06F-0001/1626 | G06F-0001/1637 | G06F-0003/0421 | G06F-0021/32 | G06K-0009/0002 | H04M-0001/026 | H04M-0001/72569 | G06F-0003/044 | G06F-0003/0416 | H04M-0001/72533 | H04M-2250/12","G06F-001/16","G06F-001/16 | G01S-007/493 | G01L-001/14 | G06T-001/00 | A61B-005/11 | G06K-009/00 | G06F-001/00 | H04M-001/72 | G06F-003/041 | H04M-001/02 | G01S-017/08 | G01S-017/88 | H04M-001/725 | G06F-003/042 | G06F-021/32 | G06F-003/044","","","","","","4920027004553"
"US","US","P","B2","System and method for providing patient record synchronization in a healthcare setting","A system provides an information sharing architecture that allows physically separate healthcare information systems, called ""deployments,"" to share and exchange information. The collection of these participating deployments is referred to as the ""Community,"" and systems within the Community sometimes store records for patients in common. The system allows participants in the Community to share information on data changes to these patients, and to reconcile concurrent and conflicting updates to the patient's record.","1. A system for synchronizing data in different instances of a first record, the system comprising: a first deployment of record management software, the first deployment implementing a first version of the record management software, wherein the first deployment is implemented by one or more computing devices, including a first computing device, that are configured to:store a first instance of a first record corresponding to a first patient, wherein the first instance comprises a plurality of data elements;receive, from a second computing device implementing a second deployment of the record management software, a request for the first record;determine that the second deployment implements a second version of the record management software, wherein the second version is older than the first version;determine that one or more of the plurality of data elements is incompatible with the second version;generate a downgraded first record by downgrading at least a portion of the first record to be compatible with the second version based at least in part on the one or more of the plurality of data elements that are incompatible with the second version;send, to the second deployment, the downgraded first record;store an indication that the second deployment hosts a second instance of the first record;receive, from the second deployment, updates to a first portion of the first record;generate an upgraded first portion of the first record using the first portion received from the second deployment to be compatible with the first version;update the first instance of the first record based on the upgraded first portion;receive, at the first computing device, changes to a second portion of the first record based on user input received at the first deployment; generate a downgraded second portion of the first record; andcause the downgraded second portion to be sent to the second deployment; andthe second deployment of record management software, the second deployment implementing the second version of the record management software, wherein the second deployment is implemented by one or more computing devices, including the second computing device, that are configured to: receive input requesting a record corresponding to the first patient;determine that the record corresponding to the first patient is not stored by the second deployment;determine that the first deployment is a home deployment for the first record corresponding to the first patient;send, from the second computing device, a request to the first deployment for the first record;receive a downgraded first record;store a second instance of the first record based on the downgraded first record;receive user input updating a first portion of the first record;send updates to the first portion of the first record to the first deployment;receive the downgraded second portion of the first record; andupdate the second instance of the first record based on the downgraded second portion of the first record.","17","15/862837","2018-01-05","2018-0129722","2018-05-10","10698922","2020-06-30","EPIC SYSTEMS CORPORATION","Daniel S.  Bormann | Aaron T.  Cornelius | Timothy W.  Escher | Sameer  Grover | Andrew M.  Giesler | Jason L.  Hansen | Clifford L.  Michalski | Vassil D.  Peytchev","","","","G06F-0016/273","G06F-0016/273 | G06F-0019/00 | G06Q-0050/22 | G16H-0010/60 | G16H-0040/00 | A61B-0005/0022","G16H-010/60","G16H-010/60 | G06F-016/27 | G06Q-050/22 | G06F-019/00 | G16H-040/00 | A61B-005/00","","","","","","4920027004960"
"US","US","P","B2","System and method for providing reconstruction of human surfaces from orientation data","A system constructs a positional contour of a variably contoured surface using data from a 3D capture device. A processor captures data from a tangential orientation capture device and produces a set of relative orientations. The set of relative orientations is transformed with a set of orientation manifold transformer parameters to produce a set of low dimensional orientations. The set of low dimensional orientations and a trained mapping function definition are used to produce a low dimensional point cloud. The low dimensional point cloud is transformed with a set of point cloud manifold transformer parameters, producing a reconstructed synchronized rotationally invariant point cloud.","1. A system (400) using data at least partially collected and derived from a 3D capture device (410) for constructing a positional contour of a variably contoured surface, comprising: a tangential orientation capture device (450); andan orientation processor (460) and a memory (470) configured to store non-transient instructions which, when executed by the processor, perform the steps of: capturing an absolute orientation description of the surface (1220) collected by the tangential orientation capture device and producing a set of relative orientations (1280);transforming the set of relative orientations and a set of orientation manifold transformer parameters (1021) to produce a set of low dimensional orientations (1230);mapping the set of low dimensional orientations and a trained mapping function definition to produce a low dimensional point cloud (1240); andinverse transforming the low dimensional point cloud with a set of point cloud manifold transformer parameters (1011) and producing a reconstructed synchronized rotationally invariant point cloud (1250).","7","15/743711","2016-07-15","2018-0204379","2018-07-19","10699480","2020-06-30","MASSACHUSETTS INSTITUTE OF TECHNOLOGY","Carlos Sanchez  Mendoza | Luca  Giancardo | Tobias  Hahn | Aurelien  Bourquard","","","","G06T-0017/30","G06T-0017/30 | A61F-0005/02 | G01B-0021/20 | G06F-0003/011 | G06K-0009/00214 | G06T-0009/007 | G06T-0009/20 | G06T-0015/04 | G06T-0017/00 | A61F-0002/5046 | G01S-0005/163 | G06T-2200/08 | G06T-2207/30004","G06T-017/30","G06T-017/30 | G06T-017/00 | A61F-005/02 | G01B-021/20 | G06F-003/01 | G06K-009/00 | G06T-009/00 | G06T-009/20 | G06T-015/04 | A61F-002/50 | G01S-005/16","","","","","","4920027005513"
"US","US","P","B1","Monitoring system, wearable monitoring device and method","A monitoring system for alerting a user to the negative effects of sedentary behaviour, comprising: a memory storing product codes for consumable, topically applied, and/or body-worn products, and data indicating respective product recommendations or from which respective product recommendations can be derived and one or more processors. The one or more processors are configured to: monitor the behaviour of the user by using motion data obtained from one or more inertial sensors worn by the user to identify periods when the user is in a sitting position or other sedentary state; and based on the behaviour of the user, select from at least a subset of the product codes, product codes for which the respective product recommendation is to be modulated. The monitoring system also comprises a visual indicator controllable by the one or more processors to provide a visual indication dependent on the number of selected products codes.","1. A monitoring system for alerting a user to the negative effects of sedentary behaviour, comprising: a memory storing product codes for consumable, topically applied, and/or body-worn products, and data indicating respective product recommendations or from which respective product recommendations can be derived;one or more processors configured to:monitor the behaviour of the user by using motion data obtained from one or more inertial sensors worn by the user to identify periods when the user is in a sitting position or other sedentary state; andbased on the behaviour of the user, select from at least a subset of the product codes, product codes for which the respective product recommendation is to be modulated; anda visual indicator controllable by the one or more processors to provide a visual indication dependent on the number of selected products codes.","21","16/567056","2019-09-11","","","10699806","2020-06-30","DNANUDGE LIMITED","Christofer  Toumazou | Maria  Karvela","","","","G16H-0020/30","G16H-0020/30 | A61B-0005/1116 | G01C-0022/006 | G06K-0009/00335 | G16H-0020/60 | G16H-0050/30","G06Q-030/00","G06Q-030/00 | G16H-020/30 | G16H-020/60 | G06K-009/00 | G01C-022/00 | A61B-005/11 | G16H-050/30","","","","","","4920027005837"
"US","US","P","B2","Personalized multi-sensory cues and personalized sensing in a targeted environment","Methods, systems and apparatuses are disclosed for delivering, in an enclosed environment, subject-directed multi-sensory stimuli output or sequence(s) to a specific subject based upon recognition and identification of a specific subject.","1. A system comprising: a detector for recognizing a subject, the subject having at least one subject-specific identifying characteristic;a controller in communication with the detector;a plurality of differing subject-directed sensory stimulus outputs in communication with the controller, said subject-directed sensory stimulus outputs configured to emit at least two subject-directed sensory stimulus types to the subject, said subject-directed sensory stimulus types selected from the group consisting of: a subject-directed visual sensory stimulus, a subject-directed olfactory sensory stimulus, and a subject-directed auditory sensory stimulus;wherein the at least two subject-directed sensory stimulus types are directed to a predetermined location in response to the subject-specific identifying characteristic; andwherein at least two of the subject-directed sensory stimulus types are directed to a predetermined location in response to the subject inhabiting the predetermined location, said subject having the subject-specific identifying characteristic;wherein the subject-directed sensory stimulus types are predetermined sensory stimuli requested by a subject;wherein the subject-directed sensory stimulus types are delivered by the system in response to a pre-collected personalized and subject-specific set of subject-specific visual, olfactory and auditory preferences; andwherein the predetermined location is a location within a vehicle cabin.","20","16/107039","2018-08-21","2020-0064905","2020-02-27","10691200","2020-06-23","THE BOEING COMPANY","Darren Carl  McIntosh","","","","G06F-0003/011","G06F-0003/011 | A61B-0005/1172 | A61B-0005/1176 | A61M-0021/00 | B60R-0016/037 | G06F-0003/017 | G06F-0003/167 | G06K-0009/00281 | G06K-0009/00288 | G06K-0009/00617 | A61M-2021/005 | A61M-2021/0016 | A61M-2021/0027 | G06F-2203/011","G06F-003/01","G06F-003/01 | A61B-005/1172 | A61B-005/1171 | G06K-009/00 | G06F-003/16 | A61M-021/00 | B60R-016/037","","","","","","4920026004455"
"US","US","P","B2","Compatibility check for continuous glucose monitoring application","Disclosed are systems, methods, and articles for determining compatibility of a mobile application and operating system on a mobile device. In some aspects, a method includes receiving one or more data values from a mobile device having a mobile medical software application installed thereon, the data value(s) characterizing a version of the software application, a version of an operating system installed on the mobile device, and one or more attributes of the mobile device; determining whether the mobile medical software application is compatible with the operating system by at least comparing the received data value(s) to one or more test values in a configuration file; and sending a message to the mobile device based on the determining, the message causing the software application to operate in one or more of a normal mode, a safe mode, and a non-operational mode.","1. A method comprising: receiving, by at least one processor, one or more data values from a user equipment having a glucose monitoring application installed on the user equipment, the one or more data values representing results from one or more self-tests performed on the user equipment, the one or more self-tests validating proper operation of one or more features of one or more of the glucose monitoring application and the user equipment;determining, by the at least one processor, whether the glucose monitoring application is compatible with an operating environment based at least on a comparison of the one or more data values with respective values from a predetermined list of results of self-tests; andsending, by the at least one processor, a message to the user equipment based on the determining, the message causing the glucose monitoring application to operate in one or more of a normal mode, a safe mode, and a non-operational mode,wherein the message causes the user equipment to display a user interface view on the user equipment while the glucose monitoring application is in the safe mode, the user interface view indicating that one or more ancillary functions are disabled; andwherein the message causes the user equipment to display a user interface view on the user equipment while the glucose monitoring application is in the non-operational mode, the user interface view indicating that one or more core functions are disabled, wherein the one or more core functions include one or more modules that are essential to the operation of the glucose monitoring application and wherein the one or more ancillary functions include one or more modules that are not essential to the operation of the glucose monitoring application, wherein the core functions includes one or more of generating an alert if a glucose level of a user is outside of a target range, displaying a glucose level, or prompting calibration of a glucose sensor assembly.","20","15/334160","2016-10-25","2017-0132120","2017-05-11","10691574","2020-06-23","DEXCOM, INC.","Issa Sami  Salameh | Douglas William  Burnette | Tifo Vu  Hoang | Steven David  King | Stephen M.  Madigan | Michael Robert  Mensinger | Andrew Attila  Pal | Michael Ranen  Tyler","","","","G06F-0011/3604","G06F-0011/3604 | A61B-0005/6801 | G06F-0008/65 | G06F-0008/70 | G06F-0008/71 | G06F-0009/44505 | G06F-0011/00 | G06F-0011/143 | G06F-0011/1433 | G06F-0011/36 | G06F-0011/3616 | G06F-0011/3688 | G16H-0040/40 | H04L-0067/34 | H04M-0001/72519 | H04W-0004/12 | H04W-0004/20 | H04W-0004/70 | A61B-0005/14532 | A61B-0005/743 | H04M-0001/72522 | H04W-0088/02","G06F-011/36","G06F-011/36 | H04W-004/70 | G06F-008/71 | G06F-008/70 | G06F-011/14 | G06F-011/00 | G06F-009/445 | G16H-040/40 | H04L-029/08 | H04W-004/20 | G06F-008/65 | H04M-001/725 | H04W-004/12 | A61B-005/00 | H04W-088/02 | A61B-005/145","","","","","","4920026004823"
"US","US","P","B2","Ultrasonic biometric sensing device integrated with optics","Aspects of this disclosure relate to a biometric sensing device that includes a sensing device and an integrated optical system for authentication. For instance, the sensing device can be an ultrasonic sensing device that can generate an image of a fingerprint and the optical system can transmit light to a finger through the ultrasonic scanning device. In some instances, the acoustic biometric sensing device can generate a liveness parameter associated with a finger based on a reflection of the light.","1. A biometric sensing device with ultrasonic fingerprint sensing, the biometric sensing device comprising: a surface configured to receive a finger;an ultrasonic fingerprint sensor comprising ultrasonic transducers configured to generate an ultrasound signal and transmit the ultrasound signal to the surface, the ultrasonic fingerprint sensor being configured to generate data indicative of an image of at least a portion of the finger on the surface; andan optical system integrated with the ultrasonic fingerprint sensor, the optical system configured to emit light through the ultrasonic fingerprint sensor to the surface.","30","16/057638","2018-08-07","2019-0087621","2019-03-21","10691912","2020-06-23","THE BOARD OF TRUSTEES OF THE LELAND STANFORD JUNIOR UNIVERSITY | ORCHID SOUND TECHNOLOGIES LLC","Butrus T.  Khuri-Yakub | Morten Fischer  Rasmussen | Gerard  Touma | John N.  Irwin, III","","","","G06K-0009/0002","G06K-0009/0002 | A61B-0005/0261 | A61B-0005/02416 | A61B-0005/02438 | A61B-0005/0816 | A61B-0005/1172 | A61B-0005/14552 | G06F-0003/0436 | G06K-0009/0012 | G06K-0009/00107 | G06K-0009/00906 | H04M-0001/03 | A61B-0005/14551 | A61B-0005/489 | G06F-2203/04103 | G06K-0009/228 | G06K-2009/00939","G06K-009/00","G06K-009/00 | A61B-005/026 | A61B-005/024 | A61B-005/08 | A61B-005/1172 | G06F-003/043 | H04M-001/03 | A61B-005/1455 | A61B-005/00 | G06K-009/22","","","","","","4920026005158"
"US","US","P","B2","System, method and apparatus for performing real-time virtual medical examinations","Disclosed herein is a method for permitting a real-time virtual medical examination using a patient device and at least one diagnostic device including receiving, at the patient device, a signal transmitted from the at least one diagnostic device; generating diagnostic information based on the received signal; encrypting the diagnostic information; establishing communication over a network between the patient device and a first remote server; establishing a video conferencing session via a second remote server; and transmitting the encrypted diagnostic information to the first remote server.","1. A method for permitting a real-time virtual medical examination using a handheld patient device and at least one diagnostic device, comprising: receiving, at the handheld patient device, a signal transmitted from the at least one diagnostic device;generating, by the handheld patient device, diagnostic information based on the received signal;encrypting, by the handheld patient device, the diagnostic information;establishing communication over a network between the handheld patient device and a remote server;establishing communication over the network between the handheld patient device and a video conferencing server comprised in a plurality of geographically distributed video conferencing servers;establishing a video conferencing session via the video conferencing server in communication with the handheld patient device;encrypting and transmitting, by the handheld patient device, first voice and video signals generated during the video conferencing session to the video conferencing server, the first voice and video signals being encrypted using a hypertext transfer protocol secure method;receiving and decrypting, by the handheld patient device, encrypted second voice and video signals generated during the video conferencing session from the video conferencing server, the second voice and video signals being encrypted using a hypertext transfer protocol secure method; andtransmitting, by the handheld patient device, the encrypted diagnostic information to the remote server.","15","15/655998","2017-07-21","2017-0324930","2017-11-09","10694144","2020-06-23","Fawzi Shaya","Fawzi  Shaya","","","","H04N-0007/141","H04N-0007/141 | A61B-0005/0022 | A61B-0005/7465 | G06F-0019/3418 | G06Q-0010/10 | G06Q-0030/0241 | G06Q-0050/22 | G16H-0010/60 | A61B-0005/021 | A61B-0005/0402 | A61B-0005/087 | A61B-0005/14532 | A61B-0005/14542 | G16H-0015/00","A61B-005/00","A61B-005/00 | G06F-019/00 | G06Q-050/22 | A61B-005/021 | A61B-005/0402 | A61B-005/087 | A61B-005/145 | H04N-007/14 | G06Q-010/10 | G06Q-030/02 | G16H-010/60 | G16H-015/00","","","","","","4920026007369"
"US","US","P","B2","Delivery of a digital therapeutic method and system","Disclosed herein is a system and method for delivering a digital therapeutic, specific to a user emotional or mental state (EMS). This entails recognizing at least one EMS selected by the user from a plurality of EMS, said selected EMS indicating at least one of a feeling, sensation, type of discomfort, mood, mental state, emotional condition, or physical status of the user. Pushing at least a primary-level message personalized to the user based on at least one stored message coupled to the selected EMS; wherein the at least primary-level messages contain at least one of a text, image, sound, video, art asset, suggested action or recommended behavior. The actions suggested or behaviors recommended are supported by at least one independent source of peer-reviewed research, as verified by a credentialed EMS expert.","1. A method for delivering a digital therapeutic, specific to a users emotional or mental state (EMS), said method comprising the steps of: selecting by the user at least one of an EMS for the user from a plurality of EMS, said EM indicating an assessment of at least one of a feeling, sensation, mood, mental state, emotional condition, or physical status of the user and categorized as at least one of Dopamine, Serotonin, Epinephrine, Norepinephrine, Endorphin, Acetylcholine, Oxytocin, or GABA neurotransmitters; andpushing a message personalized to the user based on at least one stored message coupled to the selected EMS, wherein said message comprises a visual asset suggesting an EMS-defined action or behavior to affect at least one of the neurotransmitter corresponding to the defined EMS.","27","15/959075","2018-04-20","2019-0117142","2019-04-25","10682086","2020-06-16","AEBEZE LABS","Michael Phillips  Moskowitz","","","","A61B-0005/165","A61B-0005/165 | A61B-0005/0004 | A61B-0005/0022 | A61B-0005/0484 | A61B-0005/4836 | G06F-0040/103 | G06F-0040/211 | G06F-0040/284 | G06F-0040/30 | G06F-0040/35 | G06N-0020/00 | G16H-0050/00 | H04L-0051/26 | H04L-0051/32 | G06N-0003/08 | H04L-0051/10","G06F-017/27","G06F-017/27 | A61B-005/16 | H04L-012/58 | A61B-005/00 | G06N-020/00 | G16H-050/00 | A61B-005/0484 | G06F-040/30 | G06F-040/35 | G06F-040/103 | G06F-040/211 | G06F-040/284 | G06N-003/08","","","","","","4920025000835"
"US","US","P","B2","Training of an electroencephalography based control system","A system including an electroencephalography (EEG) device configured to be positioned on a head of a user and process detected EEG signals. The system also includes a processor in communication with the EEG device, a memory accessible by the processor and instructions stored in the memory for execution by the processor to generate, based on a control instruction, a control data signal, for control of an operation of a controllable device configured to provide a premises related service in an area of a premises. In the training phase, execution of the instructions configures the processor to determine whether or not that the control operation of the control data signal is consistent with the detected EEG signals based on a trusted input from the user, and upon determination that the control operation is consistent with the detected EEG signals, store, in the memory, recognition data characterizing the detected EEG signals as a predetermined set of signals in association with the control instruction.","1. A system comprising: an electroencephalography (EEG) device configured to be positioned on a head of a user, wherein the EEG device includes one or more electrodes configured to detect EEG signals from a brain of the user;circuitry coupled to the one or more electrodes configured to process the EEG signals detected via the one or more electrodes of the EEG device;a processor coupled to or in communication with the circuitry; a memory accessible by the processor;program instructions stored in the memory for execution by the processor; data stored in the memory comprising a control instruction,wherein execution of the program instructions configures the processor to: generate, based on the control instruction, a control data signal, for control of an operation of a controllable device configured to provide a premises related service in an area of a premises; andwherein, in a training phase, execution of the program instructions further configures the processor to: determine whether or not that the control operation of the control data signal is consistent with the detected EEG signals based on a trusted input from the user, andupon determination that the control operation is consistent with the detected EEG signals, store, in the memory, recognition data characterizing the detected EEG signals as a predetermined set of signals in association with the control instruction.","19","15/948448","2018-04-09","2019-0290211","2019-09-26","10682099","2020-06-16","ABL IP HOLDING LLC","David P.  Ramer | Jack C.  Rains, Jr. | Youssef F.  Baker | Niels G.  Eegholm | Daniel M.  Megginson | Jenish S.  Kastee","","","","A61B-0005/7267","A61B-0005/7267 | A61B-0005/04004 | A61B-0005/0476 | A61B-0005/7221 | G05B-0013/0265 | G06F-0003/015 | G06K-0009/00536 | H05B-0047/105","A61B-005/00","A61B-005/00 | A61B-005/04 | A61B-005/0476 | G06F-003/01 | G06K-009/00 | G05B-013/02 | H05B-047/105","","","","","","4920025000848"
"US","US","P","B2","Methods and systems for managing, controlling and monitoring medical devices via one or more software applications functioning in a secure environment","Systems and methods that include configurations of a medical device, user device and service platform are described. Embodiments may include a secure network to run medical applications that control and/or monitor the medical device. An online store may be provided for storing and distributing medical applications to the user device and medical device. A secure environment may be provided within the user device and medical device that protects the integrity of medical applications running on those devices. A service platform may provide a service that enables a medical authority to certify and monitor the medical applications. In some implementations, various third parties and the user of the user device may be allowed to manage and monitor the medical device.","1. A computer-implemented method of interacting with a medical device in wireless communication with a user device, comprising: receiving, at the user device, a medical application wherein at least a portion of the user device is separated from at least part of the medical device and wherein the user device includes: a secure environment utilizing a secure environment processor configured to continue to process at least part of the medical application in the event of at least one of a denial of service attack, an attempt to overload processing or memory usage in the secure environment, and a reboot or shutdown of a nonsecure environment of the user device;a nonsecure environment processor wherein the secure environment processor is isolated from the nonsecure environment processor,a secure environment memory coupled to the secure environment processor and accessible only to the secure environment processor, the secure environment memory being included within the secure environment and including a security monitor executed by the secure environment processor wherein the security monitor is configured to: identify secure traffic on the user device wherein the secure traffic is associated with a function of the medical application requiring security,identify a security requirement associated with the function,manage execution of the medical application within the secure environment in accordance with the security requirement,identify other traffic on the user device wherein the other traffic is associated with a nonsecure function,determine that the nonsecure function does not require security,allow the nonsecure function to run in the nonsecure environment,a nonsecure environment memory coupled to the nonsecure environment processor;a radio for communicating with the medical device, wherein the radio is controlled by the secure environment processor when communicating with the medical device;storing code for at least a portion of the medical application in the secure environment memory wherein the secure environment memory segment is isolated from the nonsecure environment memory and wherein the nonsecure environment memory is configured to store code for other applications, wherein: the medical application operates independently of the other applications and wherein the medical application remains operational when the other applications are turned off or become non-operational or corrupted, andthe medical application does not interact with the nonsecure environment memory without approval; andinitiating establishment of a communication link from the user device to the medical device via the radio, wherein the communication link is configured to facilitate execution of the certified medical application.","27","15/490782","2017-04-18","2017-0319861","2017-11-09","10682518","2020-06-16","CHRONICMOBILE, INC.","Michael  Golden","","","","A61N-0001/37282","A61N-0001/37282 | A61B-0005/7465 | A61N-0001/37235 | G06F-0019/3418 | G06Q-0010/06 | G06Q-0050/22 | G16H-0040/40 | A61B-0005/0002","G16H-040/40","G16H-040/40 | A61N-001/372 | A61B-005/00 | G06F-019/00 | G06Q-010/06 | G06Q-050/22","","","","","","4920025001266"
"US","US","P","B2","Method for recognizing a gesture and an electronic device thereof","To recognize a gesture and control a function in an electronic device, an operating method of an electronic device includes the operations of detecting a change of a Radio Frequency (RF) signal emitted into a body using an RF sensor, determining a gesture corresponding to the RF signal based on reference data corresponding to the gesture, and executing a function of the electronic device corresponding to the determined gesture.","1. A method performed by an electronic device, the method comprising: measuring a vibration level of a body using at least one sensor;determining whether the measured vibration level exceeds a preset threshold;generating a radio frequency (RF) signal within a low frequency band in case that the vibration level exceeds the preset threshold;emitting the RF signal into the body;receiving a reflected RF signal that is changed based on a reflection of the emitted RF signal from the body;identifying a gesture of the body based on the reflected RF signal and reference data for at least one gesture; andexecuting a function of the electronic device corresponding to the identified gesture.","20","15/892800","2018-02-09","2018-0253151","2018-09-06","10684693","2020-06-16","SAMSUNG ELECTRONICS CO., LTD.","Andrey Vladimirovich  Kletsov | Alexander Gennadyevich  Chernokalov | Stanislav Vladimirovich  Polonsky","20170106851 | 10-2018-0009832","RU | KR","2017-03-02 | 2018-01-26","G06F-0003/017","G06F-0003/017 | A61B-0005/004 | A61B-0005/0507 | A61B-0005/1171 | G01S-0007/2925 | G01S-0007/412 | G01S-0007/417 | G01S-0013/0209 | G01S-0013/06 | G01S-0013/88 | G06F-0003/014 | G06F-0003/015 | G06K-0009/00335 | G06K-0009/6262","G06F-003/01","G06F-003/01 | G06K-009/00 | G01S-007/292 | G01S-013/06 | G01S-007/41 | G06K-009/62 | A61B-005/05 | G01S-013/02 | G01S-013/88 | A61B-005/1171 | A61B-005/00","","","","","","4920025003422"
"US","US","P","B2","Imaging system and method for use in surgical and interventional medical procedures","A system and method for displaying images of internal anatomy includes an image processing device configured to provide high resolution images of the surgical field from low resolution scans during the procedure. The image processing device digitally manipulates a previously-obtained high resolution baseline image to produce many representative images based on permutations of movement of the baseline image. During the procedure a representative image is selected having an acceptable degree of correlation to the new low resolution image. The selected representative image and the new image are merged to provide a higher resolution image of the surgical field. The image processing device is also configured to provide interactive movement of the displayed image based on movement of the imaging device, and to permit placement of annotations on the displayed image to facilitate communication between the radiology technician and the surgeon.","1. An image processing device for generating a display of an image of a patient'ss internal anatomy in a surgical field during a medical procedure, comprising: a memory for storing an image of the surgical field with an imaging device in a first orientation; anda processor configured to: provide instructions to display the image of the surgical field via a display;receive information indicative of movement of the imaging device or the patient from the first orientation; andprovide instructions to move the displayed image in relation to the received information indicative of movement prior to acquiring a new image of the surgical field with the imaging device;provide instructions to introduce a representation of a tracked object on the stored image;after moving the displayed image in relation to the tracked movement, acquire position data corresponding to a tracked position of the object and comparing the position data with a position of the object on the moved image; andrecalibrate the moved image based on the comparison of the position data with the position of the object on the moved image.","17","16/558155","2019-09-01","2020-0004342","2020-01-02","10684697","2020-06-16","NUVASIVE, INC.","Robert E.  Isaacs | Samuel Morris  Johnston | David Alexander  Skwerer | Randall Graham  Campbell","","","","G06F-0003/017","G06F-0003/017 | A61B-0006/06 | A61B-0006/12 | A61B-0006/4405 | A61B-0006/4441 | A61B-0006/486 | A61B-0006/5241 | A61B-0006/547 | G06T-0003/20 | G06T-0003/4053 | G06T-0007/0016 | G06T-0007/33 | G06T-0011/60 | G06T-0015/08 | H04N-0007/18 | G06T-2207/10124 | G06T-2207/20212 | G06T-2207/20221 | G06T-2207/30004 | G06T-2210/41","A61B-005/05","A61B-005/05 | G06K-009/00 | G06F-003/01 | G06T-003/20 | G06T-011/60 | H04N-007/18 | G06T-015/08 | A61B-006/06 | A61B-006/12 | A61B-006/00 | G06T-007/33 | G06T-003/40 | G06T-007/00","","","","","","4920025003426"
"US","US","P","B2","Sign language recognition system and method","Provided is a sign language recognition system, and the sign language recognition system includes an acquisition unit configured to acquire an electromyogram signal of a user from a sensor measurement device worn around an arm of the user, an extraction unit configured to extract a muscle active section from the electromyogram signal to detect a sign language gesture of the user, a producing unit configured to produce a first feature vector by performing signal processing to the muscle active section, a search unit configured to search a signal corresponding to the first feature vector in a database, and an output unit configured to output a text corresponding to the searched signal.","1. A sign language recognition system, comprising: a sensor measurement device capable of being worn around an arm of a user, wherein the sensor measurement device includes: an armband capable of being worn around the arm; multiple electrodes arranged at intervals along an inner circumference of the armband and associated with multiple electrode channels, respectively; and an inertial measurement unit provided in an area of the sensor measurement device;an acquisition unit configured to acquire an electromyogram signal through the multiple electrode channels according to a gesture of straightening a wrist of the user, identify an electrode channel having a maximum root mean square value among the multiple electrode channels on a basis of the electromyogram signal, and rearrange the multiple electrode channels in consideration of a position of the identified electrode channel, wherein the position of the identified electrode channel is a position corresponding to a position of a wrist extensor bundle;an extraction unit configured to extract a muscle active section from the electromyogram signal to detect a sign language gesture of the user;a producing unit configured to produce a first feature vector by performing signal processing to the muscle active section;a search unit configured to search a signal corresponding to the first feature vector in a database; andan output unit configured to output a text corresponding to the searched signal.","19","16/073441","2016-10-17","2019-0073525","2019-03-07","10685219","2020-06-16","UNIVERSITY INDUSTRY FOUNDATIOIN, YONSEI UNIVERSITY WONJU CAMPUS","Young Ho  Kim | Seong Jung  Kim | Han Soo  Lee | Jong Man  Kim | Min  Jo | Eun Kyoung  Choi | Soon Jae  Ahn | Young Jae  Jeong","10-2016-0010230 | 10-2016-0043914","KR | KR","2016-01-27 | 2016-04-11","G06K-0009/00355","G06K-0009/00355 | A61B-0005/0488 | G06F-0001/1694 | G06F-0003/015 | G06F-0003/017 | G09B-0021/009 | A61B-0005/04012 | A61B-0005/1116 | A61B-0005/7264 | A61B-2562/0219","G06K-009/00","G06K-009/00 | G06F-001/16 | A61B-005/0488 | G06F-003/01 | G09B-021/00 | A61B-005/11 | A61B-005/00 | A61B-005/04","","","","","","4920025003945"
"US","US","P","B2","AR system","Systems and methods are disclosed method for rendering reality for an object by performing motion tracking and area learning of an environment; selecting a pattern or color from a plurality of product variations; blending the pattern or color of the object and the environment; and displaying the color on the object as an augmented reality view.","1. A method for rendering reality for an object, comprising: using a mobile device with an accelerometer and a camera, performing motion tracking and area learning of an environment of the object with accelerometer and camera data in the mobile device;selecting a pattern or color from a plurality of products to be applied to the object to test for appearance variations using the mobile device;blending the pattern or color of the object and the environment; anddisplaying color on the object as an augmented reality view on the mobile device.","20","16/361141","2019-03-21","2019-0228570","2019-07-25","10685481","2020-06-16","Bao Tran","Bao  Tran","","","","G06T-0017/00","G06T-0017/00 | A61B-0005/0205 | A61B-0005/1036 | A61B-0005/1079 | A61B-0005/1112 | A61B-0005/1118 | A61B-0005/1128 | A61B-0005/165 | A61B-0005/6829 | A61B-0005/6898 | A61B-0005/742 | G01G-0019/44 | G06Q-0030/0643 | G06T-0003/0093 | G06T-0007/20 | G06T-0011/001 | G06T-0019/006 | G06T-0019/20 | A61B-2576/02 | A63B-2220/00 | G06T-2215/16 | G06T-2219/2012","G06T-007/20","G06T-007/20 | G06T-017/00 | G06T-019/00 | A61B-005/11 | A61B-005/00 | A61B-005/107 | G06T-011/00 | G06T-003/00 | G06T-019/20 | A61B-005/0205 | G01G-019/44 | A61B-005/16 | A61B-005/103 | G06Q-030/06","","","","","","4920025004203"
"US","US","P","B2","System and method for associating user and vehicle information for communication to a third party","A vehicle is provided that detects a first presence of a driver in a vehicle, based upon detecting the first presence, provides a user interface for the driver to enter first user information, information, and communicates the first sensitive information to a vendor to authenticate the combines the first user information and the vehicle information to generate the first sensitive driver to enable the vendor to perform a financial transaction with the driver using the first sensitive information while the vehicle is in motion. The processor is programmed to initiate automatically, on behalf of the driver, the financial transaction with the vendor in response to a sensed state or location of the vehicle.","1. A vehicle, comprising: a sensor that detects a first presence of a driver in a vehicle;a memory that stores first sensitive information of the driver of the vehicle; anda processor in communication with the sensor and the memory, the processor: receives the first presence;based upon receiving the first presence, provides a first user interface for the driver to enter first user information, the first user information comprising financial information of the driver and one or more of a biometric, a username, a password, mobile device information, payment information, a personal identification number, identifiers, an address, limits, preferences, and/or rules;receives vehicle information associated with the vehicle;combines the first user information and the vehicle information to generate a first sensitive information;sends the first sensitive information to the memory for storage, wherein the first sensitive information is encrypted in the memory; andcommunicates the first sensitive information to a vendor to authenticate the driver to enable the vendor to perform a financial transaction with the driver using the first sensitive information while the vehicle is in motion, wherein the processor is programmed to initiate automatically, on behalf of the driver, the financial transaction with the vendor in response to a sensed state or location of the vehicle, and wherein the processor authorizes the financial transaction with the vendor in response to a plurality of vehicle speed, proximity to a location of the vendor, and historical information associated with the driver or passenger.","21","15/396595","2016-12-31","2018-0009446","2018-01-11","10685503","2020-06-16","NIO USA, INC.","Christopher P.  Ricci","","","","G07C-0005/008","G07C-0005/008 | A61B-0005/1171 | A61B-0005/1172 | A61B-0005/1176 | B60L-0053/12 | B60L-0053/14 | B60L-0053/65 | B60L-0053/665 | B60L-0053/80 | B60R-0001/00 | B60R-0011/04 | B60R-0025/102 | B60R-0025/2081 | B60W-0040/08 | B60W-0050/08 | G01C-0021/36 | G01C-0021/3617 | G01C-0021/3697 | G05B-0015/02 | G05D-0001/0011 | G05D-0001/0088 | G06F-0003/011 | G06F-0016/248 | G06F-0016/951 | G06F-0021/31 | G06F-0021/32 | G06F-0021/6245 | G06K-0007/10257 | G06K-0007/10316 | G06K-0007/10425 | G06K-0009/00087 | G06K-0009/00832 | G06K-0009/00845 | G06K-0019/0708 | G06Q-0010/20 | G06Q-0020/105 | G06Q-0020/108 | G06Q-0020/14 | G06Q-0020/32 | G06Q-0020/3224 | G06Q-0020/401 | G06Q-0020/405 | G06Q-0020/4012 | G06Q-0030/012 | G06Q-0030/0206 | G06Q-0030/0208 | G06Q-0030/0601 | G06Q-0030/0613 | G06Q-0030/0625 | G06Q-0030/0635 | G07B-0015/063 | G07C-0005/02 | G07C-0005/0808 | G07C-0005/0816 | G07C-0005/0858 | G07C-0009/00563 | G08G-0001/017 | G08G-0001/0962 | G08G-0001/09626 | G08G-0001/096775 | G08G-0001/096827 | G08G-0001/096838 | G08G-0001/20 | H01Q-0001/325 | H01Q-0001/3266 | H01Q-0001/3275 | H01Q-0001/3283 | H01Q-0001/3291 | H01Q-0021/30 | H02J-0007/0068 | H04B-0005/0037 | H04L-0009/321 | H04L-0009/3226 | H04L-0063/0428 | H04W-0004/40 | H04W-0004/44 | H04W-0004/46 | H04W-0004/80 | H04W-0012/02 | H04W-0012/04 | H04W-0012/06 | A61B-2503/22 | B60K-0006/20 | B60K-0035/00 | B60K-2370/1537 | B60K-2370/334 | B60L-0005/24 | B60L-0007/10 | B60L-0008/003 | B60L-0008/006 | B60L-0009/00 | B60L-2240/549 | B60L-2240/70 | B60L-2240/72 | B60L-2270/32 | B60M-0001/00 | B60M-0007/00 | B60R-2011/0003 | B60R-2011/004 | B60R-2300/30 | B60R-2300/804 | B60R-2325/105 | B60W-2040/0809 | B60W-2050/143 | B60W-2050/146 | B60W-2300/34 | B60W-2540/00 | B60W-2540/02 | B60W-2540/04 | B60Y-2200/91 | B60Y-2200/912 | B60Y-2200/92 | B60Y-2300/60 | B60Y-2302/07 | B60Y-2400/92 | G01S-2013/936 | G06K-0009/00288 | G06K-0009/00885 | G08G-0001/16 | H04L-2209/80 | H04L-2209/805 | H04L-2209/84 | Y02T-0010/7005 | Y02T-0010/7072 | Y02T-0010/7083 | Y02T-0010/7291 | Y02T-0090/121 | Y02T-0090/122 | Y02T-0090/124 | Y02T-0090/128 | Y02T-0090/14 | Y02T-0090/16 | Y02T-0090/161 | Y02T-0090/163 | Y02T-0090/169 | Y04S-0030/14","G06Q-020/32","G06Q-020/32 | G07C-005/00 | G06F-016/248 | G06F-016/951 | H04W-004/44 | H04W-004/46 | G01C-021/36 | G08G-001/0962 | G08G-001/0967 | G08G-001/0968 | H01Q-001/32 | H04W-012/06 | G06F-021/31 | G06Q-020/10 | G06Q-020/14 | G06Q-020/40 | H04L-009/32 | B60L-053/14 | B60L-053/12 | B60L-053/80 | B60L-053/65 | B60L-053/66 | G06Q-010/00 | G06Q-030/02 | H04W-004/80 | G06Q-030/00 | G07C-005/08 | A61B-005/1171 | A61B-005/1172 | G07C-005/02 | G07C-009/00 | G06F-003/01 | G06K-009/00 | H02J-007/00 | H01Q-021/30 | H04B-005/00 | B60W-040/08 | B60W-050/08 | G08G-001/017 | G08G-001/00 | B60R-025/20 | G07B-015/06 | G06Q-030/06 | G06F-021/62 | H04W-012/02 | H04W-012/04 | H04W-004/40 | B60R-001/00 | B60R-011/04 | B60R-025/102 | G05B-015/02 | G05D-001/00 | G06F-021/32 | G06K-007/10 | G06K-019/07 | H04L-029/06 | B60L-005/24 | B60M-007/00 | G08G-001/16 | B60L-007/10 | B60L-008/00 | B60L-009/00 | B60K-035/00 | B60K-006/20 | B60R-011/00 | G01S-013/93 | B60W-050/14 | B60M-001/00","","","","","","4920025004224"
"US","US","P","B2","Physical activity and dietary based services","In an approach for providing dynamic services a computer receives a dietary plan for an individual. The computer tracks physical activity data for the individual. The computer creates one or more propositions for the individual based at least in part on the received dietary plan and the tracked physical activity data. The computer provides the created one or more propositions to the individual. The computer receives a selection from the created one or more propositions. The computer tracks the received selection.","1. A method for providing dynamic services, the method comprising: receiving, by one or more computer processors, a first dietary plan for an individual from a fitness tracking device;tracking, by the one or more computer processors, a physical activity data for the individual from the fitness tracking device, wherein the fitness tracking device incorporates accelerometers, altimeters, and gyroscopes to track distance, heartbeat, quality of sleep, type of activity, and length of activity;calculating, by the one or more computer processors, a calorie expenditure for the individual based on the physical activity data from the fitness tracking device; graphing, by the one or more computer processors, the physical activity data on the fitness tracking device;determining, by the one or more computer processors, whether the individual is at a store, wherein whether the individual is at the store is determined from a global positioning system in the fitness tracking device;responsive to determining that the individual is at the store, accessing, by the one or more computer processors, an inventory for the store;identifying, by the one or more computer processors, one or more items for purchase by the individual from the inventory for the store based on the first dietary plan and the physical activity data;calculating, by the one or more computer processors, an elapsed time, wherein the elapsed time is an actual amount of time between a completion of a workout within the physical activity data and a time of arrival at the store;determining, by the one or more computer processors, whether the elapsed time is within a defined period of time that identifies a time prior to and after the workout;responsive to determining that the physical activity occurs within the defined period of time, creating, by the one or more computer processors, a second dietary plan;creating, by the one or more computer processors, one or more meal recommendations for the individual based at least in part on the first dietary plan, the physical activity data, the one or more items for purchase by the individual within the inventory for the store, and the second dietary plan;providing, by the one or more computer processors, the one or more meal recommendations to the individual;receiving, by the one or more computer processors, a selection from the one or more meal recommendations; andtracking, by the one or more computer processors, the selection from the one or more meal recommendations on the physical fitness tracking device.","14","15/634315","2017-06-27","2018-0374385","2018-12-27","10685585","2020-06-16","INTERNATIONAL BUSINESS MACHINES CORPORATION","Stuart B.  Benefield | Samuel R.  Connor | Jonathan W.  Jackson | Joseph P.  Kuczynski","","","","G09B-0019/0092","G09B-0019/0092 | A61B-0005/14532 | A61B-0005/157 | A63B-0024/0059 | A63B-0024/0062 | A63B-0071/0686 | G06Q-0010/087 | G06Q-0030/0282 | G06Q-0050/12 | A61B-0005/4866 | A61B-0005/4872 | A63B-2220/12 | A63B-2220/17 | A63B-2220/20 | A63B-2220/40 | A63B-2220/73 | A63B-2220/74 | A63B-2220/803 | A63B-2220/836 | A63B-2230/06","G09B-019/00","G09B-019/00 | A63B-071/06 | G06Q-050/12 | A61B-005/145 | A61B-005/157 | G06Q-010/08 | A63B-024/00 | G06Q-030/02 | A61B-005/00","","","","","","4920025004306"
"US","US","P","B2","Insulin delivery apparatuses capable of bluetooth data transmission","Method and system including displaying a first representation of a medication treatment parameter profile, displaying a first representation of a physiological profile associated with the medication treatment parameter profile, detecting a modification to a segment of the medication treatment parameter profile, displaying a modified representation of the medication treatment parameter profile and the physiological profile based on the detected modification to the segment of the medication treatment parameter profile, modifying an attribute of the first representation of the medication treatment parameter profile, and modifying an attribute of the first representation of the physiological profile are provided.","1. A system comprising: a data receiver configured to receive, over a communication link, information corresponding to a detected glucose level of a user from an analyte sensor;an insulin infusion device communicatively coupled with the data receiver and configured to deliver insulin to the user'ss body;one or more processors communicatively coupled with the data receiver and the insulin infusion device, at least one of the one or more processors programmed to control the delivery of insulin from the insulin infusion device based on the information corresponding to the detected glucose level of the user and a modified glucose level;a display unit communicatively coupled to the one or more processors and a memory, wherein the memory stores instructions that, when executed by the one or more processors, causes the one or more processors to simultaneously display on the display unit: a first representation of an insulin treatment parameter profile comprising a vertical basal insulin axis and a first trace line of basal insulin over a horizontal time scale represented by at least one time axis;a modified representation of the insulin treatment parameter profile comprising the vertical basal insulin axis and a second trace line of basal insulin over the horizontal time scale based on a detected horizontal and/or vertical user modification to the first trace line of basal insulin;a first representation of a physiological profile associated with the insulin treatment parameter profile comprising a vertical glucose parameter axis and a first trace line of a glucose parameter over the horizontal time scale; anda modified representation of the physiological profile comprising the vertical glucose parameter axis and a second trace line of the glucose parameter over the horizontal time scale based on a determined corresponding modification to the glucose parameter due to the detected user modification to the first trace line of basal insulin, wherein the second trace line of the glucose parameter comprises the modified glucose level.","20","14/981863","2015-12-28","2016-0106919","2016-04-21","10685749","2020-06-16","ABBOTT DIABETES CARE INC.","Gary A.  Hayter | Timothy C.  Dunn","","","","G16H-0050/50","G16H-0050/50 | A61M-0005/142 | A61M-0005/1723 | G06F-0003/04847 | G06F-0019/3468 | G06K-0009/0055 | G06Q-0050/22 | G16H-0040/63 | H04W-0004/80 | A61M-2005/14208 | A61M-2205/18 | A61M-2205/3584 | A61M-2205/50 | A61M-2205/502 | A61M-2205/52 | A61M-2205/582 | A61M-2230/005 | A61M-2230/201","G16H-050/50","G16H-050/50 | H04W-004/80 | G06F-019/00 | G06F-003/0484 | G06Q-050/22 | G06K-009/00 | A61M-005/142 | A61M-005/172 | G16H-040/63","","","","","","4920025004470"
"US","US","P","B2","Method and device for managing display of multiple data streams","Methods and systems are provided to manage display of cardiac signals. The methods and systems receive a first data steam along a first communications path conveyed with first throughput and receiving a second data stream along a second communications path transmitted with second throughput. The first and second throughputs are asynchronous with respect to one another. The first and second data streams carry cardiac signals sensed by external and implanted electrodes, respectively, for one or more common events. The methods and systems store data from the first and second data streams in first and second memory buffers. The methods and systems synchronize the data stored in the first and second memory buffers with one another by performing at least one of: temporally offsetting activation of the storing operation for the first and second data streams with respect to one another; or managing an amount of the data maintained in at least one of the first memory buffer or the second memory buffer. The methods and systems co-display cardiac signals associated with the first and second data streams on a display by reading the data from the first and second memory buffers at a data display rate.","1. A system to manage display of cardiac signals, the system comprising: a first input to receive a first data stream along a first communications path conveyed in accordance with a first throughput;a second input to receive a second data stream along a second communications path transmitted in accordance with a second throughput, the first and second throughput asynchronous with respect to one another, the first and second data streams carrying cardiac signals sensed by external and implanted electrodes, respectively, for one or more common events;memory to store data from the first and second data streams in first and second memory buffers;one or more processors that, when executing program instructions, synchronize the data stored in the first and second memory buffers with one another by performing at least one of:i) temporally offsetting activation of the storing operation for the first and second data streams with respect to one another; orii) managing an amount of the data maintained in at least one of the first memory buffer or the second memory buffer; anda display to co-display cardiac signals associated with the first and second data stream by reading the data from the first and second memory buffers at a data display rate.","9","15/474494","2017-03-30","2018-0288147","2018-10-04","10686878","2020-06-16","PACESETTER, INC.","Muthuvale  Shanmugam | Pulkit  Bisen | Chao-Wen  Young | Yongjian  Wu | Lisbet  Miller | Xing  Pei | Reza  Shahandeh","","","","H04L-0067/1095","H04L-0067/1095 | A61B-0005/002 | A61B-0005/0006 | A61B-0005/0031 | A61B-0005/044 | A61B-0005/742 | A61N-0001/365 | A61N-0001/37217 | A61N-0001/37247 | A61N-0001/37252 | A61N-0001/3956","A61B-001/00","A61B-001/00 | H04L-029/08 | A61B-005/044 | A61B-005/00 | A61N-001/365 | A61N-001/39 | A61N-001/372","","","","","","4920025005585"
"US","US","P","B2","Integrated NIR and visible light scanner for co-registered images of tissues","Systems and methods for scanning near infrared (NIR) and visible light images and creating co-registered images are provided. A system can include a visible light image capturing device, an near infrared image capturing device, a housing unit, a light source configured to emit light at multiple wavelengths, and a processor configured to use image segmentation algorithms to measure a target issue or wound, detect hemodynamic signals, and combine the visible light image and a hemodynamic image to create a single image.","1. A system for scanning near infrared (NIR) and visible light images, the system comprising: a visible image capturing device configured to capture a visible light image, the visible light image comprising a digital color or white light image;a near infrared image capturing device configured to capture a near infrared (NIR) image of at least one wavelength;a portable, handheld, housing unit in which the visible image capturing device and the NIR image capturing device are contained, the housing unit comprising an NIR image capturing device compartment in which the NIR image capturing device is contained and a visible image capturing device compartment in which the visible image capturing device is contained, the NIR image capturing device being physically separated from the visible image capturing device by a wall of the NIR image capturing device compartment;a light source configured to illuminate a target area and connected to the housing unit,a plurality of drivers configured to control the light source;a processor; anda machine-readable medium comprising machine-executable instructions stored thereon, in operable communication with the processor,the light source comprising a plurality of light emitting diodes (LEDs) configured to emit light waves of at least one wavelength,the processor being configured to detect at least one NIR signal at at least one wavelength and generate a hemodynamic signal,the processor being configured to detect dimensional measurements of a target tissue or wound,the NIR image capturing device being disposed in the housing unit such that it faces out of a front face of the housing unit,the light source being disposed on a top face of the housing unit through a hinge, such that an angle of illumination provided by the light source is adjustable via the hinge without moving the housing unit,the processor being configured to detect a plurality of NIR images at a plurality of wavelengths, detect a visible light image, generate a hemodynamic map, and co-register the hemodynamic map onto the visible light image to generate a spatially co-registered static single image, andthe housing unit comprising a camera aperture access hole on a side face thereof different from the top face and the front face.","19","15/645677","2017-07-10","2019-0008387","2019-01-10","10674916","2020-06-09","THE FLORIDA INTERNATIONAL UNIVERSITY BOARD OF TRUSTEES","Anuradha  Godavarty","","","","A61B-0005/0035","A61B-0005/0035 | A61B-0005/0013 | A61B-0005/0077 | A61B-0005/0261 | A61B-0005/14552 | A61B-0005/445 | A61B-0005/7203 | A61B-0005/7435 | G06T-0007/0012 | G06T-0007/62 | G06F-0003/04817 | G06T-0007/11 | G06T-0007/60 | G06T-2207/10048 | G06T-2207/30088 | G06T-2207/30096 | G06T-2207/30104 | H04N-0005/2256","A61B-005/00","A61B-005/00 | A61B-005/1455 | A61B-005/026 | G06T-007/00 | G06T-007/62 | H04N-005/225 | G06T-007/11 | G06T-007/60 | G06F-003/0481","","","","","","4920024000988"
"US","US","P","B2","Networking of implantable medical devices and wearable devices","A system level scheme for networking of implantable devices, electronic patch devices/sensors coupled to the body, and wearable sensors/devices with cellular telephone/mobile devices, peripheral devices and remote servers is described.","1. A system including a mobile device and a wearable device, said system comprising: a medical device configured for placement within a body, wherein the medical device further comprises a processor;a monitoring system comprising of: an internal health data recorded by the medical device and received by the wearable device via a first wireless connection; wherein the wearable device is enabled to receive the internal health data periodically and/or continuously;wherein the wearable device is enabled to be in contact with the surface of the body; wherein the wearable device is further configured to acquire a physical activity data of the body;wherein the wearable device is configured to measure one or more environmental parameters; wherein at least one configuration of the medical device is controlled in response to the measured one or more environmental parameters;wherein the mobile device is enabled to receive from the wearable device via a second secure wireless network connection the physical activity data and the internal health data; wherein the mobile device is enabled to send to a server the physical activity data and the internal health data;the server enabled for archival of the physical activity data and the internal health data; wherein the physical activity data and the internal health data is enabled for remote access; andwherein the server is enabled to correlate the physical activity data with the internal health data.","16","15/206130","2016-07-08","2016-0317822","2016-11-03","10675475","2020-06-09","IP Holdings, Inc. | Rekha K. Rao","Raman K.  Rao | Sanjay K.  Rao","","","","A61N-0001/37264","A61N-0001/37264 | A61B-0005/0015 | A61B-0005/0022 | A61B-0005/0031 | A61B-0005/026 | A61B-0005/14551 | A61N-0001/362 | A61N-0001/365 | A61N-0001/36007 | A61N-0001/37 | A61N-0001/372 | A61N-0001/37211 | A61N-0001/37217 | A61N-0001/37288 | A61N-0001/39 | A61N-0001/3956 | G06F-0019/34 | G06F-0019/3418 | H04B-0013/005 | H04L-0063/0861 | H04M-0011/04","A61N-001/08","A61N-001/08 | A61N-001/372 | G06F-019/00 | A61B-005/00 | H04L-029/06 | A61B-005/026 | A61B-005/1455 | A61N-001/362 | A61N-001/365 | A61N-001/39 | H04B-013/00 | A61N-001/36 | A61N-001/37 | H04M-011/04","","","","","","4920024001542"
"US","US","P","B2","Display apparatus and method for controlling display apparatus","A display apparatus and a method for controlling the display apparatus are provided. More specifically, the display apparatus outputs a visual test screen and an auditory test voice signal, determines a degree and a classification of impairment of a user, and sets a User Interface (UI) or sets a voice signal output based on the determined degree and classification of impairment.","1. A display apparatus, comprising: an input unit comprising a circuitry;a speaker;a display; anda processor configured to:control the display to display visual test screens sequentially by changing a size of an object included in each of the visual test screens,based on a user input being received through the input unit while a visual test screen from among the visual test screens is displayed, identify a degree of impairment of a user and set an enlargement ratio of a User Interface (UI) to correspond to the degree of impairment of the user based on a size of the object included in the visual test screen and control the display to display the UI, andbased on a user input not being received through the input unit while a last visual test screen among the visual test screens is displayed, set the enlargement ratio of the UI to a maximum enlargement ratio of the UI and control the display to display a screen for activating a voice guidance function.","15","15/802103","2017-11-02","2018-0129518","2018-05-10","10678563","2020-06-09","SAMSUNG ELECTRONICS CO., LTD.","Bo-ra  Lee","10-2016-0145304","KR","2016-11-02","G06F-0009/451","G06F-0009/451 | A61B-0003/066 | A61B-0005/123 | G06F-0003/048 | G06F-0003/14 | G06F-0003/147 | G06F-0003/165 | G06F-0003/167 | A61F-0004/00 | G09G-2320/066 | G09G-2320/0693 | G09G-2340/04 | G09G-2340/14 | G09G-2354/00 | G09G-2380/08","G06F-017/00","G06F-017/00 | G06F-009/451 | G06F-003/048 | G06F-003/14 | A61B-003/06 | A61B-005/12 | G06F-003/147 | G06F-003/16 | A61F-004/00","","","","","","4920024004613"
"US","US","P","B2","System and method for supporting decisions during a catheterization procedure","Methods and systems for facilitating clinical decisions during a catheterization procedure based at least in part on image data captured during the catheterization procedure, are disclosed. More particularly, embodiments include analyzing the image data and transmitting decision support data representative of past catheterization procedures having a similarity to the current catheterization procedure. Other embodiments are also described and claimed.","1. A method to facilitate clinical decisions during a catheterization procedure, the method comprising: storing, in an interventional case history database, historical intervention data representative of past catheterization procedures and based on images taken during the past catheterization procedures;receiving, concurrently with a current catheterization procedure being performed in a catheterization lab, an image taken by an intravascular imaging system during the current catheterization procedures;comparing, by a data processing system, the historical intervention data based on images taken during the past catheterization procedures to current intervention data based on the image taken during the current catheterization procedure to determine a subset of past catheterization procedures having images similar to the image;determining decision support data including a plurality of procedural options for the current catheterization procedure, wherein the plurality of procedural options include respective procedural actions and associated likely clinical outcomes, and wherein the likely clinical outcomes are based on clinical outcomes of respective percentages of the subset of past catheterization procedures when the associated procedural actions were performed; andtransmitting the decision support data for display of the plurality of procedural options including the respective procedural actions and associated likely clinical outcomes by a monitor in the catheterization lab during the current catheterization procedure.","26","14/821573","2015-08-07","2017-0035514","2017-02-09","10679758","2020-06-09","ABBOTT CARDIOVASCULAR SYSTEMS INC.","Julia C.  Fox | Peter  Staehr","","","","G16H-0050/70","G16H-0050/70 | G06Q-0010/10 | G16H-0010/60 | G16H-0030/40 | G16H-0040/63 | A61B-0090/96 | A61B-2017/22051 | A61B-2034/256 | A61B-2090/376 | A61B-2090/3735 | A61B-2090/3782 | A61B-2576/00 | A61M-2025/0166","G06Q-010/10","G06Q-010/10 | G06Q-010/06 | G06Q-030/02 | G06Q-030/06 | G06Q-010/08 | G16H-050/70 | G16H-010/60 | G16H-040/63 | G16H-030/40 | A61B-090/00 | A61M-025/01 | A61B-034/00 | A61B-090/96 | A61B-017/22","","","","","","4920024005799"
"US","US","P","B2","Hearing protection earphone, hearing protection method and computer program storage medium for the same","The present invention provides a hearing protection earphone, a hearing protection method and a computer program storage medium, comprising a sound control system including a wearing-status sensing module for monitoring a current wearing status of the hearing protection earphone, sending a first monitoring signal when it is determined that the hearing protection earphone is in a wearing state, and sending a second monitoring signal when it is determined that the hearing protection earphone is in a non-wearing state; and a main control module for enabling a play function corresponding to a play mode which is adapted to the hearing protection earphone currently when the first monitoring signal sent from the wearing-status sensing module is received, and counting a stand-by time of the protection earphone and turning off the hearing protection earphone after a preset stand-by time elapses when the second monitoring signal sent from the wearing-status sensing module is received.","1. A hearing protection earphone, comprising an earphone housing, a speaker disposed inside the earphone housing and a sound control system, the sound control system including: a wearing-status sensing module for monitoring a current wearing status of the hearing protection earphone, sending a first monitoring signal when it is determined that the hearing protection earphone is in a wearing state, and sending a second monitoring signal when it is determined that the hearing protection earphone is in a non-wearing state; anda main control module for enabling a play function corresponding to a play mode which is adapted to the hearing protection earphone currently when the first monitoring signal sent from the wearing-status sensing module is received, and counting a stand-by time of the protection earphone and turning off the hearing protection earphone after a preset stand-by time elapses when the second monitoring signal sent from the wearing-status sensing module is received;wherein the play functions of the play mode includes: determining whether to enable a denoising function of the hearing protection earphone according to loudness of noise of noise signals in the external environment of the earphone housing;turning off the hearing protection earphone when the play volume of audio from the hearing protection earphone reaches a first volume threshold and/or the play time of the audio reaches a first time threshold, no matter whether the denoising function s enabled or disabled; andincreasing or decreasing the preset first volume threshold according to the stored information about the play volume of the hearing protection earphone associated with the current user before the determination about whether the play volume of the audio reaches the preset first volume threshold, in the self-adaptive mode.","21","16/416616","2019-05-20","2019-0387304","2019-12-19","10674247","2020-06-02","MERRY ELECTRONICS (SUZHOU) CO., LTD.","Guoming  Song | Ming  Zhu | Feilong  Cheng | Chunyan  Hu | Jiawei  Zhou","2018-10631569","CN","2018-06-19","H04R-0001/1041","H04R-0001/1041 | A61B-0005/117 | G06F-0003/16 | G06F-0003/165 | G06F-0009/4451 | G06K-0009/00362 | G10L-0017/005 | H04R-0001/1083","H04R-001/10","H04R-001/10 | G06F-003/16 | G10L-017/00 | G06K-009/00 | G06F-009/445 | A61B-005/117","","","","","","4920023007484"
"US","US","P","B2","Predictive fall prevention using corrective sensory stimulation","A computer-implemented method according to one embodiment includes performing a survey of a survey area of a surface in an intended direction of travel of a user, determining whether an obstacle is present in the survey area of the surface within a predetermined distance of the user, and in response to determining that a detected obstacle is present in the survey area of the surface within the predetermined distance of the user, performing a process until it is determined that the obstacle is not present in the survey area of the surface within the predetermined distance of the user. The process includes determining a corrective sensory stimulation for offsetting balance of the user in a direction away from the obstacle, and outputting the corrective sensory stimulation to a sensory user device.","1. A computer-implemented method, comprising: performing a survey of a survey area of a surface in an intended direction of travel of a user;determining whether an obstacle is present in the survey area of the surface within a predetermined distance of the user;in response to determining that an obstacle is present in the survey area of the surface within the predetermined distance of the user, performing the following process until it is determined that the obstacle is not present in the survey area of the surface within the predetermined distance of the user: determining a corrective sensory stimulation that is configured to offset balance of the user in a direction away from the obstacle; andoutputting the corrective sensory stimulation to a sensory user device; andin response to determining that the obstacle is present in the survey area of the surface outside of the predetermined distance of the user, performing another survey of the surface after a predetermined amount of time has elapsed,wherein the another survey considers at least the previous determination that the obstacle is present in the survey area of the surface outside of the predetermined distance of the user.","16","16/114100","2018-08-27","2020-0060601","2020-02-27","10660560","2020-05-26","INTERNATIONAL BUSINESS MACHINES CORPORATION","Su  Liu | Inseok  Hwang | Eric J.  Rozner | Jinho  Lee","","","","A61B-0005/4023","A61B-0005/4023 | A61N-0001/36003 | A61N-0001/36036 | G06F-0003/011","H04W-088/02","H04W-088/02 | A61B-005/00 | G06F-003/01 | A61N-001/36","","","","","","4920022001050"
"US","US","P","B2","Bedside interface for percutaneous coronary intervention planning","Devices, systems, and methods configured to assess the severity of a blockage in a vessel and, in particular, a stenosis in a blood vessel, provide measurements of a vessel that allow assessment of the vessel and, in particular, any stenosis or lesion of the vessel, simulate diagnostic visualizations a first visualization device and a second visualization device. For example, the methods can include displaying, on a first visualization device, an image of the vessel with treatment diagnostic visualizations based on obtained pressure measurements and displaying, on a second visualization device, a portion of the image of the vessel with diagnostic visualizations based on the obtained pressure measurements, wherein the portion of the image of the vessel displayed on the second visualization device is a close up of a region of interest of the vessel.","1. A method of planning treatment of a vessel of a patient, comprising: obtaining pressure measurements from first and second instruments during a diagnostic procedure where the first instrument is moved longitudinally through the vessel from a first position to a second position and the second instrument remains stationary;displaying, on a first visualization device: a two-dimensional external image of the vessel obtained by an external imaging device and comprising a region of interest of the vessel; anddiagnostic visualizations based on the obtained pressure measurements;displaying, on a touch display of a portable second visualization device separate from the first visualization device, at the same time as the display of the first visualization device: a magnified portion of the external image of the vessel that includes the region of interest; andthe diagnostic visualizations based on the obtained pressure measurements;receiving a user input on the region of interest displayed on the touch display of the second visualization device, the user input representative of a first treatment to position a treatment device in the region of interest; andupdating, in response to receiving the user input, the display of the second visualization device to include a treatment visualization overlaid on the region of interest in the magnified portion of the external image of the vessel, the treatment visualization including: a first graphical representation indicating a simulation of the first treatment, wherein the first graphical representation includes a representation of a length of the first treatment with respect to the vessel overlaid on the magnified portion of the external image at the region of interest; anda second graphical representation proximate to the first graphical representation, the second graphical representation indicating a simulated change in a pressure ratio at a position of the vessel proximate to the region of interest, the simulated change resulting from the first treatment, wherein the pressure ratio is determined based on the obtained pressure measurements.","20","14/961541","2015-12-07","2016-0166327","2016-06-16","10660769","2020-05-26","VOLCANO CORPORATION","Jacqueline  Keller","","","","A61F-0002/82","A61F-0002/82 | A61B-0005/0035 | A61B-0005/0066 | A61B-0005/02007 | A61B-0005/0215 | A61B-0005/6876 | A61B-0005/7264 | A61B-0005/743 | A61B-0006/032 | A61B-0006/12 | A61B-0006/461 | A61B-0006/469 | A61B-0006/504 | A61B-0008/06 | A61B-0008/0891 | A61B-0008/12 | A61B-0008/5223 | A61B-0034/10 | G06F-0003/0488 | G06F-0003/04815 | G16H-0030/20 | G16H-0050/50 | A61B-0005/004 | A61B-0005/0084 | A61B-0005/02158 | A61B-0005/055 | A61B-0005/6852 | A61B-0005/7445 | A61B-2034/101 | A61B-2034/107 | G16H-0040/63","A61B-034/10","A61B-034/10 | A61F-002/82 | A61B-005/0215 | A61B-005/00 | A61B-006/00 | A61B-006/03 | A61B-008/12 | A61B-008/08 | A61B-006/12 | A61B-008/06 | A61B-005/02 | G06F-003/0488 | G16H-030/20 | G16H-050/50 | G06F-003/0481 | A61B-005/055 | G16H-040/63","","","","","","4920022001258"
"US","US","P","B2","Pen needle outer cover concepts","A pen needle is enclosed by an outer cover to facilitate installation of a needle bearing hub on a medication pen. The outer cover design reduces or eliminates the likelihood of user contact with the patient end needle or the non-patient end needle during installation and disposal, and provides an audible indication when the hub is fully installed on a medication pen.","1. A pen needle, comprising: an outer cover having a closed distal end with gently concave sides forming a finger hold and an open proximal end receiving a needle-bearing hub having a patient end needle and a non-patient-end needle;the needle bearing hub having an open proximal end adapted to be attached to a medication pen, the open proximal end of the hub being defined by a proximal edge aligned with the open proximal end of the outer cover in an initial state prior to installation of the hub on the medication pen; anda flap attached to the proximal end of the outer cover by a hinge having camming or locking elements for maintaining the flap in an open position permitting installation of the hub on the medication pen and in a first closed position enclosing the non-patient end of the needle within the hub or outer cover; whereinthe flap is releasably held in the first closed position, which allows the hub to be transported and the flap later opened, so that the hub can be installed on the medication pen; andthe flap is movable to a second closed position in which the flap is permanently locked for disposal.","13","15/100279","2014-12-04","2017-0034697","2017-02-02","10661025","2020-05-26","BECTON, DICKINSON AND COMPANY","Sean  Sullivan | Sudarsan  Srinivasan | Michael  DiBiasi | Keith  Knapp | Kunjal  Oza | Sajayesh  Vijayachandran | Ganesh  Kamble","","","","A61M-0005/3213","A61M-0005/3213 | A61M-0005/002 | A61M-0005/3202 | A61M-0005/3205 | A61M-0005/3293 | A61M-0005/50 | A61M-0005/5086 | G06F-0009/4416 | H04L-0063/0876 | A61M-2005/3254","A61M-005/00","A61M-005/00 | A61M-005/32 | A61M-005/50 | G06F-009/4401 | H04L-029/06","","","","","","4920022001512"
"US","US","P","B2","Method and system for activity recognition and behaviour analysis","Energy remains a critical challenge for continuous sensing: with low-capacity batteries, wearable devices require frequent charging. In contrast, installing sensors in everyday ‘smart objects’, such as kitchen cabinets, household appliances and office equipment, supports ADL detection via indirect observations on human interaction with such objects, but cannot provide individual-specific insights in multi-tenanted environments. The embodiments herein provide a method and system for energy efficient activity recognition and behavior analysis. Architecture disclosed utilizes a hybrid mode of inexpensive, battery-free sensing of physical activities performed by a subject been monitored during his Activities for Daily Living (ADLs). The sensing combines object interaction sensing with person-specific wearable sensing to recognize individual activities in smart spaces. The method and system disclosed quantifies a probabilistic approach that uses longitudinal observations of user-item interactions, over each individual episode, to compute the anomalous behavior of the subject.","1. A processor implemented method for activity recognition and behavior analysis, the method comprising: seamlessly sensing, via one or more hardware processors using a Radio Frequency Identification (RFID) reader operating in a low power mode, sensor data received from at least one battery less primary sensor associated with at least one primary object, wherein usage of the at least one primary object is mandatory to initiate a primary activity associated with an ADL among a plurality of Activities of Daily Living (ADLs);detecting, via the one or more hardware processors, mobility of a subject to initiate the primary activity based on variation in the sensor data received from the at least one battery less primary sensor associated with the at least one primary object, wherein the variation in the sensor data indicates proximity of the subject with the at least one primary object;triggering, via the one or more hardware processors, the RFID reader to switch from the low power mode to a high power mode on detection of mobility of the subject for the primary activity, wherein the RFID reader in the high power mode receives RF data from: at least one battery less wearable tag worn by the subject, and wherein the at least one battery less wearable tag comprises a RF powered passive accelerometer; anda plurality of passive RFID tags tagged to a plurality of secondary objects placed in proximity to the at least one primary object, wherein one or more secondary objects from a plurality of secondary objects, required to be used by the subject while performing one or more secondary activities associated with each ADL among the plurality of ADLs to perform each ADL without presence of anomaly, are predefined;analyzing, via the one or more hardware processors, the RF data received from the at least one battery less wearable tag over a plurality of window intervals to tag the primary activity of the subject, for each window interval, to an ADL among the plurality of ADLs;analyzing, via the one or more hardware processors, RF data received from the plurality of passive RFID tags of interest over each window interval to detect the one or more secondary activities performed by the subject using the one or more secondary objects and interaction of the subject with the one or more secondary objects corresponding to the tagged primary activity; anddetermining, via the one or more hardware processors, presence of anomaly in each of the window interval if the tagged primary activity of each window interval and the interaction of the subject with the one or more secondary objects in the detected one or more secondary activities for each window interval maps to a predefined primary object and secondary object usage criteria, wherein the predefined criteria is set for confirming expected execution of the ADL among the plurality of ADLs.","12","16/434597","2019-06-07","2019-0377916","2019-12-12","10664671","2020-05-26","TATA CONSULTANCY SERVICES LIMITED","Dibyanshu  Jaiswal | Andrew  Gigie | Avik  Ghose | Tapas  Chakravarty | Archan  Misra","201821021608","IN","2018-06-08","G06K-0007/10366","G06K-0007/10366 | A61B-0005/1113 | A61B-0005/1114 | A61B-0005/1115 | A61B-0005/1123 | A61B-0005/6802 | G06F-0003/017 | G06K-0007/10207 | G06K-0009/00335 | G08B-0021/0446 | G08B-0021/0461","A01K-011/00","A01K-011/00 | H04W-004/029 | G06K-007/10 | G06K-009/00 | G06F-003/01 | A61B-005/00 | A61B-005/11 | G08B-021/04","","","","","","4920022005127"
"US","US","P","B2","Optical fingerprint identification display screen and display device","This disclosure relates to an optical fingerprint identification display screen and a display device. In this disclosure, a plurality of photosensitive elements for fingerprint identification is arranged on an array substrate, such that mesh regions of a mesh-like black matrix layer corresponds to the photosensitive elements. A plurality of light guide members at least covering each of the photosensitive elements is arranged between each photosensitive element and the counter substrate. Since the light guide members and the counter substrate are in contact with each other, light reflected from ridges and valleys of a fingerprint will enter the light guide members maximally after passing through the mesh regions of the black matrix layer, and then directly impinge on the photosensitive elements after refraction within the light guide members.","1. An optical fingerprint identification display screen, comprising: a counter substrate and an array substrate arranged opposite one another;a plurality of photosensitive elements arranged on a side of the array substrate facing the counter substrate for fingerprint identification;a mesh-like black matrix layer arranged on the side of the array substrate facing the counter substrate or on a side of the counter substrate facing the array substrate, mesh regions of the mesh-like black matrix layer corresponding to the photosensitive elements; anda plurality of light guide members arranged between each of the photosensitive elements and the counter substrate and at least covering each of the photosensitive elements;wherein each mesh region of the mesh-like black matrix layer is located between two directly adjacent pixels in a column of pixels;and wherein each light guide member is a truncated cone comprising a top surface and a bottom surface, an area of the top surface is smaller than an area of the bottom surface, and the top surface is in contact with the counter substrate.","20","15/326928","2016-09-05","2018-0211085","2018-07-26","10664679","2020-05-26","BOE TECHNOLOGY GROUP CO., LTD. | BEIJING BOE OPTOELECTRONICS TECHNOLOGY CO., LTD.","Wei  Liu | Xue  Dong | Xiaochuan  Chen | Haisheng  Wang | Xiaoliang  Ding | Yingming  Liu | Weijie  Zhao | Shengji  Yang | Changfeng  Li | Pengpeng  Wang","2016-10004800","CN","2016-01-04","G06K-0009/0004","G06K-0009/0004 | A61B-0005/1172 | G02F-0001/13306 | G06F-0003/0412 | H01L-0027/14623 | H01L-0027/14625 | H01L-0027/14678 | G02F-0001/1368 | G02F-0001/13338 | G02F-0001/133512 | G02F-2001/13312 | G02F-2001/133331 | H01L-0027/156 | H01L-0027/3234 | H01L-0027/3246 | H01L-0027/3283 | H01L-0031/1136 | H01L-0031/16","G06K-009/00","G06K-009/00 | G02F-001/133 | H01L-027/146 | G02F-001/1333 | G02F-001/1335 | A61B-005/1172 | G06F-003/041 | G02F-001/1368 | H01L-027/15 | H01L-027/32 | H01L-031/113 | H01L-031/16","","","","","","4920022005135"
"US","US","P","B2","Electronic device, and method for analyzing face information in electronic device","A method for analyzing face information in an electronic device is provided. The method includes detecting at least one face region from an image that is being captured by a camera module, zooming in the at least one detected face region, and analyzing the at least one detected and zoomed in face region according to at least one analysis item.","1. A method for analyzing face information in an electronic device comprising a camera, the method comprising: detecting at least one face region among a plurality of face regions of a face in an image captured by the camera based on at least one reference point captured in the image;identifying the at least one face region corresponding to at least one of an oral region, a nasal region, an ocular region, a buccal region, or a forehead region based on a zooming in or a setting of a focus of the camera on the at least one face region;identifying, based on the identification of the at least one face region, at least one analysis item corresponding to the identification of the at least one face region among a plurality of analysis items;measuring at least one skin condition in the at least one face region, based on the at least one analysis item;obtaining information related to skin analysis history corresponding to the at least one face region based on the measured at least one skin condition; anddisplaying the information related to the skin analysis history.","26","14/928402","2015-10-30","2016-0125228","2016-05-05","10664686","2020-05-26","SAMSUNG ELECTRONICS CO., LTD.","Joo-Young  Son | Jin-Ho  Kim | Woo-Sung  Kang | Yun-Jung  Kim | Hong-Il  Kim | Jae-Won  Son | Won-Suk  Chang | In-Ho  Choi | Dae-Young  Hyun | Tae-Hwa  Hong","10-2014-0152239 | 10-2015-0092549","KR | KR","2014-11-04 | 2015-06-29","G06K-0009/00248","G06K-0009/00248 | A61B-0005/0077 | A61B-0005/1176 | A61B-0005/442 | A61B-0005/444 | A61B-0005/7275 | G06F-0003/017 | G06F-0019/321 | G06K-0009/0061 | G06K-0009/00281 | G06T-0007/90 | G16H-0015/00 | G16H-0050/20 | H04N-0005/23293 | H04N-0005/23296 | A61B-0005/443 | A61B-0005/6898 | A61B-0005/743 | A61B-2576/00 | A61B-2576/02 | G06F-0001/1626 | G06F-0003/04883 | G06T-2207/30201","G06K-009/00","G06K-009/00 | G06F-003/01 | H04N-005/232 | G16H-015/00 | G16H-050/20 | A61B-005/1171 | A61B-005/00 | G06T-007/90 | G06F-001/16 | G06F-003/0488 | G06F-019/00","","","","","","4920022005142"
"US","US","P","B2","Systems and methods for quantification of postural balance of users in an augmented reality environment","Systems and methods for quantification of postural balance of users in an augmented reality (AR) environment. Traditional systems and methods provide for quantifying the postural balance using the AR environment but none of them quantify or restrict the functional tasks performed by the users to a predefined level. Embodiments of the present disclosure provide for the quantification of the postural balance with a variable step height in the AR environment by acquiring first set of information comprising of data on skeletal joints, filtering the first set of information for obtaining a filtered set of data, computing the set of postural data based upon the filtered set of data and quantifying the postural balance based upon the set of postural data by computing threshold values for obtaining postural stability index scores and determining based upon the postural stability index scores, the postural balance of the users in the AR environment.","1. A method for quantifying postural balance of users in an augmented reality (AR) environment, the method comprising a processor implemented steps of: acquiring, by a sensor, a first set of information from one or more users, wherein the first set of information comprises a set of data on skeleton joints of the one or more users performing various functional tasks in the AR environment;filtering, using a multivariate de-noising technique, the first set of information for extracting a filtered set of data to compute a set of postural data of the one or more users, wherein the filtered set of data comprises data obtained by filtering noise from the first set of information;computing, based upon the filtered set of data, the set of postural data for quantifying the postural balance of the one or more users, wherein the set of postural data comprises data on postures and activities of the one or more users, and wherein the computation of the set of postural data comprises augmenting Single Leg Stance (SLS) functional tasks with variations in step heights of the one or more users for computing SLS time duration, vibration of hip joints and center of mass sway area, and wherein the augmented SLS functional tasks with variations in step height are classified into various pre-defined activity levels based on the one or more users physical ability or difficulty level; andquantifying, using a fuzzy controller in the AR environment, the postural balance of the one or more users based upon the set of postural data by:computing a plurality of postural stability index scores, by performing a correlation of the set of postural data with one or more threshold values based upon a set of fuzzy rules, wherein the one or more threshold values comprises a set of pre-defined stability values obtained by performing a classification each of the SLS time duration, the vibration of hip joints and the center of mass sway area under different categories, and wherein the plurality of postural stability scores are computed for the SLS functional tasks of each pre-defined activity level in order to determine variations in postural balance due to changes in activity level; andproviding, real-time feedback in the AR environment for correcting the posture of the one or more users by interpreting the one or more postural stability index scores computed.","6","16/172668","2018-10-26","2019-0125238","2019-05-02","10653351","2020-05-19","TATA CONSULTANCY SERVICES LIMITED","Sangheeta  Roy | Oishee  Mazumder | Debatri  Chatterjee | Kingshuk  Chakravarty | Aniruddha  Sinha","201721038331","IN","2017-10-28","A61B-0005/4023","A61B-0005/4023 | A61B-0005/1114 | A61B-0005/1121 | A61B-0005/1126 | G06F-0017/15 | G06N-0005/048 | G06T-0019/006 | G16H-0020/30 | G16H-0050/20 | G16H-0050/30 | A61B-0005/1122 | A61B-0005/1128","A61B-005/00","A61B-005/00 | A61B-005/11 | G06N-005/04 | G06F-017/15 | G06T-019/00 | G16H-050/30 | G16H-020/30 | G16H-050/20","","","","","","4920021001030"
"US","US","P","B2","Methods and systems for display of patient data in computer-assisted surgery","Methods and systems for performing computer-assisted image-guided surgery, including robotically-assisted surgery. A method of displaying image data includes displaying image data of a patient on a handheld display device, tracking the handheld display device using a motion tracking system, and modifying the image data displayed in response to changes in the position and orientation of the handheld display device. Further embodiments include a sterile case for a handheld display device, display devices on a robotic arm, and methods and systems for performing image-guided surgery using multiple reference marker devices fixed to a patient.","1. A method for performing image-guided surgery using multiple reference marker devices fixed to a patient, the method comprising: obtaining patient images using an imaging device;registering at least a first portion of the patient images in a first patient coordinate system associated with first reference marker device fixed to a bony structure of the patient at a first location:registering at least a second portion of the patient images to a second patient coordinate system associated with a second reference marker device fixed to a bony structure of the patient at a second location that is different than the first location:selecting between display of patient images registered to the first patient coordinate system and display of patient images registered to the second patient coordinate system in an image guided surgery system based on a proximity to the first and second locations;detecting a relative movement between the first and second reference marker devices; andnotifying a user when the detected relative movement is greater than a threshold value.","13","15/701063","2017-09-11","2018-0185113","2018-07-05","10653495","2020-05-19","MOBIUS IMAGING, LLC","Eugene  Gregerson | Scott  Coppen | Todd  Furlong | Edward  Daley | Russell  Stanton | Adeline  Harris | Paul  Sebring","","","","A61B-0090/37","A61B-0090/37 | A61B-0005/055 | A61B-0005/1127 | A61B-0006/032 | A61B-0006/461 | A61B-0034/20 | A61B-0034/30 | A61B-0034/35 | A61B-0090/00 | A61B-0090/361 | A61B-0090/50 | G06T-0007/248 | G06T-0007/74 | G06T-0015/08 | G06T-0015/20 | G06T-0019/006 | A61B-0005/0035 | A61B-0005/7425 | A61B-0006/463 | A61B-2034/105 | A61B-2034/2048 | A61B-2034/2057 | A61B-2034/2059 | A61B-2034/2065 | A61B-2034/2072 | A61B-2090/365 | A61B-2090/367 | A61B-2090/372 | A61B-2090/373 | A61B-2090/374 | A61B-2090/376 | A61B-2090/378 | A61B-2090/3762 | A61B-2090/3983 | A61B-2560/0223 | G06F-0003/04883 | G06F-0003/1446 | G06T-2207/30012","A61B-090/00","A61B-090/00 | A61B-034/30 | A61B-034/20 | A61B-090/50 | A61B-006/03 | A61B-005/055 | A61B-005/11 | A61B-006/00 | A61B-034/35 | G06T-007/73 | G06T-007/246 | G06T-015/08 | G06T-015/20 | G06T-019/00 | A61B-005/00 | A61B-034/10 | G06F-003/0488 | G06F-003/14","","","","","","4920021001174"
"US","US","P","B2","Methods and apparatus for inferring user intent based on neuromuscular signals","Methods and system for predicting the onset of a motor action using neuromuscular signals. The system comprises a plurality of sensors configured to continuously record a plurality of neuromuscular signals from a user and at least one computer processor programmed to provide as input to a trained statistical model, the plurality of neuromuscular signals or information based on the plurality of neuromuscular signals, predict, based on an output of the trained statistical model, whether an onset of a motor action will occur within a threshold amount of time; and send a control signal to at least one device based, at least in part, on the output probability, wherein the control signal is sent to the at least one device prior to completion of the motor action by the user.","1. A control system, comprising: a plurality of sensors configured to continuously record a plurality of neuromuscular signals from a user; andat least one computer processor programmed to: provide as input to a trained statistical model, the plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals, wherein the trained statistical model was trained based, at least in part, on neuromuscular data recorded during at least one previous performance of a motor action by one or more users and result data indicating an outcome of the motor action performed by the one or more users; andpredict, based on an output of the trained statistical model, whether an onset of the user'ss motor action will occur within a threshold amount of time.","20","16/526401","2019-07-30","2019-0354182","2019-11-21","10656711","2020-05-19","FACEBOOK TECHNOLOGIES, INC.","Patrick  Kaifosh | Timothy  Machado | Thomas  Reardon | Erik  Schomburg","","","","G06F-0003/015","G06F-0003/015 | A61B-0005/0488 | A61B-0005/7267 | G06N-0003/0445 | G06N-0007/005 | G06N-0020/00 | A61B-0005/7282 | G06N-0003/0454 | G06N-0003/084 | G06N-0020/10","G06F-003/01","G06F-003/01 | A61B-005/0488 | G06N-007/00 | G06N-020/00 | A61B-005/00 | G06N-003/04 | G06N-020/10 | G06N-003/08","","","","","","4920021004371"
"US","US","P","B2","Apparatus for extracorporeal blood treatment comprising all-round display","An apparatus for extracorporeal blood treatment comprising a control unit and a display device, wherein the apparatus for extracorporeal blood treatment is equipped with a person locating and identifying device and the person locating and identifying device and the display device are in contact of information exchange with each other via the control unit and the person locating and identifying device is adapted to obtain and to process information about the position of a person being located in the environment of the apparatus for extracorporeal blood treatment, and the display device is adapted to display on a display information in response to the position of the person so that it is visible from the position of the person.","1. A system comprising: an apparatus for extracorporeal blood treatment;a control unit for the apparatus;an external peripheral display fixedly mounted to the apparatus such that the external peripheral display is not movable relative to the apparatus, the external peripheral display having a plurality of subareas directed in different directions; anda person locating and identifying device configured to exchange data with the external peripheral display via the control unit, and adapted to obtain and to process location information about a position of a person located in a detectable range;wherein the external peripheral display is visible from all positions inside the detectable range, and is adapted to automatically display information about at least one of a treatment cycle and the apparatus, in response to at least the position of the person relative to the apparatus, on a subarea of the external peripheral display facing in a direction of the person so that the displayed information about the at least one of the treatment cycle and the apparatus is visible to the person.","11","15/829158","2017-12-01","2018-0157335","2018-06-07","10656723","2020-05-19","B. BRAUN AVITUM AG","Sebastian  Brogger | Armin  Riess","10-2016-123371","DE","2016-12-02","G06F-0003/017","G06F-0003/017 | A61B-0005/1113 | A61B-0005/1176 | A61M-0001/14 | A61M-0001/36 | F16M-0011/128 | G06F-0003/011 | G06F-0003/1423 | G06F-0003/1431 | G06F-0009/4451 | G06K-0009/00255 | G06K-0009/00335 | G08B-0003/10 | G09G-0003/003 | G09G-0005/00 | G16H-0010/65 | G16H-0020/17 | G16H-0040/63 | A61M-2205/18 | A61M-2205/3306 | A61M-2205/502 | A61M-2205/581 | G09G-2340/0407 | G09G-2340/0464 | G09G-2340/14 | G09G-2354/00 | G09G-2380/08","G09G-005/00","G09G-005/00 | G06F-003/01 | A61M-001/14 | G06F-003/14 | G09G-003/00 | G16H-040/63 | G16H-010/65 | G16H-020/17 | F16M-011/12 | A61B-005/11 | A61B-005/1171 | A61M-001/36 | G06F-009/445 | G06K-009/00 | G08B-003/10","","","","","","4920021004383"
"US","US","P","B2","Methods for using feature vectors and machine learning algorithms to determine discriminant functions of minimum risk linear classification systems","Methods are provided for determining discriminant functions of minimum risk linear classification systems, wherein a discriminant function is represented by a geometric locus of a principal eigenaxis of a linear decision boundary. A geometric locus of a principal eigenaxis is determined by solving a system of fundamental locus equations of binary classification, subject to geometric and statistical conditions for a minimum risk linear classification system in statistical equilibrium. Feature vectors and machine learning algorithms are used to determine discriminant functions and ensembles of discriminant functions of minimum risk linear classification systems, wherein distributions of the feature vectors have similar covariance matrices, and wherein a discriminant function of a minimum risk linear classification system exhibits the minimum probability of error for classifying given collections of feature vectors and unknown feature vectors related to the collections.","1. A computer-implemented method of using feature vectors and machine learning algorithms to determine a discriminant function of a minimum risk linear classification system that classifies said feature vectors into two classes and using said discriminant function of said minimum risk linear classification system to classify unknown feature vectors related to said feature vectors, said method comprising: receiving an N×d data set of feature vectors within a computer system, wherein N is a number of feature vectors, d is a number of vector components in each feature vector, and each one of said N feature vectors is labeled with information that identifies which of two classes each one of said N feature vectors belongs to, and wherein each said feature vector is defined by a d-dimensional vector of numerical features, wherein said numerical features are extracted from digital signals;receiving within said computer system unknown feature vectors related to said data set;determining a Gram matrix using said data set, said determination of said Gram matrix being performed by using processors of said computer system to calculate a matrix of all possible inner products of signed said N feature vectors, wherein each one of said N feature vectors has a sign of +1 or ?1 that identifies which of said two classes each one of said N feature vectors belongs to, and using said processors of said computer system to calculate a regularized Gram matrix from said Gram matrix;determining scale factors of a geometric locus of signed and scaled extreme points using said regularized Gram matrix, wherein said extreme points are located within overlapping regions or near tail regions of distributions of said N feature vectors, said determination of said scale factors being performed by using said processors of said computer system to determine a solution of a dual optimization problem, wherein said scale factors and said geometric locus satisfy a system of fundamental locus equations of binary classification, subject to geometric and statistical conditions for a minimum risk linear classification system in statistical equilibrium, and wherein said scale factors determine conditional densities for said extreme points and also determine critical minimum eigenenergies exhibited by scaled extreme vectors on said geometric locus, wherein said critical minimum eigenenergies determine conditional probabilities of said extreme points and also determine corresponding counter risks and risks of a minimum risk linear classification system, wherein said counter risks are associated with right decisions and said risks are associated with wrong decisions of said minimum risk linear classification system, and wherein said geometric locus determines the principal eigenaxis of the decision boundary of said minimum risk linear classification system, wherein said principal eigenaxis exhibits symmetrical dimensions and density, wherein said conditional probabilities and said critical minimum eigenenergies exhibited by said minimum risk linear classification system are symmetrically concentrated within said principal eigenaxis, and wherein counteracting and opposing components of said critical minimum eigenenergies exhibited by said scaled extreme vectors on said geometric locus together with said corresponding counter risks and risks exhibited by said minimum risk linear classification system are symmetrically balanced with each other about the geometric center of said principal eigenaxis, wherein the center of total allowed eigenenergy and minimum expected risk of said minimum risk linear classification system is located at the geometric center of said geometric locus, and wherein said geometric locus determines a primal representation of a dual locus of likelihood components and principal eigenaxis components, wherein said likelihood components and said principal eigenaxis components are symmetrically distributed over either side of the axis of said dual locus, wherein a statistical fulcrum is placed directly under the center of said dual locus, and wherein said likelihood components of said dual locus determine conditional likelihoods for said extreme points, and wherein said principal eigenaxis components of said dual locus determine an intrinsic coordinate system of geometric loci of a linear decision boundary and corresponding decision borders that jointly partition the decision space of said minimum risk linear classification system into symmetrical decision regions;determining said extreme vectors on said geometric locus using the vector of said scale factors, said determination of said extreme vectors being performed by using said processors of said computer system to identify said scale factors that exceed zero by a small threshold, and using said processors of said computer system to determine a sign vector of signs associated with said extreme vectors using said data set, and compute the average sign using said sign vector;determining a locus of average risk for said minimum risk linear classification system using said extreme vectors, said determination of said locus of average risk being performed by using said processors of said computer system to calculate the average vector of said extreme vectors;determining said geometric locus, said determination of said geometric locus being performed by using said processors of said computer system to calculate a matrix of inner products between said signed said N feature vectors and said unknown feature vectors, and multiply said matrix by said vector of scale factors;determining the discriminant function of said minimum risk linear classification system, using said locus of aggregate risk and said average sign and said geometric locus, said determination of said discriminant function of said minimum risk linear classification system being performed by using said processors of said computer system to subtract said locus of aggregate risk from sum of said geometric locus and said average sign, wherein said discriminant function of said minimum risk linear classification system satisfies said system of fundamental locus equations of binary classification, and wherein said discriminant function of said minimum risk linear classification system determines likely locations of said N feature vectors and also determines said geometric loci of said linear decision boundary and said corresponding decision borders that jointly partition said extreme points into said symmetrical decision regions, wherein said symmetrical decision regions span said overlapping regions or said tail regions of said distributions of said N feature vectors, and wherein said discriminant function of said minimum risk linear classification system satisfies said linear decision boundary in terms of a critical minimum eigenenergy and said minimum expected risk, wherein said counteracting and opposing components of said critical minimum eigenenergies exhibited by said scaled extreme vectors on said geometric locus associated with said corresponding counter risks and risks exhibited by said minimum risk linear classification system are symmetrically distributed over said axis of said dual locus, on equal sides of said statistical fulcrum located at said geometric center of said dual locus, wherein said counteracting and opposing components of said critical minimum eigenenergies together with said corresponding counter risks and risks exhibited by said minimum risk linear system are symmetrically balanced with each other about said geometric center of said dual locus, and wherein said statistical fulcrum is located at said center of said total allowed eigenenergy and said minimum expected risk of said minimum risk linear classification system, wherein said minimum risk linear classification system satisfies a state of statistical equilibrium, wherein said total allowed eigenenergy and said expected risk of said minimum risk linear classification system are minimized, and wherein said minimum risk linear classification system exhibits the minimum probability of error for classifying said N feature vectors that belong to said two classes and said unknown feature vectors related to said data set, wherein said distributions of said feature vectors have similar covariance matrices;determining which of said two classes said unknown feature vectors belong to using said discriminant function of said minimum risk linear classification system, said determination of said classes of said unknown feature vectors being performed by using said processors of said computer system to apply said discriminant function of said minimum risk linear classification system to said unknown feature vectors, wherein said discriminant function determines likely locations of said unknown feature vectors and identifies said decision regions related to said two classes that said unknown feature vectors are located within, wherein said discriminant function recognizes said classes of said unknown feature vectors, and wherein said minimum risk linear classification system decides which of said two classes said unknown feature belong to and thereby classifies said unknown feature vectors.","6","16/523793","2019-07-26","2019-0347572","2019-11-14","10657423","2020-05-19","Denise Reeves","Denise  Reeves","","","","G06K-0009/6278","G06K-0009/6278 | A61B-0005/7264 | A61B-0005/7267 | G06F-0017/11 | G06F-0017/18 | G06K-0009/6265 | G06K-0009/6277 | G06K-0009/6286 | G06N-0020/00","G06K-009/62","G06K-009/62 | G06N-020/00 | G06F-017/18 | A61B-005/00 | G06F-017/11","","","","","","4920021005077"
"US","US","P","B2","Patient device for advanced patient communication","A provider device for advanced patient communication and methods for making and using same. According to one embodiment, a provider device comprises a receiver for receiving one or more messages from a central processing server, each of the one or more messages reflecting a patient request, an urgency level associated with the patient request, one or more action items associated with the patient request, and a lapse in time since receiving the patient request. The provider device also includes a display for displaying, based on the one or more messages, a patient listing including status information corresponding to one or more patients.","1. A computer-implemented method, comprising: providing a patient communication mechanism by which a patient communicates a first message within a healthcare facility; receiving one or more messages at a central processing server, a first message reflecting a patient request or need;processing the first message to identify an urgency level of the first message, a lapse in time and a provider skill level or role best suited to respond to the first message; generating one or more additional messages based on the first message; and transmitting the one or more additional messages to at least one specific provider device of specific providers expected to respond, wherein the one or more additional messages are routed to at least one specific provider device based on a context of the first message;presenting the one or more additional messages via a display with a selection input mechanism;enabling a provider to select at least one of the presented messages via touching the display or at least one display control button of the selection input mechanism, which enables transferring of the one or more additional messages or generation and transmission of a second message.","12","15/158070","2016-05-18","2016-0267236","2016-09-15","10658081","2020-05-19","ELOQUENCE COMMUNICATIONS, INC.","Bryan James  Traughber | Lance S.  Patak","","","","G16H-0040/63","G16H-0040/63 | G06F-0019/00 | G06Q-0050/22 | G08B-0005/222 | G08B-0021/0277 | G08B-0025/016 | G16H-0010/60 | G16H-0015/00 | G16H-0040/20 | H04M-0001/72527 | A61B-0005/0002 | A61B-0005/0022 | A61B-0005/7282 | A61B-0005/7475 | A61B-2560/045 | G08B-0021/0211 | G08B-0025/10","G06Q-010/10","G06Q-010/10 | G06Q-010/06 | G06Q-030/02 | G06Q-030/06 | G16H-040/63 | G08B-021/02 | G08B-025/01 | G16H-010/60 | G16H-040/20 | G16H-015/00 | G06F-019/00 | G08B-005/22 | G06Q-050/22 | H04M-001/725 | A61B-005/00 | G08B-025/10","","","","","","4920021005732"
"US","US","P","B2","Method of generating an adaptive partial report and apparatus for implementing the same","The invention provides a method of generating an adaptive partial report for an observer with an apparatus comprising a display, a user interface, and a processor. The apparatus can be a computer system or an electronic device, for example. The method includes the processor characterizing an iconic memory decay function for the observer. The characterization includes determining a prior for a plurality of parameters. The method further includes the processor determining a first stimulus for a first trial based on the prior for the plurality of parameters, the display generating the stimulus for viewing by the observer, the user interface receiving input for the first trial and in response to the stimulus, the processor revising respective parameter values for the parameters based on the received input, and the processor determining a new stimulus for a next trial based on the revised parameter values.","1. A method of generating an adaptive partial report (adaptive PR) for an observer with an apparatus comprising a display, a user interface, and a processor, the method comprising the processor characterizing an iconic memory decay function for the observer, the iconic memory decay function having a plurality of parameters, the characterization including determining a prior for the plurality of parameters;the processor determining a first stimulus for a first trial based on the prior of the parameters, the determined first stimulus being expected to lead to an information gain for the iconic memory decay function;the display generating the first stimulus for viewing by the observer;the user interface receiving input for the first trial and in response to the first stimulus;the processor revising a posterior distribution of parameter values for the parameters based on the received input;the processor determining a new stimulus for a next trial based on the revised posterior distribution, the determined new stimulus being expected to lead to additional information gain for the iconic memory decay function;the display generating the new stimulus for viewing by the observer;the user interface receiving new input for the next trial and in response to the new stimulus; andthe processor revising the posterior distribution of the parameter values for the parameters based on the new input,wherein the iconic memory decay function takes the form of pc(SOA)=a0+(a1?a0)e?SOA/τ where pc(SOA) is the probability of making a correct response at cue delay time SOA, a0 is the asymptotic performance level, a1 is the performance level when SOA=0, and τ is the time constant of memory decay?the time it takes for performance to drop to 37% of its initial level.","20","15/567028","2015-04-14","2018-0098724","2018-04-12","10646155","2020-05-12","OHIO STATE INNOVATION FOUNDATION | ADAPTIVE SENSORY TECHNOLOGY","Zhong-Lin  Lu | Jongsoo  Baek | Luis A.  Lesmes","","","","A61B-0005/4064","A61B-0005/4064 | A61B-0005/162 | A61B-0005/4088 | A61B-0005/7264 | A61B-0005/742 | A61B-0005/7475 | G06F-0003/041 | G06F-0017/18 | G16H-0015/00 | G16H-0050/20","A61B-005/00","A61B-005/00 | G16H-015/00 | A61B-005/16 | G06F-003/041 | G06F-017/18 | G16H-050/20","","","","","","4920020001044"
"US","US","P","B1","Wearable article for determining a task","In aspects of a wearable article for determining a task, a system includes a delivery device usable to administer a liquid responsive to an applied force, and includes a wearable article with multiple sensors to detect movements of the wearable article and handling of the delivery device. A task determination module is implemented to receive sensor data identifying the movements of the wearable article and the applied force, and can determine a task from a set of tasks associated with the delivery device that corresponds to the movements of the wearable article. The task determination module can then determine whether the task was performed correctly based on a comparison of the sensor data to a correct pattern of use for the task.","1. A system, comprising: a delivery device usable to administer a liquid responsive to an applied force, the delivery device including a delivery device tag that uniquely identifies the delivery device;a wearable article worn by a user while the liquid is administered via the delivery device with the applied force, the wearable article comprising: one or more sensors to detect movements of the wearable article and handling of the delivery device;a wearable article tag that uniquely identifies the wearable article, the wearable article tag including memory to store sensor data received from the one or more sensors, the sensor data identifying the movements of the wearable article and the applied force;a task determination module implemented to: receive the sensor data identifying the movements of the wearable article and the applied force from the wearable article tag;determine, from the sensor data, a task from a set of tasks associated with the delivery device that corresponds to the movements of the wearable article; anddetermine whether the task was performed correctly based on a comparison of the sensor data to a correct pattern of use for the task.","20","16/168569","2018-10-23","2020-0121250","2020-04-23","10646161","2020-05-12","MOTOROLA MOBILITY LLC","Sudhir C.  Vissa | Vivek Kumar  Tyagi | Scott Patrick  DeBates | Douglas Alfred  Lautner","","","","A61B-0005/6806","A61B-0005/6806 | A61B-0005/11 | A61M-0005/178 | G06F-0003/014 | G16H-0040/60","A61B-005/00","A61B-005/00 | G06F-003/01 | G16H-040/60 | A61B-005/11 | A61M-005/178","","","","","","4920020001050"
"US","US","P","B2","Stone identification methods and systems","Aspects of stone identification methods and systems are described. According to one aspect, an exemplary method comprises: transmitting to a processing unit, with an imaging element mounted on a distal end of a scope, image data about a stone object inside a body cavity; generating from the image data, with the processing unit, a visual representation of the stone object and the body cavity; establishing from a user input, with the processing unit, a scale for the visual representation; determining from the visual representation, with the processing unit, a size of the stone object on the scale; comparing, with the processing unit, the size of the stone object with a predetermined maximum size to determine a removal status; and augmenting, with the processing unit, the visual representation to include an indicator responsive to the removal status. Associated systems are also described.","1. A method comprising: receiving at a processor, from a camera mounted on a distal end of a scope, image data of a stone object inside a body cavity;generating from the image data, with the processor, a representation of the stone object and the body cavity;determining from the representation, with the processor, a size of the stone object on a scale for the representation;comparing, with the processor, the size of the stone object with a predetermined maximum size to determine a removal status of the stone object by: determining a first removal status when the size of the stone object is greater than the predetermined maximum size; anddetermining a second removal status when the size of the stone object is less than the predetermined maximum size; andaugmenting, with the processor, the representation to include an indicator responsive to the removal status by overlaying either a first indicator onto the representation based on the first removal status or a second indicator onto the representation based on the second removal status.","20","16/445678","2019-06-19","2019-0328349","2019-10-31","10646187","2020-05-12","BOSTON SCIENTIFIC SCIMED, INC.","Peter J.  Pereira | Michael S. H.  Chu | Elizabeth  Stokley | David  Salto | Candace  Rhodes","","","","A61B-0006/5217","A61B-0006/5217 | A61B-0001/0005 | A61B-0001/00009 | A61B-0001/018 | A61B-0001/307 | A61B-0005/1076 | A61B-0005/20 | A61B-0008/085 | A61B-0008/0841 | A61B-0008/12 | A61B-0008/4254 | A61B-0017/2256 | A61B-0018/26 | A61B-0034/25 | G06F-0003/0484 | G06F-0003/0488 | G06T-0011/60 | A61B-0001/00048 | A61B-0017/2255 | A61B-2018/00505 | A61B-2018/00517 | A61B-2018/00982 | A61B-2034/2074 | A61B-2090/061 | A61N-2005/061","A61B-017/22","A61B-017/22 | G06K-009/00 | A61B-006/00 | A61B-017/225 | A61B-001/307 | A61B-008/08 | A61B-001/00 | G06F-003/0488 | G06F-003/0484 | G06T-011/60 | A61B-034/00 | A61B-001/018 | A61B-005/107 | A61B-005/20 | A61B-018/26 | A61B-008/12 | A61B-008/00 | A61B-018/00 | A61B-034/20 | A61N-005/06 | A61B-090/00","","","","","","4920020001076"
"US","US","P","B2","Graphical user interface for a surgical navigation system and method for providing an augmented reality image during operation","Surgical navigation system: 3D display system with see-through visor; a tracking system for real-time tracking of: surgeon's head, see-through visor, patient anatomy and surgical instrument to provide current position and orientation data; a source of an operative plan, a patient anatomy data and a virtual surgical instrument model; a surgical navigation image generator to generate a surgical navigation image with a three-dimensional image representing simultaneously a virtual image of the surgical instrument corresponding to the current position and orientation of the surgical instrument and a virtual image of the surgical instrument, the see-through visor, the patient anatomy and the surgical instrument; the 3D display system configured to show the surgical navigation image at the see-through visor, such that an augmented reality image collocated with the patient anatomy in the surgical field underneath the see-through visor is visible to a viewer looking from above the see-through visor towards the surgical field.","1. A surgical navigation system comprising: a 3D display system with a see-through visor;a tracking system comprising means for real-time tracking of: a surgeon'ss head, the see-through visor, a patient anatomy and a surgical instrument to provide current position and orientation data;a source of an operative plan, a patient anatomy data and a virtual surgical instrument model;a surgical navigation image generator configured to generate a surgical navigation image comprising a three-dimensional image representing simultaneously a virtual image of the surgical instrument corresponding to the current position and orientation of the surgical instrument and a virtual image of the surgical instrument indicating the suggested positions and orientation of the surgical instrument according to the operative plan data based on the current relative position and orientation of the surgeon'ss head, the see-through visor, the patient anatomy and the surgical instrument;wherein the 3D display system is configured to show the surgical navigation image at the see-through visor, such that an augmented reality image collocated with the patient anatomy in the surgical field underneath the see-through visor is visible to a viewer looking from above the see-through visor towards the surgical field,wherein the 3D display system comprises a 3D projector, a plurality of opaque mirrors, an opaque projection screen and a see-through mirror, wherein the 3D projector is configured to project the surgical navigation image towards the plurality of opaque mirrors for reflecting the surgical navigation image towards the opaque projection screen for showing the surgical navigation image for emission towards the see-through mirror, which is partially transparent and partially reflective.","7","16/059061","2018-08-09","2019-0053855","2019-02-21","10646285","2020-05-12","HOLO SURGICAL INC.","Kris B.  Siemionow | Cristian J.  Luciano","2017-186307","EP","2017-08-15","A61B-0034/25","A61B-0034/25 | A61B-0005/7267 | A61B-0034/10 | A61B-0034/30 | A61B-0090/36 | A61B-0090/37 | G02B-0027/017 | G02B-0027/0172 | G06F-0003/012 | G06F-0003/013 | G06T-0005/002 | G06T-0007/11 | G06T-0019/006 | A61B-0034/20 | A61B-2017/00216 | A61B-2034/102 | A61B-2034/105 | A61B-2034/107 | A61B-2034/2055 | A61B-2034/2063 | A61B-2034/2068 | A61B-2090/363 | A61B-2090/365 | A61B-2090/367 | A61B-2090/368 | A61B-2090/3618 | A61B-2090/372 | A61B-2090/3762 | A61B-2090/3983 | A61B-2090/502 | G02B-2027/0134 | G02B-2027/0136 | G02B-2027/0138 | G02B-2027/0178 | G02B-2027/0187 | G02B-2027/0196 | G06K-0009/6257 | G06K-2209/055 | G06T-0007/20 | G06T-2207/10081 | G06T-2207/20081 | G06T-2207/20084 | G06T-2207/30012 | G06T-2207/30208 | G06T-2219/004","G02B-027/01","G02B-027/01 | G06T-007/20 | G06T-019/00 | G06F-003/01 | A61B-090/00 | A61B-034/10 | A61B-090/50 | A61B-034/20 | A61B-034/00 | G06T-007/11 | A61B-005/00 | G06T-005/00 | A61B-034/30 | A61B-017/00 | G06K-009/62","","","","","","4920020001173"
"US","US","P","B2","Device, method, and system to recognize motion using gripped object","A device, a method, and a system recognize a motion using a gripped object. The motion recognition device may estimate a state of a wrist of a user according to a writing action using the gripped object and may estimate a joint motion of a body part related to the wrist according to the writing action. The device may then estimate a state of the gripped object according to the state of the wrist and the joint motion. Additionally, the motion recognition device may control an external device by using a control signal generated by continuously tracking the state of the object.","1. A method for recognizing a motion performed using a gripped object, comprising: estimating a state of a wrist of a user, based on a first sensor configured to be disposed on the wrist of the user, according to a writing action performed using the gripped object;estimating a joint motion of a body part extending from the wrist of the user, based on a second sensor configured to be disposed on the wrist of the user, according to the writing action based on an electrical biomedical signal of the user; andestimating a state of the gripped object according to the joint motion and the state of the wrist,wherein the first sensor comprises an acceleration sensor and the second sensor comprises any one or any combination of any two or more of an electrocardiogram (ECG) sensor, electrooculogram (EOG) sensor, electromyogram (EMG) sensor, and electroencephalogram (EEG) sensor.","22","16/001114","2018-06-06","2018-0284912","2018-10-04","10649549","2020-05-12","Samsung Electronics Co., Ltd.","Sang Joon  Kim | Seung Keun  Yoon | Chang Mok  Choi","10-2013-0068870","KR","2013-06-17","G06F-0003/03545","G06F-0003/03545 | A61B-0005/0488 | A61B-0005/1122 | A61B-0005/681 | A61B-0005/6824 | G06K-0009/00355 | G06K-0009/00536 | G06K-0009/222","G09G-001/00","G09G-001/00 | G06F-003/0354 | G06K-009/00 | G06K-009/22 | A61B-005/0488 | A61B-005/11 | A61B-005/00","","","","","","4920020004414"
"US","US","P","B2","Issue-manage-style internet public opinion information evaluation management system and method thereof","The present invention is related to an issue-manage-style internet public opinion information evaluation management system and method thereof. The system mainly comprises 5 modules of 1) Issue establish/setup module for establishing new issue and the keywords thereof; 2) public opinion information collection module for retrieving and analyzing data retrieved by dredge technology, program, and community web-site open API; 3) public opinion information reputation analysis module for calculating each public opinion information evaluation score by text reputation analysis and community interactive fuzzy analysis; 4) issue trend analysis module for calculating issue trend score by disclosed method based on daily, weekly, or monthly public opinion information reputation evaluation score; 5) issue related public opinion information exchange module for presenting issue related public opinion information on each management interface or message alert of each system via internet exchange standards.","1. An issue-manage-style internet public opinion information evaluation management method, comprising steps of: configuring an issue management web-site server to establish/setup each issue and related keyword;configuring a public opinion information collection and structuring data flow server connecting with the issue management web-site server to receive the keyword and to collect an article in accordance with the keyword, wherein the article is collected from a plurality of heterogeneous data sources and transferred the data into a structured data format for storage by technologies of OFFICE Open XML, format text, international standard of data exchange, dredge technology, social network access interface, or Telnet record;configuring a database server connecting with the public opinion information collection and structuring data flow server connecting with the issue management web-site server to store the structured data format;configuring a feeling dictionary evaluation analysis server connecting with the database server to analyze an article in accordance with the structured data format and using a reputation dual-index positive/negative evaluation analysis method comprising a text reputation index analysis and a community Fuzzy community index analysis to retrieve a first reputation index and a second reputation index, wherein the feeling dictionary evaluation analysis server compares the structured data format with a reputation evaluation dictionary to produce a reputation score, and further uses the text reputation index analysis to calculate the reputation score to produce the first reputation index, and wherein the feeling dictionary evaluation analysis server uses the community Fuzzy community index analysis to analyze the structured data format to produce the second reputation index;generating, by the feeling dictionary evaluation analysis server, a public opinion information evaluation score according to the first reputation index and the second reputation index, wherein the public opinion information evaluation score is a mean or a weighted mean of the first reputation index and the second reputation index; andadjusting, by the feeling dictionary evaluation analysis server, the public opinion information evaluation score by an issue evaluation analysis method and retrieving an issue reputation score mainly related to the issue.","6","14/614167","2015-02-04","2016-0098738","2016-04-07","10650316","2020-05-12","CHUNGHWA TELECOM CO., LTD.","Hua-Tai  Huang | Meng-Hsin  Yang | Po-Wei  Huang","103134690 A","TW","2014-10-06","G06N-0007/005","G06N-0007/005 | A61B-0005/163 | A61B-0005/165 | G06F-0016/93 | G06F-0040/30 | G06K-0009/627 | G06Q-0030/0201 | G06Q-0030/0203 | G06Q-0050/01","G06N-007/00","G06N-007/00 | G06Q-030/02 | A61B-005/16 | G06K-009/62 | G06F-040/30 | G06Q-050/00 | G06F-016/93","","","","","","4920020005179"
"US","US","P","B2","Media content tracking","A method for media content tracking is disclosed. The method includes receiving a user identifier and instructing display systems to display media content based on the user identifier. Each display system has a corresponding screen. The method also includes receiving image data from an imaging system configured to have a field of view arranged to capture images of a user. The method further includes determining gaze characteristics of the user including a gaze target of the user. The method further includes determining whether the gaze target corresponds to one of the screens. When the gaze target corresponds to one of the screens, the method includes determining a time period of gaze engagement with the corresponding screen. The method also includes storing at least one of the gaze characteristics and the media content or an identifier of the media content displayed on the screen corresponding to the gaze target.","1. A method comprising: receiving, at data processing hardware, a user identifier associated with a user, the user identifier associated with the user comprising uniform resource locaters (URLs) indicating a first genre of media content relating to the user;instructing, by the data processing hardware, each of a plurality of display systems to concurrently display a respective genre of media content with a first display system of the plurality of display systems displaying the first genre of media content relating to the user based on the URLs associated with the received user identifier and a second display system of the plurality of display systems displaying a second genre of media content different than the first genre of media content, each of the plurality of display systems having a corresponding screen arranged about the user, and each of the screens concurrently viewable by the user;receiving, at the data processing hardware, image data from an imaging system configured to have a field of view arranged to capture images of the user while the user views the corresponding screens of the plurality of display systems;determining, by the data processing hardware, gaze characteristics of the user based on the image data, the gaze characteristics comprising a gaze target of the user;determining, by the data processing hardware, whether the gaze target corresponds to one of the screens; andwhen the gaze target corresponds to the corresponding screen of the first display system: determining, by the data processing hardware, a time period of gaze engagement with the corresponding screen of the first display system based on the gaze characteristics of the user; andstoring, by the data processing hardware, in memory hardware, gaze-characteristic data comprising: at least one of the gaze characteristics of the user or the time period of gaze engagement with the corresponding screen of the first display system; andthe media content or an identifier of the media content displayed on the corresponding screen of the first display system.","30","15/465022","2017-03-21","2018-0276706","2018-09-27","10650405","2020-05-12","KELLOGG COMPANY","Gustav  Hoffman | Ganapa Sashidhara  Murthy","","","","G06Q-0030/0246","G06Q-0030/0246 | A61B-0005/0077 | A61B-0005/1114 | A61B-0005/163 | A61B-0005/7264 | G06F-0003/013 | G06F-0003/0304 | G06F-0003/1446 | G06K-0009/0061 | G06K-0009/00268 | G06K-0009/00604 | G06Q-0030/02 | H04N-0021/41415 | H04N-0021/4223 | H04N-0021/441 | H04N-0021/44204 | H04N-0021/44218 | H04N-0021/44222 | H04N-0021/4532 | A61B-2503/12 | A61B-2576/00","G09G-005/00","G09G-005/00 | G06Q-030/02 | G06K-009/00 | G06F-003/14 | H04N-021/414 | H04N-021/441 | H04N-021/45 | A61B-005/00 | H04N-021/4223 | G06F-003/03 | H04N-021/442 | G06F-003/01 | A61B-005/11 | A61B-005/16","","","","","","4920020005268"
"US","US","P","B2","System and method for authenticating wireless programming devices in programmable medical systems","A medical device of a medical system is configured for communicating with an external programmer over a wireless communications link. The medical device comprises a wireless communications module configured for receiving a first unencrypted version of a random number and a first encrypted version of the random number from the external programmer over the wireless communications link. The medical device further comprises control circuitry configured for performing an authentication procedure on the external programmer based on the first unencrypted version of the random number and the first encrypted version of the random number, and preventing the external programmer from commanding the medical device to perform an action unless the authentication procedure is successful.","1. A medical device of a medical system configured for communicating with an external programmer over a wireless communications link, the medical device comprising: a wireless communications module configured for concurrently receiving a first unencrypted version of a random number and a first encrypted version of the random number from the external programmer over the wireless communications link; andcontrol circuitry configured for performing an authentication procedure on the external programmer and preventing the external programmer from commanding the medical device to perform an action unless the authentication procedure is successful, wherein the authentication procedure comprises at least one of the following:generating a second encrypted version of the random number from the first unencrypted version of the random number, comparing the first and second versions of the encrypted random number, and determining if the first and second versions of the encrypted random number match; anddecrypting the first encrypted version of the random number to recover a second unencrypted version of the random number, comparing the first and second versions of the unencrypted random number, and determining if the first and second versions of the unencrypted random number match.","28","15/452339","2017-03-07","2017-0257761","2017-09-07","10652740","2020-05-12","THE ALFRED E. MANN FOUNDATION FOR SCIENTIFIC RESEARCH","Saul  Rodriguez | Dianna (Dan)  Han | Emil  Istoc","","","","H04W-0012/06","H04W-0012/06 | A61B-0005/0024 | A61B-0005/0031 | A61F-0002/72 | A61N-0001/37252 | G16H-0040/40 | H04L-0009/3271 | H04L-0063/061 | H04L-0063/0869 | H04L-0067/12 | H04L-0067/141 | H04L-0067/20 | H04L-0069/40 | H04Q-0009/00 | H04W-0012/003 | H04W-0012/04 | A61B-0005/0004 | A61B-0005/04888 | G06F-0021/6245 | G08C-2201/60 | H04L-0063/0428 | H04L-0063/06 | H04L-2209/80 | H04L-2209/88 | H04Q-2209/43","H04L-029/06","H04L-029/06 | H04W-012/06 | G16H-040/40 | A61B-005/00 | A61F-002/72 | H04Q-009/00 | H04W-012/04 | H04L-029/08 | A61N-001/372 | H04L-009/32 | H04L-029/14 | H04W-012/00 | A61B-005/0488 | G06F-021/62","","","","","","4920020007578"
"US","US","P","B2","Method, system and computer readable medium for assessing actionable glycemic risk","A system, method and non-transient computer readable medium for assessing the opportunity to address either hyperglycemic or hypoglycemic risk (or both) in patients with diabetes based on historical continuous glucose monitoring (CGM) data.","1. A method for assessing actionable glycemic risk comprising: obtaining an output continuous glucose monitoring (BG) signal at a time t;determining a glycemic cost signal at the time t based on the output continuous glucose monitoring BGsignal with a glycemic cost function algorithm that attributes equal cost to each of two end points (BGtarget,lo, BGtarget,hi) of a desired blood glucose target range;using the glycemic cost signal to quantify actionable risk and unaddressable risk by determining an instantaneous hypoglycemia risk at the time t and an instantaneous hyperglycemia risk at the time t based on the glycemic cost signal, wherein actionable risk includes actionable hypoglycemia risk and actionable hyperglycemia risk;averaging each of the instantaneous hypoglycemia risk and the instantaneous hyperglycemia risk over a defined interval to determine a moving average hypoglycemia risk and a moving average hyperglycemia risk;averaging each of the moving average hypoglycemia risk and the moving average hyperglycemia risk across multiple days to generate a hypoglycemia risk profile (lop(s)) and a hyperglycemia risk profile (hip(s)) at time s of the day;administering insulin to a patient, via an insulin device, based on the generated hypoglycemia risk profile (lop(s)) and hyperglycemia risk profile (hip(s)).","17","15/551503","2016-02-16","2018-0020988","2018-01-25","10638981","2020-05-05","UNIVERSITY OF VIRGINIA PATENT FOUNDATION","Stephen D  Patek","","","","A61B-0005/7275","A61B-0005/7275 | A61B-0005/14532 | A61B-0005/4839 | A61B-0005/7225 | A61M-0005/1723 | G06F-0019/3468 | G16H-0050/30 | A61M-2205/3584 | G06F-0017/12 | G06F-0019/3418","A61B-005/00","A61B-005/00 | G16H-050/30 | A61B-005/145 | A61M-005/172 | G06F-019/00 | G06F-017/12","","","","","","4920019001068"
"US","US","P","B2","Image capture and identification system and process","An image-based transaction system includes a mobile device with an image sensor that is programmed to capture, via the image sensor, a video stream of a scene. The mobile device identifies a document using image characteristics from the video stream and acquires an image of at least a part of the document, and then identifies symbols in the image based on locations within the image of the document. The symbols can include alphanumeric symbols. The mobile device processes the symbols according to their type to obtain an address related to the document and the symbols and initiates a transaction associated with the identified document.","1. An image-based transaction system: a mobile device having an image sensor, wherein the mobile device, when software in the mobile device is executed, is caused to execute operations comprising: digitally capturing a video stream of a scene via the image sensor;identifying a document using image characteristics from the digitally captured video stream;automatically acquiring an image of at least part of the document in the scene;identifying symbols, including alphanumeric symbols, in the image based on locations within the image of the document;processing the symbols according to their symbol type;obtaining an address related to the identified document and the processed symbols; andinitiating a transaction associated with the identified document and with the address via a server.","53","16/577910","2019-09-20","2020-0016003","2020-01-16","10639199","2020-05-05","NANT HOLDINGS IP, LLC","Wayne C.  Boncyk | Ronald H.  Cohen","","","","A61F-0009/08","A61F-0009/08 | A63F-0013/00 | A63F-0013/20 | A63F-0013/213 | A63F-0013/335 | A63F-0013/35 | A63F-0013/45 | A63F-0013/65 | A63F-0013/70 | A63F-0013/792 | A63F-0013/92 | G06F-0003/0482 | G06F-0016/24 | G06F-0016/29 | G06F-0016/50 | G06F-0016/51 | G06F-0016/583 | G06F-0016/5838 | G06F-0016/5846 | G06F-0016/5854 | G06F-0016/5866 | G06F-0016/94 | G06F-0016/9554 | G06F-0016/9558 | G06F-0017/2235 | G06K-0009/0063 | G06K-0009/00536 | G06K-0009/00664 | G06K-0009/00671 | G06K-0009/18 | G06K-0009/228 | G06K-0009/3241 | G06K-0009/34 | G06K-0009/46 | G06K-0009/4652 | G06K-0009/4671 | G06K-0009/6201 | G06K-0009/6202 | G06K-0009/6203 | G06K-0009/6212 | G06K-0009/6215 | G06K-0009/6218 | G06K-0009/6262 | G06K-0009/64 | G06K-0009/78 | G06Q-0010/02 | G06Q-0020/102 | G06Q-0020/14 | G06Q-0020/202 | G06Q-0020/208 | G06Q-0020/24 | G06Q-0020/327 | G06Q-0020/3567 | G06Q-0020/40145 | G06Q-0030/0217 | G06Q-0030/0241 | G06Q-0030/0253 | G06Q-0030/0257 | G06Q-0030/0267 | G06Q-0030/0268 | G06Q-0030/0269 | G06Q-0030/0277 | G06Q-0030/04 | G06Q-0030/0601 | G06Q-0030/0623 | G06Q-0030/0635 | G06Q-0030/0643 | G06Q-0040/00 | G06Q-0090/00 | G06T-0007/10 | G06T-0007/11 | G06T-0007/13 | G06T-0007/136 | G06T-0007/194 | G06T-0007/246 | G06T-0007/33 | G06T-0007/337 | G06T-0007/73 | G07F-0017/3206 | G07F-0017/3241 | G07F-0017/3244 | G09B-0021/006 | H04L-0067/02 | H04L-0067/10 | H04N-0001/00244 | H04N-0005/225 | H04N-0005/23206 | H04N-0005/23222 | H04N-0005/23229 | H04N-0005/91 | H04N-0007/183 | H04N-0007/185 | H04N-0021/23109 | H04N-0021/23418 | H04N-0021/254 | H04N-0021/41407 | H04N-0021/4223 | H04N-0021/44222 | H04N-0021/4722 | H04N-0021/4781 | H04N-0021/4782 | H04N-0021/47815 | H04N-0021/6582 | H04N-0021/812 | H04N-0021/8126 | H04N-0021/8173 | H04N-2201/3253 | H04N-2201/3254 | H04N-2201/3274","G06F-016/51","G06F-016/51 | G06Q-030/06 | A61F-009/08 | G06F-016/93 | G06F-016/583 | G06F-016/58 | G06F-016/955 | G06K-009/22 | G06K-009/46 | G06K-009/62 | G06Q-030/02 | G06Q-040/00 | H04N-005/232 | H04N-021/231 | H04N-021/234 | H04N-021/414 | H04N-021/4223 | H04N-021/4722 | H04N-021/4782 | H04N-021/658 | G06T-007/73 | G06T-007/10 | G06T-007/194 | G06K-009/78 | G06K-009/00 | H04N-005/225 | G06Q-020/40 | H04N-007/18 | A63F-013/00 | H04N-021/81 | G06K-009/32 | H04N-021/254 | H04N-021/442 | G06Q-010/02 | G06Q-020/24 | G06Q-020/34 | G06F-003/0482 | H04N-001/00 | H04N-005/91 | G06Q-090/00 | G06K-009/64 | H04L-029/08 | G06K-009/18 | G06F-017/22 | G06Q-020/20 | G06Q-020/32 | A63F-013/45 | G06Q-020/10 | G06Q-020/14 | G07F-017/32 | H04N-021/478 | A63F-013/213 | A63F-013/335 | A63F-013/35 | A63F-013/65 | A63F-013/792 | A63F-013/92 | G06Q-030/04 | G06K-009/34 | G06T-007/13 | G06T-007/33 | A63F-013/70 | G09B-021/00 | G06T-007/11 | G06T-007/136 | G06T-007/246 | A63F-013/20 | G06F-016/24 | G06F-016/29 | G06F-016/50","","","","","","4920019001286"
"US","US","P","B2","Systems, apparatuses, devices, and processes for synergistic neuro-physiological rehabilitation and/or functional development","A system for facilitating a subject's functional development includes sensing devices configured for sensing mind state signals; sensing devices configured for sensing body state signals; and a set of processing resources configured for generating a mind state indicator/measure, a body state indicator/measure, and a mind-body synergy indicator/measure that corresponds to which each of the subject's mind state and body state are synergistically aligned for facilitating the subject's functional development. The system can be configured for concurrently presenting a set of activities involving a model body part; engaging in attempted imitation of the set of activities by way of attempted movement of a body part that is a mirror image of the model body part; presenting an indication of an extent to which each of the mind state and body state are cooperative with respect to performance of the set of activities; and presenting an indication of relaxation.","1. A system for facilitating rehabilitation of a body part of a subject, the system comprising: a first set of sensing devices configured for sensing signals corresponding to the subject'ss mind state;a second set of sensing devices configured for sensing signals corresponding to the subject'ss body state; a subject interaction unit comprising a set of display devices configured for providing a visual interface to the subject, the visual interface comprising: a biofeedback interface configured for presenting biofeedback to the subject while the first set of sensing devices senses signals corresponding to the subject'ss mind state and the second set of sensing devices senses signals corresponding to the subject'ss body state, the biofeedback comprising a visual representation of a measure of subject relaxed mental attention, and a visual representation of a measure of subject bodily tension, anda functional development activity sequence interface configured for presenting a set of functional development activities to the subject while the biofeedback interface presents the biofeedback to the subject, wherein the set of functional development activities shows at least one target movement of a model body part that is a mirror image of the subject body part;a set of processing resources, wherein the set of processing resources is configured for generating: a mind state alignment measure indicating whether the subject'ss mind state is conducive to learning,a body state alignment measure indicating the subject'ss body state is conducive to successfully perform the set of functional development activities, anda mind-body synergy measure correlated with a voluntary muscle contraction measure that meets or exceeds a threshold muscle contraction condition, and which is temporally associated with each of the mind statement alignment measure satisfying a mind state alignment condition and the body state alignment measure satisfying a body state alignment condition;at least one of a robotic orthosis configured for providing movement assistance to the subject and a functional electrical stimulation (FES) apparatus configured for delivering FES signals to the subject;wherein the biofeedback interface is configured for providing a visual representation of the mind state alignment measure and a visual representation of the body state alignment measure; andwherein the visual interface is configured for selectively presenting mind state training exercises to the subject following processing unit determination that a subject muscle contraction relevant to performing the set of functional development activities has occurred and the subject'ss mind state is not conducive to learning, and body state training exercises to the subject following processing unit determination that the subject'ss mind state is conducive to learning and the subject'ss body state is not conducive to successfully perform the set of functional development activities.","44","14/118772","2012-05-21","2014-0200432","2014-07-17","10639235","2020-05-05","C/O NANYANG TECHNOLOGICAL UNIVERSITY","Subhasis  Banerji | Kok Hui John Gerard  Heng","","","","A61H-0099/00","A61H-0099/00 | A61B-0005/0478 | A61B-0005/0482 | A61B-0005/0488 | A61B-0005/1125 | A61B-0005/162 | A61B-0005/165 | A61B-0005/743 | A61B-0005/7445 | A61M-0021/02 | A63B-0021/00181 | A63B-0021/4017 | A63B-0021/4019 | A63B-0021/4035 | A63B-0021/4045 | A63B-0024/0059 | A63B-0024/0062 | A63B-0071/0622 | G06F-0003/014 | G06F-0003/015 | G06F-0019/3418 | G06F-0019/3481 | G09B-0019/003 | G16H-0050/30 | A61B-0005/048 | A61B-0005/04888 | A61B-0005/1107 | A61B-0005/224 | A61B-0005/7475 | A61B-2505/09 | A61N-0001/36003 | A63B-0023/1209 | A63B-0023/14 | A63B-2022/0094 | A63B-2024/0065 | A63B-2024/0068 | A63B-2024/0096 | A63B-2071/0647 | A63B-2071/0655 | A63B-2213/004 | A63B-2225/20 | A63B-2225/50 | A63B-2230/06 | A63B-2230/08 | A63B-2230/10 | A63B-2230/207 | A63B-2230/30 | A63B-2230/42 | A63B-2230/60","A61H-099/00","A61H-099/00 | A61B-005/0478 | G16H-050/30 | A61B-005/0488 | A61B-005/16 | A61B-005/0482 | A63B-024/00 | A63B-071/06 | G06F-003/01 | G06F-019/00 | G09B-019/00 | A63B-021/00 | A61B-005/00 | A61B-005/11 | A61M-021/02 | A61N-001/36 | A61B-005/22 | A63B-023/14 | A63B-023/12 | A63B-022/00 | A61B-005/048","","","","","","4920019001321"
"US","US","P","B2","Systems and methods for biometrically authenticating a user using authentication data and liveness data","Systems and methods for biometrically authenticating a user are disclosed. In one implementation, a biometric authentication system may include a finger scanner for capturing biometric data from a plurality of sections of a finger of a user. The finger may include a distal section, a medial section, and a proximal section. The biometric authentication system may further include one or more processors configured to cause the finger scanner to capture the biometric data from the plurality of sections of the finger of the user. The biometric data may include authentication data and liveness data. The processors may be further configured to access registered authentication data associated with the user, determine whether the captured authentication data matches the authentication biometric data, and determining, using the captured liveness data, whether the finger is a live finger. Additionally, the processors may be configured to authenticate the user after the captured authentication data is determined to match the registered authentication data and after the finger is determined to be a live finger.","1. A biometric authentication system, comprising: a finger scanner for capturing biometric data from a plurality of sections of a finger of a user, the finger including a distal section, a medial section, and a proximal section at a same time; andone or more processors configured to: cause the finger scanner to simultaneously capture the biometric data from each of the plurality of sections of the finger of the user, wherein the biometric data includes both authentication data and liveness data, where the liveness data includes data indicative of each of a blood flow in the finger, a temperature of the finger and one of a heart rate or a pulse in the finger;access registered authentication data associated with the user;determine whether the captured authentication data from each of the plurality of finger sections matches the registered authentication biometric data;determine, using the captured liveness data, whether the finger is a live finger; andauthenticate the user after the captured authentication data is determined to match the registered authentication data and after the finger is determined to be a live finger.","15","15/857575","2017-12-28","2018-0211094","2018-07-26","10643057","2020-05-05","Warren M. Shadd","Warren M.  Shadd","","","","G06K-0009/00114","G06K-0009/00114 | A61B-0005/1172 | A61B-0005/489 | G06F-0021/32 | G06K-0009/00006 | G06K-0009/00067 | G06K-0009/00107 | G06K-0009/00892 | A61B-0005/02 | G06K-2009/00932 | G06K-2009/00939","G06K-009/00","G06K-009/00 | A61B-005/00 | G06F-021/32 | A61B-005/1172 | A61B-005/02","","","","","","4920019005113"
"US","US","P","B2","Detecting unauthorized visitors","An unauthorized visitor system collects an image of a person detected in a room of a patient. The system identifies reference points on the person's face, for example, points along the cheeks, jowls, and/or brow. The system may compare the reference points to reference points of images associated with registered visitors. The system then determines, based on the comparison, if the person is a registered visitor. One or more designated recipients may be alerted if the person is not a registered visitor or if the person breaches a patient identification zone established around a particular patient. The system may also register the person in a database of visitors.","1. A system for detecting unauthorized visitors, the system comprising: one or more 3D motion sensors located to provide the one or more 3D motion sensors with a view of a person and surrounding area to be monitored; anda computerized monitoring system communicatively coupled to the one or more 3D motion sensors, the computerized monitoring system configured to: receive images of the area to be monitored from the one or more 3D motion sensors;detect when a visitor enters the view of the one or more 3D motion sensors;receive a plurality of registered reference points on faces of registered visitors from a remote database;assign a plurality of reference points on the face of the visitor in one or more images from the one or more 3D motion sensors,determine whether the visitor is an unauthorized visitor by comparing positions, distances between, sizes, or shapes of the reference points to positions, distances between, sizes, or shapes of the reference points of the plurality of registered reference points on faces of registered visitors, wherein the visitor is determined to be an unauthorized visitor when it is determined that the visitor is not registered;initiate an alert being sent to one or more designated recipients; andcreate a recognition profile for the visitor upon determining the visitor is not registered.","15","16/454508","2019-06-27","2019-0318149","2019-10-17","10643061","2020-05-05","CERNER INNOVATION, INC.","Michael  Kusens | Neil  Kusens","","","","G06K-0009/00208","G06K-0009/00208 | A61B-0005/0077 | A61B-0005/11 | A61B-0005/1176 | A61B-0005/4064 | A61B-0005/746 | G06F-0019/00 | G06F-0019/3456 | G06K-0009/00288 | G06K-0009/00335 | G06K-0009/00771 | G06K-0009/4604 | G06K-0009/52 | G06K-0009/6215 | G06T-0007/0012 | G06T-0007/0016 | G06T-0007/20 | G06T-0007/292 | G06T-0011/60 | G08B-0005/22 | G08B-0013/196 | G08B-0021/182 | G08B-0025/009 | G16H-0010/60 | G16H-0015/00 | G16H-0020/10 | G16H-0030/20 | G16H-0040/63 | G16H-0040/67 | G16H-0050/30 | G16H-0080/00 | H04N-0005/23293 | H04N-0007/18 | H04N-0007/181 | H04N-0007/183 | H04N-0013/204 | H04N-0013/207 | G06F-0003/0482 | G06F-0003/04847 | G06K-0009/00228 | G06T-2200/04 | G06T-2200/24 | G06T-2207/10012 | G06T-2207/10021 | G06T-2207/10024 | G06T-2207/20221 | G06T-2207/30201 | G06T-2207/30232 | G08B-0013/19639 | G08B-0021/0476 | H04N-2013/0085","H04N-007/18","H04N-007/18 | G06K-009/00 | G08B-005/22 | G08B-025/00 | G08B-021/18 | G06F-019/00 | G06T-007/292 | G06T-007/20 | G06K-009/46 | G16H-040/63 | G16H-010/60 | H04N-013/204 | H04N-013/207 | A61B-005/00 | A61B-005/11 | G06K-009/62 | G06T-007/00 | G06T-011/60 | H04N-005/232 | A61B-005/1171 | G06K-009/52 | G08B-013/196 | G16H-030/20 | G16H-015/00 | G16H-080/00 | G16H-040/67 | G16H-050/30 | G16H-020/10 | G08B-021/04 | H04N-013/00 | G06F-003/0482 | G06F-003/0484","","","","","","4920019005117"
"US","US","P","B2","Treatment procedure planning system and method","A system and method for planning surgical procedure including a treatment zone setting view presenting at least one slice of a 3D reconstruction generated from CT image data including a target. The treatment zone setting view presenting a treatment zone marker defining a location and a size of a treatment zone and configured to adjust the treatment zone marker in response to a received user input. The system and method further including a volumetric view presenting a 3D volume derived from the 3D reconstruction and a 3D representation of the treatment zone marker relative to structures depicted in the 3D volume.","1. A system for planning a treatment procedure, the system comprising: a computing device including a memory and a processor; anda program stored in the memory that, when executed by the processor, causes the processor to present a user interface that guides a user through the planning of the treatment procedure, the user interface including:a treatment zone setting view presenting at least one slice of a 3D reconstruction generated from CT image data including a target,the treatment zone setting view further presenting a treatment zone marker defining a location and a size of a treatment zone,the treatment zone setting view configured to adjust the location and the size of the treatment zone defined by the treatment zone marker in response to received treatment zone marker adjustment user inputs,wherein the treatment zone setting view includes a 2D representation of an instrument,wherein in response to the received treatment zone marker adjustment user input an orientation and a position of the 2D representation of the instrument are adjusted relative to the at least one slice of the 3D reconstruction, andwherein the treatment zone setting view includes a user-selectable power level setting having a corresponding predetermined size limit, and an alert is generated when the size of the treatment zone defined by the treatment zone marker is adjusted to exceed the predetermined size limit corresponding to the user-selectable power level setting; anda volumetric view presenting a 3D rendering derived from the 3D reconstruction and a 3D representation of the treatment zone marker relative to structures depicted in the 3D rendering.","16","14/821912","2015-08-10","2016-0038247","2016-02-11","10643371","2020-05-05","COVIDIEN LP","Jeetendra  Bharadwaj | Kevin J.  Frank | Darren G.  Girotto | Benjamin M.  Corum","","","","G06T-0015/08","G06T-0015/08 | A61B-0006/032 | A61B-0034/10 | A61B-0090/10 | G06F-0003/0481 | G06F-0003/04842 | G06F-0003/04847 | G06T-0007/0012 | G06T-0019/00 | A61B-0006/12 | A61B-0006/463 | A61B-0006/465 | A61B-0006/469 | A61B-0006/487 | A61B-0006/5235 | A61B-0034/25 | A61B-2018/00577 | A61B-2034/101 | A61B-2034/102 | A61B-2034/105 | A61B-2034/107 | A61B-2560/0475 | A61B-2576/00 | A61N-0005/1001 | A61N-0005/103 | A61N-2005/1074 | G06T-2200/24 | G06T-2207/10081 | G06T-2207/20108 | G06T-2210/41 | G06T-2219/028","G06T-015/08","G06T-015/08 | A61B-090/10 | G06T-019/00 | A61B-034/10 | A61B-006/03 | G06F-003/0481 | G06F-003/0484 | G06T-007/00 | A61B-006/00 | A61B-006/12 | A61N-005/10 | A61B-034/00 | A61B-018/00","","","","","","4920019005427"
"US","US","P","B2","Physical activity coaching platform with dynamically changing workout content","A computer implemented coaching platform is described that utilizes contextual data associated with a user and/or his environment in order to provide dynamically changing content while the user is undergoing physical activity. Related apparatus, systems, techniques and articles are also described.","1. An electronic coaching platform comprising: an electronic content authoring tool comprising non-transitory machine-readable instructions that are executable on a computer, the content authoring tool being configured to: electronically receive a routine definition of a routine of an activity, the routine definition having one or more segments, each segment including at least one of a segment parameter, a segment goal, and a segment prompt library, the segment parameter including at least one of a duration, a distance, and an intensity defining the routine, wherein the routine definition includes one or more no-scoring segments of the one or more segments that do not have an associated segment goal,retrieve, based on a received selection by a user, at least part of the routine definition to download to an electronic device associated with the user,format the routine definition in a non-transitory machine-readable format for electronic transmission via a communications network from the computer,store each formatted routine definition in a local memory,receive biofeedback data from one or more sensors associated with the user and connected with the electronic device, the biofeedback data providing at least one contextual attribute associated with the user while performing the routine to analyze the at least one contextual attribute based on a segment goal of the routine definition to determine a state of the user during each segment of the routinecalculate a routine score based on the biofeedback data indicating how the user is able to follow and achieve segment goals defined by the routine definition, andadjust the routine score, based on the biofeedback data; anda workout store in digital communication with the local memory of the content authoring tool to receive one or more routine definitions defined by the content authoring tool in the non-transitory machine-readable format, the workout store configured to:store the one or more routine definitions and metadata associated with the one or more routine definitions in a database,organize the stored one or more routine definitions and metadata for access by a workout engine hosted on the electronic device associated with the user, the workout engine being configured to select one or more prompts from the segment prompt library based on the state of the user or the user'ss performance of the routine and the routine score, the prompt including sensory feedback information associated with the routine, the sensory feedback information being formatted as a combination of visual feedback, auditory feedback, and tactile feedback.","21","15/017537","2016-02-05","2016-0151674","2016-06-02","10643483","2020-05-05","PEAR SPORTS LLC","Kari Kristian  Rauhala | Simon  Sollberger | Joseph  Rzepiejewski | Eric  Franchomme | Robert G.  Allison","","","","G09B-0005/04","G09B-0005/04 | G06F-0019/3481 | G06Q-0010/0639 | G06Q-0030/0251 | G06Q-0030/0269 | A61B-0005/024 | A61B-0005/742 | A63B-0024/0075 | G09B-0019/003","G09B-005/00","G09B-005/00 | G09B-005/04 | G06F-019/00 | G06Q-010/06 | G06Q-030/02 | A61B-005/024 | A61B-005/00 | A63B-024/00 | G09B-019/00","","","","","","4920019005538"
"US","US","P","B2","Drug delivery device state recognition","A method of detecting and/or tracking use of a drug delivery device is disclosed. The drug delivery device includes a machine readable code and a visual indicator, and has pre-use and used states, such that use of the drug delivery device triggers a transition from the pre-use to the used state. The visual indicator has a first state when the drug delivery device is in the pre-use state and a different second state when the drug delivery device is in the used state. The method includes enabling a user device having an image sensor to capture an image of the drug delivery device, determining, by the user device processor from the captured image, whether the visual indicator of the drug delivery device is in the second state, and obtaining, by the processor, information from the machine readable code when the visual indicator is determined to be in the second state.","1. A method of detecting or tracking use of a drug delivery device, the drug delivery device including a machine readable code and a visual indicator, the drug delivery device having a pre-use state and a used state, such that use of the drug delivery device triggers a transition from the pre-use state to the used state, wherein the visual indicator is a color or image provided on at least one component of the drug delivery device and has a first state when the drug delivery device is in the pre-use state and a different second state when the drug delivery device is in the used state, the method comprising: enabling a user device having an image sensor to capture one or more images of the drug delivery device;determining, by a processor of the user device from at least one of the one or more captured images, whether the visual indicator of the drug delivery device is in the second state by determining whether the color or image is present in the at least one of the one or more captured images; andobtaining, by the processor of the user device, information from the machine readable code in response to the determination that the visual indicator is in the second state.","12","15/999805","2017-02-22","2019-0341136","2019-11-07","10643744","2020-05-05","WEST PHARMACEUTICAL SERVICES, INC.","Kevin  Hopper | Stacy  Faught | Christopher  Evans | Brian  Costello | Raymond  Protasiewicz","","","","G16H-0020/17","G16H-0020/17 | A61M-0005/31 | A61M-0005/3204 | A61M-0005/326 | G06K-0007/10722 | G06K-0007/1413 | G06K-0009/00664 | A61M-2005/3267 | A61M-2205/18 | A61M-2205/3306 | A61M-2205/3592 | A61M-2205/6054 | A61M-2205/6072 | A61M-2205/6081","G06Q-090/00","G06Q-090/00 | G16H-020/17 | A61M-005/31 | A61M-005/32 | G06K-007/10 | G06K-007/14 | G06K-009/00","","","","","","4920019005793"
"US","US","P","B2","Systems and methods for optimizing parameters of orthopaedic procedures","Systems and methods for optimizing parameters of an orthopaedic procedure for a particular patient, including parameters relating to the anatomic and biomechanic fit of an implant or implant system implanted into the patient's joint. These systems and methods may utilize patient-specific information gathered pre-operatively in conjunction with optimization algorithms to determine an optimal implant design and an optimal position and orientation for implantation of the implant into the particular patient's joint.","1. A computer-implemented method of optimizing parameters of a joint procedure involving the implantation of at least one orthopaedic implant into a joint of a particular patient, the method comprising: (a) receiving, in a computer processor, information concerning the particular patient, including information relating at least in part to a model of the particular patient'ss joint;(b) determining, using an optimization algorithm, a suggested optimal general size group for the orthopaedic implant based on one or more dimensional measurements of the model, wherein the suggested optimal general size group is one of a plurality of possible general size groups for the orthopaedic implant and each general size group comprises a plurality of different anatomic size options and each different anatomic size option comprises a plurality of different biomechanical size options;(c) determining, using a biomechanical fit optimization algorithm, an optimal biomechanical size option included in the plurality of possible general size groups and at least one of a suggested optimal position and a suggested optimal orientation for the orthopaedic implant relative to the particular patient'ss joint based on the information relating to the model, the information relating to the suggested optimal general size group determined in step (b), and one or more desired performance outcomes of the joint procedure relating to the particular patient'ss gross motor skills;(d) determining, using an anatomic fit optimizer, an optimal anatomic size option included in the plurality of possible general size groups and a suggested anatomic fit geometry for the orthopaedic implant based on the information relating to the model, the information relating to the suggested optimal general size group determined in step (b), and information relating to the at least one of the suggested optimal position and the suggested optimal orientation determined in step (c);(e) if at least one of the optimal biomechanical size option and optimal anatomic size option are not part of the suggested optimal general size group, updating the suggested optimal general size group based on the optimal biomechanical size option and optimal anatomic size option and performing steps (c)-(e); and(f) outputting from the computer processor the information relating to the suggested optimal general size group and information relating to the suggested anatomic fit geometry wherein the determining of step (c) is performed subsequent to the determining of step (b) and prior to the determining of step (d).","21","13/814648","2011-08-15","2013-0226190","2013-08-29","10631932","2020-04-28","SMITH & NEPHEW, INC.","Brian W.  Mckinnon | Ruxandra Cristiana  Marinescu Tanasoca | Randy C.  Winebarger | William L.  Bowers, Jr. | James Bennett  Wiebe, III | Nathaniel Milton  Lenz | Zachary Christopher  Wilkinson | Sean M.  Haddock | Ryan Lloyd  Landon","","","","A61B-0034/10","A61B-0034/10 | A61F-0002/46 | G09B-0023/28 | A61B-0005/107 | A61F-0002/38 | A61F-0002/44 | A61F-2002/30616 | A61F-2002/4633 | G06F-0017/50","G09B-023/28","G09B-023/28 | A61B-034/10 | A61F-002/46 | A61B-005/107 | A61F-002/38 | A61F-002/44 | A61F-002/30 | G06F-017/50","","","","","","4920018001202"
"US","US","P","B2","Method and electronic device for determining whether to allow user access","The disclosure relates to a method for determining whether to allow user access at an electronic device comprising: detecting a touch by an object on a touch-sensitive area of the electronic device, in which a plurality of electrode pairs are mounted, the plurality of electrode pairs including a first set of electrode pairs and a second set of electrode pairs; determining a subset of the first set of electrode pairs that are in contact with a part of the object; receiving electrical signals from each pair of the determined subset; calculating impedance values of respective parts of the object on the basis of the received electrical signals; determining a ratio of the calculated impedance values for each pair of electrode pairs disposed on mutually perpendicular lines from said the determined subset, and, when a first impedance value for one electrode pair included in electrode pairs disposed on the mutually perpendicular lines is greater than a second impedance value for the other electrode pair in the electrode pairs, the ratio of the calculated impedance values is a ratio of the first impedance to the second impedance; selecting two pairs of electrode pairs disposed on the mutually perpendicular lines with the maximum ratio of the calculated impedance values; and when the maximum ratio exceeds a predetermined threshold, identifying the object as a living tissue object, and allow access on the electronic device.","1. A method for determining whether to allow user access based on a user input at an electronic device, the method comprising: detecting a touch by an object on a touch-sensitive area of the electronic device, in which a plurality of electrode pairs are mounted, the plurality of electrode pairs including a first set of electrode pairs and a second set of electrode pairs;determining a subset of the first set of electrode pairs that are in contact with a part of the object;receiving electrical signals from each pair of the determined subset;calculating impedance values of respective parts of the object based on the received electrical signals;determining a ratio of the calculated impedance values for each pair of electrode pairs disposed on mutually perpendicular lines from the determined subset, and, when a first impedance value for one electrode pair included in electrode pairs disposed on mutually perpendicular lines is greater than a second impedance value for the other electrode pair in the electrode pairs, the ratio of the calculated impedance values is a ratio of the first impedance value to the second impedance value;selecting two pairs of electrode pairs disposed on mutually perpendicular lines with a maximum ratio of the calculated impedance values; andwhen the maximum ratio exceeds a predetermined threshold, identifying the object as a living tissue object, and allow access on the electronic device.","18","15/851612","2017-12-21","2018-0181734","2018-06-28","10635797","2020-04-28","SAMSUNG ELECTRONICS CO., LTD.","Maksim Alexeevich  Vilenskii | Andrey Vladimirovich  Kletsov | Aleksei Andreevich  Gavron | Alexander Gennadyevich  Chernokalov","20160151280","RU","2016-12-26","G06F-0021/32","G06F-0021/32 | A61B-0005/0531 | A61B-0005/1172 | G06F-0003/044 | G06F-0003/0416 | G06F-0021/31 | G06F-0021/45 | G06K-0009/0002 | G06K-0009/0012 | A61B-0005/6897","G06F-021/00","G06F-021/00 | G06F-021/32 | A61B-005/1172 | G06K-009/00 | G06F-003/044 | G06F-003/041 | A61B-005/053 | G06F-021/31 | G06F-021/45 | A61B-005/00","","","","","","4920018005042"
"US","US","P","B2","Foot vein authentication device","Disclosed is a foot vein authentication device comprising: a body part having a front surface and a rear surface and on which the foot of a user is placed on the front surface; a sensor unit arranged on any one area of the body part and formed so as to detect a vein pattern on the inside of the foot of the user; and a control unit for carrying out a user authentication procedure by comparing the vein pattern received from the sensor unit, with the pre-stored vein pattern of the user, wherein the sensor unit comprises: a light source unit for emitting infrared rays at the inside of the foot of the user; and an image acquisition unit for acquiring, as an image, the vein pattern on the inside of the foot of the user, at which the infrared rays are emitted, so as to transmit the same to the control unit.","1. A foot vein authentication device, comprising: a body part having a front surface and a rear surface, wherein a user'ss foot is placed on the front surface;a sensor unit disposed in one area of the body part to detect a vein pattern inside the user'ss foot; anda controller to perform a user authentication procedure by comparing the vein pattern received from the sensor unit with a restored user vein pattern, wherein the sensor unit comprises:a light source unit to irradiate infrared rays to the inside of the user'ss foot; andan image acquisition unit to acquire, as an image, the vein pattern of the inside of the user'ss foot to which the infrared rays are irradiated and transfer the acquired vein pattern image to the controller,wherein the sensor unit is disposed in a lower portion of the front surface so as to be covered with the body part,wherein the body part is provided with a light-transmissive layer disposed on the front surface and made of a transparent material so as to allow movement of light between the sensor unit and the user'ss foot, andwherein the light-transmissive layer is provided with an infrared filter layer to selectively transmit the infrared rays.","18","16/079503","2016-03-09","2019-0050627","2019-02-14","10635885","2020-04-28","LG ELECTRONICS INC.","Hyungchul  Won | Hyunho  Oh | Junhak  Lee | Hyoungkil  Yoon | Chaedeok  Lee","10-2016-0024504","KR","2016-02-29","G06K-0009/00093","G06K-0009/00093 | A61B-0005/1174 | G01N-0021/49 | G06F-0021/32 | G06K-0009/00114 | G06K-0009/00134 | G06K-0009/00885 | G06K-0009/2018 | A61B-0005/024 | G06K-0009/00013 | G06K-2009/00932 | G06T-2207/30101","H04N-005/33","H04N-005/33 | G06K-009/00 | G06F-021/32 | G06K-009/20 | A61B-005/1174 | G01N-021/49 | A61B-005/024","","","","","","4920018005129"
"US","US","P","B2","Apparatus and method for detecting brain fingerprint using causal connectivity of brainwave","When a brain fingerprint is detected, a predetermined visual stimuli is output on a screen of a display, causal connectivity formed by unique EEG signals of a subject between two or more brain regions from among a predetermined plurality of brain regions is detected on the basis of the EEG signals of the subject who selectively attends to a part corresponding to a letter or symbol conceived by the subject from among the visual stimuli output on the screen of the display, an activation pattern of causal connectivity between brain regions is recognized on the basis of the detected causal connectivity, and the subject is identified by using the recognized unique activation pattern of causal connectivity between brain regions as a brain fingerprint.","1. An apparatus for detecting a brain fingerprint comprising: a memory configured to store a brain fingerprint detecting program for identifying a subject by detecting a brain fingerprint of the subject on the basis of EEG signals of the subject who selectively attends to at least a part of visual stimuli;a communication circuit configured to transmit/receive a signal to/from a security device interworking with the apparatus for detecting a brain fingerprint; anda processor that executes the program stored in the memory,wherein in response to execution of the brain fingerprint detecting program, the processor is configured to detect causal connectivity between two or more brain regions among a plurality of brain regions on the basis of the EEG signals, determine a brain fingerprint of the subject by recognizing an activation pattern of the causal connectivity between the two or more brain regions on the basis of the causal connectivity, and identify the subject based on the determined brain fingerprint;wherein the detecting of causal connectivity includes performing an EEG source localization analysis on the basis of the EEG signals measured from the plurality of the brain regions, and sequentially selecting two or more brain regions having the highest causal connectivity from activated brain regions among the plurality of the brain regions; andwherein the processor is configured to determine whether or not the subject is a permitted user on the basis of the identified brain fingerprint of the subject, and transmit an authentication signal to the security device through the communication circuit if the subject is a permitted user.","11","15/677589","2017-08-15","2018-0053049","2018-02-22","10635899","2020-04-28","KOREA UNIVERSITY RESEARCH AND BUSINESS FOUNDATION","Byoung-Kyong  Min","10-2016-0105488","KR","2016-08-19","G06K-0009/00536","G06K-0009/00536 | A61B-0005/04012 | A61B-0005/0476 | A61B-0005/04842 | A61B-0005/103 | A61B-0005/117 | G06F-0021/32 | G06K-0009/0053 | G06K-0009/0055 | G06K-0009/00496 | G06K-0009/00523 | G06K-0009/62 | G06K-0009/6267","G06F-021/32","G06F-021/32 | G06K-009/00 | A61B-005/0476 | A61B-005/0484 | A61B-005/04 | G06K-009/62 | A61B-005/103 | A61B-005/117","","","","","","4920018005143"
"US","US","P","B2","Methods and systems for managing drug usage","Methods and systems for managing drug usage are provided. In an embodiment, reminder data associated with a drug treatment plan of a patient is accessed. The reminder data includes a reminder time indicia and a patient identifier associated with the patient. The drug treatment plan is associated with a drug to be taken by the patient. A determination of whether a reminder criterion of the prescription drug treatment plan has been met is made based on the reminder time indicia. A patient messaging configuration is accessed based on the patient identifier. A notification is generated based on a determination that the reminder criterion has been met and the patient messaging configuration. Additional methods and systems are disclosed.","1. A system comprising: a mobile electronic device comprising an image capture device configured to capture a digital image;a database configured to store reminder data and a patient messaging configuration; anda processor configured to (a) identify a patient, (b) identify a drug associated with the patient, (c) determine a reminder time schedule associated with a drug treatment plan of the patient including a reminder criterion that indicates a time at which the drug should be used by the patient, (d) access reminder data associated with the drug treatment plan of the patient based on identification of the patient, the reminder time schedule associated with the drug treatment plan of the patient, and the identification of the drug, (e) access the patient messaging configuration in the database based on the identification of the patient, (f) process the reminder data to determine a reminder time indicia that reflects a timing when the mobile electronic device should receive a notification, (g) compare the reminder time indicia against a time associated with the reminder criterion, (h) in response to determining that the reminder time indicia matches the reminder criterion, generate the notification reminding the patient to use the drug and transmit the notification to the mobile electronic device over a network according to the patient messaging configuration, (i) transmit a request to the mobile electronic device requesting that the patient capture the digital image of a drug label using the image capture device, (j) receive the digital image of the drug label from the mobile electronic device over the network, (k) decode the digital image of the drug label to determine a drug name based on the drug label by analyzing a text string on the drug label, (l) determine whether the drug name matches the drug, (m) transmit an authorization message to the mobile electronic device authorizing the patient to use the drug captured in the digital image when the drug name matches the drug, and (n) receive a message from the mobile electronic device indicating and verifying that the patient used the drug in accordance with the drug treatment plan.","12","14/323477","2014-07-03","2014-0316803","2014-10-23","10636012","2020-04-28","EXPRESS SCRIPTS STRATEGIC DEVELOPMENT, INC.","Kevin C.  Cohan | William G.  Fogarty, IV | Bryan V.  Muehlberger | Katherine H.  Sundaraman","","","","G06Q-0010/109","G06Q-0010/109 | G16H-0020/10 | A61B-0005/4833 | G06K-0009/00","G06Q-010/10","G06Q-010/10 | G16H-020/10 | A61B-005/00 | G06K-009/00","","","","","","4920018005255"
"US","US","P","B2","User interfaces for health monitoring","The present disclosure generally relates to user interfaces for health monitoring. Exemplary user interfaces for initial setup of health monitoring using a first electronic device and a second electronic device is described. Exemplary user interfaces for recording biometric information for use in health monitoring is described. Exemplary user interfaces for using an input device while recording biometric information for health monitoring is described. Exemplary user interfaces for viewing and managing aspects of health monitoring is described.","1. A first electronic device, comprising: a display;one or more input devices;one or more processors;memory storing one or more programs configured to be executed by the one or more processors, the one or more programs including instructions for: displaying, on the display, a first portion of a tutorial related to using a health monitoring function of a second electronic device, wherein the second electronic device is a wearable electronic device and is paired with the first electronic device;detecting, via the one or more input devices, a request to proceed with the tutorial;in response to detecting the request to proceed with the tutorial: displaying, on the display, instructions to provide one or more inputs on the second electronic device directed to a measurement of biological data that relate to the health monitoring function of the second electronic device; andconcurrently displaying, on the display, a first selectable user interface object that, when activated, enables a completion of the tutorial without measuring the biological data;subsequent to displaying the instructions to provide the one or more inputs on the second electronic device and the first selectable user interface object: in accordance with a determination that a communication is received from the second electronic device, wherein the communication corresponds to an indication that the biological data have been successfully measured by the second electronic device: displaying, on the display, a second portion of the tutorial that is different from the first portion of the tutorial; andin accordance with a determination that a selection of the first selectable user interface object is detected by the first electronic device: displaying, on the display, a message indicating that the first portion of the tutorial has been completed; andforgoing displaying, on the display, the second portion of the tutorial that is different from the first portion of the tutorial.","63","16/143909","2018-09-27","2019-0274562","2019-09-12","10624550","2020-04-21","APPLE INC.","Christopher D.  Soli | Matthew W.  Crowley | Bradley W.  Griffin","","","","A61B-0005/0404","A61B-0005/0404 | A61B-0005/02 | G06F-0001/163 | G06F-0003/017 | G06F-0003/0485 | G06F-0009/453 | G06T-0013/80","A61B-005/0404","A61B-005/0404 | G06F-001/16 | A61B-005/02 | G06F-009/451 | G06F-003/0485 | G06F-003/01 | G06T-013/80","","","","","","4920017001019"
"US","US","P","B2","Fitness activity monitoring systems and methods","Apparatus, systems, and methods for tracking the location of an individual during a fitness activity are disclosed. A method of tracking a participant engaged in a fitness activity includes determining a location of the participant during the fitness activity based on data received at a portable fitness device used by the participant; determining a location of a spectator during the fitness activity based on data received at a mobile spectator device used by the spectator; from a server, sending an alert to a spectator at a spectator device during the fitness activity indicating that the participant is within a predetermined distance of the spectator; and sending an alert to the portable fitness device during the fitness activity indicating that the spectator is within a predetermined distance of the participant.","1. A method of tracking a participant engaged in a fitness activity, the method comprising: receiving registration information from a spectator device associated with a spectator registering to track the participant during the fitness activity;activating a live tracking feature of a portable fitness monitoring device associated with the participant to allow participant location information to be accessed by the spectator at the spectator device; andafter the live tracking feature is activated, sending the participant location information to the spectator device.","22","16/372100","2019-04-01","2019-0224527","2019-07-25","10625118","2020-04-21","ADIDAS AG","Jon Harald  Werner | Christian  Dibenedetto | Stephen John  Black | Amy Jones  Vaterlaus","","","","A63B-0024/0062","A63B-0024/0062 | A61B-0005/02055 | A61B-0005/4875 | G01S-0019/19 | G06Q-0010/10 | G06Q-0030/0241 | G06Q-0050/01 | H04L-0067/12 | H04L-0067/18 | A61B-0005/02438 | A61B-0005/0816 | A61B-0005/112 | A61B-0005/1112 | A61B-2562/0219 | A61B-2562/0223 | A63B-2220/12 | A63B-2220/17 | A63B-2220/40 | A63B-2230/06 | A63B-2230/42 | A63B-2230/50 | G06Q-0050/22","A63F-009/24","A63F-009/24 | A63B-024/00 | H04L-029/08 | G06Q-030/02 | G06Q-050/00 | G01S-019/19 | G06Q-010/10 | A61B-005/0205 | A61B-005/00 | G06Q-050/22 | A61B-005/024 | A61B-005/08 | A61B-005/11","","","","","","4920017001583"
"US","US","P","B2","Method and apparatus for calculating safety level","Provided is a method and apparatus for calculating a safety grade of a working environment that may receive harmful gas information from a gas sensor configured to detect a harmful gas to calculate a safety grade, receive biometric information of a user from a biometric sensor configured to measure the biometric information of the user, calculate a safety grade for the user based on the harmful gas information and the biometric information, and output the calculated safety grade.","1. A method of calculating a safety grade, the method comprising: receiving harmful gas information from a gas sensor configured to detect a harmful gas;receiving biometric information of a user from a biometric sensor configured to measure the biometric information of the user;calculating a safety grade for the user based on the harmful gas information and the biometric information; andoutputting the calculated safety grade,wherein the calculating comprises: identifying the user;obtaining information related to the identified user; andcalculating the safety grade for the user based on the information related to the user and the biometric information,wherein the information related to the user is information related to a standard electromyogram (EMG) of the user, andthe biometric information is information related to a target EMG when exposed to the harmful gas.","14","16/316923","2017-12-12","2019-0250136","2019-08-15","10627381","2020-04-21","GUMI ELECTRONICS & INFORMATION TECHNOLOGY RESEARCH INSTITUTE | INDUSTRY ACADEMIC COOPERATION FOUNDATION KEIMYUNG UNIVERSITY","Hyung Jin  Kim | Jong Ha  Lee | Min Ji  Choi","10-2017-0060513","KR","2017-05-16","G01N-0033/0065","G01N-0033/0065 | A61B-0005/0402 | A61B-0005/04012 | A61B-0005/0476 | A61B-0005/0488 | A61B-0005/117 | A61B-0005/7267 | A61B-0005/746 | G01N-0033/0036 | G06N-0003/02 | G06N-0020/00 | G06Q-0010/0635 | G06Q-0050/265 | G08B-0021/14 | G08B-0021/182 | A61B-2503/20 | A61B-2560/0252 | A61B-2562/029 | G01N-0033/004","G08B-021/14","G08B-021/14 | G01N-033/00 | G06N-020/00 | G08B-021/18 | A61B-005/117 | A61B-005/0402 | A61B-005/0488 | A61B-005/00 | A61B-005/0476 | G06N-003/02 | A61B-005/04 | G06Q-010/06 | G06Q-050/26","","","","","","4920017003828"
"US","US","P","B2","Systems and methods for determining whether an individual enters a prescribed virtual zone using skeletal tracking and 3D blob detection","A method and system that allows healthcare providers to monitor disabled, elderly or other high-risk individuals to prevent or reduce falls and/or mitigate the impact of a fall by delivering automated notification of ""at risk"" behavior and falls by such an individual. Two systems are used to identify patients?a skeletal tracking system that identifies patients by biometric indicators and a virtual blob detection system. In the virtual blob system, the monitored individual is virtually represented as a blob object of at least a specific size by a computerized monitoring system, and such system detects and alerts when the blob object enters or crosses into a virtually defined or designated blob detection zone and remains in the zone for at least a predetermined period of time. These systems may be used concurrently and conflicts between the systems may be resolved.","1. A system for detecting when a monitored individual or any part of the monitored individual has crossed over a designated electronic perimeter, the system comprising: one or more 3D camera, motion, and sound sensors located in a room with an individual to be monitored and configured to capture video data of the individual within the room;a computerized monitoring system configured to: electronically receive video data from the one or more 3D camera, motion, and sound sensors;use skeletal tracking to electronically monitor the room for a crossing of a designated electronic perimeter by the individual based on the video data electronically received from the one or more 3D camera, motion, and sound sensors;use virtual blob detection to electronically monitor the room for the crossing of the designated electronic perimeter by the individual based on the video data electronically received from the one or more 3D camera, motion, and sound sensors;detect a conflict between determinations of whether the individual or part of the individual crossed the designated electronic perimeter made using skeletal tracking and virtual blob detection;resolve the conflict between the determinations made using skeletal tracking and virtual blob detection according to a predetermined setting; andbased on resolution of the conflict, electronically transmit a determination that the individual or part of the individual has crossed the designated electronic perimeter.","20","16/166857","2018-10-22","2019-0057592","2019-02-21","10629046","2020-04-21","CERNER INNOVATION, INC.","Neil  Kusens","","","","G08B-0021/043","G08B-0021/043 | A61B-0005/1117 | A61B-0005/1128 | G06K-0009/00369 | G06K-0009/00771 | G06K-0009/00778 | G06K-0009/3241 | G06K-0009/44 | G06T-0007/20 | G06T-0007/246 | G08B-0023/00 | G08B-0025/14 | H05K-0999/99 | G06K-2009/3291 | G06T-2207/10021","G06K-009/00","G06K-009/00 | G08B-021/04 | G06T-007/20 | G06K-009/32 | G08B-023/00 | A61B-005/11 | G08B-025/14 | G06K-009/44 | G06T-007/246 | G06F-003/00","","","","","","4920017005486"
"US","US","P","B2","Means and method for improved glycemic control for diabetic patients","A glycemic control system includes a physician processor, remote processor, and a portable telephone having a data input mechanism, a display, and an internal processor for bi-directional communication with the physician's processor and the remote processor. A patient inputs data to the internal processor responsive to input from the physician's processor and then transmits the information to the remote processor where an optimized number of units to be administered is sent back and displayed on the portable telephone.","1. A method comprising: obtaining, at data processing hardware, a glucose measurement of a patient and patient condition parameters during a pre-meal time, the patient condition parameters comprising a number of carbohydrates to be consumed by the patient, and the pre-meal time associated with a meal type corresponding to one of breakfast, lunch, or dinner;determining, by the data processing hardware, a recommended meal bolus for the patient based on the obtained patient condition parameters;obtaining, by the data processing hardware, an insulin sensitivity factor for the patient and a target glucose range defined by upper and lower glucose limits for the patient;determining, by the data processing hardware, whether the glucose measurement exceeds a midpoint of the target glucose range for the patient;when the glucose measurement exceeds the midpoint of the target glucose range for the patient, determining, by the data processing hardware, a correction dose by calculating: wherein CD is the correction dose, BG is the glucose measurement, Tm is the midpoint of the target glucose range, and S1 is the insulin sensitivity factor; andtransmitting the recommended meal bolus and the correction dose from the data processing hardware to a user device controlled by the patient, the recommended meal bolus and the correction dose when received by the user device, causing a user interface executing on the user device to display the recommended meal bolus and the correction dose.","18","16/519502","2019-07-23","2019-0348157","2019-11-14","10629294","2020-04-21","ASEKO, INC.","Robert C.  Booth | Robert E.  Fischell","","","","G16H-0010/40","G16H-0010/40 | A61B-0005/0022 | A61B-0005/1118 | A61B-0005/14532 | A61M-0005/1723 | G06F-0019/00 | G06F-0019/34 | G06F-0019/3456 | G06F-0019/3468 | G06Q-0050/22 | G16H-0020/17 | G16H-0020/60 | G16H-0040/67 | G16H-0050/20 | G16H-0050/30 | G16H-0080/00 | A61B-2562/0295 | G06F-0003/04847","G16H-010/40","G16H-010/40 | G16H-050/30 | G16H-020/60 | G06Q-050/22 | G06F-019/00 | G16H-050/20 | G16H-040/67 | G16H-080/00 | A61B-005/145 | A61M-005/172 | A61B-005/00 | A61B-005/11 | G16H-020/17 | G06F-003/0484","","","","","","4920017005733"
"US","US","P","B2","Systems and methods for decision support for animal health queries","A decision support system is described that solves various technical problems associated with prior systems. The system may include a thin client application that downloads question sets from a server. The question sets may include a series of interlinked questions and answers as well as scores associated with the answers. Scores of selected answers may be tallied and a decision corresponding to the cumulative score of the selected answers may be provided to a user. As a result, the system may enable the ability to update (add, revise or delete) questions, answers and question lines without needing to recompile and redistribute the client application. In addition, the transmission of a complete question set reduces overall network traffic and technical problems arising from network disruptions among other technical benefits.","1. A system for providing non-human animal health care decision support, comprising: a first software module for use on one of a personal computing device or a mobile device, the software module including instructions stored on a non-transitory computer readable medium that:collect from a user information about a non-human animal including type of non-human animal;present a non-human animal health topic to a user;receive a selection of the non-human animal health topic from the user;request, from a server computer, a question set related to the non-human animal health topic, the question set including one or more questions, each question having one or more associated answers;receive, from the server computer, the question set;display one or more questions from the question set;receive selections of answers associated with the displayed questions;determine a course of action based on the selected answers, wherein the course of action is a recommendation comprising at least one of contacting a veterinarian, making an appointment with a veterinarian, watching for change in symptoms in the non-human animal, or transporting the non-human animal to a clinic,store the recommended course of action and date of the recommendation; anddisplay the determined course of action; anda second software module for use on a server computer, the second software module including instructions stored on a non-transitory computer readable medium that:receive the request for the question set related to the non-human animal health topic; andtransmit a question set related to the non-human animal health topic, the question set including one or more questions, each question having one or more associated answers.","6","15/359033","2016-11-22","2018-0144099","2018-05-24","10629304","2020-04-21","WHISKERS WORLDWIDE, LLC","Debra  Leon | Trevor  Page | Gunnison  Carbone","","","","G16H-0050/20","G16H-0050/20 | A61B-0005/00 | G06N-0005/041 | G06N-0005/045 | G16H-0010/20 | G16H-0050/30 | H04L-0067/02 | G06N-0005/003","G16H-050/20","G16H-050/20 | G06N-005/04 | H04L-029/08 | G16H-010/20 | G16H-050/30 | A61B-005/00 | G06N-005/00","","","","","","4920017005743"
"US","US","P","B2","Optimization tool for auditory devices","An optimization system for testing a patient's hearing comprising a controller, right and left ear pieces, and a memory. The controller is configured to provide a series of tones to the right and left ear pieces and receive feedback from the patient between each tone provided, indicating that the respective tone was detected in one of the right ear piece and the left ear piece or that the respective tone was not detected. The controller is configured to also generate a data point on an audiogram after receiving each feedback and, after each data point is generated, compute a statistical distribution based on the generated data points, wherein the statistical distribution includes a lowest confidence level. A subsequent tone is selected, each subsequent tone provided in the series of tones being a tone represented at the lowest confidence level in statistical distribution at the time of selection.","1. An optimization system for testing a patient'ss hearing comprising: a controller;an ear piece in audible communication with the controller;a memory in communication with the controller and including instructions that, when executed by the controller, cause the controller to: provide a series of tones to the ear piece;receive feedback from the patient between each tone provided, wherein each feedback indicates that the respective tone was detected in the ear piece or that the respective tone was not detected;generate a data point on an audiogram after receiving each feedback, wherein each data point is based on the respective feedback;after each data point is generated, compute a statistical distribution based on the generated data points, wherein the statistical distribution includes a lowest confidence level; andselect a subsequent tone to provide in the series of tones, wherein each subsequent tone provided in the series of tones is a tone represented at the lowest confidence level in statistical distribution at the time of selection.","14","16/294912","2019-03-06","2019-0274596","2019-09-12","10617334","2020-04-14","RESONANCE MEDICAL, LLC","Christopher  Boven | Reagan John  Roberts","","","","A61B-0005/123","A61B-0005/123 | A61B-0005/6803 | A61B-0005/743 | A61N-0001/36038 | H04R-0025/305 | H04R-0025/70 | G06F-0003/165 | H04R-2225/41","H04R-025/00","H04R-025/00 | A61B-005/12 | A61B-005/00 | A61N-001/36 | G06F-003/16","","","","","","4920016001033"
"US","US","P","B2","Casing of implantable device and implantable device, method for manufacturing casing of implantable device, and method for supporting treatment using implantable device","To allow an implantable device including an electronic circuit to be implanted in the head in a more preferable manner in terms of appearance and safely. This implantable device is used for a brain-machine interface or the like. A casing of an implantable device configured to be implanted in a human head has an outer convexity surface matching an external shape of a resected skull related to at least a craniotomy site of the artificial bone designed in accordance with a skull shape of each person in order to fill the craniotomy site. That is, the outer convexity surface of the artificial bone is provided with two functions: the original function of filling the craniotomy site as the artificial bone and a function of serving as the casing of the implantable device.","1. An implantable device connected to a functional unit implanted in a human head via a cable, comprising: an electronic circuit; anda casing enclosing the electronic circuit, wherein the casing comprises an outer convexity surface configured to be flush with an external top shape of a resected skull related to at least a craniotomy site of an artificial bone designed in accordance with a skull shape of a person in order to fill the craniotomy site,wherein the electronic circuit is configured to receive measured signals transmitted by the functional unit and control the functional unit,wherein an entirety of the electronic circuit is disposed inside the casing,wherein the functional unit comprises a sheet-shaped grid electrode array configured to be disposed under a dural membrane and attach to a surface of a brain of the human head,wherein the cable is configured to penetrate the dural membrane,wherein the casing is disposed above the dural membrane,wherein the electronic circuit within the casing and the sheet-shaped grid electrode array are configured to connect with each other via the cable penetrating the dural membrane,wherein the casing comprises an inner convexity surface matching an internal shape of the resected skull, and internal space formed between the outer convexity surface and the inner convexity surface, wherein the electronic circuit is fixed in the internal space,wherein the electronic circuit comprises two or more circuit boards and a flexible printed wiring electrically connecting the circuit boards, andwherein the two or more circuit boards are positioned adjacent to each other in an in-plane direction of the casing and bendable around a connection made by the flexible printed wiring, such that the two or more circuit boards are fixed adaptably to the inner convexity surface.","4","15/251577","2016-08-30","2017-0049398","2017-02-23","10617361","2020-04-14","OSAKA UNIVERSITY","Masayuki  Hirata | Toshiki  Yoshimine | Kojiro  Matsushita | Tetsu  Goto | Takufumi  Yanagisawa | Takafumi  Suzuki | Shinichi  Yoshimura","2010-250464","JP","2010-11-09","A61B-0005/6868","A61B-0005/6868 | A61B-0005/0478 | A61F-0002/2875 | A61N-0001/0531 | A61N-0001/375 | G06F-0003/015 | A61B-2562/164 | A61B-2562/166 | A61B-2562/222","A61N-001/05","A61N-001/05 | A61B-005/00 | A61B-005/0478 | A61F-002/28 | G06F-003/01 | A61N-001/375","","","","","","4920016001060"
"US","US","P","B2","Facilitating urgency modulated beaconing rates for medical devices","Techniques for facilitating telemetry between a medical device and an external device are provided. In one example, a medical device includes a classification component and a communication component. The classification component is configured to determine a classification for data generated by the medical device. The classification component is also configured to determine an urgency level for an advertising data packet based on the classification for the data. The communication component is also configured to broadcast the advertising data packet for the medical device at a defined beaconing rate based on the urgency level for the advertising data packet.","1. A medical device configured to be employed by a patient, comprising: a housing;a memory, within the housing, that stores executable components; andcircuitry, within the housing, and configured to at least one of obtain sensed physiological data associated with the patient or deliver a therapy to the patient;a processor, within the housing, that executes the executable components stored in the memory, wherein the executable components comprise: a classification component configured to determine a classification for data generated by the medical device and to determine an urgency level for an advertising data packet based on the classification for the data, wherein the advertising data packet is a data packet that facilitates establishment of a connection with another device; anda communication component configured to: broadcast the advertising data packet for the medical device at a defined beaconing rate based on the urgency level for the advertising data packet, wherein the advertising data packet for the medical device is broadcast at the defined beaconing rate a plurality of times over an advertising period;establish the connection with the other device; andtransmit the data generated by the medical device via the established communication channel, wherein transmission of the data is via a set of packets distinct from the advertising data packet.","28","15/472371","2017-03-29","2018-0243568","2018-08-30","10617875","2020-04-14","MEDTRONIC, INC.","Wade M.  Demmer | Charles R.  Gordon | Matthew R.  Yoder | Val D.  Eisele | Matthew P.  Hanly | James R.  Peichel | Nicholas C.  Wine | Ryan D.  Wyszynski | Eric R.  Williams","","","","A61N-0001/3727","A61N-0001/3727 | A61B-0005/0002 | A61N-0001/37258 | A61N-0001/37276 | H04L-0043/103 | H04L-0043/16 | H04L-0067/12 | H04W-0004/80","A61N-001/372","A61N-001/372 | H04L-012/26 | A61B-005/00 | H04L-029/08 | H04W-004/80","","","","","","4920016001571"
"US","US","P","B2","Platform for distinguishing human from machine input","A device transmits an instruction for completing a human authentication challenge, to access a server device. The instruction includes information indicating a biometric parameter to be provided by a user, and information indicating a task, to be performed by the user, for varying the biometric parameter. The device receives a request to validate performance of the task. The device obtains a first measurement of the biometric parameter, provided by the user at a first point in time, and obtains a second measurement of the biometric parameter, provided by the user at a second point in time that is later than the first point in time. The device compares the first measurement and the second measurement, and selectively validates the request, based on a result of comparing the first measurement and the second measurement, to selectively grant access to the server device.","1. A method, comprising: transmitting, by a processor, an instruction for completing a Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA), to access a server device, wherein the instruction includes: information indicating a biometric parameter to be provided by a user, the biometric parameter including at least one of: ?a pulmonary parameter, ?a respiratory parameter, or ?a perspiration parameter, andinformation indicating a task, to be performed by the user, for varying the biometric parameter, the task being associated with a threshold biometric response that is expected based on the user performing the task;receiving, by the processor, a request to validate performance of the task;obtaining, by the processor, a baseline measurement of the biometric parameter, wherein the baseline measurement is provided by the user at a first point in time after the instruction for completing the CAPTCHA is transmitted;obtaining, by the processor, a stimulated measurement of the biometric parameter, wherein the stimulated measurement is provided by the user at a second point in time that is later than the first point in time;determining, by the processor, a change in the biometric parameter based on comparing the baseline measurement and the stimulated measurement;determining, by the processor, whether the change in the biometric parameter exceeds the threshold biometric response that is expected based on the user performing the task; andvalidating, by the processor, the request, when the change in the biometric parameter exceeds the threshold biometric response, to grant access to the server device.","20","16/053425","2018-08-02","2020-0042681","2020-02-06","10621322","2020-04-14","CAPITAL ONE SERVICES, LLC","Abdelkadar M'Hamed  Benkreira | Michael  Mossoba | Joshua  Edwards","","","","G06F-0021/32","G06F-0021/32 | A61B-0005/02 | A61B-0005/08 | G06F-0021/36 | H04L-0063/102 | G06F-2221/2103 | G06F-2221/2133","G06F-007/04","G06F-007/04 | G06F-015/16 | G06F-017/30 | H04L-029/06 | G06F-021/32 | G06F-021/36 | A61B-005/08 | A61B-005/02","","","","","","4920016004985"
"US","US","P","B2","Augmented reality therapeutic movement display and gesture analyzer","Systems and methods for displaying augmented reality clinical movements may use an augmented reality device to display aspects of a clinical movement. The systems and methods may use a motion capture device to capture the clinical movement. A method may include analyzing information about the clinical movement to determine a path of motion representative of at least a portion of the clinical movement. The method may automatically define a path region or a virtual target in an augmented reality environment overlaid on a real environment. The method may display the path region or the virtual target on an augmented reality display.","1. A method for displaying augmented reality clinical movements, the method comprising: analyzing information about a clinical movement of a therapist, captured using a movement capture apparatus, to determine a three-dimensional path of motion representative of at least a portion of the clinical movement;automatically updating a three-dimensional virtual path region and a virtual target responsive to a user movement, the three-dimensional virtual path region and virtual target defined in an augmented reality environment overlaid on a real environment using the three-dimensional path of motion, the virtual target located at an intended ending location of the three-dimensional virtual path region, the virtual target and the three-dimensional virtual path region having a fixed position relative to a physical object in the real environment; anddisplaying, using an augmented reality device, the three-dimensional virtual path region and the virtual target at the fixed position in the augmented reality environment relative to the object in the real environment.","20","15/803499","2017-11-03","2018-0121728","2018-05-03","10621436","2020-04-14","ZIMMER US, INC.","Richard  Wells | Timothy R.  Price | Ted  Spooner | Dave  Van Andel | Travis  Dittmer | John  Kotwick | Jason  Leighton","","","","G06K-0009/00671","G06K-0009/00671 | A61B-0003/0033 | A61B-0005/0002 | A61B-0005/015 | A61B-0005/1116 | A61B-0005/1118 | A61B-0005/1128 | A61B-0005/1495 | A61B-0005/486 | A61B-0005/746 | A61B-0005/7455 | G02B-0027/0093 | G02B-0027/017 | G02B-0027/0176 | G06F-0003/017 | G06F-0003/0487 | G06F-0019/3418 | G06F-0019/3481 | G06K-0009/00342 | G06T-0019/006 | G16H-0020/30 | G16H-0040/63 | A61B-0005/1112 | A61B-2505/09 | A61B-2562/0219 | A61B-2562/0247 | G06F-0003/011 | G06Q-0050/22","G09G-005/10","G09G-005/10 | G06K-009/00 | G16H-020/30 | A61B-005/00 | A61B-005/01 | A61B-005/1495 | G16H-040/63 | A61B-005/11 | G02B-027/00 | G02B-027/01 | G06F-019/00 | G06T-019/00 | A61B-003/00 | G06F-003/01 | G06F-003/0487 | G06Q-050/22","","","","","","4920016005098"
"US","US","P","B2","Intelligent assistant","Examples are disclosed herein that relate to entity tracking. One examples provides a computing device comprising a logic processor and a storage device holding instructions executable by the logic processor to receive image data of an environment including a person, process the image data using a face detection algorithm to produce a first face detection output at a first frequency, determine an identity of the person based on the first face detection output, and process the image data using another algorithm that uses less computational resources of the computing device than the face detection algorithm. The instructions are further executable to track the person within the environment based on the tracking output, and perform one or more of updating the other algorithm using a second face detection output, and updating the face detection algorithm using the tracking output.","1. A computing device, comprising: a logic processor; anda storage device holding instructions executable by the logic processor to: receive image data of an environment including a person;process the image data using a face detection algorithm to produce a first face detection output at a first frequency;select at least one tracking algorithm that uses less computational resources of the computing device than the face detection algorithm, and produces a tracking output at a second frequency greater than the first frequency;process the image data using the at least one tracking algorithm; andtrack the person within the environment based on the tracking output produced by the at least one tracking algorithm.","20","16/573677","2019-09-17","2020-0012906","2020-01-09","10621478","2020-04-14","MICROSOFT TECHNOLOGY LICENSING, LLC","Haithem  Albadawi | Zongyi  Liu","","","","G06K-0009/726","G06K-0009/726 | A61B-0005/0205 | A61B-0005/0507 | A61B-0005/117 | A61B-0005/1113 | A61B-0005/7475 | G01S-0005/18 | G01S-0005/28 | G01S-0013/726 | G06F-0001/324 | G06F-0001/3206 | G06F-0001/3231 | G06F-0003/011 | G06F-0003/017 | G06F-0003/0304 | G06F-0003/0482 | G06F-0003/04842 | G06F-0003/167 | G06F-0017/271 | G06F-0017/279 | G06F-0021/32 | G06F-0021/35 | G06K-0009/00214 | G06K-0009/00255 | G06K-0009/00261 | G06K-0009/00288 | G06K-0009/00295 | G06K-0009/00342 | G06K-0009/00362 | G06K-0009/00711 | G06K-0009/00973 | G06K-0009/6254 | G06K-0009/6255 | G06K-0009/6289 | G06K-0009/6296 | G06N-0005/025 | G06N-0005/047 | G06N-0020/00 | G06T-0007/248 | G06T-0007/292 | G06T-0007/60 | G06T-0007/70 | G06T-0007/74 | G07C-0009/00111 | G08B-0013/1427 | G10L-0015/02 | G10L-0015/063 | G10L-0015/08 | G10L-0015/18 | G10L-0015/1815 | G10L-0015/1822 | G10L-0015/19 | G10L-0015/22 | G10L-0015/24 | G10L-0015/26 | G10L-0015/28 | G10L-0015/32 | G10L-0017/04 | G10L-0017/08 | G10L-0025/51 | H04L-0051/02 | H04L-0063/102 | H04L-0067/12 | H04L-0067/22 | H04N-0005/23219 | H04N-0005/332 | H04N-0007/181 | H04N-0007/188 | H04N-0021/231 | H04N-0021/42203 | H04N-0021/44218 | H04N-0021/44222 | H04R-0001/406 | H04R-0003/005 | H04W-0004/029 | H04W-0004/33 | A61B-0005/05 | A61B-0005/1118 | G01S-0005/16 | G01S-0013/38 | G01S-0013/867 | G01S-0013/888 | G06F-0003/0488 | G06F-0016/70 | G06F-2203/0381 | G06F-2221/2111 | G06K-2209/09 | G06N-0003/0445 | G06T-2207/10016 | G06T-2207/10024 | G06T-2207/20101 | G06T-2207/30196 | G06T-2207/30201 | G06T-2207/30204 | G06T-2207/30232 | G07C-0009/00134 | G08B-0029/186 | G10L-0017/00 | G10L-2015/0635 | G10L-2015/088 | G10L-2015/223 | G10L-2015/225 | G10L-2015/228 | H04N-0005/247 | Y02D-0010/126 | Y02D-0010/173","G06K-009/72","G06K-009/72 | G06K-009/00 | G06T-007/70 | G06K-009/62 | G06F-003/16 | G10L-015/18 | G06N-020/00 | G06T-007/292 | H04W-004/33 | H04W-004/029 | A61B-005/11 | A61B-005/117 | A61B-005/00 | G01S-005/28 | G06F-001/3206 | G06F-001/3231 | G06F-001/324 | G06F-003/01 | G06F-003/03 | G06F-017/27 | G06F-021/32 | G10L-017/04 | G10L-017/08 | H04L-012/58 | H04L-029/08 | H04N-005/232 | H04N-007/18 | H04N-021/422 | H04N-021/442 | G06T-007/73 | G06T-007/246 | G01S-005/18 | G06T-007/60 | G10L-015/22 | G10L-015/28 | H04R-001/40 | H04R-003/00 | H04N-005/33 | G10L-015/02 | G06N-005/02 | G06N-005/04 | G10L-015/06 | G10L-015/24 | G10L-015/26 | G10L-015/19 | G10L-015/08 | G10L-015/32 | G10L-025/51 | H04L-029/06 | A61B-005/0205 | A61B-005/05 | G01S-013/72 | G06F-021/35 | G07C-009/00 | G08B-013/14 | G06F-003/0482 | G06F-003/0484 | H04N-021/231 | G06F-003/0488 | G06F-016/70 | G01S-005/16 | G01S-013/86 | G06N-003/04 | G08B-029/18 | G10L-017/00 | H04N-005/247 | G01S-013/38 | G01S-013/88","","","","","","4920016005139"
"US","US","P","B2","Systems and methods for associating media content with viewer expressions","Systems and methods for capturing media content in accordance with viewer expression are disclosed. In some implementations, a method is performed at a computer system having one or more processors and memory storing one or more programs for execution by the one or more processors. The method includes: (1) obtaining a momentary reaction of the user to a portion of media content; (2) comparing the captured user reaction with one or more previously captured reactions of the user; (3) identifying the user reaction as one of a plurality of reaction types based on the comparison; (4) identifying the portion of the media content corresponding to the momentary reaction of the user; and (5) generating an electronic message that includes information regarding the portion of the media content item and information regarding the identified user reaction.","1. A method comprising: at a computer system having one or more processors and memory storing one or more programs for execution by the one or more processors:while a media content item is being presented to a user, obtaining an image of a momentary reaction of the user to a moment of the media content item;identifying the momentary reaction of the user as one of a plurality of reaction types;identifying the moment of the media content item corresponding in time to the momentary reaction of the user;storing the image of the momentary reaction of the user and the identified moment of the media content item corresponding in time to the momentary reaction as a pair;identifying a social media account of the user;generating an electronic message for the social media account, including: automatically populating in the electronic message information including the stored pair of the image of the momentary reaction of the user and the identified moment of the media content item, wherein the stored pair is displayed as distinct items in the electronic message; anddisplaying the image of the momentary reaction of the user in a first location in the electronic message and displaying the identified moment of the media content item in a second location in the electronic message, distinct from the first location; andcausing the electronic message to be shared, via the social media account, with least one contact of the user.","20","15/838249","2017-12-11","2018-0103292","2018-04-12","10623813","2020-04-14","GOOGLE LLC","Ying  Zheng","","","","H04N-0021/44218","H04N-0021/44218 | A61B-0005/0022 | A61B-0005/0077 | A61B-0005/165 | G02B-0007/34 | G02B-0027/0093 | G02B-0027/017 | G02B-0027/34 | G06F-0003/005 | G06F-0003/011 | G06F-0003/017 | G06F-0003/0304 | G06K-0009/00302 | G16H-0040/67 | H04N-0001/00336 | H04N-0005/23219 | H04N-0005/76 | H04N-0021/4223 | H04N-0021/42203 | H04N-0021/4788 | A61B-2503/12 | G02B-2027/0187 | G06F-2203/011","H04N-021/442","H04N-021/442 | G16H-040/67 | G06F-003/00 | G06F-003/03 | H04N-005/76 | G06F-003/01 | A61B-005/16 | H04N-001/00 | H04N-005/232 | G06K-009/00 | G02B-027/00 | A61B-005/00 | G02B-007/34 | G02B-027/34 | G02B-027/01 | H04N-021/422 | H04N-021/4223 | H04N-021/4788","","","","","","4920016007446"
"US","US","P","B2","Methods and systems for creating and interacting with three dimensional virtual models","Systems and methods are provided for preparation of orthodontics and prosthodontics. A method may include scanning a patient's teeth to form first 3D data of the patient's teeth including a removable element that obscures part of the dental surfaces of the patient's teeth and non-obscured tooth surfaces, removing the removable element form the patient's teeth so that the removable element no longer obscures the part of the dental surfaces of the patient's teeth, and scanning the previously obscured part of the dental surfaces of the patent's teeth and the non-obscured tooth surfaces.","1. A dental system for intraorally scanning a patient'ss teeth for a dental procedure, the dental system comprising: a hand-held intraoral scanner; anda computer readable medium including instructions that when executed by a computer system, cause the computer system to:receive first 3D intraoral scan data of the patient'ss teeth from the hand-held intraoral scanner;display, to a display, a first 3D surface model of the patient'ss teeth, wherein the first 3D surface model of the patient'ss teeth is based on the received first 3D intraoral scan data of the patient'ss teeth;receive user input defining a surface portion of the first 3D surface model to be removed;after receiving the user input, remove, from the displayed first 3D surface model, the surface portion of the first 3D surface model to be removed according to the user input;after removing the surface portion of the first 3D surface model, receive second 3D intraoral scan data of the patient'ss teeth from the hand-held intraoral scanner, the second 3D intraoral scan data including surface data of a physically changed portion of the patient'ss intra-oral cavity;replace at least a portion of the removed surface portion of the first 3D surface model with at least a surface portion of a second 3D surface model including the physically changed portion based on the received second 3D intraoral scan data of the patient'ss teeth to produce a composite 3D surface model of the patient'ss teeth that is based on the first 3D intraoral scan data and the second 3D intraoral scan data; andoutput, to the display, the composite 3D surface model of the patient'ss teeth.","30","16/176474","2018-10-31","2019-0167113","2019-06-06","10610107","2020-04-07","Align Technology, Inc.","Avi  Kopelman","","","","A61B-0005/0088","A61B-0005/0088 | A61B-0005/0062 | A61B-0005/4547 | A61C-0005/77 | A61C-0007/002 | A61C-0009/0053 | A61C-0013/0004 | G06F-0017/50 | G06T-0007/0012 | G06T-0019/00 | G06T-0019/20 | A61B-0001/00039 | A61B-0001/00172 | A61C-0019/04 | B33Y-0080/00 | G06T-2200/04 | G06T-2207/30036 | G06T-2210/41 | G06T-2219/2004 | G06T-2219/2021 | G16H-0020/40","G06T-019/20","G06T-019/20 | A61C-007/00 | G06T-019/00 | G06F-017/50 | G06T-007/00 | A61B-005/00 | A61C-005/77 | A61C-013/00 | A61C-009/00 | B33Y-080/00 | G16H-020/40 | A61B-001/00 | A61C-019/04","","","","","","4920015000979"
"US","US","P","B2","User interface system and methods for overlaying surgical video output","A surgical user interface system and methods, involving: an interface having at least one overlay element of: at least one menu bar, at least one tab, at least one sidebar, at least one window, at least one icon; at least one graphical control element, at least one haptic control element, and at least one voice control element, the interface configured to: communicate with at least one surgical system, the at least one surgical system having at least one of an imaging system, a guidance system, a control system, a tracking system, a navigation system, a drive system, and a voice recognition system; display information corresponding to at least one surgical parameter of the at least one surgical system; overlay a real-time streaming image from the imaging system; receive input by way of the at least one overlay element; transmit the input to the at least one surgical system; and update, in real-time, the at least one overlay element in response to a change in the at least one surgical parameter.","1. A surgical user interface system, comprising: an interface comprising at least one overlay element of: a menu bar, at least one tab, at least one sidebar, at least one window, at least one icon; at least one graphical control element, at least one haptic control element, at least one voice control element, or any combination thereof, the interface configured to:communicate with at least one surgical system, the at least one surgical system comprising at least one of: an imaging system, a guidance system, a control system, a tracking system, a navigation system, a drive system, a voice recognition system, or any combination thereof;display information corresponding to at least one surgical parameter of the at least one surgical system;overlay a real-time streaming image from the imaging system;receive input by way of the at least one overlay element;transmit the input to the at least one surgical system; andupdate, in real-time, the at least one overlay element in response to a change in the at least one surgical parameter,the menu bar comprising: a notification icon, the notification icon configured to render if a one notification is received from the guidance system; and a status and task menu bar, the status and task bar comprising at least one of: a video recording icon, a mark log icon, a video overlay icon, a tracking camera icon, a settings icon, a help icon, a caster brake icon, or any combination thereof,the video recording icon configured to toggle for respectively commencing and terminating video recording,the mark log icon configured to toggle for adding a flag to a log of the guidance system,the video overlay icon configured to toggle for respectively displaying or hiding the at least one overlay element,the tracking camera icon configured to toggle for indicating a status of the guidance system in relation to the tracking system,the settings icon configured to toggle for accessing at least one of: a setting, an option of the guidance system, or a combination thereof,the help icon configured to toggle for accessing help information, andthe caster brake icon configured to toggle for indicating a status of a caster brake.","27","15/722481","2017-10-02","2019-0099225","2019-04-04","10610310","2020-04-07","SYNAPTIVE MEDICAL (BARBADOS) INC.","Robin Elizabeth McKenzie  Todd | David Bruce  McFadzean | Monroe Milas  Thomas | Sam Anthony  Leitch","","","","A61B-0034/25","A61B-0034/25 | A61B-0017/3205 | A61B-0090/37 | G06F-0003/048 | G06T-0011/00 | H04N-0005/23296 | H04N-0005/44504 | A61B-0034/76 | A61B-0090/30 | A61B-0090/361 | A61B-2017/00119 | A61B-2017/00199 | A61B-2017/00203 | A61B-2017/00973 | A61B-2034/105 | A61B-2034/207 | A61B-2034/2055 | A61B-2034/2065 | A61B-2034/256 | A61B-2090/064 | A61B-2090/066 | A61B-2090/364 | A61B-2090/365 | A61B-2090/372 | A61B-2217/005 | G06F-0003/0482 | G06F-0003/0484 | G06F-0003/04817 | G06K-0009/2054 | G06K-0009/3208 | G06T-0007/20 | G06T-2207/10016 | G06T-2207/30244 | H04N-0005/23216","A61B-034/00","A61B-034/00 | A61B-017/3205 | H04N-005/445 | H04N-005/232 | G06T-011/00 | G06F-003/048 | A61B-034/20 | A61B-017/00 | A61B-034/10 | A61B-090/00 | A61B-090/30 | G06F-003/0481 | G06F-003/0482 | G06F-003/0484 | G06K-009/20 | G06K-009/32 | G06T-007/20","","","","","","4920015001181"
"US","US","P","B2","User identified to a controller","Methods, systems, and computer programs for obtaining profile data of a user from a wearable device are provided. One example method includes connecting a peripheral device with a base computing device via a data connection. The peripheral device usable for interfacing with a computer game when executed by the base computing device. The method also includes detecting, by the peripheral device, a wearable device of a user that is using the peripheral device. The wearable device having an electronic circuit and a memory for storing information usable to identify a profile of the user. The method further includes reading or obtaining, by the peripheral device, the information from the memory of the wearable device, then sending the information to the base computing device. The information is used by the base computing device to identify the profile of the user. The profile of the user being used to obtain calibration data for the user, to avoid requiring the user to perform calibration each time the user interacts with the computer game.","1. A method for configuring a computer program based on a user, the method comprising: entering a signature detection mode by the computer program;detecting a signature entered by the user, the signature entered by moving a controller held by the user;exiting the signature detection mode;determining if the computer program has user information associated with the signature entered by the user; andsetting a new calibration for the controller in the computer program based on the user information when the computer program has the user information for the signature entered by the user.","4","15/263242","2016-09-12","2016-0375364","2016-12-29","10610788","2020-04-07","Sony Interactive Entertainment Inc.","Anton  Mikhailov","","","","A63F-0013/79","A63F-0013/79 | A61B-0005/1172 | A63F-0013/213 | A63F-0013/22 | A63F-0013/235 | A63F-0013/35 | A63F-0013/73 | G06F-0003/017 | A63F-2300/1018 | A63F-2300/1031 | A63F-2300/208 | A63F-2300/5546 | G06F-0003/011","A63F-013/79","A63F-013/79 | A63F-013/235 | A63F-013/22 | A63F-013/73 | A63F-013/213 | A63F-013/35 | A61B-005/1172 | G06F-003/01","","","","","","4920015001656"
"US","US","P","B2","System and method for machine-learning input-based data autogeneration","Systems, methods, and devices for automated provisioning are disclosed herein. The system can include a memory including a user profile database having n-dimension attributes of a user. The system can include a user device and a source device. The system can include a server that can: generate and store a user profile in the user profile database and generate and store a characterization vector from the user profile. The server can identify a service for provisioning, receive updates to at least some of the attributes of the first user, and trigger regeneration of the characterization vector from the received inputs. The server can: regenerate the characterization vector, determine an efficacy of the provisioned services, and automatically identify a second service for provisioning for a second user based on the efficacy of the provisioned services to the first user.","1. A machine-learning input-based data autogeneration system comprising: a memory comprising: a user profile database identifying attributes of a plurality of users, wherein the plurality of users comprises a plurality of classes of users, wherein the plurality of classes of users comprise at least one class of subject-users and at least two classes of recipient-users;a model database comprising a plurality of machine-learning models, each of the plurality of machine-learning models trained to generate a report in response to received inputs characterizing attributes of a subject-user and at least one recipient-user;a source device configured to receive source inputs and transmit the received source inputs, wherein the source inputs relate to an attribute of the subject-user;a recipient device configured to receive recipient inputs and transmit the received recipient inputs, wherein the recipient inputs identify an at least one attribute of a recipient-user; anda server configured to: generate a characterization vector characterizing a patient state;identify a state node in a first network corresponding to the patient state, the first network comprising a plurality of nodes linked via a plurality of edges, wherein each of the edges links a pair of nodes, wherein each of the plurality of edges is associated with a conditional probability of a truth of one of the nodes in a pair of nodes linked by the edge based on a status of the other of the nodes in the pair of nodes;identify an action node in a second network according to machine-learning model, the action node linked to the state node;automatically update a user schedule database with information characterizing scheduling of provisioning of a medical service associated with the identified action node;deliver the medical service associated with the identified action node;receive a request at the server for a report characterizing attributes of the subject-user and the delivered medical service;receive a plurality of inputs identifying attributes of the subject-user;receive at least one input identifying an attribute of the recipient-user;select a machine-learning model based on a comparison of the at least one attribute of the recipient-user to metadata linked with the machine-learning model;ingest received inputs into the machine-learning model;receive the generated report from the machine-learning model, wherein the generated report is customized to the at least one attribute of the recipient-user; andautomatically generate and deliver a message to the recipient device comprising at least portions of the generated report.","20","15/955557","2018-04-17","2018-0300398","2018-10-18","10614111","2020-04-07","MAMMOTH MEDICAL, LLC","Tobias  Moeller-Bertram | Christopher A.  McDonald","","","","G06F-0016/337","G06F-0016/337 | A61B-0005/4848 | A61B-0005/7264 | G06F-0009/30036 | G06F-0015/76 | G06K-0009/623 | G06K-0009/6232 | G06N-0005/022 | G06N-0020/00 | H04L-0041/16 | H04L-0041/5054 | H04L-0063/1433 | A61B-0005/0022 | H04L-0067/02 | H04L-0067/18 | H04L-0067/22 | H04L-0067/306","G06F-007/00","G06F-007/00 | G06F-016/335 | G06N-005/02 | G06N-020/00 | A61B-005/00 | G06F-015/76 | H04L-029/06 | G06F-009/30 | G06K-009/62 | H04L-012/24 | H04L-029/08","","","","","","4920015004966"
"US","US","P","B2","Devices with peripheral task bar display zone and under-LCD screen optical sensor module for on-screen fingerprint sensing","Devices or systems with display designs to include both a main display zone and a peripheral display zone that collectively form a seamless contiguous display area for displaying images, content or information over the two zones as a single display area and further allowing for operating the peripheral display zone independently from the main display zone to display certain images, information, or content only on the peripheral display zone even when the main display zone is turned off. In addition to providing display functions separate from or in combination with the display functions by the main display zone, the peripheral display zone based on the disclosed technology can be used to provide for certain sensing functions by including one or more sensors under the display area for the peripheral display zone.","1. An electronic device capable of detecting a fingerprint by optical sensing, comprising: a liquid crystal display (LCD) screen that provides touch sensing operations and includes a LCD display panel structure to display images, wherein the LCD display screen includes (1) a main display zone having LCD display pixels and a peripheral display zone having LCD display pixels wherein the main display zone and peripheral display zone collectively form a seamless contiguous LCD display area, and (2) a LCD backlighting module that provides backlighting light to illuminate both the main display zone and peripheral display zone;a designated peripheral display zone illumination module located relative to the LCD screen and structured to produce and direct illumination light only to the peripheral display zone to enable the peripheral display zone to display images or information independently from the main display zone and to be operable to display images or information when the LCD backlighting module is turned off;a top transparent layer formed over the LCD screen as an interface for being touched by a user for the touch sensing operations and for transmitting the light from LCD screen to display images or information to a user; andan optical sensor module located below the LCD display panel structure and structured to receive probe light that is from an object in contact with or near the peripheral display zone and passes through the LCD screen to detect a fingerprint.","52","15/913869","2018-03-06","2018-0260602","2018-09-13","10614283","2020-04-07","GOODIX TECHNOLOGY INC. | SHENZHEN GOODIX TECHNOLOGY CO., LTD.","Yi  He | Bo  Pi","","","","G06K-0009/0012","G06K-0009/0012 | A61B-0005/0075 | A61B-0005/024 | A61B-0005/0261 | A61B-0005/1032 | A61B-0005/1172 | A61B-0005/1495 | A61B-0005/14532 | A61B-0005/14542 | A61B-0005/681 | G06F-0003/042 | G06F-0003/044 | G06F-0003/0412 | G06F-0003/0418 | G06F-0003/0488 | G06F-0003/14 | G06F-0021/32 | G06F-0021/83 | G06K-0009/0004 | G06K-0009/0008 | G06K-0009/00114 | G06K-0009/209 | G06K-0009/2036 | G09G-0003/3413 | H04L-0063/0861 | A61B-2562/043 | G06F-2203/04106 | G06F-2221/2133 | G06K-0009/00906 | G06K-0009/2018 | G06K-2009/00939 | G09G-2310/04 | G09G-2358/00","G06K-009/00","G06K-009/00 | G06F-003/14 | G06F-003/0488 | G06F-021/32 | G06F-003/042 | G06F-003/041 | H04L-029/06 | G06F-021/83 | G06F-003/044 | G06K-009/20 | A61B-005/145 | A61B-005/00 | A61B-005/103 | G09G-003/34 | A61B-005/026 | A61B-005/1495 | A61B-005/024 | A61B-005/1172","","","","","","4920015005137"
"US","US","P","B2","Matching of findings between imaging data sets","A method includes detecting a focus of attention of an observer of an anatomical image of a set of images, determining a location of the anatomical image includes tissue with a finding of interest based on the detected focus of attention, identifying an anatomical image, from an earlier acquired imaging data set, with a same portion of tissue as the displayed image, visually displaying graphical indicia, concurrently with the displayed image, that identifies the earlier acquired image.","1. A method, comprising: detecting a focus of attention of an observer of a first anatomical image of a set of images;determining, in response to the detected focus of attention, that a location in the first anatomical image includes a tissue with a finding of interest;identifying a second anatomical image from an earlier acquired imaging data set comprising earlier acquired images, with a same portion of the tissue as the first anatomical image by determining that a distance between a first annotation of the first anatomical image and a second annotation of the second anatomical image is below a threshold; andvisually displaying graphical indicia, concurrently with the first anatomical image, that identifies the second anatomical image.","11","14/906608","2014-07-08","2016-0162745","2016-06-09","10614335","2020-04-07","KONINKIJKE PHILIPS N.V.","Eric  Cohen-Solal | Gabriel Ryan  Mankovich | Yuechen  Qian | Thusitha Dananjaya De Silva  Mabotuwana","","","","G06K-0009/2081","G06K-0009/2081 | A61B-0003/113 | A61B-0005/7425 | G06F-0003/013 | G06F-0019/321 | G06K-0009/6202 | G06T-0007/0014 | G06T-2207/20101 | G06T-2207/30004","A61B-003/113","A61B-003/113 | A61B-005/00 | G06F-019/00 | G06F-003/01 | G06K-009/20 | G06K-009/62 | G06T-007/00","","","","","","4920015005187"
"US","US","P","B2","Method and system for providing shipment tracking and notifications","Improved approaches for monitoring status of articles being shipped are disclosed. The monitoring can produce notifications to interested parties. The notifications typically contain status information pertaining to the articles being shipped. Alternatively, interested parties can gain access to status information pertaining to the articles being shipped via a website. According to one embodiment, the status information includes at least position (location) information and shipping conditions information.","1. An apparatus for tracking shipment of a plurality of packages, said apparatus comprising: a storage device to store at least computer program code; andat least one processor to perform at least some of the stored computer program code, the at least one processor performing at least some of the stored computer program code to track shipment of the plurality of packages, the stored computer program code comprises: computer program code for receiving status information associated with a package during shipment, the status information being provided by a mobile electronic device in or attached to the package, the status information including at least position information and environmental information, and the environmental information being related to environmental conditions of or around the package being shipped;computer program code for determining whether a notification condition pertaining to the package exists based on the status information and at least one notification criterion;computer program code for producing a notification message when the notification condition exists; andcomputer program code for initiating electronically sending the notification message to an interested user,wherein the notification condition is determined to exist if the environmental information includes at least one environmental condition that exceeds a predetermined threshold, andwherein the mobile electronic device is configured to induce or influence activation of a mechanical system dependent at least in part on the status information, the mechanical system being at the mobile electronic device.","54","15/933578","2018-03-23","2018-0211216","2018-07-26","10614408","2020-04-07","IpVenture, Inc.","Chung  Lau | C. Douglass  Thomas","","","","G06Q-0010/0833","G06Q-0010/0833 | A61B-0005/0002 | A61B-0005/0022 | A61B-0005/0024 | A61B-0005/02055 | A61B-0005/1112 | A61B-0005/1123 | A61B-0005/6801 | A61B-0005/7282 | A61B-0005/742 | G06F-0011/3013 | G06F-0011/3055 | G06F-0011/3058 | G06F-0019/34 | G06F-0019/3418 | G06Q-0010/00 | G06Q-0010/0832 | G06Q-0010/107 | G06Q-0050/22 | G06Q-0050/24 | G16H-0050/20 | H04L-0067/04 | H04L-0067/18 | H04W-0004/02 | H04W-0004/029 | H04W-0004/20 | A61B-0005/02 | A61B-0005/04 | A61B-0005/1116 | A61B-0005/1118 | H04W-0004/027 | H04W-0064/00 | Y10S-0128/92","G06Q-010/08","G06Q-010/08 | G06Q-050/22 | G06Q-010/10 | G06F-011/30 | G16H-050/20 | A61B-005/00 | A61B-005/11 | G06F-019/00 | G06Q-050/24 | A61B-005/0205 | H04W-004/029 | G06Q-010/00 | H04L-029/08 | H04W-004/02 | H04W-004/20 | A61B-005/02 | A61B-005/04 | H04W-064/00","","","","","","4920015005260"
"US","US","P","B2","Mobile processing device system for patient monitoring data acquisition","A mobile processing device system for patient monitoring data acquisition includes a repository of information. The information associates a particular patient monitoring device type for displaying a particular patient parameter with a particular text label identifying the particular patient parameter. A portable processing device includes an imaging device for acquiring image data representing an image presenting patient parameter data from the particular patient monitoring device type. An image recognition processor uses the information, for analyzing the image data to identify the particular text label identifying the particular patient parameter and a value of the particular patient parameter. An output processor communicates data representing the particular patient parameter and the value to a destination.","1. A computerized system the system comprising: one or more processors; and a non-transitory computer storage media storing computer-useable instructions that, when used by the one or more processors, cause the one or more processors to:capture, via a mobile device, patient data information for a patient from an interface of a non-connected medical device associated with the patient, wherein the patient data information is captured in an image format, and wherein the patient data information is clinical data for the patient;recognizing a monitoring device image and an associated mask stored in a repository based on matching predetermined features of the mask with corresponding features of the interface of the non-connected medical device using iterative rotation, scaling, and translation transformations that fit the mask to the interface;transcribe the patient data information captured from the interface of the non-connected medical device from the image format to a text format that represents the patient data information, wherein the transcribing comprises: recognizing characteristics of the non-connected medical device that are specific to the non-connected medical device, wherein the characteristics include an image type having one or more text labels specific to patient parameters within the patient data information;based on the image type of the non-connected medical device, recognizing separators of text on the interface of the non-connected medical device, wherein the separators distinguish one or more alphanumeric text values of the one or more text labels from one another; andprocessing the patient data information using image recognition and Optical Character Recognition;provide the patient data information on the mobile device; andcommunicate the patient data information to a destination.","21","15/663010","2017-07-28","2018-0040123","2018-02-08","10614569","2020-04-07","CERNER INNOVATION, INC.","Robert A.  Neff","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/0033 | A61B-0005/742 | G06K-0009/00442 | G06K-0009/3258 | A61B-0005/743 | G06F-0017/2765 | G06K-2209/03 | G06T-2207/30004","G06T-007/00","G06T-007/00 | A61B-005/00 | G06K-009/32 | G06K-009/00 | G06F-017/27","","","","","","4920015005421"
"US","US","P","B2","Personalized skin diagnosis and skincare","Methods, systems, and devices are disclosed herein for conducting skin analysis for a user. In one aspect, an apparatus for conducting skin analysis is disclosed, comprising: a reflective display operative to reflect an image of a user and to render a graphical user interface; an input interface operative to receive a user input for operating the apparatus, wherein the input interface includes a motion sensor module operative to detect gesture user input; an image capturing module, wherein the image capturing module is operative to capture an image of the user; a processing system configured to receive the captured image from the image capturing module, to receive the user input from the input interface, and to generate a skin profile corresponding to the user's skin condition based on the captured image; and a wireless communication module operative to transmit the skin profile outbound to a computing device, and operative to receive skincare feedback that is generated based on the skin profile from the computing device.","1. An apparatus for conducting personalized skin analysis, comprising: a base;a reflective display coupled to the base, wherein the reflective display is operative to reflect an image of a user and to display a graphical user interface for the user to receive information, the reflective display further operative to display a template for a part of a human body;two arrays of LED lights arranged along two sides of the reflective display operable to simulate a plurality of lighting scenarios in connection with an appearance of a product on a skin of the user, wherein each of the plurality of lighting scenarios corresponds to a light temperature of the array of LED lights;a motion sensor coupled to the base to detect gesture user input and to detect an application of the product;a camera coupled to the base, wherein the camera is operative to capture an image of the user that is adjusted according to the template;a processor in communication with the camera, the reflective display and the motion sensor, wherein the processor is configured to receive the captured image from the camera, to receive the user input from the motion sensor, and to generate a user skin profile corresponding to a skin condition of the user based on the captured image, the processor further configured to cause the graphical user interface to display a mapping between the plurality of lighting scenarios and corresponding light temperatures to allow the user to select a desired lighting scenario prior to the application of the product; anda wireless communication transmitter and a wireless communication receiver in communication with the processor, wherein the wireless communication transmitter is operative to transmit the user skin profile outbound to a computing device, and the wireless communication receiver is operative to receive skincare feedback that is generated based on the user skin profile from the computing device.","25","15/397700","2017-01-03","2017-0340267","2017-11-30","10614921","2020-04-07","CAL-COMP BIG DATA, INC.","Shyh-Yong  Shen | Min-Chang  Chi","105116064 A","TW","2016-05-24","G16H-0050/70","G16H-0050/70 | A61B-0005/0013 | A61B-0005/0075 | A61B-0005/0077 | A61B-0005/0079 | A61B-0005/442 | A61B-0005/444 | A61B-0005/445 | A61B-0005/486 | A61B-0005/6898 | A61B-0005/749 | A61B-0005/7445 | A61B-0090/96 | G06F-0003/0488 | G06F-0019/321 | G06K-0009/00228 | G06K-0009/6202 | G06T-0007/0012 | G16H-0010/60 | G16H-0030/20 | G16H-0030/40 | G16H-0040/63 | G16H-0040/67 | G16H-0050/20 | H04L-0067/10 | A61B-2090/309 | A61B-2560/0242 | A61B-2560/0431 | A61B-2562/185 | A61B-2576/00 | G06T-2207/30088","G16H-050/70","G16H-050/70 | G16H-030/40 | G16H-040/63 | G16H-040/67 | G16H-010/60 | G16H-050/20 | A61B-090/96 | A61B-005/00 | G06F-019/00 | G06F-003/0488 | G06K-009/00 | G06K-009/62 | G06T-007/00 | H04L-029/08 | G16H-030/20 | A61B-090/30","","","","","","4920015005773"
"US","US","P","B2","Enabling wearables to cognitively alter notifications and improve sleep cycles","A method, computer system, and computer program product for cognitively adjusting a notification alert delivery time are provided. The embodiment may include receiving a message notification from a sender. The embodiment may also include determining an importance of the received message notification based on a plurality of notification attributes and a plurality of person attributes that are each associated with the received message notification. The embodiment may further include, in response to determining to alert a user of the received message notification based on the determined importance, identifying a current user sleep stage. The embodiment may also include, in response to determining the current user sleep stage will minimally impact the user, transmitting the received message notification to a user device.","1. A method for cognitively adjusting a notification alert delivery time, the method comprising: receiving a message notification from a sender;determining an importance of the received message notification based on a plurality of notification attributes and a plurality of person attributes that are each associated with the received message notification;in response to determining to alert a user of the received message notification based on the determined importance, identifying a current user sleep stage, wherein the current user sleep stage is REM or NREM, and wherein the NREM sleep stage is selected from a group consisting of N1, N2, and N3;in response to determining the current user sleep stage will not minimally impact the user, tuning one or more wearable technology device parameters for a next sleep stage, wherein tuning the one or more wearable technology device parameters for a next sleep stage further comprises:calculating a minimum amount of time left in a user sleep cycle, wherein the minimum amount of time left in the user sleep cycle is calculated as T=ANTDmin+n+tprev, and wherein T is the time left in the user sleep cycle, ANTDmin is a minimum allowable notification time delay of the current and remaining sleep stages, n is a total amount of time elapsed in the current sleep stage, and tprev is a sum of an elapsed time in each previously completed sleep stage;modifying the notification delivery time based on the calculated minimum amount of time left in the user sleep cycle; andin response to determining the current user sleep stage will minimally impact the user, transmitting the received message notification to a user device.","5","16/414147","2019-05-16","2019-0273711","2019-09-05","10616167","2020-04-07","INTERNATIONAL BUSINESS MACHINES CORPORATION","Bharath  Ganesh | Dhandapani  Shanmugam | Tuhin  Sharma | Jothi  Subramani","","","","H04L-0051/24","H04L-0051/24 | A61B-0005/4812 | G06F-0001/163 | G06Q-0010/10 | G06Q-0010/107 | H04L-0051/26 | H04W-0068/005 | H04L-0051/16 | H04L-0067/12 | H04M-0001/72552 | H04M-0001/72569 | H04M-2242/26 | H04W-0068/02","A61M-021/02","A61M-021/02 | A61B-005/0476 | A61B-005/00 | G06F-003/01 | H04L-012/58 | G06F-001/16 | H04W-068/00 | G06Q-010/10 | H04M-001/725 | H04W-068/02 | H04L-029/08","","","","","","4920015007007"
"US","US","P","B2","Method for recovering patient registration","A method for updating a patient registration during a surgical procedure is disclosed. The surgical procedure uses an optical navigation system for optically tracking a patient reference object in a real world space and includes intra-operatively acquiring a first set of image data depicting a region of interest on the patient while the first registration is intact. The region of interest includes at least one anatomical landmark. The method includes: detecting that the first registration has been lost; obtaining a second set of image data depicting the region of interest; identifying a transform based on the first set of image data and the second set of image data; and applying the identified transform to data points of the first registration to obtain data points for the updated patient registration.","1. A computer-implemented method for updating a first patient registration during a surgical procedure that uses an optical navigation system for optically tracking a patient reference object in a real world space, the surgical procedure including intra-operatively acquiring a first set of image data depicting a region of interest on the patient while the first registration is intact, the region of interest including at least one anatomical landmark, the method comprising: detecting that the first registration has been lost;obtaining a second set of image data depicting the region of interest;identifying a transform based on the first set of image data and the second set of image data; andapplying the identified transform to data points of the first registration to obtain data points for the updated patient registration.","18","15/796002","2017-10-27","2019-0125451","2019-05-02","10603118","2020-03-31","SYNAPTIVE MEDICAL (BARBADOS) INC.","Kirusha  Srimohanarajah | Gal  Sela | Dorothy  Lui | Kai Michael  Hynna","","","","A61B-0034/20","A61B-0034/20 | G06Q-0050/24 | G16H-0010/60 | G16H-0020/40 | G16H-0030/40 | A61B-0017/34 | A61B-0034/10 | A61B-0090/36 | A61B-2034/107 | A61B-2034/2055 | A61B-2090/363 | A61B-2090/374 | A61B-2090/3735","G06K-009/00","G06K-009/00 | A61B-034/20 | G06Q-050/24 | G16H-010/60 | G16H-030/40 | G16H-020/40 | A61B-090/00 | A61B-034/10 | A61B-017/34","","","","","","4920014001206"
"US","US","P","B2","Systems and methods for collecting, analyzing, and sharing bio-signal and non-bio-signal data","A computer network implemented system for improving the operation of one or more biofeedback computer systems is provided. The system includes an intelligent bio-signal processing system that is operable to: capture bio-signal data and in addition optionally non-bio-signal data; and analyze the bio-signal data and non-bio-signal data, if any, so as to: extract one or more features related to at least one individual interacting with the biofeedback computer system; classify the individual based on the features by establishing one or more brain wave interaction profiles for the individual for improving the interaction of the individual with the one or more biofeedback computer systems, and initiate the storage of the brain waive interaction profiles to a database; and access one or more machine learning components or processes for further improving the interaction of the individual with the one or more biofeedback computer systems by updating automatically the brain wave interaction profiles based on detecting one or more defined interactions between the individual and the one or more of the biofeedback computer systems. A number of additional system and computer implemented method features are also provided.","1. A brainwave monitoring system comprising: a plurality of client computing devices, each of the plurality of client computing devices in communication with at least one bio-signal sensor including at least one electroencephalography (EEG) bio-signal sensor; andat least one computer server in communication with the plurality of computing devices over a communications network, the at least one computer server configured to: receive time-coded EEG bio-signal data from at least one of the plurality of client computing devices, the time-coded EEG bio-signal data having metadata indicating a user identifier of the plurality of user identifiers;acquire time-coded feature event data;generate a cloud pipeline instance to process the time-coded EEG bio-signal data and the time coded feature event data, the cloud pipeline instance defining pipeline parameters for a classification model;extract, using the cloud pipeline instance, feature events from the time coded feature event data at feature event time codes, each feature event being a set of variables and corresponding values at at least one feature event time code;automatically search the feature events to identify a pattern, the pattern linked to a feature event time code of the at least one feature event time code, the pattern representing user response associated with the feature event data at the feature event time code;using the feature event time code linked to the pattern identified in the feature-events, label segments in the time-coded EEG bio-signal data having EEG bio-signal time-codes being same or similar to the feature event time code linked to the pattern;update the classification model with the EEG bio-signal features extracted from labelled segments of the time-coded EEG bio-signal data, the classification model for predicting brain state based on the pipeline parameters;determine a response classification of the segments of the time-coded EEG bio-signal data using the classification model and pipeline parameters, the response classification being an automatic prediction of a brain state at the EEG bio-signal time codes;update, for the user identifier, a bio-signal interaction profile based on the classification model, the response classification, the time-coded EEG bio-signal data associated with that user identifier, and the time-coded feature event data;receive additional time-coded EEG bio-signal data associated with the user identifier; andgenerate an encryption key using the bio-signal interaction profile associated with the user identifier and segments of the additional time-coded EEG bio-signal data associated with the user identifier.","20","16/132242","2018-09-14","2019-0113973","2019-04-18","10606353","2020-03-31","INTERAXON INC","Trevor  Ce Coleman | Christopher Allen  Aimone | Ariel Stephanie  Garten | Locillo (Lou) Giuseppe  Pino | Paul Harrison  Baranowski | Raul Rajiv  Rupsingh | Kapil Jay Mishra  Vidyarthi | Graeme  Moffat | Samuel Thomas  Mackenzie","","","","G06F-0003/015","G06F-0003/015 | A61B-0005/0006 | A61B-0005/0022 | A61B-0005/0024 | A61B-0005/0476 | A61B-0005/165 | A61B-0005/486 | A61B-0005/7267 | G06F-0003/011 | G06F-0016/00 | G06F-0019/00 | G06N-0020/00 | G16H-0040/63 | G16H-0040/67 | G16H-0050/20 | G16H-0050/70 | H04L-0012/16 | H04L-0067/12 | H04L-0067/22 | H04L-0067/42 | A61B-0005/02416 | A61B-0005/02438 | A61B-0005/1118 | A61B-0005/4088 | G06F-2203/011 | H04L-0012/1813","G06F-003/01","G06F-003/01 | G16H-040/67 | G06F-019/00 | H04L-029/06 | H04L-012/16 | A61B-005/0476 | A61B-005/00 | G06F-016/00 | H04L-029/08 | G06N-020/00 | A61B-005/16 | G16H-040/63 | G16H-050/70 | G16H-050/20 | A61B-005/024 | A61B-005/11 | H04L-012/18","","","","","","4920014004427"
"US","US","P","B2","Intelligent motion capture element","Intelligent motion capture element that includes sensor personalities that optimize the sensor for specific movements and/or pieces of equipment and/or clothing and may be retrofitted onto existing equipment or interchanged therebetween and automatically detected for example to switch personalities. May be used for low power applications and accurate data capture for use in healthcare compliance, sporting, gaming, military, virtual reality, industrial, retail loss tracking, security, baby and elderly monitoring and other applications for example obtained from a motion capture element and relayed to a database via a mobile phone. System obtains data from motion capture elements, analyzes data and stores data in database for use in these applications and/or data mining. Enables unique displays associated with the user, such as 3D overlays onto images of the user to visually depict the captured motion data. Enables performance related equipment fitting and purchase. Includes active and passive identifier capabilities.","1. A motion capture element comprising: a memory;a sensor configured to capture one or more values associated with an orientation, position, velocity, acceleration, angular velocity, proximity, pressure or strain of said motion capture element;a first communication interface;a microcontroller coupled with said memory, said sensor and said first communication interface;wherein said motion capture element is configured to couple with a piece of equipment; andwherein said microcontroller is configured to collect data that comprises sensor values from said sensor;store said data in said memory;analyze said data to calculate a linear velocity and an acceleration of said piece of equipment;when said linear velocity or said acceleration exceeds a first threshold at a first time, determine whether said linear velocity or said acceleration changes by an amount that exceeds a second threshold within a time window after said first time;when said linear velocity or said acceleration changes by said amount within said time window, store an impact event comprising said data in said memory or transmit said impact event via said first communication interface.","19","15/866382","2018-01-09","2019-0042838","2019-02-07","10607068","2020-03-31","BLAST MOTION INC.","Bhaskar  Bose | Michael  Bentley | John  Goree | Tim  Haynes","","","","G06K-0009/00342","G06K-0009/00342 | A61B-0005/1126 | A63B-0024/0003 | A63F-0013/211 | A63F-0013/212 | A63F-0013/213 | A63F-0013/65 | G06Q-0010/0833 | H04M-0001/7253 | H04N-0005/23293 | H04N-0007/18 | H04N-0007/183 | H04N-0017/002 | H04M-2250/12 | Y02D-0070/00 | Y02D-0070/142 | Y02D-0070/144 | Y02D-0070/162 | Y02D-0070/164 | Y02D-0070/166 | Y02D-0070/26","H04N-007/18","H04N-007/18 | G06K-009/00 | A63F-013/211 | A63F-013/65 | A63F-013/212 | G06Q-010/08 | H04M-001/725 | A61B-005/11 | A63B-024/00 | A63F-013/213 | H04N-005/232 | H04N-017/00","","","","","","4920014005135"
"US","US","P","B2","Wearable digital device for personal health use for saliva, urine, and blood testing and mobile wrist watch powered by user body","Provided are a wearable personal digital device and related methods. The wearable personal digital device may comprise a processor, a display, biometric sensors, activity tracking sensors, a memory unit, a communication circuit, a housing, an input unit, a projector, a timepiece unit, a haptic touch control actuator, and a band. The processor may be operable to receive data from an external device, provide a notification to a user based on the data, receive a user input, and perform a command selected based on the user input. The communication circuit may be communicatively coupled to the processor and operable to connect to a wireless network and communicate with the external device. The housing may be adapted to enclose the components of the wearable personal digital device. The band may be adapted to attach to the housing and secure the wearable personal digital device on a user body.","1. A system comprising a wearable digital device for adoptive cell transfer for treatment of cancer by CAR T-cell therapy, a glucose metering unit, a head wearable holder, and an electrochemical detector, the wearable digital device comprising: a processor being operable to: receive data from an external device;based on the data, provide a notification to a user;receive a user input;perform a command, the command being selected based on the user input;provide a natural language user interface to communicate with the user, the natural language user interface being operable to sense a user voice and provide a response in a natural language to the user;a near field communication (NFC) unit communicatively coupled to the processor;a display communicatively coupled to the processor, the display including a touchscreen, wherein the display includes a force sensor, wherein the force sensor is operable to sense a touch force applied by the user to the display and calculate coordinates of a touch by the user, and further operable to analyze the touch force, and based on the touch force, select a tap command or a press command based on a predetermined criteria;a memory unit communicatively coupled to the processor;a communication circuit communicatively coupled to the processor and operable to connect to a wireless network and communicate with the external device, calculating hourly health data and make related mobile devices payments;activity tracking sensors operable to monitor user movements in a three-dimensional trajectory, identify a type of user activity, identify a specific motion fingerprint of an exercise, evaluate user physical form, count repetitions, calculate calories burned, sense and track position of the user to identify snoring of the user and provide a haptic notification to the user to break snoring;a housing adapted to enclose at least the processor, the display, the activity tracking sensors, the memory unit, and the communication circuit;an input unit communicatively coupled to the processor, wherein the input unit extends from the housing and is configured to perform one or more of a rotational motion and a linear motion, wherein the one or more motions are operable to input commands to the processor; anda band adapted to attach to the housing and to secure the wearable digital device on a user body;biometric sensors disposed within the band and operable to sense one or more biometric parameters of the user, wherein based on detection that the one or more of the biometric parameters exceed predetermined limits, biometric sensors are configured to produce the alarm, wherein the biometric sensors include lenses and infrared light-emitting diodes (LED) and visible-light LEDs, wherein the biometric sensors include a skin contact sensor data processing engine, the skin contact sensor data processing engine being operable to monitor a user electrocardiogram and a heart rate of the user sensed by the biometric sensors, the user electrocardiogram and the heart rate being identification and personal data of the user, wherein the skin contact sensor data processing engine is operable to prompt the user to enter a personal identification number and associate the personal identification number with both the user electrocardiogram and the heart rate obtained after the wearable digital device has been secured to a wrist of the user, wherein processor stores the obtained electrocardiogram and heart rate in the memory unit as a reference electrocardiogram and reference heart rate;a haptic touch control actuator operable to produce a haptic feedback in response to one or more events, the one or more events including receiving of the alert, receiving of a notification, a confirmation, movement of the wearable digital device, receiving of the user input, and sensing of the one or more biometric parameters, the haptic feedback being sensed by the user body, wherein the haptic feedback includes a plurality of feedback types, each of the one or more events being associated with one of the plurality of feedback types;a set of electrodes with electric wires disposed within the band;a battery disposed in the housing of the wearable digital device;a camera;the glucose metering unit configured to be attached to the housing, the glucose metering unit being in communication with the processor, the glucose metering unit being configured to: accommodate a test strip for receiving a blood sample of the user;upon insertion of the test strip having the blood sample of the user into the glucose metering unit, measure a blood glucose level in the blood sample; andcommunicate the blood glucose level to the processor;the head wearable holder comprising built-in electrodes configured to be operably coupled to the wearable digital device by a communication cable, wherein when worn on a head of the user, the wearable digital device is operable to generate electric current shock waves directed to kill early lesion and cancer cells or solid tumor and send the electric current shock waves via the built-in electrodes into a human brain of the user in conjunction with application of CAR T-cell therapy;the electrochemical detector configured to be attached to the housing, the electrochemical detector being in communication with the processor, the electrochemical detector being configured to: accommodate a sample, the sample including at least one of a blood sample, a urine sample, and a saliva sample of the user;upon placing the sample into the electrochemical detector, apply a predetermined amount of an electric current to the sample;upon applying the electric current, measure a voltage and a current generated in liquids of the sample to determine characteristic signatures of the liquids in the sample,based on the characteristic signatures, analyze the sample to determine a red blood cell distribution width and a variation of a size of red blood cells to estimate effectiveness of T cells impact in the CAR T-cell therapy of a disease used during the adoptive cell transfer, the disease including one of a cancer and a cardiovascular disease; andcommunicate data associated with the analysis to the processor, wherein the wearable digital device in configured in a form of a wrist watch to be worn by the user, wherein the wearable digital device further includes: a thermoelectric generator (TEG) configured to: collect a heat of a body of the user;convert the heat into energy; andstore the energy in the batter;a sensor configured to be in contact with a skin of the user; anda wire configured to be placed under the skin of the user beneath the sensor to obtain a sample, the sample including at least a blood sample, wherein the sensor is configured to analyze the sample to determine at least a blood glucose level;and wherein the display is further operable to log and display results of the adoptive cell transfer for treatment of cancer by CAR T-cell therapy, electric current shock waves, the sensor, the electrochemical detector, the glucose metering unit, the activity tracking sensors, and the biometric sensors.","3","16/297659","2019-03-10","2019-0206538","2019-07-04","10607732","2020-03-31","Zhou Tian Xing | Andrew H B Zhou | Tiger T G Zhou","Zhou Tian  Xing | Andrew H B  Zhou | Tiger T G  Zhou","","","","G16H-0020/10","G16H-0020/10 | A61B-0005/0024 | A61B-0005/02007 | A61B-0005/02055 | A61B-0005/0402 | A61B-0005/112 | A61B-0005/1112 | A61B-0005/1117 | A61B-0005/1118 | A61B-0005/1172 | A61B-0005/14507 | A61B-0005/14532 | A61B-0005/14546 | A61B-0005/4818 | A61B-0005/4848 | A61B-0005/4866 | A61B-0005/681 | A61B-0005/6804 | A61B-0005/7405 | A61B-0005/746 | A61B-0005/7425 | A61B-0005/7455 | A61B-0005/7495 | A61B-0010/0051 | G06F-0001/163 | G06F-0001/1639 | G06F-0003/0414 | G06F-0003/0426 | G06F-0003/04842 | G06F-0003/04883 | G06F-0003/167 | G06F-0021/32 | G06F-0021/35 | G06F-0021/6245 | G06K-0007/10762 | G06N-0020/00 | G06Q-0020/102 | G06Q-0020/204 | G06Q-0020/206 | G06Q-0020/32 | G06Q-0020/322 | G06Q-0020/327 | G06Q-0020/3221 | G06Q-0020/3224 | G06Q-0020/3229 | G06Q-0020/3274 | G06Q-0020/3276 | G06Q-0020/3278 | G06Q-0020/351 | G06Q-0020/36 | G06Q-0020/3821 | G06Q-0020/3829 | G06Q-0020/401 | G06Q-0020/4012 | G06Q-0020/40145 | G06Q-0030/0226 | G06Q-0030/0267 | G06Q-0030/06 | G06Q-0030/0601 | G06Q-0030/0641 | G07C-0009/00309 | G10L-0015/18 | G10L-0015/22 | G16H-0010/00 | G16H-0010/60 | G16H-0040/63 | G16H-0050/20 | H04B-0001/385 | H04L-0067/04 | H04L-0067/10 | H04L-0067/12 | H04M-0001/72527 | H04W-0004/33 | A61B-0005/01 | A61B-0005/021 | A61B-0005/02433 | A61B-0005/0816 | A61B-2560/0252 | A61B-2562/028 | A61B-2562/0219 | G06F-0003/016 | G06F-0003/017 | G06K-0009/00087 | G06K-0009/00335 | G06K-0009/00892 | G06K-2007/10534 | G06K-2009/00939 | G06K-2209/01 | G06Q-2220/00 | G10L-2015/223 | H04B-2001/3861 | H04M-0001/7253","A61B-005/0205","A61B-005/0205 | G16H-010/00 | G16H-020/10 | G10L-015/18 | G06F-003/0488 | G06N-020/00 | A61B-005/00 | G06F-003/041 | G06F-003/16 | A61B-005/11 | A61B-005/02 | A61B-005/145 | G06F-021/32 | G07C-009/00 | A61B-010/00 | G10L-015/22 | A61B-005/1172 | G06Q-020/36 | A61B-005/0402 | G06Q-020/32 | G06F-021/62 | G06K-007/10 | G16H-050/20 | G16H-010/60 | G16H-040/63 | G06Q-020/38 | H04L-029/08 | G06Q-020/20 | G06Q-020/34 | G06Q-020/10 | G06Q-030/06 | G06Q-030/02 | G06F-001/16 | G06Q-020/40 | H04M-001/725 | H04B-001/3827 | H04W-004/33 | G06F-021/35 | G06F-003/0484 | G06F-003/042 | A61B-005/024 | A61B-005/01 | G06F-003/01 | A61B-005/021 | G06K-009/00 | A61B-005/08","","","","","","4920014005794"
"US","US","P","B2","Systems and methods for surgical and interventional planning, support, post-operative follow-up, and functional recovery tracking","Various systems and methods are provided for surgical and interventional planning, support, post-operative follow-up, and functional recovery tracking. In general, a patient can be tracked throughout medical treatment including through initial onset of symptoms, diagnosis, non-surgical treatment, surgical treatment, and recovery from the surgical treatment. In one embodiment, a patient and one or more medical professionals involved with treating the patient can electronically access a comprehensive treatment planning, support, and review system. The system can provide recommendations regarding diagnosis, non-surgical treatment, surgical treatment, and recovery from the surgical treatment based on data gathered from the patient and the medical professional(s). The system can manage the tracking of multiple patients, thereby allowing for data comparison between similar aspects of medical treatments and for learning over time through continual data gathering, analysis, and assimilation to decision-making algorithms.","1. A surgical method, comprising: wearing a stereoscopic viewing device during performance of a surgical procedure on a patient;receiving from the stereoscopic viewing device a visualization overlaid on the patient indicating a recommended trajectory for a pedicle screw into a vertebra of the patient, the recommended trajectory being part of a pre-operative plan for the surgical procedure developed before the performance of the surgical procedure; andreceiving an alert indicating a deviation between the recommended trajectory and an actual trajectory of the pedicle screw into the vertebra of the patient.","18","16/046450","2018-07-26","2018-0344308","2018-12-06","10595844","2020-03-24","DEPUY SYNTHES PRODUCTS, INC.","Namal  Nawana | William C.  Horton | William J.  Frasier | Cody  Cranson | Max  Reinhardt | Mark T.  Hall | Matthew  Parsons | Jennifer  DiPietro | Kevin  Lee | Michelle  LaWare | John P.  Griffin | Sean P.  Selover | Jonathan  Bellas | Douglas  Raymond | Nicholas  Pavento | Mary L.  Fowler | Dennis  Chien","","","","A61B-0017/025","A61B-0017/025 | A61B-0005/0022 | A61B-0005/1118 | A61B-0005/4509 | A61B-0005/4566 | A61B-0005/4571 | A61B-0005/4824 | A61B-0005/4833 | A61B-0005/4848 | A61B-0005/7282 | A61B-0005/742 | A61B-0005/746 | A61B-0005/7475 | A61B-0006/485 | A61B-0008/08 | A61B-0017/02 | A61B-0017/50 | A61B-0034/10 | A61B-0034/20 | A61B-0034/25 | G01L-0005/00 | G06F-0019/00 | G06F-0019/321 | G06F-0019/325 | G06F-0019/3481 | G06Q-0010/00 | G06Q-0010/10 | G06Q-0050/24 | G16H-0010/20 | G16H-0040/20 | G16H-0040/40 | G16H-0040/63 | G16H-0050/20 | G16H-0050/50 | G16H-0050/70 | G16Z-0099/00 | A61B-0006/4494 | A61B-0006/506 | A61B-2010/009 | A61B-2010/0093 | A61B-2017/00115 | A61B-2017/00119 | A61B-2017/0262 | A61B-2034/101 | A61B-2034/105 | A61B-2034/2055 | A61B-2034/2057 | A61B-2034/252 | A61B-2034/254 | A61B-2034/256","A61B-017/00","A61B-017/00 | A61B-017/02 | G06Q-050/24 | G06Q-010/00 | G06F-019/00 | G06Q-010/10 | A61B-034/20 | A61B-034/00 | A61B-034/10 | G16H-010/20 | G16H-040/63 | G16H-040/20 | G16H-040/40 | G16H-050/50 | G16H-050/70 | G16H-050/20 | G16Z-099/00 | A61B-005/00 | A61B-006/00 | A61B-005/11 | G01L-005/00 | A61B-017/50 | A61B-008/08 | A61B-010/00","","","","","","4920013001122"
"US","US","P","B2","Systems and methods for inter-app communications","Methods, devices and systems are disclosed for inter-app communications between software applications on a mobile communications device. In one aspect, a computer-readable medium on a mobile computing device comprising an inter-application communication data structure to facilitate transitioning and distributing data between software applications in a shared app group for an operating system of the mobile computing device includes a scheme field of the data structure providing a scheme id associated with a target software app to transition to from a source software app, wherein the scheme id is listed on a scheme list stored with the source software app; and a payload field of the data structure providing data and/or an identification where to access data in a shared file system accessible to the software applications in the shared app group, wherein the payload field is encrypted.","1. A method for initiating inter-application communication between software applications, comprising: designating software apps to a shared app group for an operating system of a mobile computing device, the shared app group including a first software app and one or more preapproved software apps, the first software app stored on a computer-readable medium of the mobile computing device and comprising instructions executable by a processor of the mobile computing device;establishing an inter-app data communication architecture on the mobile computing device to link the first software app and a second software app included among the preapproved software apps, wherein the inter-app data communication architecture includes a data structure including (i) a scheme field to identify a software app from a scheme list and (ii) a payload field that is encrypted and includes data and/or an identification of where to access data in a shared file system of the shared app group;generating a public/private key pair for encryption and decryption of the payload field of the data structure by: providing a first public key for the first software app in a shared keychain of the shared app group, providing a first private key for the first software app in a first private keychain accessible to the first software app, providing a second public key for the second software app in the shared keychain, and providing a second private key for the second software app in a second private keychain accessible to the second software app; andgenerating a database key for encryption of a shared database in the shared file system by producing a database key in the first private keychain accessible to the first software app, and creating an encrypted database key by encrypting a copy of the database key with the second public key, wherein the encrypted database key is stored in the shared keychain.","24","15/474886","2017-03-30","2017-0286194","2017-10-05","10596318","2020-03-24","DEXCOM, INC.","Gary A.  Morris | Scott M.  Belliveau | Esteban  Cabrera, Jr. | Rian  Draeger | Laura J.  Dunn | Timothy Joseph  Goldsmith | Hari  Hampapuram | Christopher Robert  Hannemann | Apurv Ullas  Kamath | Katherine Yerre  Koehler | Patrick Wile  McBride | Michael Robert  Mensinger | Francis William  Pascual | Philip Mansiel  Pellouchoud | Nicholas  Polytaridis | Philip Thomas  Pupa | Anna Leigh  Davis | Kevin  Shoemaker | Brian Christopher  Smith | Benjamin Elrod  West | Atiim Joseph  Wiley","","","","A61M-0005/1723","A61M-0005/1723 | A61B-0005/14532 | A61B-0005/4839 | A61B-0005/742 | A61B-0005/7405 | G06F-0009/54 | G06F-0009/546 | G06F-0016/2228 | G06F-0016/955 | G06F-0019/3468 | G06F-0021/606 | G08B-0021/0453 | G08B-0025/08 | G16H-0040/63 | H04L-0009/0637 | H04L-0009/0822 | H04L-0009/0833 | H04L-0009/0861 | H04L-0009/0891 | H04L-0009/14 | H04L-0009/30 | H04L-0063/0428 | H04M-0001/7253 | H04M-0001/72527 | H04W-0012/08 | A61M-2205/3584 | A61M-2205/50 | A61M-2205/502 | A61M-2230/201 | H04L-2209/80","A61M-005/172","A61M-005/172 | H04M-001/725 | G08B-021/04 | A61B-005/145 | A61B-005/00 | H04L-029/06 | G06F-009/54 | G06F-019/00 | G06F-016/955 | G06F-016/22 | G06F-021/60 | H04W-012/08 | G08B-025/08 | G16H-040/63 | H04L-009/08 | H04L-009/06 | H04L-009/14 | H04L-009/30","","","","","","4920013001591"
"US","US","P","B2","Motion analysis device, motion analysis system, motion analysis method, program, and recording medium","A motion analysis device includes a first calculation unit that obtains a relation between a movement direction of a ball hitting surface of an exercise tool at a time of entering an impact and a posture of the ball hitting surface at the impact by using an output of an inertial sensor.","1. A motion analysis system comprising: a wireless inertial sensor that is configured to attach to a shaft of a golf club, and that measures acceleration; anda processor that is configured to wirelessly communicate with the wireless inertial sensor, and that is programmed to: calculate, based on measured acceleration data received from the wireless inertial sensor, an initial position and an initial posture of a ball hitting surface of the golf club at a timing of starting a swing;detect, based on the received measured acceleration data, a timing of actual impact between the ball hitting surface of the golf club and a golf ball;calculate a movement direction of the ball hitting surface of the golf club and an impact posture of the ball hitting surface at the timing of actual impact;calculate a relative angle of the ball hitting surface of the golf club at the timing of actual impact based on the calculated movement direction and the calculated impact posture of the ball hitting surface at the timing of actual impact; andcause a display to displayprojection-related data based on the calculated relative angle of the ball hitting surface at the timing of actual impact.","14","15/973589","2018-05-08","2018-0300728","2018-10-18","10600056","2020-03-24","SEIKO EPSON CORPORATION","Kazuhiro  Shibuya | Masafumi  Sato","2014-258533","JP","2014-12-22","G06Q-0020/4016","G06Q-0020/4016 | A61B-0005/11 | A61B-0005/6895 | G06K-0009/00342 | G06K-0009/00543 | G06Q-0010/0639 | G06Q-0020/24 | G06Q-0020/342 | G09B-0019/0038 | A61B-2503/10 | G06F-0019/3481 | G16H-0020/30 | H04M-0001/7253","A63B-069/36","A63B-069/36 | G06Q-020/40 | A61B-005/11 | G06K-009/00 | G09B-019/00 | G06Q-010/06 | A61B-005/00 | G06Q-020/24 | G06Q-020/34 | G06F-019/00 | H04M-001/725 | G16H-020/30","","","","","","4920013005302"
"US","US","P","B2","Intuitive automation in patient modeling","To overcome the difficulties inherent in conventional treatment planning approaches, new techniques are described herein for providing an intuitive user interface for automatic structure derivation in patient modeling. In an embodiment, a graphical user interface is provided that provides a list of structures of a specified region. The interface uses medical terminology instead of mathematical one. In one or more embodiments, the list of structures may be a pre-defined list of structures that correspond to that region for the purposes of treatment planning. A user is able to actuate a toggle to include and/or exclude each of the structures separately. In one or more embodiments, the user is also able to actuate a toggle to define a perimeter around each included structure, and further define a margin around the perimeter. The user is also able to specify whether the desired output should include a union or the intersection of all included structures.","1. A method of automatic structure delineation, the method comprising: causing display, by a computer system, of an image from medical image data;causing display, by the computer system, of a graphical user interface, the graphical user interface comprising a list of structures corresponding to an area of interest displayed in the image and one or more operations available to be performed;receiving user supplied input through the graphical user interface, the user supplied input corresponding to a selection of structures from the list of structures;determining and performing a Boolean operation based on the user supplied input, wherein the Boolean operation comprises a union of or an intersection of each structure of the selection of structures indicated by the user supplied input for inclusion in the Boolean operation;generating a graphical delineation of the structures resulting from the Boolean operation;storing the graphical delineation as one or more corresponding output structures; andupdating the display to include the graphical delineation of the one or more output structures.","20","15/596923","2017-05-16","2017-0340901","2017-11-30","10600514","2020-03-24","VARIAN MEDICAL SYSTEMS, INC. | VARIAN MEDICAL SYSTEMS INTERNATIONAL AG","Benjamin M.  Haas | Thomas  Coradi | Tomasz  Morgas","","","","G16H-0040/63","G16H-0040/63 | G06F-0019/00 | G06T-0007/11 | G06T-0007/149 | G16H-0050/50 | A61N-2005/1074 | G06F-0003/0488 | G06F-0003/04815 | G06F-0003/04845 | G06F-0003/04847 | G06T-0003/0068 | G06T-2200/24 | G06T-2207/30096","G16H-040/63","G16H-040/63 | G06T-007/11 | G06T-007/149 | G16H-050/50 | A61N-005/10 | G06F-003/0488 | G06F-003/0484 | G06F-003/0481 | G06T-003/00 | G06F-017/00 | G06F-019/00","","","","","","4920013005755"
"US","US","P","B2","Operatively tuning implants for increased performance","A method for preoperatively characterizing an individual patient's biomechanic function in preparation of implanting a prosthesis is provided. The method includes subjecting a patient to various activities, recording relative positions of anatomy during said various activities, measuring force environments responsive to said patient's anatomy and affected area during said various activities, characterizing the patient's biomechanic function from said relative positions and corresponding force environments, inputting the measured force environments, relative positions of knee anatomy, and patient's biomechanic function characterization into one or more computer simulation models, inputting a computer model of the prosthesis into said one or more computer simulation models, and manipulating the placement of the prosthesis in the computer simulation using said patient's biomechanic function characterization and said computer model of the prosthesis to approximate a preferred biomechanical fit of the prosthesis.","1. A process for preoperatively selecting an implant optimized to a particular patient'ss biomechanical characterization, comprising: obtaining, from at least one of a CT device, an MRI device, a radiological device, an ultrasound device and an X-ray device, image data of a patient;deriving, using a computing device, from the image data, a plurality of dimensions including at least one dimension that includes at least one of anatomic landmark data and soft tissue attachment data;accessing a database containing a correlation of anatomic data and biomechanical function related to a plurality of implant designs;executing, using the computer device, a plurality of iterative simulations of a model of the patient created from the plurality of dimensions and data from the database concerning at least one of the implant designs, wherein at least one parameter concerning a configuration of the at least one implant relative to the model of the patient is changed between iterations; andcalculating, from the plurality of iterative simulations, and outputting by the computing device a recommendation of at least one of implant size, implant position, and ligamentous releases.","18","15/088697","2016-04-01","2016-0217268","2016-07-28","10600515","2020-03-24","SMITH & NEPHEW, INC.","Jason K.  Otto | Brian W.  McKinnon | Mark Ellsworth  Nadzadi","","","","G16H-0050/50","G16H-0050/50 | A61B-0005/103 | A61B-0005/4528 | A61B-0005/4824 | A61B-0034/10 | B33Y-0050/00 | B33Y-0080/00 | G06F-0019/3481 | G16B-0005/00 | A61B-0005/4533 | A61B-0005/6878 | A61B-2034/108 | A61F-0002/38 | A61F-2002/3096 | A61F-2002/30945 | A61F-2002/30955","G06F-017/50","G06F-017/50 | G16H-050/50 | B33Y-080/00 | B33Y-050/00 | G16B-005/00 | A61B-005/103 | A61B-005/00 | G06F-019/00 | A61B-034/10 | A61F-002/38 | A61F-002/30","","","","","","4920013005756"
"US","US","P","B2","Method of constructing a data structure representative of a dynamic reorganization of a plurality of brain networks, corresponding device and program","A method for determining a sequence of activation of a set of brain networks by an electronic device in the course of a predetermined cognitive task. The method includes: obtaining at least one time series of data on encephalographic activities, according to a predetermined sampling value, the data on activities representing a signal captured on the cranial surface by a capture device, during the execution of the predetermined cognitive task by at least one individual, delivering a set having at least one measurements vector per sample of the time series; for each measurements vector, determining connectivity between cortical sources, the cortical sources being obtained through measurements of a measurements vector, delivering a connectivity network; and grouping connectivity networks according to a resemblance parameter delivering a set of groups of grouped connectivity networks, each representing an activity of a given brain network at a given instant.","1. A method for determining a sequence of activation of a set of brain networks, in the course of a predetermined cognitive task, wherein the method comprises the following acts performed by an electronic device: obtaining at least one time series of data on encephalographic activities, according to a predetermined sampling value, said data on activities representing a signal captured on the cranial surface by a capture device, during execution of said predetermined cognitive task by at least one individual, the obtaining delivering a set comprising at least one measurements vector per sample of the time series;for each measurements vector, determining a connectivity between cortical sources, said cortical sources being obtained through measurements of a measurements vector, delivering a connectivity network; andgrouping connectivity networks according to a resemblance parameter delivering a set of groups of grouped connectivity networks, each representing an activity of a given brain network at a given instant, wherein grouping comprises a statistic validation of said groups of connectivity networks obtained from substitution data, comprising a comparison of spatial distribution and temporal profiles of said groups of connectivity networks obtained in said grouping with groups of connectivity networks obtained from substitution data.","8","15/743511","2016-03-31","2018-0199848","2018-07-19","10588535","2020-03-17","UNIVERSITE DE RENNES 1 | INSTITUT NATIONALE DE LA SANTE ET DE LA RECHERCHE MEDICALE","Fabrice  Wendling | Mahmoud  Hassan","2015-056586","FR","2015-07-10","A61B-0005/04842","A61B-0005/04842 | A61B-0005/04012 | G06F-0003/015 | G06F-0017/16 | G06K-0009/0057 | G06N-0003/0454 | G06T-0007/0016","G06K-009/00","G06K-009/00 | A61B-005/04 | G06F-003/01 | G06F-017/16 | G06N-003/04 | G06T-007/00 | A61B-005/0484","","","","","","4920012001024"
"US","US","P","B2","Systems and methods for altering brain and body functions and for treating conditions and diseases of the same","The present invention relates to systems and methods for management of brain and body functions and sensory perception. For example, the present invention provides systems and methods of sensory substitution and sensory enhancement (augmentation) as well as motor control enhancement. The present invention also provides systems and methods of treating diseases and conditions, as well as providing enhanced physical and mental health and performance through sensory substitution, sensory enhancement, and related effects.","1. A method of treating a patient with impaired motor control or function due to a nervous system impairment comprising: A) having the patient participate in a rehabilitative therapy program comprising physical movement or exercise, wherein the patient'ss ability to perform the physical movement or exercise is inhibited by the patient'ss nervous system impairment;B) providing electrotactile stimulation to the patient'ss tongue while the patient concurrently engages in a physical movement or exercise of the rehabilitative therapy program, wherein the physical movement or exercise comprises a body stabilization exercise and wherein the electrotactile stimulation: 1) is provided by an array of electrodes in contact with the top surface of the patient'ss tongue, wherein the array of electrodes is in communication with a processor configured to: a) receive information from a program or detector;b) process or translate the information into a pattern to be transmitted to the array; andc) transmit the patterned information to the array to be displayed as electrical stimulation;2) stimulates one or more cranial nerves of the subject; and3) assists the subject in activating, utilizing, and/or training a portion of the brain to learn a task related to the rehabilitative therapy previously facilitated by a region of the brain damaged by the nervous system impairment;C) ceasing the physical movement or exercise and electrotactile stimulation; andD) repeating steps (B) and (C) until such time that the patient displays a rehabilitative improvement of motor control or function that persists after ceasing the physical movement or exercise and electrotactile stimulation.","19","14/692419","2015-04-21","2015-0290454","2015-10-15","10589087","2020-03-17","WICAB, INC.","Mitchell Eugene  Tyler | Yuri Petrovich  Danilov | Paul  Bach-y-Rita","","","","A61N-0001/0548","A61N-0001/0548 | A61B-0005/1124 | A61B-0005/4005 | A61B-0005/486 | A61B-0005/682 | A61B-0005/7455 | A61N-0001/36103 | G06F-0003/011 | G06F-0003/012 | G06F-0003/015 | G06F-0003/016 | G06F-0003/038 | G06F-0003/0383 | G06F-0003/03547 | A61B-0005/0492 | A61B-0005/112 | A61B-0005/1116 | A61B-0005/1123 | A61B-0005/14553 | A61B-0005/4023 | A61B-0005/4047 | A61B-0005/4528 | A61B-0005/6803 | A61B-0005/686 | A61B-0005/726 | A61B-0005/7225 | A61B-0005/7475 | A61B-2562/046 | A61N-0001/36025 | A61N-0001/36082","A61B-005/00","A61B-005/00 | A61N-001/05 | G06F-003/01 | A61B-005/11 | A61N-001/36 | G06F-003/038 | G06F-003/0354 | A61B-005/1455 | A61B-005/0492","","","","","","4920012001574"
"US","US","P","B2","Electronic device and hardware diagnosis result-based process execution method thereof","A process execution method and apparatus of an electronic device are provided for performing hardware diagnosis and executing a process based on the hardware diagnosis result. The electronic device includes a plurality of hardware components; a display configured to display information on the hardware components; and a processor configured to diagnose a hardware component selected as a diagnosis target among the hardware components, determine, based on a diagnosis result, whether the diagnosis target is operating normally, and display information indicating whether the diagnosis target is operating normally and a link for providing a service related to the diagnosis target.","1. An electronic device, comprising: a plurality of hardware components;a display configured to display information on the hardware components; anda processor configured to: diagnose a hardware component selected as a diagnosis target among the hardware components,determine, based on a diagnosis result, whether the diagnosis target is operating normally, anddisplay information indicating whether the diagnosis target is operating normally and a link for providing a service related to the diagnosis target.","20","15/408147","2017-01-17","2017-0205259","2017-07-20","10591324","2020-03-17","SAMSUNG ELECTRONICS CO., LTD.","Minsuk  Jang | Gyoseung  Koo | Seokhee  Na | Kyuok  Choi","10-2016-0005637","KR","2016-01-15","G01D-0018/00","G01D-0018/00 | A61B-0005/02055 | A61B-0005/1172 | G06F-0003/03545 | G06Q-0010/20 | A61B-0005/021 | A61B-0005/024 | A61B-2560/0276 | G06F-0003/0416 | G06F-0003/0418 | G06F-0003/0482 | G06F-0003/04817 | G06F-0011/2221","G01D-018/00","G01D-018/00 | A61B-005/1172 | G06Q-010/00 | A61B-005/0205 | G06F-003/0354 | G06F-003/041 | G06F-011/22 | A61B-005/021 | A61B-005/024 | G06F-003/0481 | G06F-003/0482","","","","","","4920012003795"
"US","US","P","B2","Device control based on a user's physical setting","A processor-implemented method controls a self-driving vehicle (SDV). One or more processors receive, from one or more physical sensors, physical state readings that describe a physical environment of multiple persons that are in spatial proximity with one another. The processors determine, based on the physical state readings, a context of a physical setting of the multiple persons. The processors identify, based on the context of the physical setting of the multiple persons, an SDV that is known to modify a state of the multiple persons. The processor(s) then transmit, to a device controller, a device activation signal to activate the SDV, in order to transport cargo that one of the multiple persons was previously scheduled to transport.","1. A method comprising: receiving, from one or more physical sensors, state readings that describe a physical environment of multiple persons that are in spatial proximity with one another;determining, based on the physical state readings that describe the physical environment of the multiple persons that are in spatial proximity with one another, a context for the multiple persons that are in spatial proximity with one another, wherein the context describes a physical setting in which the multiple persons are located;identifying, based on the context that describes the physical setting in which the multiple persons are located, a state of the multiple persons;andtransmitting, to a device controller of a self-driving vehicle (SDV), a device activation signal to activate the SDV, wherein the device activation signal directs the SDV to transport cargo that one of the multiple persons was previously scheduled to transport, wherein the device activation signal is transmitted to the device controller of the SDV via a user communication device, wherein the user communication device is in wireless communication with the device controller of the SDV, wherein the user communication device wirelessly transmits the device activation signal to the device controller of the SDV in response to the user communication device coming within a predefined distance of the device controller of the SDV, and wherein the device controller of the SDV is inactive until the user communication device is within the predefined distance of the device controller of the SDV.","12","15/702847","2017-09-13","2019-0079481","2019-03-14","10591885","2020-03-17","INTERNATIONAL BUSINESS MACHINES CORPORATION","Olympia  Gluck | Itzhack  Goldberg | Jinho  Hwang | Maja  Vukovic | Yelena  Zilberstein","","","","G05B-0019/048","G05B-0019/048 | A61B-0005/1118 | A61B-0005/165 | G05D-0001/0088 | G05D-0001/0221 | H04L-0067/12 | H04L-0067/22 | A61B-2503/12 | A61B-2560/0242 | G05B-2219/24015 | G05D-2201/0213 | G06N-0005/02 | G06N-0020/00 | H04L-0067/306","G05B-019/048","G05B-019/048 | G05D-001/00 | G05D-001/02 | A61B-005/11 | A61B-005/16 | H04L-029/08 | G06N-005/02 | G06N-020/00","","","","","","4920012004349"
"US","US","P","B2","Method and device for determining action and/or action part","The present application provides methods and devices for determining an action and/or an action part, and generally relates to the field of wearable devices. A method disclosed herein comprises: in response to that a first part on a body of a user executes an action, acquiring target blood flow information of the first part or a second part corresponding to the first part; and determining the first part and/or the action according to the target blood flow information and reference information. The methods and devices provide a new scheme for recognizing an action and/or an action part.","1. A method for determining an action and an action part, comprising: in response to detecting a motion of a first part of a body of a user, acquiring, using a photoelectric sensor, target Doppler measurement information of the first part or a second part corresponding to the first part;determining target velocity related information corresponding to the target Doppler measurement information; anddetermining the first part and the action according to the target velocity related information and reference information,wherein the target velocity related information comprises target blood flow velocity information or target blood flow information.","26","15/548721","2016-01-07","2018-0018016","2018-01-18","10591985","2020-03-17","BEIJING ZHIGU RUI TUO TECH CO., LTD.","Yuanchun  Shi | Yuntao  Wang | Chun  Yu | Lin  Du","2015-10069988","CN","2015-02-10","G06F-0003/011","G06F-0003/011 | A61B-0005/0261 | A61B-0005/6826 | A61B-0008/06 | A61B-0008/488 | G06F-0001/163 | A61B-0008/5223 | A61B-2503/12 | G06F-0003/017 | G06K-0009/0053 | G06K-0009/00355 | G06K-0009/00543","G06F-003/01","G06F-003/01 | A61B-005/026 | A61B-008/06 | A61B-008/08 | A61B-005/00 | G06F-001/16 | G06K-009/00","","","","","","4920012004447"
"US","US","P","B2","Information processing apparatus and information processing method","Provided is an information processing apparatus including: a behavior recognition mode setting unit that sets a behavior recognition mode on a basis of wearing position information of a setting target device, a behavior recognition unit that recognizes a user's behavior on a basis of the set behavior recognition mode and a detection value of a sensor corresponding to the setting target device, and a process control unit that controls execution of a process corresponding to the recognized user's behavior.","1. An information processing apparatus, comprising: a behavior recognition mode setting unit configured to set a behavior recognition mode based on wearing position information of a setting target device, wherein the wearing position information of the setting target device indicates a wearing position of the setting target device on a user;a behavior recognition unit configured to recognize a behavior of the user based on the set behavior recognition mode and a detection value of a sensor, wherein the sensor corresponds to the setting target device; anda process control unit configured to control an application corresponding to the wearing position information and the recognized behavior.","15","15/110440","2014-10-16","2016-0335557","2016-11-17","10592812","2020-03-17","SONY CORPORATION","Masatomo  Kurata | Masanori  Katsu | Sota  Matsuzawa","2014-007920","JP","2014-01-20","G06N-0007/005","G06N-0007/005 | A61B-0005/04 | A61B-0005/1038 | A61B-0005/11 | A61B-0005/113 | A61B-0005/1123 | A61B-0005/681 | A61B-0005/6803 | A61B-0005/6814 | A61B-0005/6822 | A61B-0005/6823 | A61B-0005/6824 | A61B-0005/6825 | A61B-0005/6829 | A61B-0005/7264 | G06F-0001/163 | G06F-0001/1626 | G06F-0001/1694 | G06F-0003/038 | G06F-0003/0346 | G06K-0009/00342 | G06N-0005/02 | A61B-0005/0002 | A61B-0005/1118 | A61B-0005/742 | A61B-0005/7405 | A61B-0005/7455 | A61B-0005/7465 | A61B-2562/0219 | A61B-2562/06","G06F-015/18","G06F-015/18 | G06N-007/00 | G06F-001/16 | G06F-003/0346 | G06F-003/038 | A61B-005/00 | A61B-005/04 | A61B-005/11 | A61B-005/113 | A61B-005/103 | G06K-009/00 | G06N-005/02","","","","","","4920012005271"
"US","US","P","B2","Systems and methods for individual identification and authorization utilizing conformable electronics","An identification device includes, but is not limited to, a deformable substrate; a sensor assembly including one or more identity sensors configured to generate identity sense signals associated with a physical characteristic of an individual subject; circuitry configured to receive the identity sense signals, the circuitry including an identity comparison module configured to compare identity sense signals to reference data indicative of physical characteristics associated with an identity of at least one individual to determine whether the identity sense signals correspond to the identity of the at least one individual; and a reporter configured to generate communication signals associated with a comparison of the identity sense signals to reference data, the reporter including a transmitter or transceiver configured to transmit the communication signals to a system for association with a file corresponding to the at least one individual.","1. A device, comprising: a deformable substrate configured to conform to a skin surface of a body portion of an individual subject;a sensor assembly coupled to the deformable substrate, the sensor assembly including one or more identity sensors configured to generate one or more identity sense signals associated with at least one physical characteristic of the individual subject;circuitry operably coupled to the sensor assembly and configured to receive the one or more identity sense signals associated with the at least one physical characteristic of the individual subject, the circuitry including an identity comparison module configured to compare the one or more identity sense signals generated by the sensor assembly to reference data indicative of one or more physical characteristics associated with an identity of at least one individual to determine whether the one or more identity sense signals correspond to the identity of the at least one individual;a reporter operably coupled to the circuitry and configured to generate one or more communication signals responsive to instruction by the circuitry, the one or more communication signals associated with a comparison of the one or more identity sense signals generated by the sensor assembly to reference data indicative of one or more physical characteristics associated with an identity of at least one individual, the reporter including a transmitter or transceiver configured to transmit the one or more communication signals to a system for association with a file corresponding to the at least one individual; anda unique identifier associated with at least one of the deformable substrate, the sensor assembly, the circuitry, or the reporter, wherein the unique identifier includes a first identifier and a second identifier, wherein the first identifier corresponds to a family identifier that identifies a family of devices including the device and at least one other device, and wherein the second identifier uniquely identifies the device.","18","16/042197","2018-07-23","2019-0043282","2019-02-07","10593137","2020-03-17","ELWHA LLC","Roderick A.  Hyde | Jordin T.  Kare | Melanie K.  Kitzan | Gary L.  McKnight | Robert C.  Petroski | Elizabeth A.  Sweeney","","","","G07C-0009/00087","G07C-0009/00087 | A61B-0005/0002 | A61B-0005/0059 | A61B-0005/0492 | A61B-0005/053 | A61B-0005/0531 | A61B-0005/1077 | A61B-0005/1171 | A61B-0005/441 | A61B-0005/448 | A61B-0005/489 | A61B-0005/681 | A61B-0005/6832 | A61B-0005/7203 | A61B-0005/742 | G06F-0021/32 | G06K-0009/00 | G06Q-0020/3224 | G06Q-0020/401 | G07C-0009/00563 | G08C-0017/00 | G09B-0005/02 | H04L-0029/06 | A61B-2562/164 | G07C-2009/00095 | G08B-0005/36","G07C-009/00","G07C-009/00 | A61B-005/1171 | A61B-005/053 | G06F-021/32 | G06Q-020/40 | A61B-005/00 | A61B-005/107 | G06Q-020/32 | G08C-017/00 | G09B-005/02 | H04L-029/06 | G06K-009/00 | A61B-005/0492 | G08B-005/36","","","","","","4920012005593"
"US","US","P","B2","Head/eye tracking with light source preheating","A head/eye tracking system comprising an image sensor for acquiring images of a user, a narrow band light source for illuminating the eyes, and a band-pass filter arranged between the eyes and the image acquisition device and having a pass-band corresponding to the emission spectrum of the light source at a predefined operating temperature. The system further comprises a heat source arranged in proximity to the light source and configured to preheat the light source to reach the predefined operating temperature. By shortening the period during which large temperature variation takes place, sub-optimal performance of the system can be accepted during this short period, thereby relaxing the requirements on light source and filter design.","1. An head/eye tracking system comprising: an image sensor for acquiring images of a user;a narrow band light source for illuminating the user; anda band-pass filter arranged between the user and the image acquisition device and having a pass-band corresponding to the emission spectrum of the narrow band light source for a predefined operating temperature; anda heat source arranged in proximity to the narrow band light source and configured to preheat the narrow band light source to a temperature range including the predefined operating temperature.","14","16/335491","2017-09-28","2019-0222731","2019-07-18","10594913","2020-03-17","SMART EYE AB","Per  Sorner","2016-191827","EP","2016-09-30","H04N-0005/2256","H04N-0005/2256 | A61B-0003/113 | A61B-0005/1114 | A61B-0005/18 | G02B-0027/0093 | G06F-0003/012 | G06F-0003/013 | H05B-0001/025 | G02B-0005/28 | G02B-0021/00 | G06K-0009/00 | H05B-2203/02","H04N-005/225","H04N-005/225 | A61B-003/113 | G02B-027/00 | A61B-005/11 | A61B-005/18 | G06F-003/01 | H05B-001/02 | G06K-009/00 | G02B-021/00 | G02B-005/28","","","","","","4920012007345"
"US","US","P","B2","Method and device for comparing personal biological data of two users","A wearable device comprising a memory storing data associated with a personal biology of a user, a short-range wireless transceiver for receiving, from a peer wearable device, data associated with a personal biology of a peer user, and a processor for comparing the received data with the data stored in the memory in order to determine whether or not there is a match. The device further comprises an indicator for generating a visual, audio or other sensory indication of a match when the data is determined to match.","1. A wrist-worn wearable device comprising: a memory storing data indicative of a wearer'ss nutrition and/or skin-related genetic traits and obtained by an analysis of a biological sample provided by the wearer;a short-range wireless transceiver for transmitting said data to a peer wrist-worn wearable device and for receiving, from the peer wearable device, corresponding data for the wearer of the peer device, the range of said transceiver being 10 cm or less;a processor for comparing received data with the data stored in the memory in order to determine whether or not there is a match between the wearer'ss and the peer wearer'ss nutrition and/or skin-related genetic traits; andan indicator for generating a visual, audio or other sensory indication of the result.","15","16/043709","2018-07-24","2020-0029908","2020-01-30","10582897","2020-03-10","DNANUDGE LIMITED","Christofer  Toumazou | Georgina  Toumazou","","","","A61B-0005/72","A61B-0005/72 | A44C-0005/0015 | A61B-0005/0024 | G06F-0001/163 | G06F-0003/016 | G06F-0003/017 | G06F-0009/54 | G16B-0040/00 | G16H-0010/40 | G16H-0010/65 | G06K-0007/10821","G06F-009/54","G06F-009/54 | A61B-005/00 | G06F-003/01 | G06F-001/16 | G16H-010/40 | G16H-010/65 | A44C-005/00 | G16B-040/00 | G06K-007/10","","","","","","4920011000833"
"US","US","P","B2","Apparatus operation device, apparatus operation method, and electronic apparatus system","An apparatus operation device includes a line-of-sight detecting unit that detects a line of sight of a user, a neck-mounted terminal that is mounted around a neck of the user and detects a motion of the neck of the user, a determining unit that determines, based on the line of sight that has been detected and the motion of the neck that has been detected, at least one of an electronic apparatus as a target apparatus to be operated or operation details, and an apparatus control unit that controls the electronic apparatus as the target apparatus in accordance with the determination.","1. An apparatus operation device comprising: a processor; anda neck-mounted terminal that is mounted around a neck of the user and detects a motion of the neck of the user;wherein the processor is configured to:detect a line of sight of a user, based on the line of sight that has been detected and the motion of the neck that has been detected,determine a target apparatus to be operated among a plurality of apparatuses and operation details for the target apparatus;control the target apparatus in accordance with the determination,suspend detection of the line of sight upon detection of the motion of the neck being started by the neck-mounted terminal, andstart the detection of the line of sight upon the detection of the motion of the neck being finished by the neck-mounted terminal.","19","15/898368","2018-02-16","2018-0173306","2018-06-21","10585476","2020-03-10","FUJIFILM CORPORATION","Yuuki  Okabe | Mayuko  Ikuta","2015-174575","JP","2015-09-04","G06F-0003/013","G06F-0003/013 | A61B-0001/04 | A61B-0005/1114 | A61B-0005/1128 | A61B-0005/6822 | A61B-0005/7475 | G06F-0003/01 | G06F-0003/012 | G06F-0003/015 | G06F-0003/017 | G06F-0003/038 | G06F-0003/0346 | G06F-0003/16 | G10L-0015/22 | A61B-2560/0487 | G06K-0009/00335 | G10L-2015/223","G06F-003/01","G06F-003/01 | G06F-003/16 | G10L-015/22 | G06F-003/038 | A61B-001/04 | G06F-003/0346 | A61B-005/00 | A61B-005/11 | G06K-009/00","","","","","","4920011003393"
"US","US","P","B2","Methods for sensing or stimulating activity of tissue","Methods for sensing or stimulating electrical activity of brain tissue from within an animal vessel by placement of an intravascular device within an animal vessel to control an external device, the intravascular device being adapted to at least one of sense and stimulate activity of brain tissue located outside the vessel proximate the intravascular device.","1. A method for enabling a patient to control operation of an external device using a region of a brain stimulated by the patient, the method comprising: advancing an intravascular device within a vasculature of the patient to a cerebral vessel in the brain of the patient, where the intravascular device comprises a stent structure having a plurality of discrete electrodes each having an electrode surface that extends parallel to a surface of the stent structure, where a plurality of wires are electrically coupled to the plurality of discrete electrodes, where the plurality of wires extends through the vasculature from the cerebral vessel to an extra-cranial vessel;deploying the stent structure within the cerebral vessel such that the stent structure expands to take a shape of the cerebral vessel, where expansion of the stent structure brings each electrode surface of the plurality of electrodes into engagement with a wall of the cerebral vessel without expanding or altering the shape of the electrode surface of each of the plurality of discrete electrodes, where the wall of the cerebral vessel is adjacent to a neural tissue stimulated by the patient such that the plurality of discrete electrodes sense an electrical activity in the neural tissue; andpositioning an internal unit exterior to the extra-cranial vessel and in electrical communication with the plurality of wires, the internal unit configured to generate a signal, where the electrical activity from the plurality of electrodes conducts through the plurality of wires to the internal unit located exterior to the extra-cranial vessel such that the unit generates the signal in response to the electrical activity; andwhere the internal unit is further configured to transmit the signal to the external device so that the patient controls operation of the external device by stimulating the region of the brain.","11","16/164482","2018-10-18","2019-0046119","2019-02-14","10575783","2020-03-03","SYNCHRON AUSTRALIA PTY LIMITED","Thomas James  Oxley","","","","A61B-0005/6862","A61B-0005/6862 | A61B-0005/0006 | A61B-0005/04001 | A61B-0005/0484 | A61B-0005/4064 | A61B-0005/4076 | A61B-0005/4836 | A61B-0005/4851 | A61B-0005/686 | A61B-0005/6868 | A61B-0005/6876 | A61F-0002/72 | A61N-0001/056 | A61N-0001/0553 | A61N-0001/36003 | A61N-0001/36064 | A61N-0001/36067 | A61N-0001/36082 | A61N-0001/3756 | A61N-0001/3787 | A61N-0001/37252 | G06F-0003/015 | A61B-0005/04012 | A61B-0005/0478 | A61B-0005/4094 | A61B-0005/6811 | A61B-0005/746 | A61F-0002/54 | A61F-2002/5058","A61N-001/375","A61N-001/375 | A61N-001/05 | A61B-005/04 | A61B-005/0484 | G06F-003/01 | A61F-002/72 | A61F-002/50 | A61B-005/0478 | A61B-005/00 | A61N-001/36 | A61N-001/372 | A61N-001/378 | A61F-002/54","","","","","","4920010001067"
"US","US","P","B2","Patient diabetes monitoring system with clustering of unsupervised daily CGM profiles (or insulin profiles) and method thereof","A patient diabetes monitoring system with an efficient unsupervised daily monitoring profile clustering algorithm, a method, and a computer product thereof are disclosed. The system may include a physiological data input device or sensor which receives a plurality of physiological measurements to generate a dataset, a memory which stores a clustering algorithm, and a processor. The clustering algorithm when executed by the processor, causes the processor to automatically pre-process the dataset to control an amount of bias/aggressiveness from the collected unsupervised daily monitoring profiles, thereby generating a pre-processed dataset, build a similarity matrix from the pre-processed dataset, and output an optimum number of similarity clusters found by the processor from the similarity matrix.","1. A patient diabetes monitoring system for a patient comprising: a physiological data input device which acquires a plurality of blood glucose concentration measurements of the patient within a time window to generate at least one time window dataset of collected unsupervised daily monitoring profiles;a memory storing an unsupervised daily monitoring profile clustering algorithm; anda processor in communication with said input device to receive said generated at least one time window dataset, and in communication with said memory in order to execute said unsupervised daily monitoring profile clustering algorithm,wherein said unsupervised daily monitoring profile clustering algorithm when executed by said processor causes said processor automatically to:pre-process the dataset to generate a pre-processed dataset via a data transformation of the dataset that makes the pre-processed dataset symmetric for retrospective analysis,build a similarity matrix from the pre-processed dataset, andoutput an optimum number of similarity clusters found by the processor from the similarity matrix,wherein the data transformation for retrospective analysis results from processing the dataset with a hazard function defined by: Gt=α*ln(G?β)?α*ln(α), where parameter α=Tc?β, and parameter β=Dr?1, in which Tc is a center of a transformed space, Dr is a minimum defined glucose level, Gt is the transformed data of the blood glucose concentration measurements provided in the dataset, and G is original glucose level values of the blood glucose concentration measurements provided in the dataset and measured in millimoles per liter.","18","15/058271","2016-03-02","2017-0251980","2017-09-07","10575790","2020-03-03","ROCHE DIABETES CARE, INC.","David L.  Duke | Bernd  Steiger | Chinmay Uday  Manohar","","","","A61B-0005/7271","A61B-0005/7271 | A61B-0005/14503 | A61B-0005/14532 | A61B-0005/4842 | A61B-0005/7246 | A61B-0005/742 | G06F-0017/16 | G06F-0019/3468 | G06K-0009/00496 | G06K-0009/6218","A61B-005/145","A61B-005/145 | A61B-005/00 | G06F-019/00 | G06F-017/16 | G06K-009/62 | G06K-009/00","","","","","","4920010001074"
"US","US","P","B2","Systems and methods for surgical planning of arthroplasty procedures","A method for planning an arthroplasty procedure on a patient bone. The method may include accessing generic bone data stored in a memory of a computer, using the computer to generate modified bone data by modifying the generic bone data according to medical imaging data of the patient bone, using the computer to derive a location of non-bone tissue data relative to the modified bone data, and superimposing implant data and the modified bone data in defining a resection of an arthroplasty target region of the patient bone.","1. A method for planning an arthroplasty procedure on a patient bone, the method comprising: accessing generic bone data stored in a memory of a computer;using the computer to generate modified bone data by modifying the generic bone data according to medical imaging data of the patient bone;using the computer to derive a location of non-bone tissue data relative to the modified bone data; andsuperimposing implant data and the modified bone data in defining a resection of an arthroplasty target region of the patient bone.","22","16/522281","2019-07-25","2019-0388123","2019-12-26","10575875","2020-03-03","HOWMEDICA OSTEONICS CORPORATION","Elena  Pavlovskaia | Oleg  Mishin | Boris E.  Shpungin | Ilwhan  Park | Venkata Surya  Sarva | Irene Min  Choi","","","","A61B-0017/7013","A61B-0017/7013 | A61B-0005/055 | A61B-0006/032 | A61B-0017/1675 | A61B-0017/1703 | A61B-0034/10 | A61B-0090/37 | B33Y-0010/00 | B33Y-0050/00 | B33Y-0050/02 | B33Y-0080/00 | G06F-0017/50 | G06F-0017/5009 | G06K-0009/2063 | G06K-0009/48 | G06T-0007/0012 | G06T-0007/12 | G06T-0007/13 | G06T-0017/00 | G06T-0017/20 | G16H-0050/50 | A61B-0017/155 | A61B-0017/157 | A61B-2017/1602 | A61B-2034/105 | A61B-2034/107 | A61B-2034/108 | A61B-2090/374 | A61B-2090/3762 | G06K-2009/484 | G06K-2209/055 | G06T-0007/70 | G06T-2200/08 | G06T-2207/30008 | Y10T-0029/49826","G06K-009/00","G06K-009/00 | A61B-017/70 | A61B-034/10 | A61B-006/03 | A61B-005/055 | G06F-017/50 | G06T-007/13 | G06T-007/12 | G16H-050/50 | G06T-007/00 | B33Y-050/02 | B33Y-010/00 | G06T-017/20 | G06K-009/20 | A61B-017/17 | A61B-017/16 | G06T-017/00 | G06K-009/48 | B33Y-080/00 | B33Y-050/00 | A61B-090/00 | G06T-007/70 | A61B-017/15","","","","","","4920010001158"
"US","US","P","B2","Neuro-physiology and neuro-behavioral based stimulus targeting system","An example system includes a processor to determine a first distance between a first peak in a first frequency band of neuro-response data gathered from a subject while exposed to media and a second peak in the first frequency band; determine a second distance between a third peak in the first frequency band and either the second peak in the first frequency band or a fourth peak in the first frequency band; determine a first difference between the first distance and the second distance; generate a first response profile for the subject based on the first difference; and integrate the first response profile with a second response profile associated with a second subject to form an integrated response profile. A selector is to select an advertisement or entertainment for presentation based on the integrated response profile. The processor is to modify the media to present the advertisement or entertainment.","1. A system for transforming a media presentation based on neuro-response data, the system comprising: a processor to: determine a first distance between (1) a first peak in a first frequency band of first neuro-response data gathered from a first subject while exposed to media and (2) a second peak in the first frequency band;determine a second distance between (1) a third peak in the first frequency band and either (2) the second peak in the first frequency band or (3) a fourth peak in the first frequency band;determine a first difference between the first distance and the second distance;generate a first response profile for the first subject to the media based on the first difference; andintegrate the first response profile with a second response profile associated with a second subject exposed to the media to form an integrated response profile for the media; anda selector to select a first advertisement or entertainment for presentation based on the integrated response profile, the processor to modify the media to present the first advertisement or entertainment.","20","15/989987","2018-05-25","2019-0005532","2019-01-03","10580031","2020-03-03","THE NIELSEN COMPANY (US), LLC","Anantha  Pradeep | Robert T.  Knight | Ramachandran  Gurumoorthy","","","","G06Q-0030/0244","G06Q-0030/0244 | A61B-0005/4017 | G06Q-0010/0637 | G06Q-0030/0242 | G06Q-0030/0269 | G06Q-0030/0271 | G16H-0010/20 | A61B-0005/0402 | A61B-0005/0476 | A61B-0005/0496 | A61B-0005/0533 | A61B-0005/1176 | A61B-0005/163 | A61B-0005/4035","G06Q-030/00","G06Q-030/00 | G06Q-030/02 | G06Q-010/06 | A61B-005/00 | G16H-010/20 | A61B-005/16 | A61B-005/0402 | A61B-005/0476 | A61B-005/0496 | A61B-005/053 | A61B-005/1171","","","","","","4920010005283"
"US","US","P","B2","Systems and methods for detecting an indication of malignancy in a sequence of anatomical images","A method for detecting an indication of likelihood of malignancy, comprising: receiving a sequence of anatomical images of a breast of a target individual acquired over a time interval during which contrast is administered, analyzing the sequence of anatomical images to identify: a baseline pre-contrast image denoting lack of contrast, a peak contrast image denoting a peak contrast enhancement, an initial uptake image denoting initial contrast enhancement, and a delayed response image denoting final contrast enhancement, creating a multi-channel image representation comprising: intensity channel including the peak contrast enhanced image, contrast-update channel including the computed difference between the peak contrast enhanced image and the pre-contrast image, and contrast-washout channel including the computed difference between the initial uptake image and the delayed response image, and computing by a trained deep convolutional neural network, a classification category indicative of likelihood of malignancy for the sequence according to the multi-channel image representation.","1. A method for detecting an indication of likelihood of malignancy for a sequence of anatomical images, comprising: receiving a sequence of anatomical images of at least one portion of at least one breast of a target individual, wherein the sequence of anatomical images is acquired over a time interval during which contrast is administered to the target individual;analyzing the sequence of anatomical images to identify the following images:(i) a baseline pre-contrast image denoting lack of contrast within the sequence of anatomical images,(ii) a peak contrast image denoting a peak contrast enhancement within the sequence of anatomical images,(iii) an initial uptake image denoting initial contrast enhancement within the sequence of anatomical images,(iv) a delayed response image denoting final contrast enhancement within the sequence of anatomical images;creating a multi-channel image representation of the sequence of anatomical images comprising the following image channels:(A) intensity channel including the peak contrast enhanced image,(B) contrast-update channel including the computed difference between the peak contrast enhanced image and the pre-contrast image,(C) contrast-washout channel including the computed difference between the initial uptake image and the delayed response image;computing by a trained deep convolutional neural network (CNN), a classification category indicative of likelihood of malignancy for the sequence of anatomical images according to the multi-channel image representation and;computing a patch distinctiveness saliency map by computing a statistical distance between each patch of a plurality of patches of at least one image of the sequence of anatomical images and an average patch along principal components of the plurality of patches;wherein the multi-channel image representation further includes a patch distinctiveness saliency channel that includes the patch distinctiveness saliency map.","19","15/883112","2018-01-30","2019-0236782","2019-08-01","10580137","2020-03-03","INTERNATIONAL BUSINESS MACHINES CORPORATION","Guy  Amit | Omer  Hadad","","","","G06T-0007/0016","G06T-0007/0016 | A61B-0005/055 | A61B-0010/0041 | G06N-0003/08 | G16H-0030/20 | G06F-0017/18 | G06T-2207/10096 | G06T-2207/20016 | G06T-2207/20076 | G06T-2207/20084 | G06T-2207/30068","A61B-006/00","A61B-006/00 | G06K-009/00 | G06T-007/00 | G06N-003/08 | G16H-030/20 | A61B-010/00 | A61B-005/055 | G06F-017/18","","","","","","4920010005387"
"US","US","P","B2","Electronic apparatus and method for providing skin inspection information thereof","An electronic apparatus and a method for providing skin inspection information thereof are provided. The method includes the following steps. If it is determined that current measurement information is received, a result assessment page showing a detection result of the current measurement information is displayed via a screen, to show whether the detection result achieves a skin goal via the result assessment page. A skin overview page is displayed in response to receipt of an operation performed on the result assessment page. A goal setting page is displayed via the screen in response to receipt of a first operation performed on the skin overview page, and setting of the skin goal is received via the goal setting page. A detail analysis page associated with one of skin parameters is displayed via the screen in response to receipt of a second operation performed on the skin overview page.","1. A skin inspection information providing method, for an electronic apparatus that comprises an image capturing device, an input device and a screen, the skin inspection information providing method comprising: obtaining current measurement information comprising a plurality of skin parameters of a facial skin according to an image of the facial skin captured by the image capturing device and displaying a result assessment page of a detection result of the current measurement information via the screen, and showing whether the detection result achieves a skin goal via the result assessment page by comparing the skin goal set by a user with the current measurement information to obtain the detection result of the current measurement information, wherein the skin parameters are numeric calculated based on severity of a plurality of variable features of the facial skin obtained by analyzing different areas of the image;in response to receipt of an operation performed on the result assessment page via the input device, displaying a skin overview page via the screen, wherein the skin overview page displays the skin parameters of the facial skin;in response to receipt of a first operation performed on the skin overview page via the input device, displaying a goal setting page via the screen and receiving setting of the skin goal via the goal setting page; andin response to receipt of a second operation performed on the skin overview page via the input device, displaying a detail analysis page associated with one of the skin parameters via the screen,wherein the step of receiving the setting of the skin goal via the goal setting page comprises:displaying a plurality of goal options respectively corresponding to the skin parameters via the goal setting page, wherein the goal options are icons displayed on the screen; andin response to receipt of an operation performed on one of the goal options via the input device, setting one of the skin parameters corresponding to the one of the goal options as the skin goal and setting a corresponding achievement value as the skin goal,wherein the step of displaying the result assessment page of the detection result of the current measurement information via the screen and showing whether the detection result achieves the skin goal via the result assessment page by comparing the skin goal set by the user with the current measurement information to obtain the detection result of the current measurement information comprises:if the one of the skin parameters of the detection result achieves the corresponding achievement value of the skin goal, displaying an achievement notification via a first sub-page of the result assessment page; andif the one of the skin parameters of the detection result does not achieve the corresponding achievement value of the skin goal, displaying a treatment course report via a third sub-page of the result assessment page or displaying a comment via a fourth sub-page of the result assessment page,wherein after the step of displaying the detail analysis page associated with one of the skin parameters via the screen, the skin inspection information providing method further comprises:in response to receipt of an operation performed on one of second sub-pages of the detail analysis page, displaying a plurality of comparison pages via the screen and sequentially displaying an initial facial image, a past/present comparison image, and a current facial image via the comparison pages, wherein a portion of the past/present comparison image is a portion of the initial facial image and another portion of the past/present comparison image is a portion of the current facial image.","15","15/371210","2016-12-07","2018-0085048","2018-03-29","10568562","2020-02-25","CAL-COMP BIG DATA, INC.","Dai-Jung  Lee | Chia-Ming  Yong | Hung-Tai  Hsu | Ching-Sheng  Tsai","105131281 A","TW","2016-09-29","A61B-0005/442","A61B-0005/442 | A45D-0044/00 | A61B-0005/0077 | A61B-0005/444 | G06F-0003/0482 | G06F-0003/0483 | G06F-0003/0484 | G06K-0009/00255 | G06K-0009/00268 | A45D-2044/007","A61B-005/00","A61B-005/00 | G06K-009/00 | G06F-003/0482 | G06F-003/0484 | G06F-003/0483 | A45D-044/00","","","","","","4920009001056"
"US","US","P","B2","Systems and methods for hair loss management","Comprehensive systems and methods for managing hair loss are provided which enable an individual experiencing hair loss, and/or the person consulting him or her, to manage it and to determine and efficiently plan any appropriate treatment options. Management of hair loss may comprise quantifying hair loss, determining what hair growth stimulation product or treatment to adopt and the best timing for such products and/or treatments, and allowing to track and manage any progress of the selected hair growth stimulation product or treatment.","1. A method for creating a realistic simulation of hair loss or hair gain, the method comprising: displaying, on a display device, individual hair follicles or follicular units in a region of interest in an image;simulating or allowing a user to simulate an appearance of the region of interest with a change in density of hair; andautomatically adjusting the simulated appearance of the changed density to reflect an achievable density that takes into account one or more calculated constraints; anddisplaying, on the display of the display device, the adjusted simulated appearance of the region of interest;wherein the calculated constraints comprise one or more of the following: an available number of hair grafts in a donor area, an associated classification of available donor hair grafts, a size of a tool, or how close hair may be implanted to existing or previously implanted hair.","13","15/748119","2016-07-21","2018-0214072","2018-08-02","10568564","2020-02-25","VENUS CONCEPT INC.","Gabriele  Zingaretti | Miguel G.  Canales | James W.  McCollum","","","","A61B-0005/448","A61B-0005/448 | A61B-0005/748 | A61B-0005/7435 | G06F-0017/5009 | G06T-0007/0012 | A61B-0005/7275 | G06T-2207/30088","A61B-005/00","A61B-005/00 | G06F-017/50 | G06T-007/00","","","","","","4920009001058"
"US","US","P","B2","Surgical skin lesion removal","Embodiments include methods, systems, and computer program products for treating skin lesions. Aspects include receiving an indication that a patient is oriented. Aspects also include acquiring data concerning an area of the patient, the area including a skin lesion. Aspects also include analyzing the data to distinguish between an affected region and an unaffected region of the area of the patient. Aspects also include excising the affected area.","1. A computer-implemented method for treatment of skin lesions, the method comprising: acquiring, by a processor, multimodal data comprising digital images concerning an area of a patient, the area comprising a skin lesion, wherein the multimodal data comprises one or more of confocal microscopy data, dermoscopy data, or optical coherence tomography data;analyzing, by the processor, the multimodal data to distinguish between an affected region and an unaffected region of the area of the patient;determining, by the processor, a boundary of the affected region;projecting, by a projector, an image onto a surface of a patient'ss skin, the image comprising a visual indication that distinguishes between the affected region and the unaffected region, the visual indication including the boundary;automatically, by a mechanical process, excising the affected region based upon the analysis, wherein the mechanical process is controlled by a computer or machine without clinician interaction, and wherein excising the affected region defines an excised boundary;determining, by the processor, that the affected region was not completely removed from the area of the patient based on a multimodal analysis by the processor of tissue that remains attached to the patient, the tissue adjacent to the excised boundary; andresponsive to the determination that the affected region was not completely removed, providing, by the processor, a second visual indication comprising a boundary of a remaining affected region.","4","15/275877","2016-09-26","2018-0085166","2018-03-29","10568695","2020-02-25","INTERNATIONAL BUSINESS MACHINES CORPORATION","Noel C.  Codella | Jonathan H.  Connell | Sharathchandra  Pankanti | Nalini K.  Ratha","","","","A61B-0034/10","A61B-0034/10 | G06T-0007/0012 | H04L-0067/10 | A61B-0017/3205 | A61B-2017/00761 | A61B-2034/107 | G06T-2207/30088 | G06T-2207/30096","A61B-005/00","A61B-005/00 | A61B-034/10 | H04L-029/08 | G06T-007/00 | A61B-017/3205 | A61B-017/00","","","","","","4920009001189"
"US","US","P","B2","Biological information measurement system","The biological information measurement system of the present invention includes a test subject-side device provided in a toilet installation room, and a server communicable with the test subject-side device, the test subject-side device includes a sulfur-containing gas sensor sensitive to sulfur-containing gas and outputting detection data, a transmitter-receiver transmitting measurement data including detection data of the sulfur-containing gas detected by the sulfur-containing gas sensor to the server, and the server includes a database in which measurement data including detection data of sulfur-containing gas detected by the sulfur-containing gas sensor is accumulated and recorded with dates and times of defecation acts by being associated with test subject identification information, and server-side data analyzer that analyzes physical condition of a test subject on the basis of a time-dependent variation tendency of the measurement data accumulated and recorded in the database.","1. A biological information measurement system that diagnoses a risk of illness of a test subject based defecation gas discharged into a bowl of flush toilet, the biological information measurement system comprising a test subject-side device provided in a room where the flush toilet is installed, and a server communicable with the test subject-side device, wherein the test subject-side device comprises:a suction device that sucks gas in the bowl into which the defecation gas is discharged during a defecation act of the test subject;a gas detector that is sensitive to a methyl mercaptan gas including an odiferous gas containing a sulfur component and an odiferous gas other than the methyl mercaptan gas, wherein the gas sucked by the suction device comprises the methyl mercaptan gas and the odiferous gas other than the methyl mercaptan gas, and wherein the gas detector outputs a first detection data;a test subject identification device that accepts an input of a test subject identification information;a control device that controls the suction device and the gas detector; anda communication device that transmits a measurement data including the first detection data to the server, andthe server comprises:a database wherein the measurement data is accumulated and recorded with a date and time of the defecation act by being associated with the test subject identification information accepted by the test subject identification device;a server-side analyzer that analyzes the risk of illness of the test subject on the basis of a time-dependent variation tendency of the measurement data accumulated and recorded in the database; anda server-side output device that outputs an analysis result by the server-side data analyzer.","14","15/546919","2015-12-14","2017-0370936","2017-12-28","10571470","2020-02-25","TOTO LTD.","Aya  Hasegawa | Tetsuhiro  Wasada | Aya  Takao | Satoko  Kizuka | Hidenori  Oka | Akemi  Takeshita | Masayuki  Nagaishi | Koji  Sonoda | Shingo  Yamaya | Hiroshi  Tsuboi","2015-017454 | 2015-232232","JP | JP","2015-01-30 | 2015-11-27","G01N-0033/57419","G01N-0033/57419 | A61B-0005/0004 | A61B-0005/082 | A61B-0005/4255 | A61B-0005/4283 | A61B-0005/6891 | G01N-0033/005 | G01N-0033/0044 | G01N-0033/0059 | G01N-0033/0062 | G01N-0033/0073 | G06Q-0010/101 | G06Q-0030/0201 | G06Q-0050/22 | A61B-2505/07 | A61M-2230/432 | G01N-2033/4975","A61B-005/00","A61B-005/00 | G01N-033/574 | G06Q-050/22 | G01N-033/00 | G06Q-010/10 | G06Q-030/02 | A61B-005/08 | G01N-033/497","","","","","","4920009003950"
"US","US","P","B2","Preserving a level of confidence of authenticity of an object","Apparatuses and methods associated with preserving a level of confidence of authenticity of an object are disclosed herein. In embodiments, a method includes acquiring first information corresponding to a physical object; identifying first authentication data based on the first information; initializing a database record associated with the physical object responsive to identifying the first authentication data; determining whether the first authentication data corresponds to original provenance for the physical object; in response to determining that the first authentication data does not correspond to original provenance for the physical object, acquire and store in the database record first record data including authenticity information available in association with identification of the first authentication data; in response to determining that the first authentication data does correspond to original provenance for the physical object, retaining second record data in the database record. Other embodiments may be disclosed or claimed.","1. A method, comprising: acquiring digital image data of an image of at least a portion of a physical object;with one or more processors: analyzing the digital image data to form a digital fingerprint of the physical object for an authentication of the physical object, wherein the digital fingerprint is responsive to a natural structure of the physical object;initializing a database record associated with the physical object responsive to forming the digital fingerprint;determining whether the digital fingerprint corresponds to original provenance for the physical object;in response to determining that the digital fingerprint does not correspond to original provenance for the physical object, acquiring and storing in the database record first data including authenticity information available in association with formation of the digital fingerprint;in response to determining that the digital fingerprint does correspond to original provenance for the physical object, retaining second data in the database record.","20","15/436646","2017-02-17","2017-0243232","2017-08-24","10572883","2020-02-25","ALITHEON, INC.","David Justin  Ross | Justin Lynn  Withrow | David Keesu  Kim | Mark  Tocci | Scot E.  Land","","","","G06Q-0030/0185","G06Q-0030/0185 | G06F-0016/51 | G06F-0016/5838 | G06F-0016/5866 | G06K-0009/00577 | G06K-0009/4604 | G06K-0009/4642 | G06K-0009/4671 | G06K-0009/6202 | G06K-0009/6215 | G06F-2221/2111 | G06K-2009/0059","A61B-005/00","A61B-005/00 | G06Q-030/00 | G06F-016/51 | G06F-016/583 | G06F-016/58 | G06K-009/46 | G06K-009/62 | G06K-009/00 | G06F-003/00","","","","","","4920009005348"
"US","US","P","B2","Information processing apparatus, information processing method, program","There is provided an information processing apparatus including: a sensor data generator sensing a user behavior and generating sensor data corresponding to the user behavior; a behavior recognizing unit performing a predetermined threshold value process on the sensor data to recognize the behavior exhibited by the user and generating behavior information that is information indicating the behavior exhibited by the user; a behavior manager managing the behavior information generated by the behavior recognizing unit in correspondence with the time point at which the behavior corresponding to the behavior information is exhibited; and a behavior information post-processing unit performing a predetermined post-process on the behavior information managed by the behavior manager, wherein the behavior recognizing unit further includes a plurality of behavior determination units specified to specific behaviors exhibited by the user and generates the behavior information based on the determination results of the plurality of behavior determination units.","1. A non-transitory computer-readable medium having embodied thereon a program, which when executed by a computer causes the computer to execute an information processing method, the method comprising: recognizing a user action of a user based on sensor data retrieved from a sensor, including recognizing the user action by using a characteristic detection process with respect to a predetermined processing for the user action from the sensor data, wherein the user action includes a vehicle boarding;managing the recognized user action; andcausing a storage medium to store the recognized user action,wherein the predetermined processing for the user action includes outputting an identification function based on the sensor data by using machine learning and identifying a vehicle type by using the identification function, andwherein the predetermined processing for the user action further includes determining horizontal acceleration of the user and vertical acceleration of the user from the sensor data and determining a horizontal direction variance value of the horizontal acceleration of the user over a predetermined period of time and a vertical direction variance value of the vertical acceleration of the user over the predetermined period of time and comparing the horizontal direction variance value and the vertical direction variance value to determine a smaller variance value, and comparing an integration value representing integration over the predetermined period of time of the smaller variance value resulting from the comparison between the horizontal direction variance value and the vertical direction variance value with a minimum determination threshold for the user action.","13","15/169151","2016-05-31","2016-0275403","2016-09-22","10565510","2020-02-18","SONY CORPORATION","Yasutaka  Fukumoto | Makoto  Murata | Masatomo  Kurata | Masanori  Katsu","2009-017187 | 2009-230580","JP | JP","2009-01-28 | 2009-10-02","G06N-0005/04","G06N-0005/04 | A61B-0005/1116 | A61B-0005/1123 | G06N-0005/02 | A61B-0005/1038 | A61B-2562/0219","G06N-005/04","G06N-005/04 | A61B-005/11 | G06N-005/02 | A61B-005/103","","","","","","4920008005168"
"US","US","P","B2","Image calibration patient identification","A digital image is captured. The captured digital image includes a calibration pattern. The calibration pattern includes displayed information about the calibration pattern. The displayed information is read to obtain calibration information about the captured digital image.","1. A method for making a measurement comprising: (a) capturing a digital image, the captured digital image including: (i) an item associated with a patient,(ii) a calibration pattern being affixed to said item associated with said patient, the calibration pattern being square in shape, the calibration pattern including displayed encoded information arranged in a two dimensional pattern, and(b) locating said calibration pattern in said digital image and decoding said calibration pattern in said digital image to determine said displayed encoded information;(c) identifying said patient based upon said displayed encoded information of said calibration pattern being affixed to said item associated with said patient, and in response to said identifying said patient based upon decoding said calibration pattern being affixed to said item associated with said patient, displaying patient information on a display associated with a computing device that is separate from and not based upon an image of any item associated with said patient that includes said calibration pattern, wherein said patient information includes a name associated with said displayed encoded information, wherein said patient information includes medical records associated with said displayed encoded information, wherein said patient information includes an image representative of an individual associated with said displayed encoded information, and wherein said patient information includes a matching version of said calibration pattern wherein said matching version of said calibration pattern and said calibration pattern include the same displayed encoded information therein.","10","15/807713","2017-11-09","2018-0158212","2018-06-07","10565735","2020-02-18","PIXAMETER CORP.","Mansoor  Ghazizadeh","","","","G06T-0007/80","G06T-0007/80 | A61B-0005/445 | G06K-0007/10722 | G06K-0007/1417 | G06T-0007/0014 | G06T-0007/62 | A61B-0005/6898 | A61B-2560/0233 | G06T-0007/90 | G06T-2200/24 | G06T-2207/10024 | G06T-2207/30004 | G06T-2207/30088 | G06T-2207/30204 | G16H-0010/60","G06K-007/14","G06K-007/14 | A61B-005/00 | G16H-010/60 | G06T-007/80 | G06T-007/00 | G06K-007/10 | G06T-007/62 | G06T-007/90","","","","","","4920008005392"
"US","US","P","B2","Apparatus and method for determination of medication location","A method, apparatus and computer program stored on a non-volatile computer readable storage medium for confirming a pill in the mouth of a user. The computer program causing a general purpose computer to perform the steps of capturing one or more images of a user by an image capture device, confirming the position of the face of the user within the captured image by measuring a size of the face, and setting a predetermined portion of the face of the user to be a region of interest. An open mouth of the user is confirmed within the region of interest, and the open mouth of the user is classified as one of a mouth with a pill therein and a mouth without a pill therein.","1. A method for confirming a pill in the mouth of a user, comprising: predefining one or more steps associated with confirming a pill in the mouth of a user, the one or more steps comprising at least proper identification of a medication pill, proper positioning of the face of the user, proper positioning of the open mouth of the user, and proper showing of whether there is a pill in the mouth of the user;displaying on a display one or more guidance instructions for properly positioning of a face of the user relative to the image capture camera;capturing a first set of one or more video frames by an image capture camera associated with the display;determining, by one or more processors in near real time from the first set of one or more video frames, that the user has properly positioned the face of the user in response to the one or more guidance instructions;confirming, by the one or more processors in near real time, that the face of the user is an expected face;in response to a confirmation that the face of the user is the expected face, displaying on the display one or more guidance instructions for positioning the medication pill relative to the image capture camera upon determination that the user has properly positioned the face of the user;capturing a second set of one or more video frames by the image capture device;determining, by the one or more processors in near real time, that the user has properly positioned the medication pill within the field of view in response to the one or more guidance instructions for positioning the medication pill, and that the medication pill is an expected medication pill from the second set of one or more video frames;setting a bottom portion of the face of the user as a region of interest, the region of interest including the mouth of the user, responsive to determining that the user has properly positioned their face in response to the one or more guidance instructions for positioning of the face of the user, that the user is the expected user, and that the medication pill is the expected medication pill;determining, by the one or more processors in near real time, that the mouth of the user in the region of interest is an open mouth from the second set of one or more video frames;subsequent to determining that the mouth of the user is the open mouth, extracting an image of the open mouth from the second set of one or more video frames, and classifying, by the one or more processors, the open mouth from the extracted image as a mouth without a pill therein;responsive to classifying the open mouth as the mouth without a pill therein, displaying on the display guidance for positioning the open mouth of the user relative to the image capture camera; anddisplaying on the display guidance to the user to place the medication pill in their mouth.","18","13/214201","2011-08-21","2013-0044196","2013-02-21","10558845","2020-02-11","AIC INNOVATIONS GROUP, INC.","Lei  Guan | Adam  Hanina","","","","G06K-0009/00221","G06K-0009/00221 | A61B-0005/0022 | A61B-0005/1128 | A61B-0005/4833","G06Q-010/00","G06Q-010/00 | G06K-009/00 | A61B-005/00 | A61B-005/11","","","","","","4920007003944"
"US","US","P","B2","Methods and apparatus for sharing of music or other information","One or more sensors may detect a gesture or gestures by one or more human users. The detected gesture or gestures may trigger sharing of music or other information. For instance, a first user may be listening to music on headphones. A second user may turn her head, so that her head is facing toward the first user. A sensor may detect this head orientation of the second user. This head orientation may trigger the system to share the first user's music with the second user, for at least as long as this head orientation continues.","1. A method comprising: (a) causing audio content to be audibly presented to a first user;(b) detecting a set of one or more gestures, which set includes a first gesture that comprises a second user'ss head being oriented toward the first user;(c) performing a calculation to determine whether a first privacy setting and a second privacy setting permit the audio content to be shared with the second user, the first and second privacy settings having been selected by the first and second users, respectively; and(d) if the calculation determines that the first and second privacy settings permit the first audio content to be shared with the second user, (i) wirelessly transmitting a radio signal that encodes the audio content,(ii) causing a receiver worn by the second user to tune to the radio signal, and(iii) causing the audio content to be audibly presented to the second user during a time period in which the first gesture occurs.","20","15/972228","2018-05-07","2018-0322335","2018-11-08","10558853","2020-02-11","MASSACHUSETTS INSTITUTE OF TECHNOLOGY","Amos  Golan | Tal  Achituv","","","","G06K-0009/00335","G06K-0009/00335 | G06F-0003/011 | G06F-0003/012 | G06F-0003/017 | G06F-0003/165 | G06Q-0050/01 | G06T-0007/70 | G06T-0007/73 | G06T-2207/10048 | G06T-2207/30204","A61B-005/00","A61B-005/00 | G06K-009/00 | G06F-003/01 | G06Q-050/00 | G06T-007/70 | G06T-007/73 | G06F-003/16 | G06F-003/00","","","","","","4920007003952"
"US","US","P","B2","Method for generating personal identification information using an electrocardiogram and method for identifying a person using the personal identification information","Disclosed are a method for generating personal identification information using an electrocardiogram and a method for identifying a person using the personal identification information. The methods dramatically increase an identification rate by using two-dimensional image data converted from an electrocardiogram signal as personal identification information, and enable real-time identification by reducing a calculation amount by converting only a single electrocardiogram cycle into the two-dimensional image data.","1. A method for generating personal identification information from an electrocardiogram signal using a computer, the method comprising: receiving an electrocardiogram signal;extracting a single-cycle electrocardiogram signal containing P, Q, R, S, and T waves from the electrocardiogram signal after the receiving of the electrocardiogram signal;converting the electrocardiogram signal into two-dimensional image data; andgenerating personal identification information from the two-dimensional image data and storing the generated personal identification information,wherein the two-dimensional image data is generated by converting the single-cycle electrocardiogram signal.","14","15/391384","2016-12-27","2018-0098719","2018-04-12","10548515","2020-02-04","INDUSTRY-ACADEMIC COOPERATION FOUNDATION CHOSUN UNIVERSITY","Sung-Bum  Pan | Gyu-Ho  Choi | Hae-Min  Moon | Youn-Tae  Kim | Keun-Chang  Kwak","10-2016-0132046","KR","2016-10-12","A61B-0005/117","A61B-0005/117 | A61B-0005/04012 | A61B-0005/0456 | G06F-0021/32 | G06K-0009/00885 | G06K-0009/6247 | H04L-0063/0861 | G06K-2009/00939","A61B-005/117","A61B-005/117 | H04L-029/06 | G06K-009/00 | G06K-009/62 | A61B-005/04 | A61B-005/0456 | G06F-021/32","","","","","","4920006000983"
"US","US","P","B2","Medical image processing apparatus, medical image processing method, and program","A medical image processing apparatus includes a unit configured to analyze a target medical image, a unit configured to register information representing an aptitude of each doctor with respect to interpretation of a specific lesion and a modality used by each doctor, and a unit configured to, when the analysis result includes information associated with a lesion, decide an assigned doctor based on information representing the aptitude of each doctor with respect to interpretation of the specific lesion, and, when the analysis result includes no information associated with a lesion, decide an assigned doctor based on the modality.","1. A medical image processing apparatus comprising: a processor; anda memory storing instructions that, when executed by the processor, cause the medical image processing apparatus to function as: a selection unit configured to: obtain lesion information relating to a medical image of an object of a plurality of medical images obtained by imaging an object using a medical imaging apparatus;acquire additional information related to the medical image;acquire time schedules of one or more doctors of a plurality of doctors;determine whether a degree of urgency is set as a part of the additional information related to the medical image;in a case where a determination is made that the degree of urgency is set, assign the medical image to a doctor of the plurality of doctors who is currently performing interpretation;in a case where a determination is made that the degree of urgency has not been set, determine whether an interpretation deadline has been set as a part of the additional information related to the medical image;in a case where a determination is made that the interpretation deadline has been set, assign the medical image to a doctor of the plurality of doctors whose acquired time schedule is set within the interpretation deadline; andin a case where a determination is made that the interpretation deadline has not been set, assign the medical image to a doctor of the plurality of doctors whose acquired time schedule is set within a set time; andan output unit configured to output, to a display unit, information corresponding to the doctor to which the medical image is assigned, together with the information corresponding to the assigned medical image.","16","15/647818","2017-07-12","2017-0372132","2017-12-28","10552672","2020-02-04","CANON KABUSHIKI KAISHA","Yoshihiko  Iwase | Hiroshi  Imamura","2007-333193","JP","2007-12-25","G06K-0009/00362","G06K-0009/00362 | G06F-0019/321 | G06Q-0010/10 | G06Q-0050/22","G06K-009/00","G06K-009/00 | G06F-019/00 | G06Q-010/10 | G06Q-050/22","","","","","","4920006005112"
"US","US","P","B2","Systems and methods for monitoring and reconciling inventory","In some embodiments, apparatuses and methods are provided herein useful to monitoring and reconciling inventory. In some embodiments, there is provided a system including: an inventory location for one type of merchandise item intended for the inventory location; a first sensor configured to collect data regarding the presence of the merchandise item at the inventory location; a second sensor configured to collect identification data of the merchandise item at the inventory location; a memory configured to store the identification data; a database including identification information corresponding to the merchandise item intended for the inventory location; a control circuit configured to: compare the identification data collected by the second sensor with the identification information from the database corresponding to the merchandise item; verify that the identification data from the second sensor corresponds to the identification information from the database; and calculate a quantity of inventory at the inventory location.","1. A system for monitoring inventory at various merchandise shelves in a shopping facility, the system comprising: a plurality of merchandise shelves disposed along aisles in a shopping facility;each merchandise shelf disposed adjacent an aisle and configured to contain a plurality of one type of merchandise item intended for a predetermined location on each merchandise shelf;a first type of sensor disposed at each merchandise shelf and configured to collect data regarding the presence of the type of merchandise item at each predetermined location on each merchandise shelf, the first type of sensor comprising a plurality of weight sensors arranged at a bottom surface of each merchandise shelf supporting merchandise items to collect weight data regarding merchandise items at each predetermined location of each merchandise shelf;a mobile robot including a second type of sensor, the mobile robot configured to move along the aisles of the shopping facility systematically and to capture image data of the type of merchandise item at each predetermined location on the plurality of merchandise shelves;a memory configured to store the image data collected by the second type of sensor;a product database including image information and weight information corresponding to the merchandise item intended for each merchandise shelf;an inventory database including an on-hand inventory record of the quantity of each type of merchandise item;a control circuit communicatively coupled to the sensors and in communication with the product and inventory databases, the control circuit configured to: compare the image data collected by the second type of sensor with the image information from the product database corresponding to merchandise items;verify that the image data from the second sensor of a merchandise item at each predetermined location corresponds to the image information of the merchandise item from the product database intended for the predetermined location according to a predetermined arrangement of types of merchandise items on the merchandise shelves;calculate a quantity of inventory at each predetermined location of a merchandise shelf based on the total weight of merchandise items at each predetermined location measured by the first type of sensor and based on the known weight of an individual merchandise item from the product database;compare the on-hand inventory record to the calculated quantity of inventory at each predetermined location; andadjust the on-hand inventory record to the calculated quantity.","15","15/790305","2017-10-23","2018-0114184","2018-04-26","10552791","2020-02-04","WALMART APOLLO, LLC","Cristy C.  Brooks | Greg A.  Bryan | Todd D.  Mattingly","","","","G06Q-0010/087","G06Q-0010/087 | G01G-0023/18 | G06K-0007/10544 | G06K-0009/20 | A61B-0005/0404","G06Q-010/08","G06Q-010/08 | G01G-023/18 | G06K-007/10 | G06K-009/20 | A61B-005/0404","","","","","","4920006005229"
"US","US","P","B1","Image processing methods and arrangements useful in automated store shelf inspections","Imagery captured by an autonomous robot is analyzed to discern digital watermark patterns. In some embodiments, identical but geometrically-inconsistent digital watermark patterns are discerned in an image frame, to aid in distinguishing multiple depicted instances of a particular item. In other embodiments, actions of the robot are controlled or altered in accordance with image processing performed by the robot on a digital watermark pattern. The technology is particularly described in the context of retail stores in which the watermark patterns are encoded, e.g., on product packaging, shelving, and shelf labels. A great variety of other features and arrangements are also detailed.","1. A method comprising the acts: with a camera-equipped robot system at a first position in an aisle of a retail store, capturing first imagery from a shelving unit to one side of said aisle, the first imagery depicting a first visual beacon; andafter moving a distance down the store aisle, the robot system capturing second imagery from said shelving unit, the second imagery depicting a second, different, visual beacon;wherein the first and second visual beacons are both formed by printing at different locations along a single elongated printed shelf label;wherein the first visual beacon is positioned proximate to a first item on a shelf of said shelving unit, said first visual beacon comprising a first machine readable indicia useful to identify the first item, and the second visual beacon is positioned proximate to a second item on said shelf, the second visual beacon comprising a second machine readable indicia useful to identify the second item, wherein the visual beacons serve as navigational landmarks while also enabling identification of proximate items stocked in the shelving unit; andwherein the relative position of the first visual beacon to the second visual beacon cannot become mis-adjusted because the relative position is fixed by printing of said beacons on a common substrate, thereby helping assure accuracy of the robot system operation.","19","15/830874","2017-12-04","","","10552933","2020-02-04","DIGIMARC CORPORATION","Sean  Calhoon | Tony F.  Rodriguez | Joel R.  Meyer","","","","G06T-0001/0092","G06T-0001/0092 | G06Q-0010/087 | A61B-0017/00234 | G05D-0001/0088 | G06K-0007/10861 | G06K-0007/1417 | G06K-0007/1421 | G06K-0009/78 | G06N-0003/049 | G06Q-0020/208 | G06Q-0030/00 | G06T-0001/005 | G06T-0001/0007 | G06T-2201/0065","G06T-001/00","G06T-001/00 | G06Q-010/08 | G06K-007/14 | A61B-017/00 | G06K-009/78 | G06N-003/04 | G06K-007/10 | G06Q-020/20 | G05D-001/00 | G06Q-030/00","","","","","","4920006005370"
"US","US","P","B2","Aural measurements from earphone output speakers","According to some embodiments of the present invention there is provided a method of using an earphone output speaker as a microphone for a phone call between two and/or more participants, or for measuring biometric data of a user. The method may comprise playing a received signal to an electro-acoustic output transducer of an earphone. The method may comprise instructing an audio processing circuit of a local client terminal to record an audio signal from the same electro-acoustic output transducer. The method may comprise calculating a voice signal and/or a biometric measurement based on a function combining the recorded audio signal, the received signal, and filtration coefficients, using a processing unit of the local client terminal. The method may comprise sending the voice signal and/or a biometric measurement through an output interface of the local client terminal.","1. A method of using an earphone output speaker as a microphone for a phone call between a plurality of participants, comprising: playing a remote voice signal received from a remote client terminal with an electro- acoustic output transducer, wherein said remote voice signal represents a voice of a remote participant recorded from the remote client terminal;recording a first local voice signal from same said electro-acoustic output transducer, wherein said first local voice signal represents a voice of a local participant using a local client terminal;calculating a transmission voice signal based on a function combining said first local voice signal, said remote voice signal, and filtration coefficients, using a processing unit of said local client terminal; andsending said transmission voice signal through an output interface of said local client terminal, thereby enabling acoustic voice playing of said transmission voice signal by said remote client terminal at a remote location for a phone call communication.","20","16/119769","2018-08-31","2018-0376267","2018-12-27","10555102","2020-02-04","BUGATONE LTD.","Edmund  Ben-Ami | Noam  Petrank","","","","H04R-0029/001","H04R-0029/001 | A61B-0005/0051 | A61B-0005/02055 | A61B-0005/0295 | A61B-0005/02133 | A61B-0005/02438 | A61B-0005/6803 | A61B-0005/7228 | A61B-0005/7278 | A61B-0005/7405 | A61B-0007/045 | G06F-0003/165 | G06K-0009/00 | H04M-0009/08 | H04R-0001/1091 | H04R-0003/04 | A61B-0005/486 | A61B-0005/6817 | A61B-2562/0204 | G06K-2009/00939","A61B-005/00","A61B-005/00 | A61B-007/04 | G06F-003/16 | G06K-009/00 | H04M-009/08 | H04R-001/10 | H04R-003/04 | A61B-005/021 | A61B-005/024 | H04R-029/00 | A61B-005/0205 | A61B-005/0295","","","","","","4920006007521"
"US","US","P","B2","Systems and methods for providing location-based security and/or privacy for restricting user access","Exemplary embodiments are disclosed of systems and methods for providing location-based security and/or privacy for restricting user access. In an exemplary embodiment, a system is configured to restrict and condition access to the system and/or data based on a user's selection of location-based data from a plurality of options presented by the system for selection by the user. The plurality of options include the location-based data and one or more other options that are selectable by the user.","1. A system for providing security or privacy, the system configured to restrict and condition access to data for a person based on a user'ss selection of location-based data from a plurality of options presented by the system for selection by the user, the plurality of options including the location-based data and one or more other options that are selectable by the user, wherein the system includes a plurality of devices or sensors configured to: determine, through one or more communications networks, a location of a person and a context of the person at the location;predict and evaluate a risk of a pre-identified addiction-related or parolee violation-related behavior by the person in relation to the location and the context; andfacilitate one or more actions or activities to mitigate the risk of the pre-identified addiction-related or parolee violation-related behavior, if any, or react to the pre-identified addiction-related or parolee violation-related behavior, if any, by the person; andwherein the system is configured to determine, based on data obtained through a plurality of sensors, at least one historical location of the user and at least one historical context of the user at the at least one determined historical location, wherein the system is configured to, in connection with the determining the at least one historical location and the at least one historical context:determine the at least one historical location based on data obtained through at least one location sensor; anddetermine the at least one historical context based on data obtained through the at least one location sensor and at least one different sensor;wherein the system is further configured to:receive a request for access by the user to data for the person obtained via one or more of the plurality of devices or sensors through the one or more communications networks;present one or more queries or qualifiers to prompt the user to select at least one of the plurality of options in response to the one or more queries or qualifiers;present the plurality of options for selection by the user, the plurality of options including location-based data for the user and the one or more other options, the location-based data for the user including data based on the determined at least one historical location of the user and the determined at least one historical context of the user, wherein the system is configured to include the location-based data for the user in the at least one of the plurality of options based on a consistency between (a) the one or more queries or qualifiers and (b) the determined at least one historical location for the user and the determined at least one historical context for the user;allow the requested access by the user to the data for the person, based on the user'ss selection of at least one of the plurality of options including the location-based data for the user, whereby the user is the person, another person, and/or an accessor.","36","15/840775","2017-12-13","2018-0173866","2018-06-21","10555112","2020-02-04","David H. Williams","David H.  Williams","","","","H04W-0004/021","H04W-0004/021 | A61B-0005/0022 | A61B-0005/4842 | A61B-0005/6802 | A61B-0005/7264 | A61B-0005/747 | A63F-0009/12 | G06F-0021/36 | G06Q-0010/0635 | G06Q-0020/3224 | G06Q-0020/401 | G06Q-0020/4014 | G06Q-0020/4016 | G07F-0017/3237 | G16H-0040/67 | G16H-0050/30 | H04L-0063/107 | H04L-0063/20 | H04L-0067/12 | H04W-0004/029 | H04W-0012/08 | G06F-2221/2111 | H04W-0012/06","H04L-009/00","H04L-009/00 | H04W-004/021 | H04L-029/08 | G07F-017/32 | G06Q-020/40 | G06Q-020/32 | A61B-005/00 | G16H-040/67 | G16H-050/30 | H04W-004/029 | A63F-009/12 | G06F-021/36 | G06Q-010/06 | H04L-029/06 | H04W-012/08 | H04W-012/06","","","","","","4920006007531"
"US","US","P","B2","Method and device to manage modifications of protected registers in an implantable medical device","Circuits, devices and methods are provided to manage modifications to protected registers within an implantable medical device (IMD). The circuit comprises a bus controller that includes an address register, an unlock register and a protected register (PR) enable unit. The PR enable unit sets a protect enable signal to an access state based on content loaded into the unlock register. A peripheral block includes a protected register that retains content for operating the IMD. The peripheral block includes a register access input to receive the protected enable signal. A PR write control unit is provided to enable an attempted write of the content from a data interface to the protected register when the protected enable signal has an access state.","1. A circuit to manage modifications to protected registers within an implantable medical device (IMD), comprising: a bus controller including an address register, and unlock register and a protected register (PR) enable unit, the PR enable unit to set a protect enable signal to an access state based on content loaded into the unlock register; anda peripheral block including a protected register to retain content for operating the IMD, the peripheral block including a register access input to receive the protected enable signal; anda PR write control unit to enable an attempted write of the content from a data interface to the protected register when the protected enable signal has an access state, wherein the peripheral block further comprises: a parity register configured to be set to a coherent value based on content of the protected register; anda comparator to compare content of the parity register and the protected register in connection with validating the content of the protected register.","22","15/852999","2017-12-22","2019-0196734","2019-06-27","10543370","2020-01-28","PACESETTER, INC.","David  Doudna | Dean  Andersen | Thomas  Ng","","","","A61N-0001/37254","A61N-0001/37254 | G06F-0003/0604 | G06F-0003/0619 | G06F-0003/0637 | G06F-0003/0673 | G06F-0011/1004 | A61B-0005/04011 | A61N-0001/3688 | A61N-0001/3704 | A61N-0001/37247","A61N-001/372","A61N-001/372 | G06F-003/06 | G06F-011/10 | A61N-001/368 | A61B-005/04 | A61N-001/37","","","","","","4920005001306"
"US","US","P","B2","Method and system to control a workflow and method and system for providing a set of task-specific control parameters","The invention relates to a system and method to control a workflow comprising at least one task to be performed by a person (P3), wherein information is provided about at least one certain object (20, 32, 36, 38) related to the at least one task of the workflow, eye data (24, 26) are captured of at least one eye of the person (P3), and in dependency of the eye data (24, 26) and the information about the at least one certain object (20, 32, 36, 38) it is checked whether at least one task condition consisting in whether the task had been performed and/or whether the task is allowed to be performed is fulfilled. The invention also relates to a system and method for providing a set of task-specific control parameters (CP).","1. A method comprising: capturing an image of the eye of a user;determining a gaze direction of the user based on the image of the eye of the user;determining, based on the gaze direction, that the user has inspected a plurality of objects in a predefined order; andin response to determining that the user has inspected the plurality of objects in the predefined order, enabling a device to allow the user to perform a task associated with the plurality of objects.","19","15/750032","2016-08-05","2018-0225509","2018-08-09","10546193","2020-01-28","APPLE INC.","Eberhard  Schmidt | Tom  Sengelaub","2015-180283","EP","2015-08-07","G06K-0009/00597","G06K-0009/00597 | A61B-0003/113 | A61B-0005/1128 | A61B-0005/163 | A61B-0005/168 | G05B-0019/0426 | G06K-0009/00671 | G06Q-0010/0633 | G06Q-0010/063114 | G06T-0007/70 | G05B-2219/24024","G06K-009/00","G06K-009/00 | A61B-005/16 | G05B-019/042 | G06T-007/70 | A61B-003/113 | A61B-005/11 | G06Q-010/06","","","","","","4920005004102"
"US","US","P","B2","Automated clinical documentation system and method","A method, computer program product, and computing system for tracking encounter participants is executed on a computing device and includes obtaining encounter information of a patient encounter, wherein the encounter information includes machine vision encounter information obtained via one or more machine vision systems. The machine vision encounter information is processed to identify one or more humanoid shapes.","1. A computer-implemented method executed on a computing device, comprising: obtaining encounter information of a patient encounter, wherein the encounter information includes machine vision encounter information obtained via one or more machine vision systems;processing the machine vision encounter information to identify one or more humanoid shapes, wherein processing the machine vision encounter information includes identifying a first humanoid shape of the one or more humanoid shapes and tracking the movement of the first humanoid shape within a monitored space, and adding a second humanoid shape within the monitored space;steering one or more audio recording beams toward one of the first and second humanoid shapes to capture audio encounter information;processing the encounter information to generate at least a portion of an encounter transcript; andprocessing at least the portion of the encounter transcript to populate at least a portion of a medical record associated with the patient encounter.","12","16/058951","2018-08-08","2019-0051382","2019-02-14","10546655","2020-01-28","NUANCE COMMUNICATIONS, INC.","Donald E.  Owen | Daniel Paulino  Almendro Barreda | Dushyant  Sharma","","","","G16H-0010/60","G16H-0010/60 | A61B-0005/7405 | G06F-0003/16 | G06F-0016/637 | G06F-0016/904 | G06F-0017/243 | G06F-0017/2785 | G06F-0017/28 | G06F-0021/6245 | G06K-0009/00221 | G06K-0009/00288 | G06K-0009/00342 | G06K-0009/00369 | G06K-0009/00664 | G06K-0009/00771 | G06K-0009/6288 | G06K-0019/07762 | G06N-0003/006 | G06T-0007/00 | G10L-0015/08 | G10L-0017/005 | G10L-0021/0232 | G11B-0027/10 | G16B-0050/00 | G16H-0010/20 | G16H-0015/00 | G16H-0030/00 | G16H-0030/20 | G16H-0030/40 | G16H-0040/20 | G16H-0040/60 | G16H-0040/63 | G16H-0050/20 | G16H-0050/30 | G16H-0080/00 | H04L-0051/02 | H04L-0051/20 | H04N-0007/183 | H04R-0001/326 | H04R-0003/005 | H04R-0003/12 | G06T-2207/10024 | G06T-2207/10044 | G06T-2207/10048 | G06T-2207/10116 | G06T-2207/10132 | G10L-0015/1815 | G10L-0015/22 | G10L-0015/265 | G10L-2021/02082 | H04N-0007/181 | H04R-0001/406 | H04R-0003/02 | H04R-2420/07 | H04S-2400/15","G06T-007/00","G06T-007/00 | G16H-010/60 | H04R-003/12 | G06K-009/00 | G16H-040/20 | H04L-012/58 | G16H-050/30 | G16H-080/00 | A61B-005/00 | G16H-030/00 | G16H-040/63 | H04N-007/18 | H04R-003/00 | G16H-010/20 | G06F-017/27 | G06F-017/28 | H04R-001/32 | G16H-015/00 | G10L-017/00 | G16H-040/60 | G06F-021/62 | G06F-016/904 | G06F-003/16 | G16H-030/20 | G06K-009/62 | G16H-030/40 | G10L-021/0232 | G16H-050/20 | G06N-003/00 | G16B-050/00 | G06F-016/635 | G06K-019/077 | G10L-015/08 | G06F-017/24 | G11B-027/10 | H04R-003/02 | H04R-001/40 | G10L-015/22 | G10L-015/26 | G10L-021/0208 | G10L-015/18","","","","","","4920005004560"
"US","US","P","B2","Augmented reality product selection","Systems and methods are disclosed for recommending products or services by receiving a three-dimensional (3D) model of one or more products; performing motion tracking and understanding an environment with points or planes using accelerometer sensor and estimating light or color in the environment using one video camera without a depth sensor in a mobile phone; acquiring sensor data from sensors and optimizing features extracted from each image and sensor data, where a feature conveys data unique to the image at a specific pixel location; and projecting the product in the environment.","1. A method for recommending products, comprising: with a camera and an accelerometer, performing motion tracking and understanding an environment with points or planes;acquiring sensor data from sensors and optimizing features extracted from each image and sensor data;selecting products each with dimensions from a 3D model plus a predetermined gap;correlating different manufacturer'ss product sizes and creating correspondences among different manufacturer products;recommending a new product by looking up the correspondences among different manufacturer products; andrendering the product in an augmented reality environment.","20","16/161063","2018-10-16","2019-0340671","2019-11-07","10540776","2020-01-21","Bao Tran | Ha Tran","Bao  Tran | Ha  Tran","","","","G06T-0007/62","G06T-0007/62 | A43B-0003/0005 | A43B-0017/00 | A43D-0001/025 | A45D-0044/005 | B33Y-0080/00 | G06K-0009/00208 | G06K-0009/00369 | G06K-0009/00664 | G06K-0009/2018 | G06K-0009/22 | G06K-0009/4671 | G06K-0009/6206 | G06Q-0030/0631 | G06Q-0030/0643 | G06T-0007/20 | G06T-0007/90 | G06T-0019/20 | H04N-0005/272 | A43B-0003/0015 | A43B-0007/04 | A43B-0007/24 | A43D-2200/60 | A45D-2044/007 | A61F-0002/0059 | A61F-0002/12 | G06T-2207/10028 | G06T-2207/10048 | G06T-2207/30201 | G06T-2219/2012 | G06T-2219/2016 | H04N-2005/2726","G06Q-030/06","G06Q-030/06 | G06T-007/20 | G06T-007/90 | H04N-005/272 | G06T-007/62 | A43D-001/02 | A45D-044/00 | G06T-019/20 | A43B-003/00 | A43B-017/00 | B33Y-080/00 | G06K-009/20 | G06K-009/00 | G06K-009/62 | G06K-009/22 | G06K-009/46 | A61F-002/12 | A61F-002/00 | A43B-007/04 | A43B-007/24","","","","","","4920004004288"
"US","US","P","B2","System for determining anatomical feature orientation","The systems and methods disclosed herein provide determination of an orientation of a feature towards a reference target. As a non-limiting example, a system consistent with the present disclosure may include a processor, a memory, and a single camera affixed to the ceiling of a room occupied by a person. The system may analyze images from the camera to identify any objects in the room and their locations. Once the system has identified an object and its location, the system may prompt the person to look directly at the object. The camera may then record an image of the user looking at the object. The processor may analyze the image to determine the location of the user's head and, combined with the known location of the object and the known location of the camera, determine the direction that the user is facing. This direction may be treated as a reference value, or ""ground truth."" The captured image may be associated with the direction, and the combination may be used as training input into an application.","1. An apparatus for determining an orientation of an anatomical feature, comprising: anatomical feature location determination circuitry configured to: identify an anatomical feature of a subject within an environment; and determine a location of the anatomical feature of the subject within the environment; and orientation reference circuitry configured to: cause communications circuitry to establish a communications link with a target; cause the communications circuitry to transmit an instruction to the target; prompt the subject to orient the anatomical feature toward the target within the environment; determine a location of the target within the environment; and determine an orientation of the anatomical feature based on the location of the anatomical feature and the location of the target.","25","15/639555","2017-06-30","2019-0005673","2019-01-03","10540778","2020-01-21","INTEL CORPORATION","Glen J.  Anderson | Giuseppe  Raffa | Carl S.  Marshall | Meng  Shi","","","","G06T-0007/70","G06T-0007/70 | A61B-0090/361 | G06F-0003/012 | G06K-0009/66 | A61B-0005/70 | G06T-2207/30196","G06K-009/00","G06K-009/00 | G06T-007/70 | A61B-090/00 | G06F-003/01 | G06K-009/66 | A61B-005/00","","","","","","4920004004290"
"US","US","P","B2","Utilizing signed credentials for secure communication with an implantable medical device","Methods and devices for establishing secure communications with an implantable medical device (IMD) are provided. The method and devices receive a credential from an external instrument (EI). The credential is signed utilizing a private key, and the credential includes at least two of a credential time to live (TTL) indicator, an IMD Identifier (ID), and an EI ID. The method and device authenticate the credential using a public key and verify the at least two of the TTL indicator, the IMD ID, and the EI ID. The method and device establish a secure communications session with the EI based on the verification and authentication.","1. A method for establishing secure communications with an implantable medical device (IMD), the method comprising: receiving a credential from an external instrument (EI), the credential signed utilizing a private key, wherein the IMD and EI do not have access to the private key, the credential including an IMD identifier (ID) and at least one of a time to live (TTL) indicator or an EI ID;authenticating the credential using a public key;verifying the IMD ID and the at least one of the TTL indicator or the EI ID; andestablishing a secure communications session with the EI based on the verifying and authenticating.","24","15/659419","2017-07-25","2019-0036886","2019-01-31","10541977","2020-01-21","PACESETTER, INC.","Yongjian  Wu | Mostafa  Sadeghi | Chao-Wen  Young | Jun  Yang | Samir  Shah | Simon  Skup","","","","H04L-0063/0407","H04L-0063/0407 | A61N-0001/37282 | A61B-0005/0006 | A61B-0005/0031 | H04L-0063/0272 | H04L-0063/0823","H04L-029/06","H04L-029/06 | A61N-001/372 | A61B-005/00","","","","","","4920004005481"
"US","US","P","B2","Image display device, image display system, image display method, and program","Image display device includes image outputting unit, part moving unit, and matching degree score calculating unit. Image outputting unit outputs, among a plurality of images obtained by performing a multilayered anatomy in a plurality of parts of a human body, an image of one layer of one part as a current image. Part moving unit acquires a part moving instruction after current image is output. Matching degree score calculating unit calculates a matching degree score indicating the matching degree between the organ included in current image and a candidate image by comparing label information indicating the organ included in current image and label information indicating the organ included in candidate image, with respect to each of a plurality of candidate images of a movement target part. Image outputting unit outputs candidate image in which a maximum matching degree score is calculated as a new current image.","1. An image display device comprising: a memory storing instructions; anda processor that, when executing the instructions stored in the memory, perform operations including:outputting, among a plurality of images obtained by performing a multilayered anatomy and photographing organs in a plurality of parts of a human body, an image of one layer in the multilayered anatomy of one part as a current image;acquiring a part moving instruction which instructs to display a different part from the part of the current image after the current image is output; andcalculating a matching degree score indicating a matching degree between at least one organ included in a candidate image and at least one organ included in the current image, with respect to each of a plurality of candidate images which are the plurality of images of individual layers corresponding to a part instructed to be displayed by the part moving instruction in the plurality of images, wherein the matching degree score is based on an existence of an organ commonly included in the current image and in the candidate image,wherein the outputting outputs the candidate image in which a maximum matching degree score is calculated as a new current image.","14","15/558430","2016-02-10","2018-0055458","2018-03-01","10531840","2020-01-14","PANASONIC INTELLECTUAL PROPERTY MANAGEMENT CO., LTD.","Kenjiro  Tsuda","2015-056363","JP","2015-03-19","A61B-0005/7425","A61B-0005/7425 | A61B-0005/0033 | A61B-0005/0037 | A61B-0005/0077 | G06F-0003/14 | G06F-0003/147 | G06F-0016/00 | G06K-0009/00718 | G06K-0009/6202 | G06K-0009/6203 | G06K-0009/6253 | G06T-0007/0012 | G09G-0005/14 | A61B-0005/7246 | A61B-2560/0475 | A61B-2576/00 | G06K-2209/051 | G09G-2380/08","A61B-005/00","A61B-005/00 | G06K-009/62 | G06K-009/00 | G06F-003/147 | G06F-003/14 | G06F-016/00 | G09G-005/14 | G06T-007/00","","","","","","4920003000828"
"US","US","P","B2","Method and system for image processing to determine blood flow","Embodiments include a system for determining cardiovascular information for a patient. The system may include at least one computer system configured to receive patient-specific data regarding a geometry of the patient's heart, and create a three-dimensional model representing at least a portion of the patient's heart based on the patient-specific data. The at least one computer system may be further configured to create a physics-based model relating to a blood flow characteristic of the patient's heart and determine a fractional flow reserve within the patient's heart based on the three-dimensional model and the physics-based model.","1. A computer-implemented method for image processing to determine blood flow, the method comprising: receiving patient-specific imaging data regarding a geometry of an anatomical structure of a patient, the anatomical structure including at least a portion of one or more arteries supplying blood to brain tissue of the patient;generating a three-dimensional model representing at least a portion of the anatomical structure based on the patient-specific imaging data, the portion of the anatomical structure including at least the portion of the one or more arteries supplying blood to the brain tissue of the patient;determining a mass or volume of the brain tissue of the patient using one or both of the received patient-specific imaging data and the generated three-dimensional model;generating a blood flow model relating to a blood flow characteristic within the portion of the anatomical structure based, at least in part, on the mass or volume of the brain tissue of the patient; anddetermining at least one value of the blood flow characteristic of the patient within the portion of the anatomical structure based on the three-dimensional model and the blood flow model.","20","15/664596","2017-07-31","2017-0340392","2017-11-30","10531923","2020-01-14","HEARTFLOW, INC.","Charles A.  Taylor","","","","A61B-0034/10","A61B-0034/10 | A61B-0005/004 | A61B-0005/0035 | A61B-0005/0044 | A61B-0005/02 | A61B-0005/021 | A61B-0005/024 | A61B-0005/026 | A61B-0005/02007 | A61B-0005/029 | A61B-0005/02028 | A61B-0005/0263 | A61B-0005/055 | A61B-0005/1075 | A61B-0005/1118 | A61B-0005/22 | A61B-0005/4848 | A61B-0005/6852 | A61B-0005/7246 | A61B-0005/7275 | A61B-0005/7278 | A61B-0005/745 | A61B-0006/03 | A61B-0006/032 | A61B-0006/481 | A61B-0006/503 | A61B-0006/504 | A61B-0006/507 | A61B-0006/5205 | A61B-0006/5217 | A61B-0006/5229 | A61B-0008/02 | A61B-0008/04 | A61B-0008/06 | A61B-0008/065 | A61B-0008/481 | A61B-0008/5223 | A61B-0008/5261 | A61B-0034/25 | A61M-0005/007 | G01R-0033/5601 | G01R-0033/5635 | G01R-0033/56366 | G06F-0017/10 | G06F-0017/5009 | G06F-0017/5018 | G06F-0019/00 | G06F-0019/321 | G06F-0019/324 | G06G-0007/60 | G06K-0009/00147 | G06K-0009/46 | G06K-0009/4604 | G06K-0009/52 | G06K-0009/6215 | G06K-0009/6267 | G06K-0009/6298 | G06T-0007/0012 | G06T-0007/0014 | G06T-0007/11 | G06T-0007/12 | G06T-0007/13 | G06T-0007/149 | G06T-0007/20 | G06T-0007/60 | G06T-0007/62 | G06T-0007/70 | G06T-0007/73 | G06T-0007/74 | G06T-0011/00 | G06T-0011/001 | G06T-0011/008 | G06T-0011/20 | G06T-0011/60 | G06T-0015/10 | G06T-0017/00 | G06T-0017/005 | G06T-0017/20 | G16B-0005/00 | G16B-0045/00 | G16H-0010/40 | G16H-0010/60 | G16H-0030/20 | G16H-0030/40 | G16H-0050/30 | G16H-0050/50 | G16H-0050/70 | A61B-2034/104 | A61B-2034/105 | A61B-2034/107 | A61B-2034/108 | A61B-2090/374 | A61B-2090/3762 | A61B-2090/3764 | A61B-2576/00 | A61B-2576/023 | G06K-2009/4666 | G06T-2200/04 | G06T-2207/10012 | G06T-2207/10072 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/10104 | G06T-2207/10108 | G06T-2207/20036 | G06T-2207/20124 | G06T-2207/30048 | G06T-2207/30104 | G06T-2210/41 | G06T-2211/404 | Y02A-0090/22 | Y02A-0090/26","G06K-009/00","G06K-009/00 | A61B-034/10 | G06F-017/10 | A61B-034/00 | G16B-005/00 | G16B-045/00 | G06T-007/70 | G06T-007/73 | G06T-007/11 | G06T-007/12 | G06T-007/13 | G06T-007/149 | G06T-007/62 | A61B-005/02 | A61B-006/00 | G16H-010/60 | G16H-050/30 | G16H-050/50 | A61B-005/026 | G06G-007/60 | A61B-005/00 | A61B-005/029 | A61B-006/03 | A61B-008/06 | A61B-008/08 | G01R-033/563 | A61B-005/107 | G06T-007/00 | G06T-017/00 | G06K-009/62 | A61B-005/021 | G06F-017/50 | A61B-005/024 | A61B-005/22 | G06F-019/00 | G06K-009/46 | G06T-007/20 | G06T-011/00 | G06T-011/20 | A61M-005/00 | G06K-009/52 | A61B-005/055 | A61B-005/11 | G06T-017/20 | G06T-015/10 | G06T-011/60 | G06T-007/60 | A61B-008/02 | A61B-008/04 | G01R-033/56 | G16H-030/20 | G16H-030/40 | G16H-010/40 | G16H-050/70 | A61B-090/00","","","","","","4920003000909"
"US","US","P","B2","Method and system for inserting recognized object data into a virtual world","A method of rendering virtual content comprises capturing an image of a field of view of a user, extracting a set of map points based on the captured image, recognizing an object based on the extracted set of map points, retrieving semantic data associated with the recognized object and attaching the semantic data to object data associated with the recognized object, and inserting the recognized object data and the semantic data attached thereto into a virtual world model such that virtual content, when rendered at a user device of the user, is displayed in relation to the recognized object.","1. A method of rendering virtual content, comprising: capturing, at an image capture device of a virtual or augmented reality system, at least one image of a field of view of a user;extracting a set of map points based on the at least one image;recognizing an object based at least in part on the set of map points, recognizing the object comprising: segmenting the set of map points into a plurality of smaller subsets of map points;storing a first smaller subset of the plurality of smaller subsets of map points locally on the virtual or augmented reality system but not on a remote computational resource communicatively coupled to the virtual or augmented reality system based at least in part upon density of a plurality of fiducial points for registration of one or more other map points of the set of map points;recognizing the object as a first type of objects at least by processing a first smaller subset of the plurality of smaller subsets of map points into a first processed subset representing the first type of objects with a first object recognizer on the virtual or augmented reality system, wherein map points in the first smaller subset include information comprising respective coordinates of the map points that are used to localize the map points and to recognize the object as the first type of objects; andrecognizing the object as a purveyor object specific to a purveyor at least by processing the first processed subset with a second object recognizer pertaining to the purveyor based at least in part upon an interaction of the user with the object; andrendering virtual content that includes an offer of product or service from an establishment of the purveyor near the user and displaying the virtual content to the user in relation to the object.","20","14/704800","2015-05-05","2015-0235088","2015-08-20","10533850","2020-01-14","MAGIC LEAP, INC.","Rony  Abovitz | Brian T.  Schowengerdt | Mathew D.  Watson","","","","G01B-0011/303","G01B-0011/303 | A61B-0034/10 | A63F-0013/00 | A63F-0013/213 | A63F-0013/428 | G02B-0006/10 | G02B-0006/34 | G02B-0027/0101 | G02B-0027/017 | G02B-0027/0172 | G02B-0027/42 | G02B-0027/4205 | G02B-0027/4227 | G06F-0003/005 | G06F-0003/011 | G06F-0003/013 | G06F-0003/017 | G06F-0003/0304 | G06F-0003/0485 | G06F-0003/0487 | G06F-0003/04815 | G06F-0003/04842 | G06F-0003/04845 | G06F-0003/04883 | G06F-0016/7837 | G06F-0019/325 | G06K-0009/00214 | G06K-0009/00355 | G06K-0009/00664 | G06K-0009/00671 | G06K-0009/00711 | G06K-0009/6201 | G06K-0009/6212 | G06K-0009/6215 | G06Q-0030/0643 | G06T-0007/60 | G06T-0019/006 | G16H-0040/00 | G16H-0040/20 | H04B-0010/2504 | A61B-2034/101 | G02B-2027/014 | G02B-2027/0105 | G02B-2027/0127 | G02B-2027/0178 | G02B-2027/0185 | G02B-2027/0187 | G06K-0009/00389 | G06T-2200/04 | G06T-2200/24 | G06T-2207/10004 | G06T-2207/30196 | G06T-2210/41 | G06T-2219/024","A61B-003/00","A61B-003/00 | A61B-003/113 | A61B-003/14 | A61B-005/00 | A61B-005/0476 | A61B-005/145 | A61B-005/1455 | A61B-008/10 | G02B-027/01 | A61F-007/00 | A61F-009/00 | G01B-011/30 | G06F-003/01 | G06F-003/00 | G06F-003/0488 | G02B-027/42 | G02B-006/10 | G06F-016/783 | G06K-009/00 | G06T-019/00 | G06K-009/62 | G02B-006/34 | H04B-010/25 | G06F-019/00 | G06Q-030/06 | G06F-003/03 | G06F-003/0487 | G06F-003/0481 | G06F-003/0484 | G06F-003/0485 | A63F-013/00 | A61B-034/10 | A63F-013/428 | A63F-013/213 | G06T-007/60 | G16H-040/20 | G16H-040/00","","","","","","4920003002817"
"US","US","P","B2","Authentication using prism member","A prism member of an authentication apparatus includes a living body contact surface configured to be in contact with the living body, and an imaging surface opposed to the living body contact surface and formed at a position generally parallel therewith. The prism member includes a reflection surface in contact with the living body contact surface and the imaging surface, to totally reflect light reflected from the former surface toward the latter surface. The reflection surface is at angle such that (i) light through the living body contact surface into the prism member does not reach to the reflection surface, and (ii) light from an inside of the prism member is totally reflected at the living body contact surface in an optical path running from the imaging surface and reaching the living body contact surface by way of the reflection surface. A first imaging unit captures a living-body reflected light.","1. An authentication apparatus including: a prism member;a first imaging unit; anda visible light source configured to radiate a visible light to a living body,wherein the prism member comprises: a living body contact surface configured to be in contact with the living body;an imaging surface configured to be opposed to the living body contact surface and to be formed at a position generally parallel therewith; anda reflection surface configured to be in contact with the living body contact surface and the imaging surface, and to totally reflect light reflected from the living body contact surface toward the imaging surface,wherein the reflection surface is disposed at such an angle that: (i) first light passing through the living body contact surface into the prism member does not reach to the reflection surface, and(ii) second light from an inside of the prism member is totally reflected at the living body contact surface, wherein the first light passes from the imaging surface, to the living body contact surface, and then passes to the imaging surface,wherein the second light passes from the imaging surface, to the living body contact surface, is then reflected by the reflection surface, and then passes to the imaging surface,wherein the first imaging unit is configured to capture a living-body reflected light that is light radiated from the visible light source and then reflected by the living body in contact with the living body contact surface, andwherein the living-body reflected light comprises the first light and the second light.","14","16/123008","2018-09-06","2019-0065718","2019-02-28","10534902","2020-01-14","NEC CORPORATION","Teruyuki  Higuchi","","","","G06F-0021/32","G06F-0021/32 | A61B-0005/0077 | A61B-0005/1172 | G06K-0009/00046","G06F-021/32","G06F-021/32 | G06K-009/00 | A61B-005/00 | A61B-005/1172","","","","","","4920003003854"
"US","US","P","B2","Image display of a centerline of tubular structure","Systems and methods for determining a centerline of a tubular structure from volumetric data of vessels where a contrast agent was injected into the blood stream to enhance the imagery for centerlining. Given a 3D array of scalar values and a first and second point, the system and methods iteratively find a path from the start position to the end position that lies in the center of a tubular structure. A user interface may be provided to visually present and manipulate a centerline of the tubular structure and the tubular structure itself.","1. A method for displaying a vessel in a user interface of a computing device, comprising: receiving medical image data that includes pixel data to provide a visualization of the vessel;displaying a vessel finder within the user interface to receive a selection of the vessel from the medical image data and for automatically displaying a centerline of the vessel;displaying an analysis view that provides at least one tool for analyzing the vessel, the at least one tool comprising a stenosis tool and an aneurysm tool to display characteristics of the vessel, the analysis view further comprising at least one cross section window that displays a cross section of the vessel at a location received within the analysis view;providing a moveable slider perpendicular to, and centered along, edges of the vessel, the moveable slider being moveable along a path defined by the centerline of vessel;receiving a selection from the moveable slider;updating, in real-time in accordance with movement of the moveable slider, a display of the cross section of the vessel in the at least one cross section window to show the cross section at the current location of the moveable slider; anddisplaying a report view of the analysis performed on the vessel.","19","15/249770","2016-08-29","2017-0178405","2017-06-22","10535189","2020-01-14","CALGARY SCIENTIFIC INC.","Torin Arni  Taerum | Jonathan Neil  Draper | Robert George  Newton","","","","G06T-0019/003","G06T-0019/003 | A61B-0005/02014 | A61B-0005/742 | G06F-0003/0488 | G06F-0003/04842 | G06F-0003/04847 | G06F-0019/321 | G06T-0007/0012 | G06T-0011/206 | G06T-0019/00 | G16H-0040/63 | A61B-0006/466 | A61B-0006/481 | A61B-0006/5205 | A61B-0008/466 | A61B-0008/481 | A61B-0008/483 | A61B-0008/5207 | G06F-2203/04806 | G06T-2200/24 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/10136 | G06T-2207/20076 | G06T-2207/30101 | G06T-2210/41 | G06T-2219/028","G06T-019/00","G06T-019/00 | A61B-005/02 | G06T-007/00 | G16H-040/63 | A61B-005/00 | G06F-003/0484 | G06F-003/0488 | G06F-019/00 | G06T-011/20 | A61B-008/08 | A61B-006/00 | A61B-008/00","","","","","","4920003004137"
"US","US","P","B2","Identifying deceptive answers to online questions through human-computer interaction data","The present invention provides a system and a method for eliciting information to sensitive questions and reliably detecting whether one is being deceptive, concealing information, or experiencing a heightened emotional response to the question. In particular, the system and the method of the invention are based on analyzing the user behavioral biometric of using one or more input device(s).","1. A real-time behavioral biometric-based deception analysis system for determining whether a subject is truthful or deceptive to a question of interest that is presented on a display screen, said system comprising: a data interception unit configured to intercept input in real-time from a subject that is directed to a question presented on a display screen, wherein the data interception unit is configured to passively collect a pointing device usage characteristic in real-time;a behavior analysis unit operatively coupled to said data interception unit to receive the passively collected pointing device usage characteristic; anda behavior comparison unit operatively coupled to said behavior analysis unit, wherein said system dynamically monitors and passively collects behavioral biometric information in real-time, and translates said behavioral biometric information into representative data comprised of cursor trajectory data, wherein the representative data is normalized against population data and the cursor trajectory data is rescaled to account for screen resolution, stores and compares results, and outputs a result associated with truthfulness or deception of the subject to the question of interest presented on the display screen.","18","14/899865","2014-06-18","2016-0143570","2016-05-26","10524713","2020-01-07","THE ARIZONA BOARD OF REGENTS ON BEHALF OF THE UNIVERSITY OF ARIZONA","Joseph S.  Valacich | Jeffrey L.  Jenkins","","","","A61B-0005/164","A61B-0005/164 | G06F-0021/316 | G06F-0021/32 | G06F-0021/40","A61B-005/16","A61B-005/16 | G06F-021/32 | G06F-021/62 | G06Q-010/10 | G06F-021/31 | G06F-021/40","","","","","","4920002001055"
"US","US","P","B2","Condition detection in a virtual reality system or an augmented reality system","Techniques that facilitate condition detection in a virtual reality system and/or an augmented reality system are provided. In one example, a system includes a virtual reality component and an anomaly detection component. The virtual reality component collects motion data and biometric data from a virtual reality device. The motion data is indicative of motion information associated with one or more accelerometer sensors of the virtual reality device. The biometric data is indicative of biometric information associated with one or more biometric sensors of the virtual reality device. The anomaly detection component integrates the motion data and the biometric data into a machine learning model to generate anomaly detection data for the virtual reality device.","1. A system, comprising: a memory that stores computer executable components;a processor that executes computer executable components stored in the memory, wherein the computer executable components comprise: a virtual reality component that collects motion data and biometric data from a virtual reality device, wherein the motion data is indicative of motion information associated with one or more accelerometer sensors of the virtual reality device, wherein the motion data is indicative of rotational information associated with the one or more accelerometer sensors and positional information associated with one or more positional sensors of the virtual reality device, and wherein the biometric data is indicative of biometric information associated with one or more biometric sensors of the virtual reality device; andan anomaly detection component that integrates the motion data and the biometric data into a machine learning model to generate anomaly detection data for the virtual reality device.","17","15/974178","2018-05-08","2019-0343465","2019-11-14","10524737","2020-01-07","INTERNATIONAL BUSINESS MACHINES CORPORATION","Aldis  Sipolins | Jenna  Reinen | Hui  Wu | Ravi  Tejwani | Marco  Cavallo","","","","A61B-0005/7282","A61B-0005/7282 | A61B-0005/0205 | A61B-0005/0402 | A61B-0005/1113 | A61B-0005/1121 | A61B-0005/4809 | A61B-0005/7267 | A61B-0005/747 | A61B-0005/7435 | A61B-0005/7475 | G06F-0003/011 | G06N-0020/00 | A61B-2503/12 | A61B-2562/0219","A61B-005/00","A61B-005/00 | G06F-003/01 | A61B-005/0205 | A61B-005/0402 | A61B-005/11 | G06N-020/00","","","","","","4920002001078"
"US","US","P","B2","Twin-monitor electronic display system","The invention concerns an electronic display system, associated with ultrasound imaging equipment capable of for capturing a medium image, said system comprising a first monitor to display an ultrasound image captured by the ultrasound imaging equipment and image processing means. The system comprises a second touch-screen monitor, means to duplicate the ultrasound image, means to send this duplicate to the second monitor on which at least part thereof is displayed, means to display at least one graphical element which, by means screen tactility, is used to perform at least one processing operation on the ultrasound image, means for instant application of all processing operations performed using the second monitor to the duplicate ultrasound image displayed on the second monitor, and means for instant or deferred application to the ultrasound image displayed on the first monitor of the processing operations performed on the duplicate ultrasound image via the second monitor.","1. An electronic display system for coupling with an ultrasound imaging equipment capable of capturing an image of a medium by means of an ultrasound probe, the system comprising: a first monitor to display an ultrasound image captured via the ultrasound imaging equipment;a second monitor, separate from the first monitor, the second monitor comprising a touch-screen monitor, the second monitor displaying at least a part of the ultrasound image displayed on the first monitor;means for displaying at least one graphical element on the touch-screen monitor, wherein the at least one graphical element is displayed in a superimposed manner over the ultrasound image and wherein the at least one graphical element relates to a processing operation to be performed on an ultrasound image when the at least one graphical element is manipulated by a user in a tactile manner via the touch screen;means for processing tactile screen inputs on the at least one graphical element,means for allowing size measurement to be performed simultaneously on said first monitor and said touch-screen monitor during simultaneous display of said ultrasound image on said first monitor and at least said part of said ultrasound image on said second monitor; andmeans for:instantly displaying the image on the second monitor with said size measurement, such that the user can immediately observe the size measurement on the image on the second monitor based upon said tactile screen inputs, and displaying the ultrasound image on the first monitor with said size measurement caused by the performance of the tactile screen inputs.","21","14/166088","2014-01-28","2014-0143690","2014-05-22","10524739","2020-01-07","SUPERSONIC IMAGINE","Pascal  Roncalez | Pierre-Lin  Laneyrie","2008-051397","FR","2008-03-04","A61B-0005/7445","A61B-0005/7445 | A61B-0008/464 | A61B-0008/467 | A61B-0008/468 | G06F-0003/0488 | G06F-0003/04812 | G06F-0003/04842 | G06F-0003/04847 | G06F-0003/04883 | G06F-0003/1423 | G06T-0007/0012 | A61B-0008/469 | G06T-2200/24 | G06T-2207/10132 | G06T-2207/30004 | G09G-2340/12","A61B-005/00","A61B-005/00 | G06F-003/0488 | G06F-003/14 | G06T-007/00 | G06F-003/0484 | A61B-008/00 | G06F-003/0481","","","","","","4920002001080"
"US","US","P","B2","Artificial skin and elastic strain sensor","An elastic strain sensor can be incorporated into an artificial skin that can sense flexing by the underlying support structure of the skin to detect and track motion of the support structure. The unidirectional elastic strain sensor can be formed by filling two or more channels in an elastic substrate material with a conductive liquid. At the ends of the channels, a loop port connects the channels to form a serpentine channel. The channels extend along the direction of strain and the loop portions have sufficiently large cross-sectional area in the direction transverse to the direction of strain that the sensor is unidirectional. The resistance is measured at the ends of the serpentine channel and can be used to determine the strain on the sensor. Additional channels can be added to increase the sensitivity of the sensor. The sensors can be stacked on top of each other to increase the sensitivity of the sensor. In other embodiments, two sensors oriented in different directions can be stacked on top of each other and bonded together to form a bidirectional sensor. A third sensor formed by in the shape of a spiral or concentric rings can be stacked on top and used to sense contact or pressure, forming a three dimensional sensor. The three dimensional sensor can be incorporated into an artificial skin to provide advanced sensing.","1. A joint sensor for sensing an angle of a first limb with respect to second limb, wherein both limbs are connected to the joint, the joint sensor comprising: an elastic strain sensor adapted to sense strain along a strain axis, having a first end at a first position along the strain axis and a second end at a second position that is a first distance from the first position;wherein the elastic strain sensor includes two or more channels, each extending from a first end to a second end along the strain axis and a loop portion connecting the first end of a first channel to the first end of a second channel, wherein the loop portion has a substantially large cross-sectional area along an axis transverse to the strain axis, and a conductive liquid extending continuously from at least the second end of the first channel, the loop portion, to the second end of the second channel;wherein the first end of the elastic strain sensor is configured to be worn on the first limb and the second end of the elastic strain sensor is configured to be worn on the second limb, such that the elastic strain sensor becomes elongated when the joint is flexed and causes a change in resistance of the conductive liquid measured from the second end of the first channel to the second end of the second channel and the angle of the joint can be determined as a function of the resistance of the conductive liquid measured from the second end of the first channel to the second end of the second channel.","8","15/823030","2017-11-27","2018-0143091","2018-05-24","10527507","2020-01-07","PRESIDENT AND FELLOWS OF HARVARD COLLEGE","Robert J.  Wood | Yong-Lae  Park | Carmel S.  Majidi | Bor-rong  Chen | Leia  Stirling | Conor James  Walsh | Radhika  Nagpal | Diana  Young | Yigit  Menguc","","","","G01L-0001/22","G01L-0001/22 | A43B-0013/203 | A43B-0023/029 | A61B-0005/1036 | A61B-0005/112 | A61F-0002/105 | B25J-0013/08 | G01L-0001/2287 | G06F-0003/011 | G06F-0003/014 | A61B-0005/6807 | A61B-2562/0247 | A61B-2562/0261","G01L-001/22","G01L-001/22 | B25J-013/08 | G06F-003/01 | A61B-005/103 | A61B-005/11 | A61F-002/10 | A43B-013/20 | A43B-023/02 | A61B-005/00","","","","","","4920002003826"
"US","US","P","B2","Method and apparatus for authenticating user using electrocardiogram signal","A method and apparatus to authenticate a registered user are described. The method and apparatus include a processor configured to identify a first electrocardiogram (ECG) signal measured from the user, and determine a similarity between the first ECG signal and a second ECG signal based on the identified first ECG signal and the second ECG signal included in a reference ECG signal set. The processor is also configured to determine an authentication threshold corresponding to the reference ECG signal set, and determine whether to authenticate the first ECG signal measured from the user by comparing the determined similarity and the authentication threshold.","1. A method of authenticating a user, comprising: identifying a first electrocardiogram (ECG) signal measured from the user;determining a similarity between the first ECG signal and a second ECG signal based on the identified first ECG signal and the second ECG signal included in a reference ECG signal set;determining an authentication threshold, based on a state of the user, corresponding to the reference ECG signal set; anddetermining whether to authenticate the first ECG signal measured from the user by comparing the determined similarity and the authentication threshold,whether the reference ECG signal set is updated using the first ECG signal, when the authentication with respect to the first ECG signal is a success.","20","15/867147","2018-01-10","2018-0196932","2018-07-12","10528714","2020-01-07","SAMSUNG ELECTRONICS CO., LTD.","Chao  Zhang | Haixiao  Liu | Yang  Liu | Chisung  Bae | Sang Joon  Kim","2017-10019864 | 10-2017-0149410","CN | KR","2017-01-11 | 2017-11-10","G06F-0021/32","G06F-0021/32 | A61B-0005/0452 | A61B-0005/7264 | A61B-0005/04012 | A61B-0005/117 | G06K-2009/00939","G05B-019/00","G05B-019/00 | G05B-023/00 | G06F-007/00 | G06F-007/04 | G08B-029/00 | G08C-019/00 | H04B-001/00 | H04B-003/00 | H04Q-009/00 | G06F-021/32 | A61B-005/0452 | A61B-005/00 | G06K-009/00 | A61B-005/117 | A61B-005/04","","","","","","4920002005024"
"US","US","P","B2","Authentication device, authentication system, authentication method, and program","An authentication device includes: a wearing position determination unit that determines a wearing position, the wearing position being a position at which a wearable article comprising a sensor is being worn on a body; and an authentication unit that performs authentication by using biometric information of the body, the biometric information being detected by the sensor at the wearing position.","1. An authentication device comprising: an annular casing that surrounds a space;an authentication circuit configured to enable authentication when the annular casing is located at a first position of a body by using biometric information of the body; anda first sensor configured to enable determination of whether the annular casing is worn on a second position of the body different from the first position on the body,wherein the second position is a base of a finger.","31","16/286111","2019-02-26","2019-0188367","2019-06-20","10528715","2020-01-07","NEC CORPORATION","Hiroshi  Fukuda","2015-141177","JP","2015-07-15","G06F-0021/32","G06F-0021/32 | A61B-0005/117 | G06K-0009/00013 | G06K-0009/00597 | G06K-0009/00892 | G06K-0009/00912 | G06K-0009/209 | G06T-0001/00 | G06F-2221/2111 | G06K-2009/00932","G06K-009/00","G06K-009/00 | G06F-021/32 | A61B-005/117 | G06K-009/20 | G06T-001/00","","","","","","4920002005025"
"US","US","P","B2","Iris image capturing device, iris image recognition device and method thereof","An iris image capturing device, an iris image recognition device and an iris image recognition method are provided. Multiple data sequences are captured, in which each data sequence includes an iris image. These data sequences are selected to be a positioning image or an image to be processed. The positioning image is for locating the iris, and the image to be processed is for generating a protected iris image according to where the iris is located in the positioning image.","1. An iris image capturing device, used for capturing an iris image to protect the iris image, comprising: an image sensor, capturing an image of a scene in front of the image sensor to sequentially generate a plurality of data sequences, wherein each data sequence includes the iris image;a digital signal processor, connected to the digital signal processor, selecting a first data sequence among the data sequences as a positioning image and lowering the resolution of the positioning image to generate a low-resolution image; anda feature analyzer, connected to the digital signal processor, receiving the low-resolution image, calculating a set of coordinates of the iris image in the low-resolution image, and transmitting the set of coordinates of the iris image to the digital signal processor;wherein after receiving the set of coordinates of the iris image, the digital signal processor selects a second data sequence among the data sequences as an image to be processed, and according to the set of coordinates of the iris image, the digital signal processor captures, compresses and encrypts the iris image in the image to be processed to generate and transmit a protected iris image to the feature analyzer;wherein the positioning image is included in one data sequence, the image to be processed is included in another data sequence, and the two data sequences are adjacent to each other.","17","15/867367","2018-01-10","2018-0232576","2018-08-16","10528809","2020-01-07","REALTEK SEMICONDUCTOR CORP.","Kai  Liu | Wen-Tsung  Huang","106104894 A","TW","2017-02-15","G06K-0009/00604","G06K-0009/00604 | A61B-0003/14 | A61B-0005/1171 | G06F-0021/32 | G06K-0009/0061 | A61B-0005/163 | G06K-0009/00281 | G06K-0009/00597 | G06K-0009/00617 | G06T-2207/30041","G06K-009/00","G06K-009/00 | G06F-021/32 | A61B-003/14 | A61B-005/1171 | A61B-005/16","","","","","","4920002005119"
"US","US","P","B2","Information processing apparatus and information processing method","A report concerning the contents obtained by interpretation based on a medical image can be efficiently created without any constraints of expression. An information processing apparatus according to this invention includes an image analysis unit which acquires information concerning a region name or disease name based on an analysis result on the input medical image, an input unit which inputs the result obtained by interpreting the medical image as character information, a conversion candidate prediction unit which outputs conversion candidates concerning the input character information, and a display control unit which displays the input character information upon converting the character information into character information selected from the conversion candidates. The apparatus further includes a priority level setting unit which sets priority levels in advance for character information output as the conversion candidates.","1. An information processing apparatus, which is communicably connected to a database, for creating a report concerning an interpretation result on a medical image, the information processing apparatus comprising: a processor; anda memory storing instructions that, when executed by the processor, cause the information processing apparatus to: receive a medical image obtained by imaging an object by using a medical imaging apparatus from the database;receive region information found in the received medical image;input at least one first character relating to the medical image;determine a first text candidate and a second text candidate from a plurality of text candidates in a candidate table, based on the at least one first character, wherein the first text candidate describes a first region, and the second text candidate describes a second region, wherein a character length of the first text candidate and a character length of the second text candidate are longer than a character length of the at least one first character;determine an interpretation status for the first region and the second region, wherein the interpretation status does not include information representing whether or not the first text candidate and the second text candidate were selected, and wherein the interpretation status indicates whether the medical image has been interpreted;determine, based on the determined interpretation status, a priority level for the first text candidate and the second text candidate, wherein if the first region has already been interpreted and the second region has not yet been interpreted, a priority level for the first text candidate is determined to be higher than a priority level for the second text candidate; andvisually present, based on the determined priority levels for the first text candidate and the second text candidate, the first text candidate and the second text candidate in this order.","13","15/970157","2018-05-03","2018-0253812","2018-09-06","10529045","2020-01-07","CANON KABUSHIKI KAISHA","Yoshihiko  Iwase | Akihiro  Katayama | Hiroshi  Imamura","2007-256011","JP","2007-09-28","G06Q-0050/22","G06Q-0050/22 | G06F-0019/00","G06Q-050/22","G06Q-050/22 | G06F-019/00","","","","","","4920002005353"
"US","US","P","B2","Information processing apparatus, system, and method for displaying bio-information or kinetic information","An information processing apparatus includes a bio-information obtaining unit configured to obtain bio-information of a subject; a kinetic-information obtaining unit configured to obtain kinetic information of the subject; and a control unit configured to determine an expression or movement of an avatar on the basis of the bio-information obtained by the bio-information obtaining unit and the kinetic information obtained by the kinetic-information obtaining unit and to perform a control operation so that the avatar with the determined expression or movement is displayed.","1. An information processing method, the method comprising: determining an emotional state of a subject based on at least one of a kinetic information and a biometric information;determining a figure of a person corresponding to the emotional state of the subject;displaying the figure of a person to another person; anddisplaying time information on a map.","20","16/291792","2019-03-04","2019-0197757","2019-06-27","10529114","2020-01-07","SONY CORPORATION","Akane  Sano | Masamichi  Asukai | Taiji  Ito | Yoichiro  Sako","2007-204114","JP","2007-08-06","G06T-0013/40","G06T-0013/40 | A61B-0003/113 | A61B-0005/0006 | A61B-0005/0008 | A61B-0005/0022 | A61B-0005/01 | A61B-0005/02055 | A61B-0005/0402 | A61B-0005/0476 | A61B-0005/0488 | A61B-0005/1118 | A61B-0005/1123 | A61B-0005/14551 | A61B-0005/165 | A61B-0005/4266 | A61B-0005/742 | A61B-0005/744 | G06F-0003/015 | G06K-0009/00335 | G06T-0007/20 | G16H-0050/50 | A61B-0005/021 | A61B-0005/024 | A61B-0005/026 | A61B-0005/0533 | A61B-0005/08 | Y10S-0345/95","G06T-013/40","G06T-013/40 | G06K-009/00 | A61B-005/11 | A61B-005/1455 | A61B-005/00 | G06T-007/20 | A61B-005/01 | A61B-003/113 | G16H-050/50 | A61B-005/16 | A61B-005/0205 | A61B-005/0488 | A61B-005/0476 | A61B-005/0402 | G06F-003/01 | A61B-005/026 | A61B-005/021 | A61B-005/053 | A61B-005/024 | A61B-005/08","","","","","","4920002005421"
"US","US","P","B1","Methods and systems for treating autism","A method for treating autism is provided. The method includes presenting to affected subjects therapeutic content in the form of images or video in a virtual or augmented reality system and monitoring in real time the behaviors and responses of the subject to the therapy. The virtual or augmented reality system may further include audio, and the monitoring of the therapy may be achieved using one or more tracking sensors, such as a camera.","1. A method for diagnosing a user with a mental or developmental condition, comprising: (a) providing a first user having a first mental or developmental condition a virtual or augmented experience, wherein the virtual or augmented experience provides one or more of a visual, auditory, and haptic stimulation to the first user;(b) generating a first set of sensory data of the first user in response to the one or more of the visual, auditory, and haptic stimulation;(c) associating the first set of sensory data to the first mental or developmental condition;(d) providing a second user the virtual or augmented experience;(e) generating a second set of sensory data of the second user in response to the one or more of the visual, auditory, and haptic stimulation; and(f) processing the second set of sensory data to the first set of sensory data to diagnose the second user with the first mental or developmental condition or lack thereof.","20","16/387885","2019-04-18","","","10529140","2020-01-07","FLOREO, INC.","Vijay  Ravindran | Vibha  Sazawal | Ali  Moeeny | Rita  Solorzano | Sinan  Turnacioglu","","","","G06T-0019/006","G06T-0019/006 | A61B-0005/742 | A61N-0001/36025 | G02B-0027/0101 | G06F-0003/011 | A61M-2021/005 | G01N-2800/28 | G02B-2027/0178 | G06K-0009/00671","G06T-019/00","G06T-019/00 | A61B-005/00 | A61N-001/36 | G02B-027/01 | G06F-003/01 | G06K-009/00 | A61M-021/00","","","","","","4920002005447"
"US","US","P","B2","Method and system for correlating an image capturing device to a human user for analysis of cognitive performance","A method capturing eye movement data for detection of cognitive anomalies, includes a computer application displaying a frame on a display, capturing and displaying a video image of a user's face and eyes, while the user aligns the face to the frame, capturing and processing the face image to initiate an image eye movement capture process, outputting an indication on a display and moving the indication spatially to one of a plurality of images, capturing a video of each user eye, to track the position of the indication of the display, the image of each eye comprising a sclera portion, an iris portion, and a pupil portion, parsing the video to determine a reference images corresponding to eye positions, capturing the user's eyes while the user views familiar and novel images, and correlating the images of the user's eyes to the familiar or novel images using the reference images.","1. A method of processing information including aligning eye movement with an image capturing device for detection of cognitive anomalies, the method comprising: initiating an application, under control of a processor, to output an image of a frame on a display device to a user, the display device being coupled to the processor, the processor being coupled to a communication device coupled to a network of computers, the network of computers being coupled to a server device;initiating a camera coupled to the application to capture a video image of a head of a user, the head of the user being positioned by the user viewing the display device;displaying the video of the image of the head of the user on the display device within a vicinity of the frame being displayed;positioning the head of the user within the frame to align the head to the frame, and capturing an image of the head of the user;processing captured information regarding the image of the head to initiate an image capturing process of eye movement of the user;outputting an indication on a display after initiation of the image capturing process; and moving the indication spatially to one of a plurality of images being displayed on the display device;capturing a video of each eye of the human user, while the head is maintained at an approximately stationary spatial position relative to the camera, and each of the eyes moves to track the position of the indication of the display, the image of each eye comprising a sclera portion, an iris portion, and a pupil portion;parsing the video to determine a first reference image corresponding to a first eye position for a first spatial position for the indication; and a second reference image corresponding to a second eye position for a second spatial position of the indication; andcorrelating each of the other plurality of images to either the first reference image or the second reference image.","10","15/809880","2017-11-10","2018-0125404","2018-05-10","10517520","2019-12-31","NEUROTRACK TECHNOLOGIES, INC.","Nick  Bott | Alexander R.  Lange | Rob  Cosgriff | Roger  Hsiao | Brad  Dolin","","","","A61B-0005/163","A61B-0005/163 | A61B-0005/165 | A61B-0005/4088 | A63F-0013/822 | A63F-0013/85 | G06F-0003/013 | G06T-0007/11 | G09B-0019/00 | G09B-0019/18 | H04N-0005/23293 | H04N-0007/185 | A63F-0013/213","A61B-005/16","A61B-005/16 | H04N-007/18 | H04N-005/232 | G06T-007/11 | G06F-003/01 | A61B-005/00 | A63F-013/822 | A63F-013/85 | G09B-019/18 | G09B-019/00 | A63F-013/213","","","","","","4920001001057"
"US","US","P","B2","Mining social media for ultraviolet light exposure analysis","Social media databases are minded for data related to a subject person. The data in indicative of a level of ultraviolet light exposure of the subject person. An ultraviolet violet exposure profile for the subject person is generated based upon the data and a health assessment report provided. The data may include timestamped images of the subject person and other related persons. The skin characteristics within images are analyzed to determine an ultraviolet light exposure level for the subject person from each image. The skin characteristics may include skin color, freckling and blemishing. The ultraviolet light exposure profile may be developed over an extended interval based upon the image timestamps. The health report may be used to mitigate risks, such as skin cancer, associated with exposure to ultraviolet light.","1. A method comprising: receiving a multiplicity of images from an at least one remote database;analyzing, by a digital processing machine, the multiplicity of images to determine an ultraviolet light exposure profile of a subject person; andthe analyzing further includes: determining a presence of a related person within the multiplicity of images;determining a related skin characteristic of the related person for each of the multiplicity of images; anddetermining an ultraviolet light exposure level for the related person, andthe determining the ultraviolet light exposure profile of the subject person further includes determining the ultraviolet light exposure profile of the subject person based upon the ultraviolet light exposure level of the related person.","19","16/299249","2019-03-12","2019-0209075","2019-07-11","10517524","2019-12-31","INTERNATIONAL BUSINESS MACHINES CORPORATION","Rahil  Garnavi | Timothy M.  Lynar | Suraj  Pandey | Ziyuan  Wang | John M.  Wagner","","","","A61B-0005/444","A61B-0005/444 | A61B-0005/1032 | A61B-0005/445 | A61B-0005/7275 | A61B-0005/742 | A61B-0005/746 | G06F-0019/3418 | G06Q-0030/0201 | G06Q-0050/01 | G16H-0010/60 | G16H-0015/00 | G16H-0040/67 | G16H-0050/20 | G16H-0050/30 | G06T-0007/0012","G06K-009/00","G06K-009/00 | A61B-005/00 | G16H-050/30 | G16H-015/00 | G16H-050/20 | G16H-010/60 | G06Q-050/00 | G06F-019/00 | G06Q-030/02 | A61B-005/103 | G16H-040/67 | G06T-007/00","","","","","","4920001001061"
"US","US","P","B2","Systems and methods for treatment planning based on plaque progression and regression curves","Systems and methods are disclosed for evaluating a patient with vascular disease. One method includes receiving patient-specific data regarding a geometry of the patient's vasculature; creating an anatomic model representing at least a portion of a location of disease in the patient's vasculature based on the received patient-specific data; identifying one or more changes in geometry of the anatomic model based on a modeled progression or regression of disease at the location; calculating one or more values of a blood flow characteristic within the patient's vasculature using a computational model based on the identified one or more changes in geometry of the anatomic model; and generating an electronic graphical display of a relationship between the one or more values of the calculated blood flow characteristic and the identified one or more changes in geometry of the anatomic model.","1. A computer-implemented method of evaluating a patient with vascular disease, the method comprising: receiving patient-specific image data regarding a geometry of the patient'ss vasculature;creating, based on the received patient-specific image data, a patient-specific anatomic model representing a diseased region of the patient'ss vasculature at a first point of time;computing a plaque type using one or more image features of the received patient-specific image data;predicting, using the computed plaque type, a change to a geometric parameter of the diseased region of the patient'ss vasculature at a second point of time;modifying a geometry of the patient-specific anatomic model to include the predicted change to the geometric parameter of the diseased region at the second point in time; andcomputing a value of a blood flow characteristic using the modified patient-specific anatomic model.","20","15/185618","2016-06-17","2016-0296288","2016-10-13","10517677","2019-12-31","HEARTFLOW, INC.","Sethuraman  Sankaran | Charles A.  Taylor | Gilwoo  Choi | Michiel  Schaap | Christopher K.  Zarins | Leo  Grady","","","","A61B-0034/10","A61B-0034/10 | A61B-0005/02007 | A61B-0005/02028 | A61B-0005/7275 | A61B-0006/032 | A61B-0006/504 | A61B-0006/507 | A61B-0006/5217 | G06F-0019/00 | G06F-0019/325 | G16B-0045/00 | G16H-0050/20 | G16H-0050/30 | G16H-0050/50 | A61B-0005/026 | A61B-2034/105 | G06F-0017/50 | G06F-0017/5009 | G06T-0007/0012 | G06T-2207/30096 | G06T-2207/30101","A61B-034/10","A61B-034/10 | G16B-045/00 | G06F-019/00 | A61B-005/02 | A61B-005/00 | G16H-050/50 | G16H-050/20 | A61B-005/026 | G06T-007/00 | A61B-006/00 | A61B-006/03 | G16H-050/30 | G06F-017/50","","","","","","4920001001213"
"US","US","P","B2","Methods and systems for predicting sensitivity of blood flow calculations to changes in anatomical geometry","Embodiments include methods and systems for determining a sensitivity of a patient's blood flow characteristic to anatomical or geometrical uncertainty. For each of one or more of individuals, a sensitivity of a blood flow characteristic may be obtained for one or more uncertain parameters. An algorithm may be trained based on the sensitivities of the blood flow characteristic and one or more of the uncertain parameters for each of the plurality of individuals. A geometric model, a blood flow characteristic, and one or more of the uncertain parameters of at least part of the patient's vascular system may be obtained for a patient. The sensitivity of the patient's blood flow characteristic to one or more of the uncertain parameters may be calculated by executing the algorithm on the blood flow characteristic of at least part of the patient's vascular system, and one or more of the uncertain parameters.","1. A computer-implemented method of determining a sensitivity of a patient'ss blood flow characteristic to uncertainty in a geometric model of a patient'ss vascular system, the method comprising: obtaining, for each of a plurality of individuals, a geometric model of at least a portion of a vascular system of each individual;calculating, for each geometric model, at least one sensitivity of a blood flow characteristic to at least one uncertainty in geometry in the geometric model;identifying a plurality of features of each geometric model;mapping, in a machine learning database, the identified features to the calculated sensitivities;generating, for a patient, a geometric model of at least part of the patient'ss vascular system using patient-specific imaging data of at least a portion of the patient'ss vascular system;determining, for the patient, a blood flow characteristic, at least one feature, and at least one value of uncertainty in geometry in the geometric model of at least part of the patient'ss vascular system; anddetermining a sensitivity of the blood flow characteristic of the patient to the at least one value of uncertainty in geometry in the geometric model of at least part of the patient'ss vascular system, using the at least one feature and the machine learning database.","20","15/298964","2016-10-20","2017-0039340","2017-02-09","10522254","2019-12-31","HEARTFLOW, INC.","Sethuraman  Sankaran | Leo  Grady | Charles A.  Taylor","","","","G16H-0050/50","G16H-0050/50 | A61B-0005/7267 | A61B-0006/00 | A61B-0006/507 | A61B-0006/5217 | G06F-0017/18 | G06N-0003/00 | G06T-0007/0012 | A61B-0005/026 | A61B-2576/02 | G06T-2207/30104","G16H-050/50","G16H-050/50 | A61B-006/00 | A61B-005/00 | A61B-005/026 | G06N-003/00 | G06T-007/00 | G06F-017/18","","","","","","4920001005760"
"US","US","P","B2","Establishing secure communication at an emergency care scene","Among other things, we describe a system that includes a first medical device for treating a patient at an emergency care scene, the first medical device including a processor and a memory configured to detect a request for a connection between the first medical device and a second medical device for treating the patient at the emergency care scene, the request for connection including an identifier of the second medical device, responsive to receiving the request for connection, enabling a wireless communication channel to be established between the first medical device and the second medical device based on the identifier of the second medical device and an identifier of the first medical device; and enabling transmission and/or exchange of patient data between the first medical device and the second medical device via the wireless communication channel. Such communications with more than two devices may also be possible.","1. A system for establishing secure dynamically reconfigurable wireless communications between a defibrillator and a computing device, the system for diagnosing or delivering therapy to a patient, the system comprising: a defibrillator having one or more electrode pads configured to provide a defibrillating shock to the patient and configured to perform a close proximity wireless communication protocol;a plurality of electrodes coupled with the defibrillator and configured to sense an electrocardiogram (ECG) of the patient and to generate ECG signals based on the sensed ECG;a computing device comprising a receiver and transmitter configured to establish a secure communication channel with the defibrillator according to the close proximity wireless communication protocol, the communication channel having a range of less than 100 cm with the defibrillator;a sensor configured to sense at least one feature from an immediate environment of the defibrillator; anda processor with memory configured to perform operations comprising: detecting a request for connection based at least in part on the at least one sensed feature of the immediate environment,determining whether spatial localization is achieved between the defibrillator and the computing device based at least in part on the sensed feature of the immediate environment,providing mutual authentication between the defibrillator and the computing device based at least in part on the spatial localization, wherein providing mutual authentication comprises the defibrillator authenticating the computing device and the computing device authenticating the medical device, andestablishing the secure communication channel between the defibrillator and the computing device for exchanging patient data comprising one or more of (i) treatment data comprising ECG signals of the patient, or (ii) patient information.","32","15/464515","2017-03-21","2017-0325091","2017-11-09","10524123","2019-12-31","ZOLL MEDICAL CORPORATION","Gary A.  Freeman | Guy R.  Johnson | Frederick J.  Geheb | Mark  Weary | Timothy F.  Stever","","","","H04W-0012/06","H04W-0012/06 | A61B-0005/0077 | A61B-0005/02055 | A61B-0005/0402 | A61B-0005/4836 | A61B-0005/6801 | A61M-0016/0048 | A61M-0016/0057 | A61M-0016/10 | A61N-0001/37252 | A61N-0001/39044 | G16H-0040/63 | H04L-0063/0869 | H04W-0004/80 | H04W-0004/90 | H04W-0072/04 | H04W-0076/10 | A61B-0005/021 | A61B-0005/0816 | A61B-0005/0836 | A61B-0005/1123 | A61B-0005/14532 | A61B-0005/14552 | A61B-2560/0252 | A61B-2560/0257 | A61B-2562/0204 | A61B-2562/0219 | A61M-2205/332 | A61M-2205/3303 | A61M-2205/3368 | A61M-2205/3375 | A61M-2205/3569 | A61M-2205/3592 | A61M-2205/505 | A61M-2230/63 | H04L-0067/12 | H04W-0076/50","H04W-012/06","H04W-012/06 | A61N-001/39 | H04W-072/04 | A61B-005/00 | A61B-005/0205 | A61B-005/0402 | A61M-016/00 | A61M-016/10 | A61N-001/372 | H04W-004/80 | H04W-076/10 | H04L-029/06 | H04W-004/90 | G16H-040/63 | H04L-029/08 | A61B-005/021 | A61B-005/083 | A61B-005/11 | A61B-005/145 | A61B-005/1455 | A61B-005/08 | H04W-076/50","","","","","","4920001007609"
"US","US","P","B2","System and method for operant learning brain machine interface by receiving electrodes and neural signals at neural processor","A method, system and computer readable media for a BMI using a fixed decoder based on ratios of different frequency bands, making the decoder robust, less jittery, and resistant to artifacts. The fixed decoder can be configured to use a limited subset of available channels. The decoder can therefore be optimized for each human subject (frequency bands to use, ratios to process the received signals, which channels, weights, etc.) and then fixed. Output from the fixed decoder can be provided to a training program that implements specific feedback and training parameters, thereby enabling subjects to learn to control devices rapidly, as well as consolidate this control. The training program provides continuous feedback of the current transformation being output by the fixed decoder in conjunction with feedback of the past transformations (e.g., up to a second before) and saliency of the feedback when goals of the task are achieved.","1. A method for generating an output command by a neural processor through use of an operant learning brain-machine interface, the method comprising: selecting one or more electrodes from a plurality of electrodes by program code executing on the neural processor;receiving neural signals at the neural processor from the one or more selected electrodes;setting thresholds based on the received neural signals;setting a timer at the neural processor to define an output command rate;while the timer has not elapsed, executing program code by the neural processor for retrieving and processing the received neural signals; andcalculating a control command through the use of a fixed decoder in the neural processor that receives the retrieved and processed neural signals as input.","20","15/744865","2016-07-13","2018-0199840","2018-07-19","10512410","2019-12-24","FUNDA??O D. ANNA SOMMER CHAMPALIMAUD E DR. CARLOS MONTEZ CHAMPALIMAUD","Nuno  Loureiro | Vitor  B. Paixao | Rui  M.Costa | Fernando  Santos","108690","PT","2015-07-13","A61B-0005/04001","A61B-0005/04001 | A61B-0005/048 | A61B-0005/0482 | A61B-0005/7267 | A61F-0002/72 | A61F-0004/00 | G06F-0003/015 | A61B-0005/0478 | A61B-0005/6814","A61B-005/04","A61B-005/04 | A61B-005/00 | A61B-005/048 | A61B-005/0482 | G06F-003/01 | A61F-002/72 | A61F-004/00 | A61B-005/0478","","","","","","4919052000841"
"US","US","P","B2","System for displaying medical monitoring data","A first medical device can receive a physiological parameter value from a second medical device. The second physiological parameter value may be formatted according to a protocol not used by the first medical device such that the first medical device is not able to process the second physiological parameter value to produce a displayable output value. The first medical device can pass the physiological parameter data from the first medical device to a separate translation module and receive translated parameter data from the translation module at the first medical device. The translated parameter data can be processed for display by the first medical device. The first medical device can output a value from the translated parameter data for display on the first medical device or an auxiliary device.","1. A system for providing medical data for display on a medical monitoring hub, the system comprising: a first medical device comprising a processor configured to: receive a physiological signal associated with a patient from a physiological sensor;calculate first physiological parameter data based on the physiological signal; andprovide the first physiological parameter data to a monitoring hub; andthe monitoring hub configured to: receive the first physiological parameter data from the first medical device;receive second physiological parameter data from a second medical device, wherein the second physiological parameter data is formatted according to a protocol other than a protocol natively readable or displayable by the monitoring hub;translate the second physiological parameter data to be readable and displayable by the monitoring hub;receive measurement synchronization data associated with the second medical device;determine, based at least in part on the measurement synchronization data, a time-wise synchronization of the first physiological parameter data and the second physiological parameter data; anddisplay physiological parameter measurements based on the first physiological parameter data and the second physiological parameter data, wherein the physiological parameter measurements are time-wise synchronized.","21","15/919792","2018-03-13","2018-0242921","2018-08-30","10512436","2019-12-24","MASIMO CORPORATION","Bilal  Muhsin | Ammar  Al-Ali | Massi Joe E.  Kiani | Peter Scott  Housel","","","","A61B-0005/742","A61B-0005/742 | A61B-0005/0002 | A61B-0005/002 | A61B-0005/021 | A61B-0005/02055 | A61B-0005/0816 | A61B-0005/14551 | A61B-0005/743 | A61M-0016/0051 | A61M-0016/021 | G06F-0021/84 | G16H-0040/63 | H04Q-0009/00 | A61B-0005/4821 | A61B-0005/4836 | A61B-2560/0214 | A61B-2560/045 | A61B-2562/08 | A61B-2562/227 | A61M-0005/172 | A61M-2205/18 | A61M-2205/3368 | A61M-2205/3375 | A61M-2205/3561 | A61M-2205/3569 | A61M-2205/3584 | A61M-2205/3592 | A61M-2205/505 | A61M-2209/086 | A61M-2230/04 | A61M-2230/10 | A61M-2230/201 | A61M-2230/202 | A61M-2230/205 | A61M-2230/208 | A61M-2230/30 | A61M-2230/42 | A61M-2230/432 | A61M-2230/50","A61B-005/00","A61B-005/00 | H04Q-009/00 | A61B-005/08 | A61B-005/1455 | A61B-005/021 | A61B-005/0205 | A61M-016/00 | G06F-021/84 | G16H-040/63 | A61M-005/172","","","","","","4919052000867"
"US","US","P","B2","Interface system for vehicle","A user interface system for a vehicle includes: at least one display unit provided in the vehicle; a detachable interface apparatus configured to be detachably attached to any one of the at least one display unit provided in the vehicle; at least one processor; and a computer-readable medium having stored thereon instructions that, when executed by the at least one processor, cause the at least one processor to perform operations that include: in a state in which the detachable interface apparatus is attached to a selected display unit among the at least one display unit of the vehicle, determining a first user menu corresponding to the selected display unit; and displaying, on the selected display unit or on the detachable interface apparatus, the first user menu corresponding to the selected display unit.","1. A user interface system for a vehicle, comprising: at least one display unit provided in the vehicle;a detachable interface apparatus configured to be detachably attached to any one of the at least one display unit provided in the vehicle;at least one processor; anda non-transitory computer-readable medium having stored thereon instructions that, when executed by the at least one processor, cause the at least one processor to perform operations comprising: in a state in which the detachable interface apparatus is attached to a selected display unit among the at least one display unit of the vehicle, determining a first user menu corresponding to the selected display unit; anddisplaying, on the selected display unit or on the detachable interface apparatus, the first user menu corresponding to the selected display unit,wherein the vehicle further comprises a camera,wherein the vehicle further comprises at least one electromagnet disposed at a rear surface of the at least one display unit and configured to have a variable magnetic force,wherein the detachable interface apparatus further comprises an electromagnet module disposed at a rear surface of the detachable interface apparatus and configured to have a variable magnetic force, andwherein the operations executed by the at least one processor further comprise: in a state in which the detachable interface apparatus is attached to the selected display unit of the vehicle: determining whether the vehicle is in an autonomous mode or a manual mode, based on vehicle state information acquired through an interface unit of the vehicle,determining whether a driver of the vehicle or a passenger of the vehicle attempts to detach the detachable interface apparatus, based on an image of an inside of the vehicle acquired through the camera,based on a determination that the vehicle is in a manual driving mode and that the driver of the vehicle attempts to detach the detachable interface apparatus, increasing an adhesive force by which the detachable interface apparatus is attached to the selected display unit of the vehicle by increasing at least one of a magnetic force of the at least one electromagnet of the at least one display unit, or a magnetic force of the electromagnet module of the detachable interface apparatus, andbased on a determination that the vehicle is in a manual driving mode and that the passenger of the vehicle attempts to detach the detachable interface apparatus, adjusting an adhesive force by which the detachable interface apparatus is attached to the selected display unit of the vehicle to a default degree by adjusting at least one of a magnetic force of the at least one electromagnet of the at least one display unit, or a magnetic force of the electromagnet module of the detachable interface apparatus.","19","15/856544","2017-12-28","2018-0370365","2018-12-27","10513184","2019-12-24","LG ELECTRONICS INC.","Gu  Lee | Uniyoung  Kim | Daihyung  Ryu | Dohyeon  Kim | Sungjun  Park | Jieun  Song | Jaeyoung  Lee","10-2017-0080676","KR","2017-06-26","B60K-0037/06","B60K-0037/06 | B60K-0035/00 | B60K-0037/02 | G06F-0003/0227 | G06F-0003/0482 | G06F-0003/0487 | G06K-0009/00845 | B60K-2370/11 | B60K-2370/122 | B60K-2370/126 | B60K-2370/145 | B60K-2370/1537 | B60K-2370/195 | B60K-2370/46 | B60K-2370/55 | B60K-2370/736 | B60K-2370/739 | B60K-2370/81 | B60K-2370/828 | H01F-0007/06","G01C-021/20","G01C-021/20 | B60K-035/00 | G05D-001/00 | B60K-037/06 | H04M-001/60 | G01C-021/36 | A61B-005/024 | B60R-011/02 | G06F-017/50 | G06F-021/62 | B60R-016/037 | G06Q-010/08 | B60K-037/02 | G06F-003/02 | G06F-003/0482 | G06F-003/0487 | G06K-009/00 | H01F-007/06","","","","","","4919052001610"
"US","US","P","B2","System and method for assessing speaker spatial orientation","System and method for assessing speaker spatial orientation are provided. For example, audio data, as well as input from other sensors, may be analyzed to assess speaker spatial orientation. For example, the audio data may be analyzed to determine that two speakers are engaged in conversation. relative direction of one speaker with respect to the other may be obtained. Spatial orientation of at least one of the speakers may be obtained. The spatial orientation may be assessed according to the relative direction and the determination that the two speakers are engaged in conversation. Feedbacks and reports may be provided based on the assessed speaker spatial orientation.","1. A system for assessing spatial orientation of speakers, the system comprising: at least one processing unit configured to: obtain audio data captured by one or more audio sensors;obtain one or more images captured by one or more image sensors;analyze the audio data to determine that two speakers are engaged in conversation, the two speakers comprises a first speaker and a second speaker;obtain directional information associated with a relative direction of the first speaker with respect to the second speaker;analyze the one or more images to identify a spatial orientation of at least one of a torso, a face and an eye of at least one of the two speakers;use the obtained directional information and the identified spatial orientation to calculate a difference between the relative direction of the first speaker with respect to the second speaker and the identified spatial orientation of the at least one of a torso, a face and an eye of the at least one of the two speakers to assess the spatial orientation according to the directional information, therefore obtaining spatial orientation assessment; andprovide information based on the calculated difference between the relative direction of the first speaker with respect to the second speaker and the identified spatial orientation of the at least one of a torso, a face and an eye of the at least one of the two speakers.","20","15/650916","2017-07-16","2018-0020285","2018-01-18","10516938","2019-12-24","ARGSQUARE LTD","Ron  Zass","","","","H04R-0001/406","H04R-0001/406 | A61B-0005/16 | A61N-0001/36082 | G06F-0017/20 | G06F-0017/21 | G06K-0009/00275 | G06K-0009/00369 | G10L-0015/1822 | G10L-0017/005 | G10L-0017/26 | G10L-0021/0205 | G10L-0021/028 | G10L-0021/0224 | G10L-0025/63 | G10L-0025/72 | G16H-0050/70 | H04R-0001/265 | H04R-0003/005 | H04R-0025/407 | A61B-0005/02055 | A61B-0005/1114 | A61B-0005/1128 | A61B-2562/0204 | A61B-2562/0219 | G01N-2800/28 | G06K-0009/00228 | G06K-0009/00362 | G06K-0009/46 | H04R-0005/0335 | H04R-2201/023 | H04R-2225/43","H04R-001/40","H04R-001/40 | H04R-001/26 | G06K-009/00 | G16H-050/70 | A61N-001/36 | G10L-017/00 | G10L-017/26 | G10L-021/02 | G10L-021/028 | H04R-003/00 | H04R-025/00 | G10L-025/72 | G10L-015/18 | G06F-017/21 | G06F-017/20 | G10L-021/0224 | G10L-025/63 | A61B-005/16 | G06K-009/46 | H04R-005/033 | A61B-005/0205 | A61B-005/11","","","","","","4919052005339"
"US","US","P","B2","Cleanliness monitoring","A system for monitoring cleanliness in a store. The system may include a server, a database and at least one sensor. The database may be in communication with the server and may store cleanliness parameters. The system includes at least one sensor configured to transmit measured cleanliness characteristics to the server and the server is configured to transmit a message based on a comparison of the measured cleanliness characteristics and the cleanliness parameters stored in the database.","1. A system for monitoring cleanliness of a retail store, the system comprising: a server;a database in communication with the server and storing cleanliness parameters;at least one sensor configured to transmit measured cleanliness characteristics to the server, wherein the server is configured to generate and transmit a message based on a location of the consumer and a comparison of the measured cleanliness characteristics and the cleanliness parameters stored in the database.","14","15/660202","2017-07-26","2018-0028038","2018-02-01","10499785","2019-12-10","SPOT YOU MORE, INC.","Joel R.  Setchell | James D.  Haley","","","","A47L-0013/20","A47L-0013/20 | A47L-0011/4008 | A47L-0013/10 | A47L-0013/42 | A61B-0005/103 | G01C-0019/02 | G01F-0023/0007 | G01L-0019/0092 | G01N-0027/048 | G06Q-0010/00 | A47K-0010/18 | F21V-0031/04 | F25D-0023/028 | G01B-0011/005 | G01L-2019/0053 | H04L-0067/06","A47L-013/20","A47L-013/20 | A61B-005/103 | G01C-019/02 | G01F-023/00 | G01L-019/00 | G01N-027/04 | A47L-011/40 | A47L-013/10 | A47L-013/42 | G06Q-010/00 | A47K-010/18 | F21V-031/04 | F25D-023/02 | G01B-011/00 | H04L-029/08","","","","","","4919050000977"
"US","US","P","B2","Detection of worsening heart failure events using heart sounds","Systems and methods for detecting events indicative of worsening using heart sounds are disclosed. A system can include a signal sensor circuit to sense a heart sound (HS) signal. The system can detect at least first and different second HS components using the HS signal, and generate respective first and second HS metrics. The system can determine a trend indicator for the first or second HS metric, and selectively generate one or more composite HS metrics using the first and second HS metrics, according to the trend indicator indicating a growing or decay trend. The system can include a heart failure (HF) event detector to produce a HF status using the composite HS metrics, and output an indication of the HF status, or deliver therapy according to the HF status.","1. A system, comprising: a metric generator circuit configured to receive cardiac acceleration information of a patient, and to generate a first signal metric and a different second signal metric using the received cardiac acceleration information; anda blending circuit configured to generate a composite metric using (1) a ratio of the second signal metric to the first signal metric or (2) a product of the first and second signal metrics; anda cardiac event detector circuit configured to detect a heart failure (HF) status using a combination of (1) at least one of the first or second signal metric and (2) the composite metric.","20","16/133911","2018-09-18","2019-0015053","2019-01-17","10499858","2019-12-10","Cardiac Pacemakers, Inc.","Pramodsingh Hirasingh  Thakur | Qi  An","","","","A61B-0005/7282","A61B-0005/7282 | A61B-0005/02028 | A61B-0005/7275 | A61B-0007/04 | A61N-0001/3627 | A61N-0001/36514 | A61N-0001/37235 | A61N-0001/3962 | A61N-0001/3987 | H04L-0067/12","A61B-005/00","A61B-005/00 | A61N-001/362 | A61B-005/02 | A61B-007/04 | A61N-001/365 | A61N-001/372 | A61N-001/39 | H04L-029/08","","","","","","4919050001050"
"US","US","P","B2","Exercise computer with zoom function and methods for displaying data using an exercise computer","An exercise computer includes a page object that includes an ordered list of data fields. The ordered list includes a first data field pertaining to a first data value and a second data field pertaining to a second data value. A first layout stored defines a first cell having a position and size and a second cell, the cells for displaying the first data value and the second data value, respectively. A second layout defines a third cell also for displaying the first data value, but having a size and/or position different than those of the first cell. A processing unit of the exercise computer is configured to selectively display the first layout and the second layout and to populate each of the cells with the corresponding data value.","1. An exercise computer comprising: a processing unit in communication with a non-transitory storage and a display;a page object stored in the non-transitory storage, the page object comprising an ordered list of data fields, each data field of the ordered list of data fields assigned a respective priority;a first page layout stored in the non-transitory storage, the first page layout having a first arrangement of cells for displaying data values for a respective first set of the ordered list of data fields, the first set including a highest priority data field of the ordered list of data fields and a first lower priority data field of the ordered list of data fields;a second page layout stored in the non-transitory storage, the second page layout having a second arrangement of cells for displaying data values for a respective second set of the ordered list of data fields, the second set being including the highest priority data field of the ordered list of data fields and a second lower priority data field of the ordered list of data field, the second lower priority data field being different than the first lower priority data field;wherein the processing unit is configured to: render the page object on the display according to the first page layout; andin response to receiving a command to change page layouts, re-render the page object on the display according to the second page layout such that re-rendering the page object according to the second page layout displays at least one more data field or displays at least one less data field as compared to the first page layout.","24","15/416242","2017-01-26","2017-0212666","2017-07-27","10500440","2019-12-10","WAHOO FITNESS LLC","Harold M.  Hawkins, III | Benjamin P.  Johnston | Shane A.  Byler","","","","A63B-0024/0062","A63B-0024/0062 | G06F-0003/0481 | G06F-0003/04847 | G06F-0017/212 | G06F-0017/245 | A61B-0005/02438 | A61B-0005/11 | A61B-0005/742 | A61B-2503/10 | G06F-2203/04803 | G06F-2203/04806","G06F-003/14","G06F-003/14 | A63B-024/00 | G06F-017/21 | G06F-017/24 | G06F-003/0481 | G06F-003/0484 | A61B-005/00 | A61B-005/024 | A61B-005/11","","","","","","4919050001629"
"US","US","P","B2","Golf clubs and golf club heads","Golf clubs according to at least some example aspects of this disclosure may include a golf club head and a shaft configured to engage with the golf club head which includes a grip engaged with the shaft. Further, the golf club may include a monitoring device, which includes a sensor and a transmitter. Additionally, the monitoring device may be configured to determine data related to the characteristics of a golf swing. Further, the monitoring device may be configured to transmit the data related to the characteristics of a golf swing to a remote computer.","1. A golf bag comprising: a golf bag base;a pocket on an exterior of the golf bag with a first induction coil positioned beneath a wall of the pocket, the first induction coil configured to connect to a first power source;a container attached to the golf bag base wherein the container is configured to retain a golf club; andwherein a first electrical current is configured to flow in the first induction coil to induce a second electrical current into a second induction coil to charge a second power source of a monitoring device.","22","15/905469","2018-02-26","2018-0178096","2018-06-28","10500452","2019-12-10","NIKE, INC.","Michael  Wallans | Robert M.  Boyd | Philip J.  Hatton | Mario A.  Lafortune | John T.  Stites","","","","A63B-0053/0487","A63B-0053/0487 | A61B-0005/1122 | A61B-0005/6895 | A63B-0053/047 | A63B-0053/0466 | A63B-0053/10 | A63B-0053/14 | A63B-0060/16 | A63B-0060/46 | A63B-0060/50 | A63B-0069/3632 | A63B-0069/3685 | A63B-0071/0619 | A63B-0071/0622 | G01S-0019/19 | G06F-0001/1684 | G06F-0003/0346 | G06K-0009/00342 | G06Q-0050/01 | A61B-2503/10 | A61B-2505/09 | A63B-0049/035 | A63B-0049/08 | A63B-0053/04 | A63B-0059/20 | A63B-0059/50 | A63B-0059/70 | A63B-2053/0433 | A63B-2053/0437 | A63B-2071/0063 | A63B-2071/068 | A63B-2071/0647 | A63B-2102/18 | A63B-2102/24 | A63B-2209/00 | A63B-2220/12 | A63B-2220/16 | A63B-2220/30 | A63B-2220/40 | A63B-2220/53 | A63B-2220/803 | A63B-2220/833 | A63B-2225/15 | A63B-2225/20 | A63B-2225/50 | A63B-2225/54","A61B-005/00","A61B-005/00 | A63B-053/04 | A63B-069/36 | A63B-071/06 | A63B-053/10 | A63B-053/14 | G06F-003/0346 | A63B-060/16 | A63B-060/50 | G01S-019/19 | G06K-009/00 | G06Q-050/00 | A61B-005/11 | G06F-001/16 | A63B-060/46 | A63B-049/08 | A63B-102/24 | A63B-049/035 | A63B-059/70 | A63B-059/20 | A63B-102/18 | A63B-059/50 | A63B-071/00","","","","","","4919050001641"
"US","US","P","B2","User identification via motion and heartbeat waveform data","The disclosure relates to methods, devices, and systems to identify a user of a wearable fitness monitor using data obtained using the wearable fitness monitor. Data obtained from motion sensors of the wearable fitness monitor and data obtained from heartbeat waveform sensors of the wearable fitness monitor may be used to identify the user.","1. A method comprising: receiving motion data generated by one or more motion sensors of a wearable device when the wearable device is worn by a wearer;receiving an indication that the wearable device is being used to authenticate a transaction;determining a first motion signature based at least on the motion data, wherein the first motion signature characterizes a movement experienced by the wearable device;comparing the first motion signature to one or more reference features of a reference user;determining, based on the comparison, that the wearer of the wearable device is not the reference user; andpreventing, responsive to determining that the wearer of the wearable device is not the reference user, the wearable device from authenticating the transaction.","33","16/153618","2018-10-05","2019-0050064","2019-02-14","10503268","2019-12-10","FITBIT, INC.","Shelten Gee Jao  Yuen | James  Park | Atiyeh  Ghoreyshi | Anjian  Wu","","","","G06F-0003/017","G06F-0003/017 | A61B-0005/0002 | A61B-0005/02416 | A61B-0005/02438 | A61B-0005/0402 | A61B-0005/11 | A61B-0005/112 | A61B-0005/117 | A61B-0005/1112 | A61B-0005/1118 | A61B-0005/1123 | A61B-0005/441 | A61B-0005/681 | A61B-0005/6802 | A61B-0005/725 | A61B-0005/7257 | A61B-0005/7264 | A61B-0005/7267 | A61B-0005/7271 | A61B-0005/742 | A61B-0005/7475 | A63B-0024/0062 | G01C-0022/006 | G01P-0001/02 | G01P-0013/00 | G01S-0019/00 | G01S-0019/19 | G06F-0001/163 | G06F-0019/00 | G06F-0021/32 | G06K-0009/00342 | G06K-0009/00885 | G06Q-0050/01 | G09B-0005/02 | A61B-0005/0022 | A61B-0005/0024 | A61B-0005/0404 | A61B-0005/1032 | A61B-0005/1172 | A61B-0005/6844 | A61B-2560/0223 | A61B-2562/0219 | A63B-0069/36 | G06K-0009/0053 | G06K-0009/00335 | G06K-2009/00939","G06F-003/01","G06F-003/01 | G06K-009/00 | G06F-001/16 | G01S-019/19 | G06Q-050/00 | G01S-019/00 | A61B-005/00 | A61B-005/11 | A61B-005/024 | A61B-005/0402 | A63B-024/00 | G01C-022/00 | G01P-013/00 | G01P-001/02 | A61B-005/117 | A63B-069/36 | A61B-005/1172 | A61B-005/103 | A61B-005/0404 | G06F-021/32 | G09B-005/02 | G06F-019/00","","","","","","4919050004440"
"US","US","P","B2","Information processing apparatus, information processing method, and program","In one example embodiment, an information processing apparatus, for an observed image associated with an observation target object (e.g., a section of biological tissue), associates and stores position information and observation magnification information. In this embodiment, the information processing apparatus causes a display device to: (i) display an image associated with the observation target object; (ii) indicate the first positional information of the first observed image; and (iii) indicate the first observation magnification information of the first observed image.","1. A method of displaying a microscopic image, the method comprising: causing a display device to display a first area and a second area of the microscopic image, wherein the first area of the microscopic image is configured to be displayed in a first resolution and the second area of the microscopic image is configured to be displayed in a second resolution; andcausing the display device to display a first part of the first area in a first color, wherein the first part of the first area corresponds to the second area of the microscopic image, wherein the first color includes one or more colors, and wherein the first color is representative of a magnification level of the second area of the microscopic image.","78","15/434888","2017-02-16","2017-0161898","2017-06-08","10506167","2019-12-10","SONY CORPORATION","Yoichi  Mizutani | Shigeatsu  Yoshioka | Yoshihiro  Wakita | Masashi  Kimoto | Naoki  Tagami","2009-269495","JP","2009-11-27","H04N-0005/23293","H04N-0005/23293 | A61B-0005/0059 | A61B-0090/20 | G06F-0003/14 | G06F-0019/321 | G06T-0007/0012 | G06T-0011/00 | G06T-0011/60 | G16H-0030/20 | G06T-2207/10056 | G06T-2207/30024","G06K-009/00","G06K-009/00 | H04N-005/232 | G06F-019/00 | G06T-011/00 | G06T-007/00 | G06T-011/60 | G06F-003/14 | A61B-090/20 | A61B-005/00 | G16H-030/20","","","","","","4919050007319"
"US","US","P","B2","Case display apparatus having tomographic image display including of slice position shift and image capture time shift, case displaying method, and non-transitory storage medium","A user input obtainer receives an image movement instruction including identification information specifying a position shift or an image capture time shift to be performed and also including a displacement amount. When the identification information specifies the position shift, a slice position selector determines a tomographic image at a destination of the position shift based on the displacement amount from a set of tomographic images captured at the same time. On the other hand, when the identification information specifies the image capture time shift, the image capture time selector determines a tomographic image at a destination of the shift based on the displacement amount from sets of tomographic images that are identical to each other in terms of a patient, an examination portion, and a modality. A displaying image obtainer reads out the determined tomographic image from an image storage device and gives it to a display information generator.","1. A case display apparatus, comprising: at least one memory configured to store a program; and at least one processor configured to execute the program and control the case display apparatus to:generate display information displayed on a display device;when the display information includes a first tomographic image, receive an image movement instruction including identification information and a displacement amount, the identification information specifying a slice position shift or an image capture time shift to be performed;when the identification information specifies that the slice position shift is to be performed, determine a second tomographic image at a destination of the slice position shift from a first tomographic image set including the first tomographic image, based on a position movement amount corresponding to the displacement amount, the first tomographic image set being a first plurality of tomographic images;when the identification information specifies that the image capture time shift is to be performed, select a third tomographic image from a second tomographic image set, the second tomographic image set being a second plurality of tomographic images, a target person of the first tomographic image and target persons of the second tomographic image set being identical, an examination portion captured in the first tomographic image and examination portions captured in the second tomographic image set being identical, a modality for the first tomographic image and modalities for the second tomographic image set being identical, and image capture times of the first tomographic image set and image capture times of the second tomographic image set being different, an image capture time of the third tomographic image being shifted from an image capture time of the first tomographic image based on a time movement amount corresponding to the displacement amount; andread out the second tomographic image or the third tomographic image from an image storage device, and give a read out tomographic image;wherein in a case where a new image movement instruction is not received within a predetermined period of time after a user inputs an image capture time shift on a tomographic image, control displaying such that a slice position of a displayed tomographic image is moved up and down in a tomographic image set including a tomographic image being currently displayed, and subsequently receive a new image movement instruction.","6","14/997540","2016-01-17","2016-0128795","2016-05-12","10492883","2019-12-03","PANASONIC INTELLECTUAL PROPERTY MANAGEMENT CO., LTD.","Kazuki  Kozuka | Kenji  Kondo | Kazutoyo  Takata","2013-164154 | 2014-127893","JP | JP","2013-08-07 | 2014-06-23","A61B-0090/37","A61B-0090/37 | A61B-0006/03 | A61B-0006/032 | A61B-0006/463 | A61B-0006/469 | G06F-0003/04842 | G06F-0003/04845 | G06F-0003/04847 | G06F-0019/321 | G06T-0007/0016 | A61B-0005/055 | A61B-2090/374 | A61B-2090/378 | A61B-2090/3762 | A61B-2560/0487 | G06T-2200/24 | G06T-2207/10081 | G06T-2207/20108","A61B-090/00","A61B-090/00 | G06F-003/0484 | G06F-019/00 | G06T-007/00 | A61B-006/03 | A61B-006/00 | A61B-005/055","","","","","","4919049001291"
"US","US","P","B2","Facilitating trusted pairing of an implantable device and an external device","Systems, apparatus, methods and computer-readable storage media facilitating trusted pairing between an implantable medical device (IMD) and an external device are provided. In one embodiment, an IMD includes a housing configured to be implanted within a patient, a memory and circuitry within the housing and a processor that executes executable components stored in the memory. The executable components can include: a communication component configured to initiate establishing a telemetry connection with an external device in accordance with a first telemetry protocol based on reception of a request, from the external device, to establish the telemetry connection with the IMD using the first telemetry protocol; and a validation component configured to restrict establishment of the telemetry connection with the external device in accordance with the first telemetry protocol based on reception of validation information from the external device, wherein provision of the validation information is excluded from the first telemetry protocol.","1. An implantable medical device configured to be at least partially implanted within a patient, comprising: a housing configured to be implanted at least partially within the patient;a memory, within the housing, that stores executable components; andcircuitry, within the housing, and configured to at least one of obtain sensed physiological data associated with the patient or deliver a therapy to the patient;a processor, within the housing, that executes the executable components stored in the memory, wherein the executable components comprise: a communication component configured to initiate establishing a telemetry connection with an external device in accordance with a first telemetry protocol based on reception of a request, from the external device, to establish the telemetry connection with the implantable medical device using the first telemetry protocol;a negotiation component configured to negotiate one or more encryption keys with the external device in accordance with the first telemetry protocol in response to reception of the request, and associate the one or more encryption keys and an identifier for the external device with a first data in the memory that characterizes the external device as potentially authorized to establish the telemetry connection with the implantable medical device in accordance with the first telemetry protocol; anda validation component configured to restrict establishment of the telemetry connection with the external device in accordance with the first telemetry protocol based on reception of validation information from the external device, wherein provision of the validation information is excluded from the first telemetry protocol.","15","15/443269","2017-02-27","2018-0243573","2018-08-30","10493287","2019-12-03","MEDTRONIC, INC.","Matthew R.  Yoder | Gary P.  Kivi | Richard A.  Sanden | Bo  Zhang | Eric D. J.  Dorphy","","","","A61N-0001/37252","A61N-0001/37252 | A61B-0005/0031 | A61B-0005/686 | A61N-0001/37217 | H04L-0063/18 | H04W-0004/80 | A61N-0001/37223 | H04W-0012/04 | H04W-0012/06","A61B-005/00","A61B-005/00 | A61N-001/372 | H04L-029/06 | H04W-004/80 | H04W-012/04 | H04W-012/06","","","","","","4919049001691"
"US","US","P","B2","Motion-based music recommendation for mobile devices","A method comprising acquiring a plurality of measurements from at least one sensor in a mobile device, determining an activity classification of a user of the mobile device based on the plurality of measurements, acquiring an audio file for the mobile device, wherein the audio file is selected based on the activity classification, and playing the audio file by the mobile device.","1. A method comprising: acquiring a plurality of measurements of a mobile device from at least one sensor in the mobile device;determining an activity classification of a user of the mobile device based on the plurality of measurements, the activity classification identifying an activity of a plurality of activities;mapping the activity to a mood from a plurality of moods, wherein an audio file obtained by the mobile device is associated with the mood; andplaying the audio file associated with the mood to the user through an output of the mobile device, wherein the audio file is selected based on the activity classification and the mood.","17","15/250347","2016-08-29","2016-0371371","2016-12-22","10496700","2019-12-03","FUTUREWEI TECHNOLOGIES, INC.","Chia-Chin  Chong | Jianyu  Zhang","","","","G06F-0016/636","G06F-0016/636 | A61B-0005/1118 | G06F-0003/16 | G06F-0003/165 | G06F-0016/635 | G06F-0016/639 | G06F-0016/686 | G06F-0016/90324 | G06N-0020/00 | H04H-0060/33 | H04H-0060/46 | H04H-0060/49 | H04H-0060/65 | A61B-0005/01 | A61B-0005/02055 | A61B-0005/0402 | A61B-0005/0476 | A61B-0005/4806 | A63B-0024/0062 | G06F-0016/68","A61B-005/00","A61B-005/00 | A61B-005/01 | A61B-005/11 | G06F-003/16 | A63B-024/00 | G06F-016/68 | G06N-020/00 | A61B-005/0205 | A61B-005/0402 | A61B-005/0476 | G06F-016/635 | G06F-016/638 | G06F-016/9032 | H04H-060/49 | H04H-060/33 | H04H-060/46 | H04H-060/65","","","","","","4919049005080"
"US","US","P","B2","Spatially selective interventional neuroparticle with magnetoelectric material","An apparatus and method stimulate or sense neurons or groups of neurons in a subject, e.g., a human or animal brain, with positional dependence. This utility is provided in part by utilizing individually-addressable Radio-Frequency IDentification (RFID) coils so that locations of those coils in the brain would be monitored and known.","1. An apparatus comprising: a power source and at least one radio frequency antenna, coupled together and located external to a living body; andat least one radio particle including a frequency identification device (RFID) introduced internal to the living body,wherein the at least one particle'ss RFID includes magnetoelectric material,wherein the at least one particle'ss RFID is situated in or near one or more neurons within the living body, andwherein the at least one internally-located particle includes components controlled using the externally-located radio-frequency antenna to selectively stimulate or sense at least one characteristic of the one or more neurons in response to a selective emanation from the externally-located radio frequency antenna.","18","15/614061","2017-06-05","2017-0265927","2017-09-21","10485605","2019-11-26","WEINBERG MEDICAL PHYSICS INC.","Irving N.  Weinberg","","","","A61B-0018/1206","A61B-0018/1206 | A61B-0005/0031 | A61B-0005/04001 | A61B-0005/04008 | A61B-0005/40 | A61B-0005/486 | A61B-0018/10 | A61B-0018/18 | A61F-0007/00 | A61M-0005/142 | A61N-0001/36125 | A61N-0001/3787 | A61N-0001/37205 | A61N-0007/00 | G06F-0003/015 | H01F-0038/14 | H02J-0050/10 | H02J-0050/80 | A61B-0005/01 | A61B-0005/055 | A61B-0005/14546 | A61B-0018/14 | A61B-2017/00221 | A61B-2018/00434 | A61B-2018/00613 | A61B-2034/2051 | A61B-2090/3954 | A61B-2560/0209 | A61B-2562/08 | A61N-0002/006 | A61N-2007/0047","A61B-018/12","A61B-018/12 | H01F-038/14 | A61N-001/372 | H02J-050/10 | A61N-001/36 | A61M-005/142 | A61B-018/18 | A61B-018/10 | A61N-001/378 | A61N-007/00 | A61B-005/00 | A61B-005/04 | A61F-007/00 | G06F-003/01 | H02J-050/80 | A61N-002/00 | A61B-005/01 | A61B-005/055 | A61B-005/145 | A61B-018/14 | A61B-017/00 | A61B-018/00 | A61B-034/20 | A61B-090/00","","","","","","4919048001197"
"US","US","P","B2","Communication system, control method, and storage medium","A communication system, a control method, and a storage medium, which can guide a user to an action for having the predetermined feeling in accordance with a feeling map. A communication system including: an acquisition unit configured to acquire present position information of a user; a guiding information generation unit configured to generate guiding information in accordance with the present position information and map information in which feeling data is mapped; and a supply unit configured to supply the guiding information to the user.","1. A communication system comprising: an acquirer to acquire present position information of a user;a guiding information generator to generate guiding information in accordance with the present position information and map information in which feeling data is mapped;a supplier to supply the guiding information to the user; anda first feeling estimator to estimate the feeling data on the basis of current surrounding environment information around the user,wherein the guiding information generator generates the guiding information that proposes an improvement of the surrounding environment to the user, on the basis of the feeling data estimated on the basis of the current surrounding environment information.","12","15/302093","2015-01-20","2017-0205240","2017-07-20","10488208","2019-11-26","SONY CORPORATION","Takatoshi  Nakamura | Akira  Tange | Masakazu  Yajima | Mitsuru  Takehara | Yasunori  Kamada | Katsuhisa  Aratani | Kazunori  Hayashi | Takayasu  Kon | Kohei  Asada | Kazuhiro  Watanabe | Tsuyoshi  Abiko | Yuki  Koga | Tomoya  Onuma","2014-087608","JP","2014-04-21","G01C-0021/3407","G01C-0021/3407 | A61B-0005/165 | G01C-0021/265 | G01C-0021/3484 | G01C-0021/3617 | G01C-0021/3641 | G01C-0021/3682 | G06F-0016/00 | G06F-0016/86 | G06K-0009/00892","G01C-021/34","G01C-021/34 | G01C-021/26 | G01C-021/36 | G06K-009/00 | G06F-017/30 | A61B-005/16 | G06F-016/84 | G06F-016/00","","","","","","4919048003787"
"US","US","P","B2","Fiber optic shape sensing applications","Using a suitably constructed fiber optic cable and interrogation circuitry, the fiber optic cable can be positioned along an object to monitor its shape and the position of various points along the object thereon. Embodiments disclosed herein apply fiber optic position and shape sensing in various ways. In one embodiment, as subject's gait is monitored for analysis. In another embodiment, a tool is displayed moving within a patient's body. In an additional embodiment, the movement of a subject's head is tracked.","1. A system comprising a garment and a controller; wherein, the garment comprises clothing stretched over part of a wearer'ss body and a plurality of optical fibers connected to fabric of the garment to enable fiber optic position and shape sensing; andwherein, the plurality of optical fibers comprise a plurality of fiber Bragg gratings;the system characterized in that:a) at least some of the optical fibers cross each other and press on each other, thus creating pairs of points of stress at different lengths along the respective fibers, but with identical XYZ coordinates in a reference frame relative to the body of the wearer; andb) the controller is configured to: i) interrogate the optical fibers at sampling rates of hundreds of times per second enabling the position of each fiber Bragg grating along the optical fibers to be determined to provide a record of the motion of the part of the wearer'ss body enclosed by the clothing;ii) use the points at which the optical fibers cross each other for calibration of the sensed positions of the fibers, forcing the positions of said points to be the same in the reference frame relative to body of the wearer, and interpolating between said points to calibrate other points along the fibers; andiii) at least some of the optical fibers extend along at least four sides of the part of the wearer'ss body enclosed by the clothing, to monitor general cross sections along the part of the body.","10","14/737297","2015-06-11","2015-0359455","2015-12-17","10488916","2019-11-26","DSIT SOLUTIONS LTD.","Meir  Hahami | Itzhak  Pomerantz","","","","G06F-0003/011","G06F-0003/011 | A61B-0005/112 | A61B-0005/6804 | A61B-0005/6805 | G06K-0009/00342 | A61B-0005/6803 | A61B-0006/12 | A61B-2562/0266 | A61B-2562/043 | A61B-2562/046","G06F-003/01","G06F-003/01 | G06K-009/00 | A61B-005/00 | A61B-005/11 | A61B-006/12","","","","","","4919048004488"
"US","US","P","B1","Determining a body mass index of a user of a transaction device and verifying the user for utilization of the transaction device based on the body mass index","A device receives sensor data that provides an indication of a height of a user of a transaction device, receives camera data that includes one or more images of the user, and scale data that provides an indication of a weight of the user. The device identifies one or more features associated with the user based on the camera data and processes the sensor data, the scale data, and feature information describing the one or more features, with a machine learning model, to estimate a body mass index of the user. The device determines whether the user is verified for utilizing the transaction device to conduct a transaction based on the body mass index and one or more credentials associated with the user and performs one or more actions based on determining whether the user is verified for utilizing the transaction device to conduct the transaction.","1. A method, comprising: receiving, by a device and from a sensor associated with a transaction device, sensor data, wherein the sensor data provides an indication of a height of a user of the transaction device;receiving, by the device and from a camera associated with the transaction device, camera data, wherein the camera data includes images of the user of the transaction device;receiving, by the device and from a scale associated with the transaction device, scale data, wherein the scale data provides an indication of a weight of the user of the transaction device;identifying, by the device, one or more features associated with the user based on the camera data;processing, by the device, the sensor data, the scale data, and feature information describing the one or more features, with a machine learning model, to estimate a body mass index of the user; determining, by the device, whether the user is verified for utilizing the transaction device to conduct a transaction, based on the body mass index of the user and one or more credentials associated with the user; andperforming, by the device, one or more actions based on determining whether the user is verified for utilizing the transaction device to conduct the transaction, wherein performing the one or more actions includes one or more of: associating the body mass index of the user with a profile of the user;causing the transaction device to request an additional credential from the user;causing the transaction device to request that the user confirm the body mass index;causing the transaction device to request that the user provide an estimated weight of clothing worn by the user;causing the transaction device to request that the user remove an article of clothing;causing the transaction device to request that the user provide an actual height and/or weight of the user;enabling or preventing the transaction to be conducted with the transaction device; orcausing one or more of the sensor, the camera, or the scale to be recalibrated.","20","16/362100","2019-03-22","","","10489788","2019-11-26","CAPITAL ONE SERVICES, LLC","Joshua  Edwards | Abdelkadar M'Hamed  Benkreira | Michael  Mossoba","","","","G06Q-0020/405","G06Q-0020/405 | A61B-0005/1171 | A61B-0005/4872 | A61B-0005/7264 | G01G-0019/44 | G06N-0020/00 | A61B-2576/00 | G06N-0003/04 | G06N-0020/10 | G06Q-0020/1085 | G06Q-0020/20","G06Q-020/20","G06Q-020/20 | G06Q-020/40 | G06N-020/00 | G01G-019/44 | A61B-005/00 | A61B-005/1171 | G06Q-020/10 | G06N-020/10 | G06N-003/04","","","","","","4919048005354"
"US","US","P","B2","Unified computational method and system for patient-specific hemodynamics","A method for computing patient-specific hemodynamics. The method includes receiving three dimensional imaging data of a patent, extracting anatomical data from the three dimensional imaging data, calculating velocity and pressure fields corresponding to the extracted anatomical data, and calculating displacement and velocity of extracted solid particles corresponding to the anatomical data. The anatomical data comprises an anatomical boundary.","1. A method of non-invasively quantifying in vivo blood flow and flow-artery interaction in an artery, comprising: receiving image data of anatomical features of the artery;processing the image data on a GPU parallel-computation framework employing mesoscale models; andcausing display of information representing the flow-artery interaction;wherein processing comprises using a simplified lattice Boltzmann method (""SLBM"") to model anatomical segmentation of the artery,using a volumetric lattice Boltzmann method (""VLBM"") to model fluid dynamics of the flow-artery interaction,using a lattice spring method (""LSM"") to model structure mechanics of the flow-artery interaction, andusing the SLBM to model interface tracking of the flow-artery interaction.","12","15/520283","2015-10-22","2017-0337327","2017-11-23","10482215","2019-11-19","INDIANA UNIVERSITY RESEARCH AND TECHNOLOGY CORPORATION | KENT STATE UNIVERSITY","Huidan  Yu | Chen  Lin | Ye  Zhao","","","","G06F-0019/321","G06F-0019/321 | G06K-0009/4604 | G06T-0007/0012 | G06T-0007/11 | G06T-0007/12 | A61B-0005/0033 | A61B-0006/032 | A61B-0006/507 | A61B-0006/5217 | A61B-0008/06 | A61B-0008/488 | A61B-0008/5223 | A61B-2576/02 | G06F-0017/11 | G06T-2200/28 | G06T-2207/10028 | G06T-2207/10072 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/10136 | G06T-2207/20161 | G06T-2207/30104 | G16H-0050/50","G06F-019/00","G06F-019/00 | G06T-007/00 | G06T-007/12 | G06T-007/11 | G06K-009/46 | G16H-050/50 | A61B-006/03 | A61B-006/00 | A61B-005/00 | A61B-008/06 | A61B-008/08 | G06F-017/11","","","","","","4919047005260"
"US","US","P","B2","Emotional/cognative state-triggered recording","Emotional/cognitive state-triggered recording is described. A buffer is used to store captured video content until a change in an emotional or cognitive state of a user is detected. Sensor data indicating a change in an emotional or cognitive state of a user triggers the creation of a video segment based on the current contents of the buffer.","1. A system comprising: a camera configured to capture video data;one or more processors;one or more sensors configured to obtain sensor data; andmemory storing instructions that, when executed by the one or more processors, cause the system to: detect, based at least in part on the sensor data, a change from a first emotional or cognitive state of a user to a second emotional or cognitive state of the user;in response to detecting the change from the first emotional or cognitive state of the user to the second emotional or cognitive state of the user, add at least a portion of the video data being captured by the camera to a video segment;detect, based at least in part on additional sensor data, a change from the second emotional or cognitive state of the user to a third emotional or cognitive state of the user; andcease adding the at least the portion of the video data to the video segment based at least in part on detecting the change from the second emotional or cognitive state of the user to the third emotional or cognitive state of the user.","20","16/183609","2018-11-07","2019-0075239","2019-03-07","10484597","2019-11-19","MICROSOFT TECHNOLOGY LICENSING, LLC","John C.  Gordon | Cem  Keskin","","","","H04N-0005/23219","H04N-0005/23219 | A61B-0003/112 | A61B-0003/113 | A61B-0005/01 | A61B-0005/0402 | A61B-0005/165 | G02B-0027/0172 | G06F-0003/012 | G06F-0003/013 | G06F-0003/015 | G06F-0003/16 | G06K-0009/00302 | G06K-0009/00335 | G06K-0009/00597 | H04N-0005/77 | H04N-0005/772 | H04N-0009/8205 | A61B-2503/12 | G02B-2027/0138","H04N-005/232","H04N-005/232 | G06F-003/01 | H04N-005/77 | G06K-009/00 | A61B-003/11 | A61B-003/113 | A61B-005/01 | A61B-005/0402 | A61B-005/16 | G02B-027/01 | G06F-003/16 | H04N-009/82","","","","","","4919047007610"
"US","US","P","B2","System and method for mapping activity in peripheral nerves","Systems and methods are provided for controlling an entity in response to activity in a peripheral nerve comprising a plurality of fascicles. A multicontact electrode assembly is configured to record activity from the peripheral nerve. A processing component includes a sensor mapping component configured to quantify activity associated with a proper subset of the plurality of fascicles, an evaluation component configured to determine an adjustment of the status of the controlled entity from the quantified activity of the proper subset of the plurality of fascicles, and a controller configured to provide a control signal, representing the adjustment of the status of the controlled entity, to the controlled entity.","1. A method comprising: for each of a plurality of contacts of a multicontact electrode assembly: stimulating a test model of a peripheral nerve with a known voltage at a position associated with the contact; andrecording induced voltages at each of a plurality of pixels within the test model of the peripheral nerve due to stimulating the position with the known voltage as an m×1 vector, where m is a number of the plurality of pixels;generating a sensitivity matrix from each of the m×1 vectors for each of the plurality of contacts, wherein the sensitivity matrix represents the spatial sensitivity of the multicontact electrode assembly, wherein n is a number of the plurality of contacts;for each of the plurality of pixels: determining a set of weights for the plurality of contacts of the multicontact electrode assembly based on the sensitivity matrix; andproviding a n×1 vector for the set of weights; andconcatenating the n×1 vectors for each of the plurality of pixels into a transformation matrix for the multicontact electrode assembly.","4","15/459349","2017-03-15","2017-0181652","2017-06-29","10470680","2019-11-12","CASE WESTERN RESERVE UNIVERSITY","Dominique M.  Durand | Brian  Wodlinger","","","","A61B-0005/04001","A61B-0005/04001 | A61B-0005/4041 | A61N-0001/0551 | A61N-0001/36003 | A61N-0001/36103 | G06F-0017/5009 | A61B-0005/4029 | A61B-0005/4064 | A61F-0002/72","A61B-005/04","A61B-005/04 | A61F-002/72 | G06F-017/50 | A61N-001/36 | A61B-005/00 | A61N-001/05","","","","","","4919046001168"
"US","US","P","B2","Systems and methods for selecting, activating, or selecting and activating transducers","Transducer-based systems can be configured to display a graphical representation of a transducer-based device, the graphical representation including graphical elements corresponding to transducers of the transducer-based device, and also including between graphical elements respectively associated with a set of the transducers and respectively associated with a region of space between the transducers of the transducer-based device. Selection of graphical elements and/or between graphical elements can cause activation of the set of transducers associated with the selected elements. Selection of a plurality of graphical elements and/or between graphical elements can cause visual display of a corresponding activation path in the graphical representation. Visual characteristics of graphical elements and between graphical elements can change based on an activation-status of the corresponding transducers. Activation requests for a set of transducers can be denied if it is determined that a transducer in the set of transducers is unacceptable for activation.","1. A transducer-activation system comprising: a data processing device system;an input-output device system communicatively connected to the data processing device system; anda memory device system communicatively connected to the data processing device system and storing a program executable by the data processing device system, the program comprising:graphical representation instructions configured to cause the input-output device system to display a graphical representation of at least a portion of a transducer-based device, at least part of the transducer-based device positionable within a bodily cavity, and the graphical representation comprising a between graphical element associated with a region of space between a first transducer and a second transducer of the transducer-based device, the region of space not including any transducer;activation instructions configured to cause, via the input-output device system, an energy source device system connected to at least the first transducer and the second transducer to deliver energy to each of the first transducer and the second transducer;determination instructions configured to cause determination of an energy-delivery status associated with at least one of the first transducer and the second transducer, the energy-delivery status indicating a status of the energy delivery by the energy source device system to the at least one of the first transducer and the second transducer; andenergy-delivery-indication instructions configured to cause the input-output device system to change a displayed visual characteristic of the between graphical element based at least on the determined energy-delivery status of the at least one of the first transducer and the second transducer.","16","15/860921","2018-01-03","2018-0140363","2018-05-24","10470826","2019-11-12","KARDIUM INC.","Jeffery Charles  Brewster | Daniel Martin  Reinders | Daniel Robert  Weinkam","","","","A61B-0034/25","A61B-0034/25 | A61B-0005/026 | A61B-0005/042 | A61B-0005/0422 | A61B-0005/053 | A61B-0005/0538 | A61B-0005/6858 | A61B-0005/743 | A61B-0005/7435 | A61B-0018/1206 | A61B-0018/1233 | A61B-0018/14 | A61B-0018/1492 | A61N-0001/37264 | G06F-0003/0482 | G06F-0003/04842 | A61B-0005/01 | A61B-0005/6869 | A61B-2017/00199 | A61B-2018/00267 | A61B-2018/00351 | A61B-2018/00357 | A61B-2018/00363 | A61B-2018/00577 | A61B-2018/00642 | A61B-2018/00648 | A61B-2018/00708 | A61B-2018/00797 | A61B-2018/00839 | A61B-2018/00863 | A61B-2018/00875 | A61B-2018/00892 | A61B-2018/00904 | A61B-2018/00988 | A61B-2018/124 | A61B-2034/254 | A61N-0001/362","A61B-034/00","A61B-034/00 | A61B-005/053 | A61B-018/12 | A61B-005/00 | A61B-005/042 | A61B-018/14 | A61N-001/372 | G06F-003/0482 | G06F-003/0484 | A61B-005/026 | A61B-018/00 | A61N-001/362 | A61B-005/01 | A61B-017/00","","","","","","4919046001314"
"US","US","P","B2","Monitoring fitness using a mobile device","Athletic performance monitoring and tracking may provide multiple ways in which to track athletic movement and activity. Workouts may also be tagged with various parameters including mood, weather, terrain, athletic equipment, friends used and the like. Workout information may be shared to social messaging and networking outlets. Workout information shared may include map information including images of maps, interactive maps, links to maps, route information and the like and/or combinations thereof. Additionally or alternatively, an application may be configured to execute within a context of a social networking system to facilitate athletic activity data transfer and generation of workout entries in the social networking site.","1. An apparatus comprising: a processor;a user interface;a sensor configured to monitor athletic activity performed by a first user; andmemory storing computer-readable instructions that, when executed, cause the apparatus to: receive, from the sensor, athletic activity data recorded during the athletic activity performed by the first user;communicate a message to one or more other users when the athletic activity data indicates that the first user has completed an activity objective;receive, during the athletic activity and from a computing device, communication data including one or more congratulatory notifications from the one or more other users;in response to receiving the communication data, communicate, to the first user and via the user interface, the one or more congratulatory notifications, wherein the one or more congratulatory notifications are delayed until the athletic activity data indicates that the first user has completed the athletic activity and until the athletic activity data indicates that a heart rate of the first user is below a threshold value; andin response to receiving the communication data and in response to detection, by the sensor, of the first user being at a goal location, send an acknowledgement message to the one or more other users.","21","15/609871","2017-05-31","2017-0262698","2017-09-14","10474885","2019-11-12","NIKE, INC.","Michael T.  Hoffman | Kwamina  Crankson | Jason  Nims | Michael Levi  Orenstein | Kristen Laina  White","","","","G06K-0009/00342","G06K-0009/00342 | A61B-0005/0002 | A61B-0005/1118 | G01C-0021/20 | G01C-0022/006 | G06F-0001/1698 | G06F-0019/3481 | G06Q-0050/01 | A61B-0005/6807 | A61B-0005/6895 | A61B-0005/742 | Y02A-0090/26","A63B-071/00","A63B-071/00 | G06K-009/00 | A61B-005/11 | G01C-021/20 | G01C-022/00 | G06F-001/16 | G06F-019/00 | G06Q-050/00 | A61B-005/00","","","","","","4919046005338"
"US","US","P","B2","Medication adherence monitoring system and method","A medication management system is described that is operable to determine whether a user is actually following a protocol, provide additional assistance to a user, starting with instructions, video instructions, and the like, and moving up to contact from a medication administrator if it is determined that the user would need such assistance in any medical adherence situation, including clinical trial settings, home care settings, healthcare administration locations, such as nursing homes, clinics, hospitals and the like. Suspicious activity on the part of a patient or other user of the system is identified and can be noted to a healthcare provider or other service provider where appropriate.","1. A display and image capture apparatus for monitoring medication adherence of a user, comprising: an image capture device for capturing one or more video sequences associated with at least intake of medication into the user'ss body;a computer processor arranged to receive the captured one or more video sequences, and to determine, based at least in part on the captured one or more video sequences, whether the user has properly performed a predetermined portion of a predetermined process representative of at least intake of the medication into the user'ss body;a presentation device arranged to present visually to the user one or more instructions encouraging proper performance of the predetermined portion of the predetermined process representative of at least intake of the medication into the user'ss body if the computer processor has determined that the user has not properly performed the predetermined portion of the predetermined process, and arranged to present visually an acknowledgment of proper performance of the predetermined portion of the predetermined process representative of intake of the medication into the user'ss body if the computer processor has determined that the user has properly performed the predetermined portion of the predetermined process.","29","15/985285","2018-05-21","2018-0374565","2018-12-27","10475533","2019-11-12","AIC INNOVATIONS GROUP, INC.","Adam  Hanina | Gordon  Kessler | Lei  Guan","","","","G16H-0020/10","G16H-0020/10 | A61B-0005/0022 | A61B-0005/1128 | A61B-0005/4833 | G06F-0019/00 | G06F-0019/3456 | G06K-0009/00 | G06K-0009/00771 | G06Q-0050/22 | G16H-0020/13 | H04N-0007/183","G16H-020/10","G16H-020/10 | G06F-019/00 | G06K-009/00 | G06Q-050/22 | A61B-005/11 | A61B-005/00 | G16H-020/13 | H04N-007/18","","","","","","4919046005984"
"US","US","P","B2","System and method for using performance signatures","A system and method for using performance signatures can include generating a set of performance features during an activity of the first participant by collecting kinematic data from at least one inertial measurement unit and generating a set of biomechanical signals; combining the set of performance features into the performance signature; generating at least a second performance signature from a set of participants; comparing the performance signature of the first participant to at least the second performance signature; and applying a result of the comparison to an interaction with at least one participant.","1. A method comprising: for a first participant performing an activity, generating a set of performance features during an activity of the first participant;wherein at least a subset of the performance features are generated by: collecting kinematic data from at least one inertial measurement unit that is attached to a body portion of the first participant, andgenerating a set of biomechanical signals that are, at least in part, based on the kinematic data, wherein the set of biomechanical signals comprises a first plurality of biomechanical signals, wherein each biomechanical signal quantifies at least a portion of a motion executed during the activity of the first participant, wherein the biomechanical signals are ground contact time, braking, pelvic rotation, pelvic tilt, pelvic drop, vertical oscillation of the pelvis, and forward velocity properties of the pelvis;combining the set of performance features into a first performance signature;comparing the first performance signature to at least a second performance signature of a second participant engaged in the same activity as the first participant, wherein the second performance signature comprises a second plurality of biomechanical signals, wherein each biomechanical signal of the second plurality of biomechanical signals quantifies at least a portion of a motion being executed during the activity of the second participant; andproviding a training recommendation to the first participant based on the comparing, wherein the training recommendation specifies one or more of the biomechanical signals the first participant is required to change to more approximately emulate the second performance signature of the second participant.","20","15/388670","2016-12-22","2017-0182360","2017-06-29","10463909","2019-11-05","LUMO LLC","Andrew Robert  Chang | Chung-Che Charles  Wang","","","","A63B-0022/0605","A63B-0022/0605 | A61B-0005/1118 | A63B-0021/06 | A63B-0022/025 | G06F-0007/02 | G06F-0021/32 | G06K-0009/00342 | H04L-0063/0861 | A61B-2503/10 | A63B-0022/0242 | A63B-0022/04 | A63B-0022/0664 | A63B-0024/0087 | A63B-0069/00 | A63B-0069/002 | A63B-0069/0002 | A63B-0069/0022 | A63B-0069/0024 | A63B-0069/0028 | A63B-0069/0071 | A63B-0069/06 | A63B-0069/16 | A63B-0069/18 | A63B-0069/3608 | A63B-0069/38 | A63B-0071/0622 | A63B-2024/0009 | A63B-2024/0015 | A63B-2024/0093 | A63B-2069/0008 | A63B-2071/0625 | A63B-2071/0655 | A63B-2220/10 | A63B-2220/12 | A63B-2220/17 | A63B-2220/18 | A63B-2220/20 | A63B-2220/30 | A63B-2220/34 | A63B-2220/40 | A63B-2220/53 | A63B-2220/70 | A63B-2220/73 | A63B-2220/75 | A63B-2220/76 | A63B-2220/78 | A63B-2220/803 | A63B-2220/806 | A63B-2220/807 | A63B-2220/833 | A63B-2220/836 | A63B-2225/50 | A63B-2244/09","A63B-022/06","A63B-022/06 | G06F-007/02 | H04L-029/06 | G06F-021/32 | A63B-021/06 | A63B-022/02 | A61B-005/11 | G06K-009/00 | A63B-071/06 | A63B-069/00 | A63B-069/16 | A63B-069/36 | A63B-069/18 | A63B-069/06 | A63B-069/38 | A63B-022/04 | A63B-024/00","","","","","","4919045001827"
"US","US","P","B2","Eye movement detecting device, electronic device and system","According to one embodiment, an eye movement detecting device comprises first, second, third, fourth and fifth electrodes. A line connecting the first and the third electrodes passes through the right eye and a line connecting the second and the fourth electrodes passes through the left eye on at least one of a front view, a plan view or a side view. A distance between the fifth and the first electrodes is equal to a distance between the fifth and the second electrodes. A distance between the fifth and the third electrodes is equal to a distance between the fifth and the fourth electrodes. The detector respectively detects a horizontal movement of the right eye and a horizontal movement of the left eye.","1. An eye movement detecting device comprising: a first electrode on a right of a right eye, a second electrode on a left of a left eye, a third electrode on a left of the right eye, a fourth electrode on a right of the left eye and a fifth electrode, which are contactable with a head, whereina line connecting the first electrode and the third electrode passes through the right eye and a line connecting the second electrode and the fourth electrode passes through the left eye on at least one of a front view, a plan view or a side view;a distance between the fifth electrode and the first electrode is equal to a distance between the fifth electrode and the second electrode;a distance between the fifth electrode and the third electrode is equal to a distance between the fifth electrode and the fourth electrode;the eye movement detecting device further comprises: a first detector which detects a first eye potential based at least in part on a difference between a signal from the first electrode and a signal from the second electrode with a signal from the fifth electrode as a reference;a second detector which detects a second eye potential based at least in part on a difference between the signal from the first electrode and a signal from the third electrode with the signal from the fifth electrode as a reference;a third detector which detects a third eye potential based at least in part on a difference between the signal from the second electrode and a signal from the fourth electrode with the signal from the fifth electrode as a reference; anda fourth detector which detects a horizontal movement of the right eye and a horizontal movement of the left eye based at least in part on the first eye potential, the second eye potential and the third eye potential.","20","16/004851","2018-06-11","2019-0286226","2019-09-19","10466781","2019-11-05","KABUSHIKI KAISHA TOSHIBA","Hiroaki  Komaki","2018-051471","JP","2018-03-19","G06F-0003/013","G06F-0003/013 | A61B-0005/0496 | H04N-0013/344 | A61B-2562/0209 | G02B-0027/0172 | G02B-2027/0134 | G02B-2027/0178 | G06Q-0010/087","G06F-003/01","G06F-003/01 | A61B-005/0496 | H04N-013/344 | G06Q-010/08 | G02B-027/01","","","","","","4919045004676"
"US","US","P","B2","System and method for motion detection using a PPG sensor","A photoplethysmography (PPG) circuit obtains PPG signals at one or more wavelengths. The PPG signal is processed to identify motion artifacts. The motion artifacts are correlated with predetermined PPG signal patterns associated with a movement of a body part. The PPG signals may thus be used to detect movement of the body part. A user device may be controlled in response to the detected movement of the body part.","1. A biosensor, comprising: a sensor configured for positioning over an area of tissue of a user and configured to obtain a photoplethysmography (PPG) signal, wherein the PPG signal includes a spectral response around a first wavelength of light detected from the area of the tissue of the user, and wherein a distance between the sensor and the area of the tissue remains relatively constant;a processing device configured to: process the PPG signal at the first wavelength detected over the area of the tissue of the user to identify a first motion artifact at a first time interval; andprocess the PPG signal at the first wavelength detected over the same area of the tissue of the user to identify a second motion artifact at a second time interval, wherein the first and second motion artifacts reflect changes in blood flow through vessels in the area of the tissue;correlate the first motion artifact in the PPG signal to a first predetermined PPG signal pattern, wherein the first PPG signal pattern reflects changes in blood flow through vessels in the area of the tissue at the first time interval;correlate the second motion artifact in the PPG signal to a second predetermined PPG signal pattern, wherein the second PPG signal pattern reflects changes in blood flow through vessels in the same area of the tissue at the second time interval;obtain first motion data for a first moving body part associated with the first predetermined PPG signal pattern, wherein the first motion data includes a direction of movement of the first moving body part and a speed of the movement of the first moving body part;obtain second motion data for a second moving body part associated with the second predetermined PPG signal pattern, wherein the second motion data includes a direction of movement of the second moving body part and a speed of the movement of the second moving body part and wherein the first moving body part and the second moving body part are different than a body part of the area of tissue of the user; andcontrol operation of a device in response to the first motion data or the second motion data.","30","16/103876","2018-08-14","2019-0286233","2019-09-19","10466783","2019-11-05","SANMINA CORPORATION","Robert  Newberry","","","","G06F-0003/014","G06F-0003/014 | A61B-0005/0075 | A61B-0005/0488 | A61B-0005/6825 | A61B-0005/725 | A61B-0005/7475 | G06F-0003/015 | G06F-0003/017 | G06F-0003/0304 | G06K-0009/00355 | G06F-0001/163","G06F-003/01","G06F-003/01 | G06F-003/03 | G06K-009/00 | A61B-005/0488 | A61B-005/00 | G06F-001/16","","","","","","4919045004678"
"US","US","P","B2","Finger-worn device with compliant textile regions","A wearable device includes: at least one compliant region adapted and configured to be placed over a joint of a subject and at least two flexible but less compliant regions coupled to opposite ends of the compliant region. The device provides a wearable robotic device including a wearable and at least one actuator adapted and configured to move the flexible but less compliant regions relative to each other.","1. A wearable device comprising: at least one compliant textile region adapted and configured to be placed over a joint of a subject; andat least two flexible but less compliant textile regions coupled to opposite ends of the compliant region located on either side of the joint and encircling the joint;wherein the joint is a finger joint.","14","16/188386","2018-11-13","2019-0101983","2019-04-04","10466784","2019-11-05","DREXEL UNIVERSITY","Andrew  Cohen | Genevieve  Dion | Mark  Winter | Eric  Wait | Michael  Koerner","","","","G06F-0003/014","G06F-0003/014 | A61B-0005/0022 | A61B-0005/225 | A61B-0005/6806 | A61F-0002/583 | A61F-0005/0102 | A61F-0005/013 | A61H-0001/0288 | B25J-0013/025 | G06F-0003/016","A61F-005/01","A61F-005/01 | A61B-005/00 | A61H-001/02 | G06F-003/01 | B25J-013/02 | A61B-005/22 | A61F-002/58","","","","","","4919045004679"
"US","US","P","B2","System and method for providing assistance in surgery in presence of tissue deformation","Various aspects of a system and a method to provide assistance in a surgery in presence of tissue deformation are disclosed herein. In accordance with an embodiment, the system includes an electronic device that receives one or more tissue material properties of a plurality of surface structures of an anatomical portion. One or more boundary conditions associated with the anatomical portion may also be received. Surface displacement of the anatomical portion may be determined by matching a first surface of the anatomical portion before deformation with a corresponding second surface of the anatomical portion after the deformation. The volume displacement field of the anatomical portion may be computed based on the determined surface displacement, the received one or more tissue material properties, and the received one or more boundary conditions.","1. A system for surgery assistance, said system comprising: one or more circuits in an electronic device configured to: receive information related to at least one tissue material property of a plurality of surface structures of an anatomical portion;receive at least one boundary condition associated with a propensity of deformation of said plurality of surface structures of said anatomical portion;match a first surface of said anatomical portion before said deformation of said plurality of surface structures of said anatomical portion directly with a corresponding second surface of said anatomical portion after said deformation;determine surface displacement of said anatomical portion based on said match of said first surface with said corresponding second surface;compute volume displacement field of said anatomical portion based on said determined surface displacement, said received information, and said received at least one boundary condition; andapply said computed volume displacement to at least one of said plurality of surface structures for compensation of said deformation in a graphical view of said anatomical portion.","23","15/049870","2016-02-22","2017-0243344","2017-08-24","10467497","2019-11-05","SONY CORPORATION","Liangyin  Yu | Bi  Song | Ming-Chang  Liu","","","","G06K-0009/6201","G06K-0009/6201 | A61B-0005/0042 | A61B-0005/0044 | A61B-0005/055 | A61B-0008/0808 | A61B-0090/37 | G06F-0017/50 | G06T-0003/0081 | G06T-0007/0012 | G06T-0007/33 | A61B-0005/0077 | A61B-2090/374 | A61B-2090/3762 | A61B-2505/05 | A61B-2576/026 | G06T-2207/10012 | G06T-2207/10028 | G06T-2207/10088 | G06T-2207/30016","G06K-009/62","G06K-009/62 | A61B-005/055 | A61B-005/00 | A61B-090/00 | G06T-007/33 | G06T-003/00 | G06F-017/50 | A61B-008/08 | G06T-007/00","","","","","","4919045005390"
"US","US","P","B2","Method for clearing of virtual representations of objects","A method for clearing unwanted data from optically detected virtual representations of objects includes: a. Defining an extension line of the representation; b. Generating a projection plane at one point of the extension line, which is perpendicular to the generated projection plane; c. Projecting all known points in space of the representation from one region on the projection plane onto the projection plane, the corresponding point in space being stored for each projected point; d. Generating a two-dimensional curve on the projection plane; e. Determining maxima, minima and a center of the curve; f. Identifying projected points of the curve that?viewed from the center of the curve?lie outside of the minima or maxima; g. Removing the points in space that correspond to the projected points that were identified in step f.; and h. Optionally, repeating starting from step b. for one further point of the extension line.","1. Method for clearing, in particular for removing, unwanted data from optically detected virtual representations of objects, in particular teeth and intraoral structures, the method comprising: a. Defining an extension line of the representation,b. Generating a projection plane at one point of the extension line, the extension line at this point being perpendicular to the generated projection plane,c. Projecting all known points in space of the representation from one region corresponding to the projection plane onto the projection plane, the corresponding point in space being stored for each projected point,d. Generating a two-dimensional curve on the projection plane from the projected points,e. Determining maxima, minima and a center of the curve,f. Identifying projected points of the curve that?viewed from the center of the curve?lie outside of the minima or maxima,g. Removing the points in space that correspond to the projected points that were identified in f.,h. Optionally, repeating starting from b. for one further point of the extension line.","20","15/783251","2017-10-13","2018-0104029","2018-04-19","10456225","2019-10-29","A.TRON3D GMBH","Juergen  Jesenko | Engelbert  Kelz","2016-193819","EP","2016-10-13","A61C-0013/0004","A61C-0013/0004 | A61B-0005/0088 | A61B-0005/055 | A61C-0009/004 | A61C-0019/04 | G06K-0009/34 | G06T-0007/11 | G06T-0019/20 | H04N-0013/167 | A61C-0009/0053 | G06F-0017/50 | G06T-2200/04 | G06T-2207/10028 | G06T-2207/30036 | G06T-2219/2021 | H04N-0005/7416","A61B-005/055","A61B-005/055 | A61C-019/04 | G06T-019/20 | A61C-013/00 | H04N-013/167 | A61B-005/00 | A61C-009/00 | G06K-009/34 | G06T-007/11 | G06F-017/50 | H04N-005/74","","","","","","4919044001310"
"US","US","P","B2","Methods and systems for generating a three dimensional representation of a human body shape","In a method of generating a three dimensional representation of a human body shape from a depth image of a clothed human subject is disclosed. The method comprises identifying at least one sample from a plurality of pre-calculated representative samples, each pre-calculated representative sample comprising a three dimensional representation of a human body shape and a corresponding depth map, by comparing the depth maps of the pre-calculated representative samples with the depth image of the clothed human subject; determining a neighbourhood of the data space of possible depth images of unclothed human body shapes from the depth map of the at least one representative sample; generating a parametric model for the human body shape from a neighbourhood of the data space of human body shapes, the neighbourhood of the data space of human body shapes corresponding to the neighbourhood of the data space of possible depth images of unclothed human body shapes; and generating the three dimensional representation of the human body shape by fitting the parametric model to the depth image of the clothed human subject.","1. A method of generating a three dimensional representation of a human body shape from a depth image of a clothed human subject, the method comprising: identifying at least one representative sample from a plurality of pre-calculated representative samples, each pre-calculated representative sample comprising a three dimensional representation of a human body shape and a corresponding depth map, by comparing depth maps of the pre-calculated representative samples with the depth image of the clothed human subject, the depth maps corresponding to unclothed human body shapes;determining a neighbourhood of first data space of possible depth images of unclothed human body shapes from the depth map of the at least one representative sample;generating a parametric model for the human body shape from a neighbourhood of second data space of human body shapes, the neighbourhood of the second data space of human body shapes corresponding to the neighbourhood of the first data space of possible depth images of the unclothed human body shapes; andgenerating the three dimensional representation of the human body shape by fitting the parametric model to the depth image of the clothed human subject.","18","15/117735","2014-06-19","2017-0147874","2017-05-25","10460158","2019-10-29","KABUSHIKI KAISHA TOSHIBA","Frank  Perbet | Minh-Tri  Pham | Bjorn  Stenger | Sam  Johnson","","","","G06K-0009/00362","G06K-0009/00362 | A61B-0005/1077 | A61B-0005/1079 | G06K-0009/00201 | G06K-0009/6202 | G06Q-0030/0643 | G06T-0017/10 | H04N-0013/204 | A61B-0005/107","G06K-009/00","G06K-009/00 | G06Q-030/06 | H04N-013/204 | A61B-005/107 | G06K-009/62 | G06T-017/10","","","","","","4919044005212"
"US","US","P","B2","Biometric authentication device and system","A biometric authentication device including a housing, a light source unit that is installed on an upper surface of the housing and includes a light source, and an opening that is provided in the upper surface of the housing and located below the light source, and an imaging unit that is disposed inside the housing is disclosed. In the device, an optical axis of the light source intersects with a longitudinal direction of the housing, and the imaging unit images a user's biometric feature irradiated with an irradiation light from the light source through the opening.","1. A biometric authentication device comprising: a housing having a front side surface, a rear side surface, a passage side surface and an upper surface;a light source array that is installed on the upper surface of the housing and includes a plurality of light sources;an opening that is provided in the upper surface of the housing and located between the light source array and an intersection of the front side surface and the upper surface;an infrared camera that is disposed inside the housing below the opening in the upper surface; anda processor, whereinan optical axis of a majority of the light sources intersects with the upper surface of the housing at an angle less than 90 degrees,a plane formed by the light source array intersects with the passage side surface of the housing at an angle of less than 90 degrees, andthe processor is programmed to perform authentication of a biometric feature of a user irradiated with an irradiation light from the light sources and imaged by the infrared camera through the opening.","8","15/756289","2015-12-18","2018-0247142","2018-08-30","10460187","2019-10-29","HITACHI, LTD.","Masaru  Oda | Akira  Omachi | Yoshihiro  Iwama | Yusuke  Daimon | Daisuke  Matsubara | Hiroko  Hasebe | Akio  Nagasaka | Yusuke  Matsuda | Naoto  Miura","","","","G06K-0009/00885","G06K-0009/00885 | A61B-0005/0077 | G01B-0011/24 | G06F-0016/583 | G06F-0021/32 | G06K-0009/00033 | G06K-0009/00919 | G06K-0009/2027 | G06T-0007/0002 | G07C-0009/00158 | H04L-0063/0861 | G06K-0009/00375 | G06K-2009/00932 | G06T-2207/10004","G06K-009/00","G06K-009/00 | G07C-009/00 | G06F-016/583 | G01B-011/24 | G06F-021/32 | A61B-005/00 | G06T-007/00 | H04L-029/06 | G06K-009/20","","","","","","4919044005241"
"US","US","P","B2","Trachea marking","Disclosed are systems, devices, and methods for marking a main carina and a trachea of a patient, an exemplary method comprising importing slice images of a chest of the patient, generating a three-dimensional (3D) model based on the imported slice images, displaying the 3D model in a graphical user interface (GUI), locating the main carina by viewing 2D images of the 3D model in an axial orientation, marking the main carina in one of the 2D images of the 3D model, adjusting a view plane of the 3D model around a rotation axis defined by the marked location of the main carina to adjust the view plane from an axial orientation to a coronal orientation while keeping the main carina in the view plane to thereby display the entire trachea on the GUI, and marking an upper end of the trachea in one of the 2D images of the 3D model.","1. A non-transitory computer-readable storage medium storing instructions for marking a trachea of a patient, the instructions, when executed by a processor, cause a computing device to: generate a three-dimensional (3D) model based on a plurality of two-dimensional (2D) images of the patient;receive, via a graphical user interface (GUI), a first mark at a main carina in one of the plurality of two-dimensional (2D) images of the patient;adjust a view plane of the three-dimensional (3D) model around a rotation axis defined by the first mark; andreceive, via the GUI, a second mark at an upper end of the trachea in one of the plurality of 2D images of the patient.","12","16/112105","2018-08-24","2018-0365832","2018-12-20","10460441","2019-10-29","COVIDIEN LP","Elad D.  Lachmanovich | Evgeni  Kopel | Eyal  Klein","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/0033 | G06F-0003/04815 | G06T-0017/00 | G06T-0019/00 | G06T-2200/24 | G06T-2210/41 | G06T-2219/008","G06T-015/00","G06T-015/00 | G06T-007/00 | G06F-003/0481 | G06T-017/00 | G06T-019/00 | A61B-005/00","","","","","","4919044005493"
"US","US","P","B2","Method for estimating the fat mass of a subject through digital images","A method for determining the fat mass of a subject includes the steps of acquiring an image of the subject through a digital device, and generating a virtual frame that contains at least in part that image. The virtual frame contains the subject, on the basis of its height or of the greater size in the case of animals, to provide an estimation of the content of the fat mass through an algorithm on the basis of at least an indicative index of the area occupied by the subject with respect to the area of the frame in which it is contained at least in part.","1. A method for determining fat mass of a subject comprising the steps of: acquiring at least one image containing a background and a subject (2) through a digital device (1);inputting at least a height value of the subject;generating, within the at least one image, a virtual frame (A, A′, B′, B) that contains at least a part of said subject (2) in the image, the virtual frame (A, A′, B′, B) being generated with two horizontal parallel lines (A-A′, B-B′) to which a value of a distance therebetween is attributed based on the inputted height (h) value of the subject, and with two vertical lines (A-B, A′-B′) to which a value of distance therebetween is attributed also based on a fraction of the height (h) value of the subject,wherein the virtual frame (A, A′, B, B′) is generated through the digital device that acquires the image, wherein the horizontal lines are translatable, andwherein, independently from a value of translation of the horizontal lines, a value of a distance between the horizontal lines remains fixed as a reference height (h) value of the subject;defining an outer profile of the at least a part of said subject, said outer profile delimiting a first area (A_1), the virtual frame delimiting a second area (B_1); anddetermining a content of fat mass through an algorithm that uses at least one index which is indicative of the first area (A_1) occupied by the at least a part of the subject (2) in the virtual frame with respect to the second area (B_1) of the virtual frame.","12","15/571842","2016-03-01","2018-0300883","2018-10-18","10460450","2019-10-29","Antonio Talluri","Antonio  Talluri","2015-425037","EP","2015-05-26","G06T-0007/194","G06T-0007/194 | A61B-0005/0077 | A61B-0005/4872 | G06T-0007/0012 | G06T-0007/62 | G06T-0007/90 | G06T-0011/60 | G16H-0030/40 | H04N-0005/2621 | A61B-2560/0487 | G06T-2207/30196 | H04L-0067/10","G06T-007/194","G06T-007/194 | H04N-005/262 | G06T-011/60 | G06T-007/90 | G16H-030/40 | G06T-007/62 | A61B-005/00 | G06T-007/00 | H04L-029/08","","","","","","4919044005502"
"US","US","P","B2","Apparatus and method of implantable bidirectional wireless neural recording and stimulation","A device and method is described for electronic human prosthetics, and specifically a skull- and/or spine implantable bi-directional neural-communication/brain-machine interface (BBMI) device where the input, output and on-board computing are combined into a single unit to form a compact neuro-prosthetics device. This invention is also directed to a fully implantable wireless spinal electronic recording and stimulation system using the BBMI in a human. The bi-directional devices (BBMIs) communicate with other bi-directional brain-machine interface devices (BBMI) and/or with external controllers wirelessly. The compact implantable stimulator has ultrasonic secondary battery charging system. One or more BBMI can be wirelessly connected so that a closed loop of BBMIs, or a BBMI and an external controller, can wirelessly send trigger pulses to this fully implanted stimulator over the spinal cord.","1. A bi-directional brain-machine interface (BBMI) device, comprising: a biocompatible container housing an ultrasonic wireless power module, said power module comprises a piezoelectric composite transducer connected to a power rectifier circuit, and a rechargeable battery, wherein the piezoelectric composite transducer forms an internal part of a wireless two-part ultrasonic power transmission system having an external piezoelectric composite transducer paired with the internal part for wirelessly transferring power to recharge the rechargeable battery;a wireless RF communication System on Chip (SoC) within the housing, said SoC having a processor core and powered by the power module, said processor core configured to control wireless data transmission and reception, said processor core configured to control charging of the rechargeable battery, said processor core configured to acquire sensor output data, said processor core configured to control stimulation input pulses, and said SoC configured to use low-power near field wireless communication;a sensor electronics module that interfaces with the SoC and comprises a digital electro-physiology interface chip, a programmable amplifier, and analog to digital converter, wherein the sensor electronics module is configured to record at least 16 channels of neural tissue activity;a stimulation module that interfaces with the SoC and comprises a pulse circuit configured to transmit electrical stimuli, wherein the pulse circuit is configured to generate at least 4 channels of stimulation; and,a bidirectional microelectrode array that interfaces with the sensor electronics module and the stimulation module, wherein the bidirectional microelectrode array is configured to provide a bidirectional interface to record neural tissue activity and transmit electrical stimuli.","38","15/295988","2016-10-17","2017-0108926","2017-04-20","10452143","2019-10-22","SAN DIEGO STATE UNIVERSITY RESEARCH FOUNDATION | ELECTRONICS AND TELECOMMUNICATION RESEARCH INSTITUTE","Kee S.  Moon | Yusuf  Ozturk | Sung Q.  Lee | Woosub  Youm | Gunn  Hwang","","","","G06F-0003/015","G06F-0003/015 | A61B-0005/0031 | A61B-0005/04001 | A61B-0005/048 | A61B-0005/0478 | A61B-0005/4064 | A61B-0005/4836 | A61N-0001/0529 | A61N-0001/0551 | A61N-0001/36103 | A61N-0001/375 | A61B-0005/0024 | A61B-2560/0219 | A61N-0001/36082","A61N-001/05","A61N-001/05 | G06F-003/01 | A61N-001/375 | A61B-005/00 | A61B-005/04 | A61B-005/0478 | A61B-005/048 | A61N-001/36","","","","","","4919043004391"
"US","US","P","B2","Image handling and display in X-ray mammography and tomosynthesis","A method and system for acquiring, processing, storing, and displaying x-ray mammograms Mp tomosynthesis images Tr representative of breast slices, and x-ray tomosynthesis projection images Tp taken at different angles to a breast, where the Tr images are reconstructed from Tp images.","1. A method of acquiring and displaying x-ray images comprising: acquiring x-ray tomosynthesis image Tp data representative of projection images taken at different angles of an origin or imaging x-rays relative to a compressed breast, from an acquisition unit configured to selectively acquire the tomosynthesis image Tp data;reconstructing at least a subset of the acquired tomosynthesis image Tp data into reconstructed tomosynthesis image Tr data representative of images of slices of the compressed breast that have selected orientations and thicknesses; andapplying computer aided detection (CAD) algorithms to at least one of the acquired tomosynthesis image Tp data and the reconstructed tomosynthesis image Tr data to detect a suspected abnormality in the breast.","20","16/127570","2018-09-11","2019-0095087","2019-03-28","10452252","2019-10-22","HOLOGIC, INC.","Nikolaos A.  Gkanatsios | Loren  Niklason | Ian  Shaw | Christopher  Ruth | Andrew P.  Smith | Jay A.  Stein","","","","G06F-0003/04847","G06F-0003/04847 | A61B-0005/0048 | A61B-0006/025 | A61B-0006/463 | A61B-0006/464 | A61B-0006/465 | A61B-0006/466 | A61B-0006/502 | A61B-0006/5235 | A61B-0006/563 | G06T-0007/0012 | G06T-0011/003 | G06T-0011/006 | A61B-0005/7232 | G06T-2207/10016 | G06T-2207/10112 | G06T-2207/10116 | G06T-2207/20104 | G06T-2207/20108 | G06T-2207/20212 | G06T-2207/30068","G06F-003/0484","G06F-003/0484 | A61B-005/00 | A61B-006/02 | A61B-006/00 | G06T-007/00 | G06T-011/00","","","","","","4919043004499"
"US","US","P","B2","System, method, and apparatus for electronic patient care","A system for electronic patient care includes a hub. The hub is configured to monitor a patient-care device. The sandbox may be configured to control access to at least one of a hardware resource and a software resource. The hub is further configured to identify the patient-care device and execute an application to monitor the patient-care device. The hub executes the application within the sandbox component such that the application accesses the at least one of the hardware resource and the software resource through the sandbox component. The hub may be further configured to control the patient-care device. The hub may be further configured to receive an identification from the patient-care device and download the application from a server associated with the identification. The hub may be further configured to receive an identification from the patient-care device and update the application from a server associated with the identification.","1. A system for electronic patient care, the system comprising: a hub configured to monitor a plurality of patient-care devices, the hub comprising: an operating system component configured to access at least one of a hardware resource of the hub and a software resource of the hub;a sandbox component configured to control the access to the at least one of the hardware resource and the software resource, wherein the sandbox component is configured to manage the execution of a plurality of applications, wherein the plurality of applications includes at least two applications to each monitor different patient-care devices of the plurality of patient-care devices and an application to monitor a sensor; anda dock configured to receive at least a first and second of the different patient-care devices of the plurality of patient-care devices and enable communication via a wired connection, wherein the at least first and second patient-care devices treat a single patient;a wearable system monitor; anda wearable dock configured to be worn by the patient and releasably couple to the wearable system monitor, wherein the wearable dock is configured to identify a caregiver, wherein the wearable system monitor is configured to: start a timer when the wearable system monitor is uncoupled from the wearable dock,stop treatment by a third patient-care device separate from the wearable system monitor and wearable dock after a predetermined amount of time has elapsed after the timer is started,pair, upon a determination that the identified caregiver is an authorized caregiver, the wearable system monitor with a fourth patient-care device while uncoupled from the wearable dock,recouple with the wearable dock,identify and authenticate the wearable dock, andresume treatment of the third patient-care device after the wearable system monitor is recoupled to the wearable dock, the wearable dock is identified by the wearable system monitor, and the wearable dock is authenticated by the wearable system monitor,wherein: the hub is further configured to identify the different patient-care devices and execute the at least two applications to monitor the different patient-care devices, respectively,the hub executes the at least two applications to monitor the different patient-care devices within the sandbox component such that the at least two applications access the at least one of the hardware resource and the software resource through the sandbox component,the hub is further configured to monitor the plurality of applications to determine whether a monitored one of the plurality of applications is attempting to violate a locally-stored Drug Error Reduction System (""DERS"") rule and prevent the at least two monitored applications from performing the violation of the rule, andthe sandbox component is configured to: receive multiple requests to set an alarm condition from multiple applications of the plurality of applications,prioritize the alarm requests,display on a user interface a prioritized list of the prioritized alarm requests,receive a user selection of an alarm request within the list of the prioritized alarm requests, anddisable the user selected alarm request.","32","13/333574","2011-12-21","2012-0185267","2012-07-19","10453157","2019-10-22","DEKA PRODUCTS LIMITED PARTNERSHIP","Dean  Kamen | John J.  Biasi | Jacob W.  Scarpaci | John M.  Kerwin | James G.  Turner | Todd A.  Ballantyne","","","","G06Q-0050/22","G06Q-0050/22 | A61B-0005/0024 | A61M-0005/142 | A61M-0005/1413 | A61M-0005/1415 | A61M-0005/1417 | A61M-0005/16827 | G06F-0019/3418 | G06F-0019/3468 | A61M-2205/3553 | A61M-2205/3561 | A61M-2205/3569 | A61M-2205/3584 | A61M-2205/6009 | G06F-2009/45587","G06Q-050/22","G06Q-050/22 | A61B-005/00 | A61M-005/168 | G06F-009/455 | G06F-019/00 | A61M-005/14 | A61M-005/142","","","","","","4919043005392"
"US","US","P","B2","Apparatus having a digital infrared sensor","An apparatus that senses temperature from a digital infrared sensor is described. A digital signal representing a temperature without conversion from analog is transmitted from the digital infrared sensor received by a microprocessor and converted to body core temperature by the microprocessor.","1. A device comprising: a first circuit board including: a microprocessor;a battery that is operably coupled to the microprocessor;a display device that is operably coupled to the microprocessor;a first digital interface that is operably coupled to the microprocessor;a second circuit board including: a second digital interface, the second digital interface being that is operably coupled to the first digital interface; anda digital infrared sensor that is operable to receive an infrared signal, the digital infrared sensor also being operably coupled to the second digital interface, the digital infrared sensor having ports that provide digital readout signals that are representative of the infrared signal that is received by the digital infrared sensor,wherein the microprocessor is operable to receive from the ports of the digital infrared sensor the digital readout signals that are representative of the infrared signal and the microprocessor is operable to determine a temperature from the digital readout signals that are representative of the infrared signal, andwherein no analog-to-digital converter is operably coupled between the digital infrared sensor and the microprocessor.","20","16/127182","2018-09-10","2019-0005642","2019-01-03","10453194","2019-10-22","ARC DEVICES LTD.","Martin  Crawley | Michael G.  Smith | Irwin  Gross | Mark  Khachaturian | Steven  Gerst | John  Barrett | Michael  Cronin | Derek  Turnbull","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/0008 | A61B-0005/0013 | A61B-0005/0059 | A61B-0005/0064 | A61B-0005/0075 | A61B-0005/0077 | A61B-0005/01 | A61B-0005/015 | A61B-0005/02055 | A61B-0005/0261 | A61B-0005/0402 | A61B-0005/1455 | A61B-0005/14551 | A61B-0005/14552 | A61B-0005/441 | A61B-0005/6898 | A61B-0005/725 | A61B-0005/7225 | A61B-0005/7257 | A61B-0005/7264 | A61B-0005/7267 | A61B-0005/7275 | A61B-0005/7278 | A61B-0005/742 | A61B-0005/743 | A61B-0005/7425 | G01J-0005/0025 | G01J-0005/025 | G01J-0005/0893 | G01J-0005/30 | G01J-0005/32 | G01K-0001/02 | G01K-0013/004 | G06F-0003/042 | G06F-0019/00 | G06K-0009/00221 | G06K-0009/00241 | G06K-0009/00268 | G06K-0009/00288 | G06K-0009/00456 | G06K-0009/00624 | G06K-0009/00711 | G06K-0009/46 | G06K-0009/4604 | G06K-0009/6218 | G06T-0003/40 | G06T-0005/00 | G06T-0005/10 | G06T-0005/20 | G06T-0007/0016 | G06T-0007/13 | G06T-0007/20 | G06T-0007/90 | G16H-0030/20 | G16H-0040/63 | H04N-0005/33 | H04N-0005/378 | A61B-0005/021 | A61B-0005/024 | A61B-0005/02416 | A61B-0005/02433 | A61B-0005/0816 | A61B-2560/0214 | A61B-2560/0475 | A61B-2576/00 | G01J-2005/0077 | G06K-2009/4666 | G06T-2207/10004 | G06T-2207/10016 | G06T-2207/10024 | G06T-2207/10048 | G06T-2207/20024 | G06T-2207/20076 | G06T-2207/20132 | G06T-2207/30004 | G06T-2207/30088 | G06T-2207/30104 | G06T-2207/30201 | G06T-2210/22","G06K-009/00","G06K-009/00 | G06T-007/00 | G16H-040/63 | A61B-005/026 | G01J-005/32 | G01J-005/02 | G01J-005/08 | G01J-005/00 | A61B-005/00 | A61B-005/01 | G06T-005/20 | A61B-005/0205 | A61B-005/0402 | A61B-005/1455 | G06K-009/46 | G06K-009/62 | G06T-007/20 | G06T-003/40 | G06T-005/10 | G01J-005/30 | H04N-005/33 | G01K-001/02 | G01K-013/00 | G06F-003/042 | H04N-005/378 | G06T-005/00 | G06T-007/13 | G06T-007/90 | G16H-030/20 | G06F-019/00 | A61B-005/021 | A61B-005/024 | A61B-005/08","","","","","","4919043005429"
"US","US","P","B2","Brain image reconstruction apparatus","A brain image reconstruction apparatus can reconstruct a brain image as a sharper image. A brain image reconstruction apparatus has a data acquisition unit that acquires brain activity data of a user; a brain image reconstructor that detects image information from the brain activity data and constructs a brain image; a linguistic information detector that detects linguistic information from the brain activity data; an image database that stores sample images corresponding to the linguistic information; and an image processor that superimposes the sample image with the brain image, and constructs a process image.","1. A brain image reconstruction apparatus comprising: a data acquisition unit that acquires brain activity data of a user;a brain image reconstructor that detects image information from the brain activity data and constructs a brain image;a non-image information detector that detects non-image information from the brain activity data;an image database that stores sample images corresponding to the non-image information; andan image processor that superimposes the sample image with the brain image, and constructs a process image.","9","15/735442","2016-07-29","2018-0168452","2018-06-21","10441172","2019-10-15","SEIKO EPSON CORPORATION","Toshiyuki  Tanaka | Hiroaki  Hosomi","2015-154823","JP","2015-08-05","A61B-0005/0042","A61B-0005/0042 | A61B-0005/0476 | A61B-0005/0484 | A61B-0005/05 | A61B-0005/055 | A61B-0005/16 | A61B-0005/4064 | A61B-0005/7246 | A61B-0005/04009 | A61B-0005/7475 | G06F-0003/01 | G06F-0003/015 | G06T-2207/10088 | G16H-0050/20 | G16H-0050/70","G06K-009/00","G06K-009/00 | A61B-005/00 | A61B-005/0476 | A61B-005/05 | A61B-005/055 | A61B-005/16 | A61B-005/0484 | G06F-003/01 | G16H-050/70 | G16H-050/20 | A61B-005/04","","","","","","4919042001208"
"US","US","P","B1","Biomechanical motion measurement and analysis for self-administered tests","A client device is configured with a test administration application for conducting self-administered tests. A user interface of the test administration application includes motion restriction regions configured to prevent select types of body motion during particular segments of self-administered tests, and testing regions configured to receive a touch input performed by a specific digit of the user. For example, a touch input involves touching, holding, or tapping a single digit within the bounds of a testing region in accordance with instructions provided by the test administration application. The test administration module records motion data comprising one or more touch events, each touch event describing a touch input performed by the user. Undesired touch inputs that may obscure or degrade the reliability of biomechanical data are identified. The test administration module determines whether a user has successfully completed the test in accordance with instructions provided by the test administration application.","1. A computer-implemented method comprising: configuring a touch-sensitive surface of a client device configured to present a self-administered test of biomechanical motor functions of digits of a user, the touch-sensitive surface configured to include a plurality of predetermined motion restriction regions and at least one testing region, wherein: the motion restriction regions are arranged on the touch-sensitive surface to biomechanically isolate a specified digit contacting the testing region when a plurality of other digits of the user are anchored to the motion restriction regions, andlocations of the plurality of motion restriction regions and the at least one testing region are displayed on the touch-sensitive surface;prior to a start of the self-administered test, receiving touch inputs on the touch-sensitive surface in the motion restriction regions indicating that the plurality of other digits of the user are anchored to the plurality of motion restriction regions, and responsive to such inputs, starting the self-administered test;receiving, during the self-administered test, first touch inputs in the testing region;receiving, during the self-administered test, second touch inputs in at least one of the motion restriction regions, and determining from the second touch inputs whether at least one of the plurality of other digits is no longer anchored to at least one of the motion restriction regions; andresponsive to determining that at least one of the plurality of other digits is no longer anchored to at least one of the motion restriction regions, indicating that touch inputs received in the testing region are invalid touch inputs.","16","14/882393","2015-10-13","","","10444980","2019-10-15","THE COGNITIVE HEALTHCARE COMPANY","Shenly  Glenn | Joel  Mefford","","","","G06F-0003/04883","G06F-0003/04883 | A61B-0005/4064 | A61B-0005/4082 | A61B-0005/4088 | A61B-0005/6898 | G06F-0003/0412 | G06F-0003/04886 | G06K-0009/00355 | G16H-0050/30 | G06F-2203/04803 | G06F-2203/04808","G06F-003/041","G06F-003/041 | A61B-005/00 | G06F-003/0488 | G06K-009/00 | G16H-050/30","","","","","","4919042004983"
"US","US","P","B2","Breath ketone measurements system capable of detecting ketone measurement patterns associated with program non-compliance events","A portable system is provided for measuring a ketone, such as an acetone, in the breath or other bodily fluid of a user. The system includes a portable measurement device that analyzes fluid samples and generates corresponding ketone measurements. The portable measurement device communicates with an application which runs on a smartphone or other mobile device of the user. The application tracks, and generates graphs of, the ketone measurements, and may include various features for facilitating the analysis of the measurements.","1. A system for measuring and monitoring ketone levels in a human, comprising: a disposable cartridge configured to receive a breath sample and to react to a ketone in the breath sample;an analysis unit configured to analyze the disposable cartridge after the disposable cartridge receives the breath sample, and to generate a ketone measurement based on the analysis of the disposable cartridge, the analysis unit comprising a wireless transceiver capable of transmitting the ketone measurement to a separate device; anda non-transitory storage medium having stored thereon program instructions that direct a computing system comprising one or more computing devices to perform a process that comprises: receiving a sequence of ketone measurements generated by the analysis unit from respective breath samples of a user;determining whether the sequence of ketone measurements corresponds to a user behavior associated with non-compliance with a behavioral program, wherein determining whether the sequence corresponds to the user behavior comprises comparing the sequence to a ketone pattern associated with the user behavior; andin response to determining that the sequence corresponds to the user behavior, generating a notification of a possible occurrence of the user behavior.","15","15/466287","2017-03-22","2017-0188884","2017-07-06","10433786","2019-10-08","INVOY HOLDINGS, LLC","Lubna M.  Ahmad | Salman A.  Ahmad | Zachary  Smith","","","","A61B-0005/4833","A61B-0005/4833 | A61B-0005/0015 | A61B-0005/0024 | A61B-0005/082 | A61B-0005/083 | A61B-0005/097 | A61B-0005/486 | A61B-0005/4866 | A61B-0005/6898 | A61B-0005/7264 | A61B-0005/7267 | A61B-0005/743 | A61B-0005/7405 | A61B-0005/7475 | G01N-0033/497 | G01N-0033/64 | G06F-0003/0482 | G06F-0003/04842 | G06F-0009/453 | G08B-0021/18 | G08B-0021/182 | H04L-0043/045 | H04W-0004/80 | A61B-2010/0087 | A61B-2560/045 | A61B-2560/0431 | G01N-2033/4975","A61B-005/00","A61B-005/00 | G08B-021/18 | A61B-005/08 | G06F-003/0482 | G06F-003/0484 | G06F-009/451 | H04W-004/80 | G01N-033/64 | G01N-033/497 | H04L-012/26 | A61B-005/083 | A61B-005/097 | A61B-010/00","","","","","","4919041001133"
"US","US","P","B2","Method for configuring an insulin pump with configuring device","An insulin pump is configurable by a configurator. The pump has parameter blocks, each with a respective parameter and an associated restriction setting, and the configurator has an authorization level. Configuring the pump includes receiving, by the configurator, a request to access a parameter on the pump. The method also includes identifying, by the configurator, the parameter block that includes the parameter. Moreover, the method includes retrieving, by the configurator from the pump, the parameter and the associated restriction setting, and comparing, by the configurator, the authorization level of the configurator to the restriction setting. Also, the method includes determining, by the configurator, whether the configurator is authorized to write to the parameter block based on the comparison. Additionally, the method includes writing, by the configurator, to the parameter block on the insulin pump in response to a determination that the configurator is authorized to write to the parameter block.","1. A computer-implemented method of configuring an insulin pump using a pump configuring device, the pump configuring device having a predetermined authorization level, the method comprising: defining a plurality of parameter blocks in a memory device of the insulin pump;storing a plurality of parameters and an associated restriction setting in the plurality of parameter blocks, each of the parameter blocks in the plurality of parameter blocks includes a different parameter and an associated restriction setting;receiving, by the pump configuring device, a request to access a given parameter on the insulin pump;identifying, by the pump configuring device, a given parameter block from the plurality of parameter blocks by querying the insulin pump for a memory location of the given parameter block in the memory device of the insulin pump;retrieving, by the pump configuring device from the insulin pump, the given parameter and the given restriction setting from the given parameter block;comparing, by a processor of the pump configuring device, the authorization level of the pump configuring device to the given restriction setting retrieved from the insulin pump;determining, by the pump configuring device, if the authorization level of the pump configuring device is greater than the given restriction setting retrieved from the insulin pump;performing one of: writing, by the pump configuring device, a new value of the given parameter to the given parameter block in response to the determination that the authorization level of the pump configuring device is greater than the given restriction setting retrieved from the insulin pump; orchanging, by the pump configuring device, a visual attribute of the given parameter on the display in response to the determination that the authorization level of the pump configuring device is less than the given restriction setting retrieved from the insulin pump; anddisplaying, by the pump configuring device, the given parameter on a display.","19","13/726992","2012-12-26","2014-0180241","2014-06-26","10434254","2019-10-08","ROCHE DIABETES CARE, INC.","Erich  Imhof | Guido  Konrad | James R.  Long | Phillip E.  Pash | Robert E.  Reinke","","","","A61M-0005/1723","A61M-0005/1723 | G06F-0019/3468 | G06F-0021/6218 | G06F-2221/2149","G06Q-050/00","G06Q-050/00 | A61M-005/172 | G06F-019/00 | G06F-021/62 | G06Q-010/00","","","","","","4919041001596"
"US","US","P","B2","Display apparatus and controlling method thereof","A display apparatus is disclosed. The display apparatus may include a display configured to operate as at least one of a screen and a mirror, a photographing unit configured to generate a photographed image in which a subject present in a display direction of the display is photographed, and a processor configured to control the display in order for a first area of the display operate as a screen displaying part of the photographed image and a second area other than the first area to operate as a mirror.","1. A display apparatus comprising: a display configured to display a screen when the display is in a display mode and operate as a mirror when the display is in a mirror mode;a camera configured to photograph an image; anda processor configured to: acquire a first image including a subject via the image having been photographed via the camera;in response to a gesture selecting a part of the subject when the display is in a mirror mode, convert a first area of the display from the mirror mode into the display mode while a second area other than the first area is in the mirror mode;control the display to display a second image including the selected part of the subject from the first image on the first area of the display and to display the first image on the second area other than the first area; andswitch the first area from a display mode displaying the second image into a mirror mode to operate as a mirror based on a determination that a distance between a body part of the second image and the display is equal to or greater than a predetermined distance.","18","15/450537","2017-03-06","2018-0091772","2018-03-29","10440319","2019-10-08","SAMSUNG ELECTRONICS CO., LTD.","Ji-youn  Han | Sung-hyun  Jang","","","","H04N-0007/147","H04N-0007/147 | A61B-0005/0077 | A61B-0005/1072 | A61B-0005/1077 | A61B-0005/1079 | A61B-0005/1114 | A61B-0005/1123 | A61B-0005/1128 | A61B-0005/6801 | A61B-0005/6887 | A61B-0005/742 | A61B-0005/7425 | G06F-0003/017 | G06F-0003/0484 | G06K-0009/00362 | G06K-0009/78 | H04N-0005/23293 | A47F-2007/195 | A47G-0001/02 | G06F-2203/04806","H04N-007/14","H04N-007/14 | A61B-005/00 | G06F-003/01 | G06K-009/00 | G06K-009/78 | H04N-005/232 | A61B-005/107 | A61B-005/11 | G06F-003/0484 | A47G-001/02 | A47F-007/19","","","","","","4919041007620"
"US","US","P","B2","Connectors with switchable terminal loads","Switchable grounded terminal loads are built into, or otherwise coupled to, connectors on motherboards and control devices. The terminal loads are coupled to the bus termination at the connector when the connector is ""stuffed"" (connected to a mating connector). The switchable grounded terminal loads replace dummy connectors in preventing empty ""unstuffed"" connectors from increasing error risks on active channels.","1. An apparatus, comprising: a pair of spring-loaded members including a first spring-loaded member, the first spring-loaded member including a compression part at one end, a board contact at another end to be in contact with a baseboard, and a fixed connector contact between the compression part and the board contact; anda stationary member to be in contact with the baseboard, the stationary member including at least one terminal load,the pair of spring-loaded members to expand to an expanded position to admit a detachable mating connector and to exert a compressive restoring force on the detachable mating connector,the pair of spring-loaded members to return to an equilibrium position when the detachable mating connector is not present,wherein, in the equilibrium position, the fixed connector contact of the first spring-loaded member is in contact with the stationary member including the at least one terminal load, andwherein, in the expanded position, neither of the pair of spring-loaded members is in contact with the stationary member including the at least one terminal load.","18","15/607333","2017-05-26","2017-0258372","2017-09-14","10426381","2019-10-01","INTEL CORPORATION","Yunhui  Chu | Charles C.  Phares | John M.  Lynch","","","","A61B-0005/117","A61B-0005/117 | G06F-0021/32 | G06F-0021/83 | G06K-0009/00597","H01R-029/00","H01R-029/00 | A61B-005/117 | G06F-021/32 | G06K-009/00 | G06F-021/83","","","","","","4919040001085"
"US","US","P","B2","Medicine injection and disease management systems, devices, and methods","One or more embodiments of the present disclosure may include an insulin delivery system that includes an insulin delivery device, a user interface that includes multiple user-selectable icons or buttons each representing different meal characteristics, memory to store one or more user-specific dosage parameter, and a processor in communication with the memory and adapted to receive blood glucose data. The processor may also be adapted to determine initial meal characteristics associated with each of the user-selectable icons or buttons based on at least one of the user-specific dosage parameters. The processor may also be adapted to update the meal characteristics associated with each of the user-selectable icons or buttons based upon the blood glucose data.","1. A pen cap for an insulin pen comprising: one or more sensors adapted to detect a position of a plunger within the insulin pen;a user interface comprising one or more user-selectable icons or buttons adapted to announce a meal or an intent to have a meal;a sensor adapted to detect a characterization of the insulin pen or a type of insulin in the insulin pen;a memory to store information about different types of insulin pens or different types of insulin; anda processor to determine the type of insulin pen or the type of insulin, wherein the processor is configured to change the user interface dependent on the type of insulin pen or the type of insulin, wherein some types of insulin or insulin pens result in a user-interface that does not include any user-selectable icons or buttons adapted to announce a meal or an intent to have a meal.","11","15/717805","2017-09-27","2018-0085532","2018-03-29","10426896","2019-10-01","BIGFOOT BIOMEDICAL, INC.","Lane  Desborough | Bryan  Mazlish | Andrew  Bochenko | Ross  Naylor | Per John  Sjolund","","","","A61M-0005/3202","A61M-0005/3202 | A61M-0005/1723 | G06F-0003/0482 | G06F-0003/04817 | G06F-0003/04847 | G06F-0019/3468 | G16H-0020/10 | G16H-0050/20 | A61M-2205/3303 | A61M-2205/3306 | A61M-2205/3561 | A61M-2205/50 | A61M-2205/505 | A61M-2205/52 | A61M-2230/201 | G06F-0003/04883 | G06F-0019/3418 | G16H-0010/60 | G16H-0040/63","G06F-017/00","G06F-017/00 | A61M-005/32 | A61M-005/172 | G06F-003/0481 | G06F-003/0482 | G06F-003/0484 | G06F-019/00 | G16H-050/20 | G16H-020/10 | G16H-010/60 | G16H-040/63 | G06F-003/0488","","","","","","4919040001594"
"US","US","P","B2","Remote assistance workstation, method and system with a user interface for remote assistance with spatial placement tasks via augmented reality glasses","A remote assistance workstation 12 comprises a communications module 54, a user interface (UI) module 52, and a controller 56, for being coupled to a portable device 14 that includes a pair of augmented reality (AR) glasses 36 worn by a first responder to carry out an action using an object with a subject at a scene. The UI module 52 renders a remote assistant graphical user interface (GUI) 100 that includes (i) a first pane 96 for displaying a live video stream of a remote assistance request and (ii) a second pane 98 for displaying a 2D representation of the object at the scene being moveable therein by remote assistant inputs. The GUI 100 renders a corresponding item of 3D virtual content within the first pane relative to a reference point. The controller 56 outputs remote assistance signals to the portable device 14 for displaying the item of 3D virtual content 38 on the AR glasses in a live view of the scene, appearing at a location determined by the remote assistant inputs moving the 2D representation within the second pane 98 for assisting the first responder at the scene.","1. A remote assistance workstation configured for being operatively coupled to a portable device that comprises at least a pair of stereoscopic augmented reality glasses, the portable device for use by a first responder to carry out at least one action using a first object at a scene in connection with at least one of (i) a subject; and (ii) second object at the scene, the remote assistance workstation comprising: a communications module, configured for communicating with the portable device in response to a remote assistance request initiated from the portable device; the remote assistance request including at least a live video stream captured via a camera of the stereoscopic augmented reality glasses at the scene;a user interface module configured for (a) rendering a remote assistant graphical user interface on a display device and (b) receiving remote assistant inputs from a remote assistant, wherein the remote assistant graphical user interface includes at least(i) a first pane that comprises a 3D pane for displaying the live video stream of the remote assistance request, and(ii) a second pane that comprises a 2D pane for displaying a 2D representation of the first object at the scene, wherein the rendered 2D representation is moveable within the second pane in response to one or more remote assistant inputs, the remote assistant graphical user interface further for rendering within the first pane an item of 3D virtual content that corresponds with the rendered 2D representation of the first object at the scene within the second pane, relative to at least a reference point within the first pane, wherein the reference point is based upon a content of the live video stream; anda controller for generating one or more remote assistance signals to be output, via the communications module, to the portable device for displaying, in response to the one or more remote assistant inputs moving the rendered 2D representation of the first object at the scene within the second pane, the item of 3D virtual content on the stereoscopic augmented reality glasses to the first responder within a live view of the scene as is captured by the camera of the stereoscopic augmented reality glasses, such that the item of 3D virtual content appears at a correct location with respect to the reference point within the live view, for assisting the first responder to carry out the at least one action using the first object in connection with the subject or the second object at the scene.","20","15/772287","2016-10-12","2018-0322702","2018-11-08","10431008","2019-10-01","KONINKLIJKE PHILIPS N.V.","Johan Partomo  Djajadiningrat | Pei-Yin  Chao | Wing Lam  Lui","","","","G06T-0019/006","G06T-0019/006 | A61B-0005/0404 | A61B-0090/36 | A61H-0031/007 | A61N-0001/3993 | G02B-0027/0172 | G06F-0009/453 | G06F-0019/3418 | G06F-0019/3481 | G16H-0040/67 | G16H-0080/00 | A61B-2090/365 | A61B-2090/502 | A62B-0099/00 | G02B-2027/0134 | G02B-2027/0138 | G02B-2027/0141 | G02B-2027/0178 | G06F-0003/041 | G06K-0009/00221 | G06T-0003/20 | G06T-0003/60 | G06T-2200/24","G06T-019/00","G06T-019/00 | G06F-019/00 | G16H-080/00 | A61B-090/00 | G16H-040/67 | G06F-009/451 | A61B-005/0404 | A61H-031/00 | A61N-001/39 | G02B-027/01 | A61B-090/50 | A62B-099/00 | G06F-003/041 | G06K-009/00 | G06T-003/20 | G06T-003/60","","","","","","4919040005683"
"US","US","P","B2","CPR quality assessment accounting for pause aspect","Devices, systems, software and methods for CPR quality assessment. Patient data is received, derived from a session of administering sets of CPR chest compressions to a patient. The sets can be separated by pauses. In some embodiments, a penalty value can be determined for at least one of the pauses, from at least one control factor unrelated to a constant linear dependence on the pause duration. An indicative value can be derived from the penalty value. In some embodiments, at least some of the pauses are classified in one or more pause groups, depending on how well they meet one or more classification criteria. The indicative value can be derived for one of the pause groups. The indicative value can be output, and/or an alarm can be emitted if it exceeds a threshold. CPR quality assessment can be improved in real time, and provide feedback for training.","1. A system for Cardiopulmonary Resuscitation (CPR) feedback, comprising: a sensor configured to detect sets of CPR chest compressions received by a patient, the sets separated by pauses;a base device operatively coupled with the sensor and configured to generate patient data from the detected sets; a user interface coupled to the base device; anda processor configured to: receive the patient data,identify at least some of the pauses from the patient data,receive a classification criterion from the user interface, the classification criterion being related to the pauses in the sets of CPR chest compressions,classify at least some of the identified pauses in one of at least two pause groups based on the classification criterion,determine a penalty value for each pause group based on a corresponding classification, andderive respective indicative values for each of the pause groups based on the corresponding penalty values, andin which the user interface is configured to output the indicative values and a prompt to alter an administration of CPR chest compressions received by the patient based at least in part on the indicative values.","13","14/183367","2014-02-18","2014-0236053","2014-08-21","10420702","2019-09-24","PHYSIO-CONTROL, INC.","Robert G.  Walker | Ronald E.  Stickney | Fred W.  Chapman","","","","A61H-0031/005","A61H-0031/005 | A61B-0005/024 | A61H-0031/00 | A61H-0031/007 | A61N-0001/3925 | C07D-0413/14 | G06F-0019/3481","G06Q-050/00","G06Q-050/00 | A61H-031/00 | A61B-005/024 | C07D-413/14 | G06F-019/00 | A61N-001/39 | G06Q-010/00","","","","","","4919039001161"
"US","US","P","B2","Real-time user authentication using integrated biometric sensor","A computing device includes a housing, a processor, memory, a human interface device (i.e., a keyboard or a trackpad), and a biometric sensor integrated into the housing. The biometric sensor is configured for capturing biometric data (i.e., heartbeat data or a vein scan) from one or more of hands of a user of the device while the user's fingers are interacting with the human interface device. The memory stores executable instructions that, when executed by the at least one processor, cause the computing device to: compare the captured biometric data to one or more records of biometric data associated with the user; determine, based on the comparison, whether the captured biometric data satisfies a matching condition with the one or more records of biometric data; and authenticate the user, when the captured biometric data satisfies the matching condition.","1. A method of authenticating a user while the user is interacting with a human interface device of a computing device, the method comprising: capturing biometric data of the user from a biometric sensor integrated into a housing of the computing device, the biometric sensor being integrated into the housing such that the biometric data is captured from one or more of the user'ss hands while the user'ss fingers are interacting with the human interface device and while entering a password to the computing device, wherein the human interface device is selected from the group consisting of a keyboard and a trackpad, wherein the biometric data is selected from the group consisting of heartbeat data and a vein scan, and wherein the biometric sensor is selected from the group consisting of a heartbeat monitor and a vein scanner;comparing the captured biometric data to one or more records of biometric data associated with the user;determining, based on the comparison, whether the captured biometric data satisfies a matching condition with the one or more records of biometric data;authenticating the user, when the captured biometric data satisfies the matching condition;determining that biometric data of the user is not captured for a first period of time that exceeds a first threshold; andprompting the user, based on the determining that biometric data of the user is not captured for the first period of time that exceeds the first threshold, to place the one or more of the user'ss hands on a palm rest portion of the housing.","16","15/220891","2016-07-27","2018-0032709","2018-02-01","10423768","2019-09-24","GOOGLE LLC","Alberto  Martin Perez | Katie Leah  Roberts-Hoffman","","","","G06F-0021/32","G06F-0021/32 | A61B-0005/117 | G06K-0009/00362 | H04L-0063/0861 | A61B-0005/0062 | A61B-0005/0245 | A61B-0005/02416 | A61B-0005/489 | H04L-0063/0853 | H04W-0012/06","G06F-021/00","G06F-021/00 | G06F-021/32 | A61B-005/117 | G06K-009/00 | H04L-029/06 | A61B-005/00 | A61B-005/024 | A61B-005/0245 | H04W-012/06","","","","","","4919039004201"
"US","US","P","B2","Control of wireless communication device capability in a mobile device with a biometric key","An iris biometric recognition module includes technology for capturing images of an iris of an eye of a person, whether the person is moving or stationary. The iris biometric recognition technology can perform an iris matching procedure for, e.g., authentication or identity purposes, by comparing a digital iris image to a reference iris image and, if the digital and reference iris images match, authenticating a person as authorized to access a first device and transmitting a wireless communication from the first device to a second device.","1. A biometric access control device comprising: a camera having a field of view;an illuminator device comprising one or more illuminators that emit light into the field of view;a client device enabled to authenticate a person to access a wireless communication capability to transmit a wireless communication to a second device;an input device;memory storing program instructions; anda processor communicatively coupled to the illuminator device, the camera, the client device, the input device, and the memory, and further communicatively coupled to a database storing a reference iris image for a user validated to access the client device, the processor executing the program instructions to: receive an input signal from the input device;determine that the input signal comprises a permission to scan an iris of a person in proximity to the client device;align the camera with the iris of the person;send a first control signal to the illuminator device, the first control signal activating a synchronous emission of light by the one or more illuminators;send a second control signal to the camera, the second control signal activating a capture of a plurality of digital images by the camera, the capture being synchronous with the synchronous emission of light;receive the plurality of digital images from the camera;access the database and retrieve the reference iris image;determine that a first digital image of the plurality of digital images matches the reference iris image, wherein the first digital image is a low resolution image selected from a plurality of resolutions, and wherein determining the match comprises selecting a low frequency component corresponding to said low resolution image, said low resolution image and said low frequency component being the lowest sufficient to identify coarse iris features;authenticate the person as authorized to access the wireless communication capability; andtransmit the wireless communication from the client device to the second device.","20","15/514098","2015-09-24","2017-0251366","2017-08-31","10425814","2019-09-24","PRINCETON IDENTITY, INC.","Steven N.  Perna | Mark A.  Clifton | Jongjin  Kim | Bobby S.  Varma | Stephen J.  Piro | Barry E.  Mapen | Kevin P.  Richards | David Alan  Ackerman | Ann-Marie  Lanzillotto | David J.  Wade | Timothy J.  Davis | Michael P.  Fleisch | Jitendra J.  Bhangley | Glen J.  Van Sant","","","","H04W-0012/06","H04W-0012/06 | A61B-0003/1216 | A61B-0005/1171 | G06F-0021/32 | G06F-0021/83 | G06Q-0020/1085 | G06Q-0020/322 | G06Q-0020/40145 | G07F-0019/20 | G07F-0019/201 | H04L-0063/0861 | A61B-0003/112 | A61B-0005/117 | G06K-0009/00604 | G06K-0009/2027 | G07C-0009/00087 | H04W-0012/00504 | H04W-0012/08 | H04W-0088/02","H04W-012/06","H04W-012/06 | G06F-021/32 | G06F-021/83 | A61B-003/12 | A61B-005/1171 | H04L-029/06 | G06Q-020/10 | G07F-019/00 | G06Q-020/32 | G06Q-020/40 | H04W-012/08 | A61B-003/11 | A61B-005/117 | G06K-009/00 | G06K-009/20 | H04W-088/02 | G07C-009/00 | H04W-012/00","","","","","","4919039006227"
"US","US","P","B2","Apparatus and method for brain computer interface","The present disclosure discloses an apparatus for a brain computer interface (BCI) including a feature extraction filter trainer for training a feature extraction filter which minimizes an influence of a background brain wave while maximizing a difference between intended brain waves; and a classifier trainer for training a classifier for classifying the intended brain waves by using a feature vector obtained by filtering the intended brain wave at the feature extraction filter. With the apparatus, only the background brain wave is additionally measured, such that previous intended brain wave data can be reused and the brain wave can be classified more quickly and accurately.","1. An apparatus for a brain computer interface (BCI), comprising: an electroencephalograph configured to measure brain waves including a background brain wave and intended brain waves; anda processor configured to:train a feature extraction filter which minimizes an influence of the background brain wave while maximizing a difference between intended brain waves,train a classifier for classifying the intended brain waves by using a feature vector obtained by filtering the intended brain waves with the feature extraction filter,calculate a classifier bias by using the feature extraction filter, a current background brain wave and the classifier, andcalibrate the classifier by using the calculated classifier bias,wherein the processor calculates the classifier bias by providing a predicted transition value, which is obtained by orthogonally projecting the current background brain wave to the feature extraction filter, predicted from the feature extraction filter, to the classifier.","8","15/362818","2016-11-29","2017-0238831","2017-08-24","10413204","2019-09-17","GWANGJU INSTITUTE OF SCIENCE AND TECHNOLOGY","Hohyun  Cho | Sung Chan  Jun","10-2016-0019607","KR","2016-02-19","A61B-0005/04017","A61B-0005/04017 | A61B-0005/0476 | A61B-0005/7267 | G06F-0003/015 | A61B-2560/0223 | G06K-0009/00536","A61B-005/04","A61B-005/04 | A61B-005/0482 | A61B-005/00 | A61B-005/0476 | G06F-003/01 | G06K-009/00","","","","","","4919038001149"
"US","US","P","B2","Perfusion device for treating an injured blood vessel","The present disclosure concerns embodiments of an implantable perfusion device that can be implanted in an injured blood vessel to control bleeding without occluding the vessel. In one specific implementation, the perfusion device can be implanted percutaneously into a patient's descending aorta to control bleeding at the site of a ruptured portion of the aorta (known as torso hemorrhage) while still allowing for the antegrade flow of blood from a location upstream of the ruptured portion of the aorta to a location downstream of the ruptured portion of the aorta. The perfusion device can be left inside the patient as the patient is transported to a medical facility where the injury can be repaired. Following repair of the vessel, the perfusion device can be withdrawn from the patient.","1. A perfusion device for treating a ruptured blood vessel of a patient, comprising: at least one elongated member extending from a proximal end portion to a distal end portion;a handle coupled to the proximal end portion of the at least one elongated member; andan expandable sealing member affixed to the distal end portion of the elongated member, the sealing member having a blood-impermeable surface configured to form a seal along an inner surface of the blood vessel adjacent a ruptured portion of the blood vessel when the sealing member is deployed from a radially collapsed state to a radially expanded, deployed state inside the vessel to control bleeding through the ruptured portion of the vessel;wherein the sealing member permits the antegrade flow of blood through the sealing member from a location upstream of the ruptured portion of the vessel to a location downstream of the ruptured portion of the vessel;wherein the sealing member is configured to be radially collapsible from the deployed state to the radially collapsed state for removal of the sealing member from the patient'ss body; andwherein the handle is spaced from the expandable sealing member by the at least one elongated member and is a non-expandable portion of the perfusion device, and wherein the at least one elongated member is sized such that the handle remains outside of the patient'ss body and remains coupled to the at least one elongated member when the sealing member is deployed inside the blood vessel and when the sealing member is radially collapsed for removal from the patient'ss body.","28","14/904063","2014-07-10","2016-0157868","2016-06-09","10413301","2019-09-17","UNIVERSITY OF PITTSBURGH - OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION","Bryan W.  Tillman | William W.  Clark | Sung Kwon  Cho | Youngjae  Chun","","","","A61B-0017/12109","A61B-0017/12109 | A61B-0005/0215 | A61B-0005/02141 | A61B-0017/1204 | A61B-0017/12031 | A61B-0017/12036 | A61B-0017/12136 | A61B-0090/98 | A61F-0002/966 | G06K-0007/10366 | A61B-2017/00115 | A61B-2090/397 | A61B-2090/3966 | A61F-0002/07 | A61F-2002/9511","A61B-017/12","A61B-017/12 | A61F-002/966 | A61B-005/021 | A61B-005/0215 | A61B-090/98 | G06K-007/10 | A61F-002/07 | A61F-002/95 | A61B-017/00 | A61B-090/00","","","","","","4919038001246"
"US","US","P","B2","Systems and methods for identifying personalized vascular implants from patient-specific anatomic image data","Embodiments include methods of identifying a personalized cardiovascular device based on patient-specific geometrical information, the method comprising acquiring a geometric model of at least a portion of a patient's vascular system; obtaining one or more geometric quantities of one or more blood vessels of the geometric model of the patient's vascular system; determining the presence or absence of a pathology characteristic at a location in the geometric model of the patient's vascular system; generating an objective function defined by a plurality of device variables and a plurality of hemodynamic and solid mechanics characteristics; and optimizing the objective function using computational fluid dynamics and structural mechanics analysis to identify a plurality of device variables that result in desired hemodynamic and solid mechanics characteristics.","1. A method of identifying a personalized cardiovascular device based on patient-specific geometrical information, the method comprising: acquiring a geometric model of at least a portion of a patient'ss vascular system;obtaining one or more geometric quantities of one or more blood vessels of the geometric model of the patient'ss vascular system;determining the presence or absence of a pathology characteristic at a location in the geometric model of the patient'ss vascular system;generating an objective function defined by a plurality of device variables and a plurality of hemodynamic and solid mechanics characteristics; andoptimizing the objective function using computational fluid dynamics and structural mechanics analysis to identify a plurality of device variables that result in desired hemodynamic and solid mechanics characteristics.","20","14/887849","2015-10-20","2016-0038251","2016-02-11","10413432","2019-09-17","HEARTFLOW, INC.","Leo J.  Grady | Charles A.  Taylor | Gilwoo  Choi | Campbell  Rogers","","","","A61F-0002/95","A61F-0002/95 | A61B-0006/00 | A61B-0034/10 | G06K-0009/6293 | G06T-0007/0012 | G16H-0050/20 | G16H-0050/50 | A61B-2034/105 | A61B-2034/107 | A61B-2034/108 | A61B-2090/3762 | A61B-2576/023 | A61F-2002/30943 | A61F-2240/004 | G06F-0017/5009","G06G-007/58","G06G-007/58 | A61F-002/95 | G16H-050/50 | G16H-050/20 | A61B-006/00 | G06K-009/62 | G06T-007/00 | A61B-034/10 | A61F-002/30 | G06F-017/50 | A61B-090/00","","","","","","4919038001376"
"US","US","P","B2","Implantable medical device with gyroscope","An implantable medical device (IMD) that includes a housing, a first electrode secured relative to the housing, a second electrode secured relative to the housing, and a gyroscope secured relative to the housing. The IMD may include circuitry in the housing in communication with the first electrode, the second electrode, and the gyroscope. The circuitry may be configured to determine and store a plurality of torsion data measurements, from which a representation of a twist profile may be determined.","1. A leadless cardiac pacemaker (LCP) configured to sense cardiac activity and to pace a patient'ss heart, the LCP comprising: a housing;an electrode secured relative to the housing and exposed to an environment outside of the housing;a gyroscope disposed relative to the housing;circuitry in the housing in communication with the electrode and the gyroscope, the circuitry configured to generate a twisting profile over one or more cardiac cycles based at least in part on data obtained from the gyroscope:wherein the circuitry is further configured to: update one or more pacing parameters of the LCP based at least in part on the twisting profile; andpace the patient'ss heart with the electrode using one or more of the updated pacing parameters.","20","15/791286","2017-10-23","2018-0117340","2018-05-03","10413733","2019-09-17","CARDIAC PACEMAKERS, INC.","Bin  Mi | Pramodsingh Hirasingh  Thakur | Jeffrey E.  Stahmann | Keith R.  Maile | Qi  An | Brendan Early  Koop | Yinghong  Yu | Viktoria A.  Averina | Michael J.  Kane | Krzysztof Z.  Siejko","","","","A61N-0001/36578","A61N-0001/36578 | A61B-0005/00 | A61B-0005/02028 | A61B-0005/1121 | A61N-0001/3756 | G01C-0019/38 | G06F-0003/0346 | A61B-0005/0205 | A61B-0005/0215 | A61B-0005/042 | A61B-0005/0472 | A61B-0005/4839 | A61B-2562/0219 | A61N-0001/37252","A61N-001/365","A61N-001/365 | G06F-003/0346 | G01C-019/38 | A61N-001/375 | A61B-005/00 | A61B-005/02 | A61B-005/11 | A61N-001/372 | A61B-005/0205 | A61B-005/0215 | A61B-005/042 | A61B-005/0472","","","","","","4919038001674"
"US","US","P","B2","Systems and methods for detecting traffic in a shopping facility","In some embodiments, apparatuses and methods are provided herein useful for detecting traffic in a shopping facility. A system for detecting traffic in a shopping facility comprises: a plurality of light emitters coupled to motion sensors configured to emit light when motion is detected by the motion sensor; a light detector having a field of view including at least one of the plurality of light emitters; a database; and a control circuit configured to obtain data from the light detector relating to light emitted from the light emitters, estimate a location of the light emitted from the light emitters based on location data associated with the light emitter stored in the database, and track a path of a customer based on successive light emissions from the light emitters.","1. A system for detecting traffic in a shopping facility, the system comprising: a plurality of light emitters positioned at predetermined locations throughout the shopping facility, each light emitter being coupled to an associated motion sensor configured to detect motion such that each light emitter emits a light signal when motion of an approaching customer is detected by the associated motion sensor;a light detector having a field of view including the plurality of light emitters and configured to detect the light signals emitted from the plurality of light emitters;a database configured to store signal data obtained from the light detector and location data associated with the plurality of light emitters; anda control circuit coupled to the light detector and the database, the control circuit configured to: obtain the signal data from the light detector relating to the light signals emitted from the plurality of light emitters;estimate a location of the light signals emitted from the plurality of light emitters based on the location data associated with the plurality of light emitters stored in the database; andtrack a path of the approaching customer based on successive light signal emissions from at least two of the plurality of light emitters,wherein the control circuit is further configured to estimate a location of a store worker by comparing a scan from a handheld device carried by the store worker, the handheld device being coupled to the control circuit, with scan data stored in the database, anddetermine if the store worker is present when at least one of the plurality of light emitters is activated by the approaching customer by comparing the location of the store worker to the signal data obtained from the light detector and the location data associated with the at least one of the plurality of light emitters.","14","15/609085","2017-05-31","2017-0344129","2017-11-30","10416784","2019-09-17","WALMART APOLLO, LLC","Nicholaus A.  Jones | Robert J.  Taylor | Aaron J.  Vasgaard | Matthew A.  Jones","","","","G06F-0003/0325","G06F-0003/0325 | G06F-0016/487 | G06Q-0030/00 | G06T-0007/292 | A61B-0005/1113 | A61B-0005/1122 | A61B-2503/12","G06F-003/03","G06F-003/03 | A61B-005/11 | G06F-016/487 | G06T-007/292 | G06Q-030/00","","","","","","4919038004710"
"US","US","P","B2","System and method for noninvasively measuring ventricular stroke volume and cardiac output","A system for non-invasively measuring cardiac output, stroke volume, or both comprises a pulse oximeter, a data processor, and means for generating an output reporting measured one or more CO or SV values to a user. A method for non-invasively measuring cardiac output, stroke volume, or both comprises collecting plethysmographic waveform data of a patient, providing the plethysmographic waveform to a data processor, and calculating measured values for CO or SV. The data processor comprises a mathematical model of the cardiovascular system integrated in a dynamic state space model (DSSM).","1. A system for non-invasively measuring left ventricular stroke volume (SV) and/or cardiac output (CO) of a patient, said system comprising: a pulse oximeter, a data processor, and means for generating an output reporting a measured SV or CO value to a user wherein:the pulse oximeter is configured to collect plethysmographic waveform data of the patient and to transmit the plethysmographic waveform data to the data processor;the data processor is configured to receive said plethysmographic waveform data and comprises software that calculates the measured value for SV and/or CO using said plethysmographic waveform data and reports the measured value for SV and/or CO to the user;the software that calculates a measured value for SV and/or CO from plethysmographic waveform data comprises a probabilistic processor and a mathematical model of a cardiovascular system integrated in a dynamic state space model (DSSM); andthe mathematical model of the cardiovascular system comprises aortic pressure, radial pressure, peripheral resistance, aortic impedance, heart rate, stroke volume, and blood density as state or model parameters.","12","15/225803","2016-08-01","2017-0119261","2017-05-04","10405762","2019-09-10","VITAL METRIX INC.","Rodrigo E.  Teixeira","","","","A61B-0005/0295","A61B-0005/0295 | A61B-0005/0205 | A61B-0005/14551 | A61B-0005/6826 | G06K-0009/00523 | G06K-0009/6226 | A61B-0005/021 | A61B-0005/02416 | A61B-0005/0816 | A61B-0005/7203 | A61B-0005/7267 | A61B-0005/7405 | A61B-0005/7455","A61B-005/0205","A61B-005/0205 | A61B-005/1455 | A61B-005/00 | A61B-005/024 | A61B-005/021 | A61B-005/08 | G06F-017/18 | A61B-005/0295 | G06K-009/00 | G06K-009/62","","","","","","4919037001152"
"US","US","P","B2","Use of gyro sensors for identifying athletic maneuvers","Embodiments of the present disclosure help identify athletic maneuvers performed by actors and/or their sports equipment using data from sensors, including data from at least one gyroscopic sensor. Among other things, various embodiments can help judges and spectators of extreme sports to identify and assess athletic maneuvers more easily and accurately compared to conventional methods.","1. A method comprising: measuring, by a gyroscope, angular velocity of one or more of an actor and the actor'ss equipment over a time period;measuring, by an accelerometer, acceleration of one or more of the actor and the actor'ss equipment over the time period;monitoring, by a Hall effect sensor, a speed of the actor'ss equipment before the time period, during the time period, or after the time period;receiving, by a computer system, sensor data related to motion over the time period by one or more of the actor and the actor'ss equipment, wherein the sensor data includes the measured angular velocity and the measured acceleration;determining, by the computer system and based on the sensor data, a plurality of motion characteristics; andidentifying, based on the plurality of motion characteristics and the monitored speed of the actor'ss equipment, an athletic maneuver associated with the motion during the time period.","21","14/675387","2015-03-31","2015-0335949","2015-11-26","10408857","2019-09-10","ALPINEREPLAY, INC.","Anatole M.  Lokshin | Vitaly A.  Kuzkin | Claire Louise  Roberts-Thomson","","","","G01P-0015/14","G01P-0015/14 | A61B-0005/11 | A61B-0005/1121 | A61B-0005/1123 | A61B-0005/7246 | G01S-0019/19 | G06F-0003/017 | G06K-0009/00342 | G16H-0020/30 | G16H-0050/20 | A61B-0005/0022 | A61B-0005/7267 | A61B-2503/10 | A61B-2562/0219","G01P-015/14","G01P-015/14 | A61B-005/11 | G06F-003/01 | A61B-005/00 | G01S-019/19 | G06K-009/00 | G16H-050/20 | G16H-020/30","","","","","","4919037004225"
"US","US","P","B2","Detecting tooth wear using intra-oral 3D scans","A method for detecting tooth wear using digital 3D models of teeth taken at different times. The digital 3D models of teeth are segmented to identify individual teeth within the digital 3D model. The segmentation includes performing a first segmentation method that over segments at least some of the teeth within the model and a second segmentation method that classifies points within the model as being either on an interior of a tooth or on a boundary between teeth. The results of the first and second segmentation methods are combined to generate segmented digital 3D models. The segmented digital 3D models of teeth are compared to detect tooth wear by determining differences between the segmented models, where the differences relate to the same tooth to detect wear on the tooth over time.","1. A computer-implemented method for displaying an indication of tooth wear, comprising steps executed by a processor: receiving a digital 3D model of a tooth;computing changes in volume and height for the tooth based upon first and second digital 3D models of the tooth, wherein the first digital 3D model was taken at a first time, the second digital 3D model was taken at a second time later than the first time, and the changes in the volume and height result from detected tooth wear of the tooth; anddisplaying the digital 3D model of the tooth with a visual indication of the changes in volume and height, wherein the visual indication of the changes in volume and height provides an indication of tooth wear of the tooth, wherein the computing changes step comprises computing the changes in the height for each cusp of the tooth and locating a point with a largest change in a worn area of each of the cusps.","18","15/448978","2017-03-03","2017-0178327","2017-06-22","10410346","2019-09-10","3M INNOVATIVE PROPERTIES COMPANY","Guruprasad  Somasundaram | Evan J.  Ribnick | Ravishankar  Sivalingam | Aya  Eid | Theresa M.  Meyer | Golshan  Golnari | Anthony J.  Sabelli","","","","G06T-0007/0016","G06T-0007/0016 | A61B-0005/0088 | A61B-0005/4547 | A61C-0009/0053 | A61C-0019/04 | G06F-0017/50 | G06T-0007/11 | G06T-0013/20 | G06T-0015/08 | G06T-0019/20 | A61C-0007/002 | G06T-2200/04 | G06T-2207/30036 | G06T-2210/41","G06K-009/00","G06K-009/00 | G06T-007/00 | G06F-017/50 | A61C-009/00 | A61C-019/04 | G06T-007/11 | G06T-013/20 | G06T-015/08 | G06T-019/20 | A61B-005/00 | A61C-007/00","","","","","","4919037005706"
"US","US","P","B2","Dynamic sampling","A wrist-worn athletic performance monitoring system, including an analysis processor, configured to execute an activity recognition processes to recognize a sport or activity being performed by an athlete, and a sampling rate processor, configured to determine a sampling rate at which an analysis processor is to sample data from an accelerometer. The sampling rate processor may determine the sampling rate such that the analysis processor uses a low amount of electrical energy while still being able to carry out an activity classification process to classify an activity being performed.","1. A non-transitory computer-readable medium comprising computer-executable instructions that when executed by a processor is configured to perform at least: receive acceleration data representing movement of an appendage of a user at a sampling rate processor located on a device configured to be worn on an appendage of a human, wherein the acceleration data was obtained by an accelerometer located on the device while the accelerometer is operating at a first sampling rate;based, at least in part, on the received acceleration data itself, classify the acceleration data into one of a plurality of activity categories representing sporting activity, recognized from a plurality of sporting activities, being performed by the user; andbased upon at least the sporting activity, selecting a second sampling rate of hardware of the accelerometer, from a plurality of sampling rates for operating the accelerometer during the activity being performed by the user,wherein the selection of the first sampling rate and the second sampling rate are selected to prolong a battery life of the device,wherein the accelerometer is a first accelerometer and the medium further comprises computer executable instructions that when executed further perform at least: compare a value of acceleration data obtained from the accelerometer during its operation at the first sampling rate to a plurality of threshold values;determining that the value of acceleration data corresponds to a first threshold value within the plurality the threshold values; andbased upon the correspondence to the first threshold value and a classified activity category, selecting a second threshold value.","17","14/292031","2014-05-30","2014-0358473","2014-12-04","10398358","2019-09-03","NIKE, INC.","Manan  Goel | Kate  Cummings","","","","A61B-0005/1118","A61B-0005/1118 | G01P-0001/00 | G01P-0015/00 | G06F-0003/05 | A61B-0005/0002 | A61B-0005/6807 | A61B-0005/6831 | A61B-2560/0209 | A61B-2562/0219 | G01D-0021/00 | G06F-0017/40 | G06F-0019/00","A61B-005/11","A61B-005/11 | G06F-003/05 | G01P-001/00 | G01P-015/00 | G01D-021/00 | G06F-017/40 | G06F-019/00 | A61B-005/00","","","","","","4919036001213"
"US","US","P","B2","Systems and methods for manufacturing custom surgical instruments","Systems and methods are disclosed in which customized instruments, e.g., surgical instruments, can be manufactured to provide improved ergonomics, comfort, and accuracy. Instruments can be customized based on various parameters, including a quantitative assessment of the user, desired or intended use of the instrument, user preferences, and so forth. Exemplary instrument properties which can be customized include size, geometry, durometer, mechanical assist, texture, color, markings, modulus of elasticity, sensor inclusion, sensor type, sensor feedback type, balance, finish, and weight.","1. A method for manufacturing a custom surgical instrument, comprising: capturing an optical image of an exterior of a user'ss hand using an imaging device;extracting, with a computer system, anthropometric data of the user'ss hand from the captured image;receiving, with a computer system, a data set representing one or more parameters of the user, the data set including the anthropometric data;generating, with a computer system, a custom instrument handle design based on the data set; andproducing a custom surgical instrument handle by controlling a computer-aided manufacturing system based on the generated instrument handle design.","26","15/197100","2016-06-29","2018-0000468","2018-01-04","10398417","2019-09-03","DEPUY SYNTHES PRODUCTS, INC.","Michael J.  O'Neil | Robert  Sommerich | Roman  Lomeli","","","","A61B-0017/00","A61B-0017/00 | A61B-0034/00 | A61B-0090/06 | A61B-0005/0488 | A61B-0005/1125 | A61B-0005/1126 | A61B-0034/74 | A61B-2017/0042 | A61B-2017/0046 | A61B-2017/00424 | A61B-2017/00526 | A61B-2090/061 | A61B-2090/065 | A61B-2562/0219 | A61B-2562/0247 | B33Y-0080/00 | G06F-0017/50","A61B-017/00","A61B-017/00 | A61B-034/00 | A61B-090/00 | A61B-005/0488 | G06F-017/50 | A61B-005/11 | B33Y-080/00","","","","","","4919036001272"
"US","US","P","B2","Augmented reality based injection therapy","Approaches for augmented reality systems and methods for administering repeated injections are provided. An augmented reality (AR) system for administering injections includes: an AR headset comprising a display that is configured to display at least one marker superimposed on a real-world view of a subject, the at least one marker being displayed at a user-defined location on the subject. The display may be configured to continuously display the at least one marker at the location on the subject as the real-world view of the subject changes. The marker may be generated based on user input received from a user wearing the AR headset. The location on the subject may be defined by a location of a marker device relative to the subject when the user input is received. The AR headset may include a face mapping system.","1. A augmented reality (AR) system for administering injections to a person, comprising: an AR headset comprising a display that is configured to display at least one marker superimposed on a real-world view of the person, the at least one marker being displayed at a user-defined location on the person, and the at least one marker defining a location of an injection into the person.","25","15/812185","2017-11-14","2019-0143052","2019-05-16","10398855","2019-09-03","William T. McClellan","William T.  McClellan","","","","A61M-0005/427","A61M-0005/427 | G06F-0019/3468 | G06K-0009/00255 | G06K-0009/00671 | A61M-2205/3584 | A61M-2205/507 | G06F-0003/0202 | G06F-0003/167","A61M-005/42","A61M-005/42 | G06K-009/00 | G06F-019/00 | G06F-003/02 | G06F-003/16","","","","","","4919036001707"
"US","US","P","B2","Personalized network searching","Personalized network searching, in which a search query is received from a user, and a request is received to personalize a search result. Responsive to the search query and the request to personalize the search result, a personalized search result is generated by searching a personalized search object. Responsive to the search query, a general search result is generated by searching the general search object. The personalized search result and the general search result are provided to a client device, an advertisement is selected based at least in part upon the personalized search object, and the advertisement, the personalized search result, and the general search result are displayed.","1. A system to search network-based search objects, comprising one or more servers to: generate a personalized search object comprising a plurality of uniform resource locators (URLs), the personalized search object associated with a user of a client device;receive a search query from the client device, the search query comprising a plurality of search terms;generate, based on the search query, a first search result based on a search of a respective content item associated with each of the plurality of URLs in the personalized search object;generate, based on the search query, a second search result based on a search of a general search object with the plurality of search terms;select a first content item based on the first search result; andtransmit, to the client device, the first content item and a result list comprising a plurality of content items based on the second search result.","20","15/492513","2017-04-20","2017-0323021","2017-11-09","10398898","2019-09-03","GOOGLE LLC","Gregory Joseph  Badros | Stephen  Lawrence","","","","A61N-0001/36071","A61N-0001/36071 | A61N-0001/36003 | A61N-0001/36017 | A61N-0001/36021 | A61N-0001/36057 | G06F-0016/9535 | G06F-0016/972 | G06Q-0030/0201 | G06Q-0030/0241 | Y10S-0707/99933 | Y10S-0707/99943 | Y10S-0707/99945","G06F-016/30","G06F-016/30 | A61N-001/36 | G06F-016/9535 | G06F-016/958 | G06Q-030/02","","","","","","4919036001750"
"US","US","P","B2","Medical viewing system with a viewing plane determination","A medical viewing system (10) determines a viewing plane and provides medical images with the determined viewing plane. The medical viewing system (10) includes an X-ray image acquisition device (1), an echocardiographic image acquisition device (2) and a processing unit (3). The X-ray image acquisition device (1) is adapted to acquire an X-ray image in an X-ray imaging plane. The echocardiographic image acquisition device (2) is adapted to acquire a plurality of echocardiographic images. The processing unit (3) is adapted for a determination of an indicator in the X-ray image indicating a viewing plane for an echocardiographic image. The indicator may be an indicator line (41) in the X-ray image indicating the viewing plane perpendicular to the X-ray imaging plane. The processing unit (3) is further adapted for registering or fusing the X-ray image and the plurality of echocardiographic images together, and for then providing an echocardiographic image in the identified viewing plane. The identified viewing plane may be related to specific plane of a device (valve clips, plugs. . .) or of a specific anatomical structure.","1. A medical viewing system comprising: an X-ray image acquisition device adapted to acquire an X-ray image in an X-ray imaging plane, the X-ray image including an interventional device;an echocardiographic image acquisition device adapted to acquire an echocardiographic image;a processing unit; anda user interface for providing, in the X-ray image, an indicator for indicating a viewing plane comprising the interventional device;wherein the processing unit is adapted to register the X-ray image and the echocardiographic image, to provide a view of the echocardiographic image in accordance with the indicated viewing plane, and to determine an additional indication in the echocardiographic image to define the viewing plane together with the indicator in the X-ray image, the defined viewing plane being non-perpendicular to the X-ray imaging plane.","14","15/127473","2015-03-11","2017-0132796","2017-05-11","10402990","2019-09-03","KONINKLIJKE PHILIPS N.V.","Aleksandra  Popovic | John Allen  Bracken | David Paul  Noonan","2014-161136","EP","2014-03-21","G06T-0007/30","G06T-0007/30 | A61B-0005/0402 | A61B-0005/04012 | A61B-0006/463 | A61B-0006/467 | A61B-0006/5247 | G06F-0003/048 | G06T-0007/0012 | G06T-0019/00 | G06T-2207/10028 | G06T-2207/10116 | G06T-2207/30048","A61B-005/00","A61B-005/00 | A61B-006/00 | G06T-007/30 | G06T-019/00 | A61B-005/04 | A61B-005/0402 | G06F-003/048 | G06T-007/00","","","","","","4919036005823"
"US","US","P","B2","Physical face cloning","A computer-implemented method is provided for physical face cloning to generate a synthetic skin. Rather than attempt to reproduce the mechanical properties of biological tissue, an output-oriented approach is utilized that models the synthetic skin as an elastic material with isotropic and homogeneous properties (e.g., silicone rubber). The method includes capturing a plurality of expressive poses from a human subject and generating a computational model based on one or more material parameters of a material. In one embodiment, the computational model is a compressible neo-Hookean material model configured to simulate deformation behavior of the synthetic skin. The method further includes optimizing a shape geometry of the synthetic skin based on the computational model and the captured expressive poses. An optimization process is provided that varies the thickness of the synthetic skin based on a minimization of an elastic energy with respect to rest state positions of the synthetic skin.","1. A method for generating an object shape for a synthetic skin, the method comprising: determining a first target surface and a second target surface, wherein the first target surface comprises a neutral target pose, and the second target surface comprises an expressive target pose;generating a shape geometry for the synthetic skin, the shape geometry having an outer surface and an inner surface, wherein the outer surface is determined based on the first target surface comprising the neutral target pose;generating one or more material parameters for the synthetic skin based on a computational model that simulates deformation behavior of a fabricated object having the shape geometry and made from a defined physical material, such that the outer surface of the shape geometry in a deformed state more closely matches the expressive target pose of the second target surface; andfabricating the synthetic skin based on the shape geometry and the one or more material parameters, wherein the one or more material parameters define physical attributes of the synthetic skin.","20","14/797755","2015-07-13","2015-0317451","2015-11-05","10403404","2019-09-03","THE WALT DISNEY (SWITZERLAND) GMBH | DISNEY ENTERPRISES, INC. | ETH ZURICH (EIDGENONESSISCHE TECHNISCHE HOCHSCHULE ZURICH)","Bernd  Bickel | Peter  Kaufmann | Bernhard  Thomaszewski | Derek Edward  Bradley | Philip John  Jackson | Stephen R.  Marschner | Wojciech  Matusik | Markus  Gross | Thabo Dominik  Beeler","","","","G16H-0050/50","G16H-0050/50 | G06F-0017/10 | G06T-0019/20 | A61B-0005/442 | A63F-2300/6607 | G06F-0017/5018 | G06K-0009/00268 | G06T-0017/00 | G06T-0017/10 | G06T-2207/30201 | G06T-2219/2021 | G10L-2021/105","G06T-019/20","G06T-019/20 | G16H-050/50 | G06F-017/10 | G06K-009/00 | G06T-017/00 | A61B-005/00 | G10L-021/10 | G06T-017/10 | G06F-017/50","","","","","","4919036006234"
"US","US","P","B2","Medical overlay mirror","Medical overlay mirror methods and related systems.","1. A system, comprising: at least one processor; andone or more instructions which, when executed on the at least one processor, configure the at least one processor for performing one or more operations including at least: providing a display of at least one field of view of a light reflecting structure;facilitating a zoomed-in display of the at least one field of view of the light reflecting structure responsive to a selection by a user of a region of the at least one field of view for the zoomed-in display;identifying one or more landmarks present within one or more images and present within the zoomed-in display;registering at least some of the one or more images with the at least one field of view of the light reflecting structure at least partially based on the identifying the one or more landmarks present within the one or more images and present within the zoomed-in display;comparing at least one specified feature visible in at least one of the one or more images or the at least one field of view of the light reflecting structure against at least one reference value associated with the at least one specified feature;overlaying at least one portion of at least one of the one or more images or the at least one field of view of the light reflecting structure; andoutputting one or more presentations of the at least one of the one or more images or the at least one field of view of the light reflecting structure, including at least outputting at least one alert if the at least one specified feature exceeds the at least one reference value by at least one defined amount.","29","15/484973","2017-04-11","2017-0311905","2017-11-02","10390770","2019-08-27","Invention Science Fund I, LLC","Paul G.  Allen | Edward K. Y.  Jung | Royce A.  Levien | Mark A.  Malamud | John D.  Rinaldo, Jr.","","","","A61B-0005/7445","A61B-0005/7445 | A45D-0044/005 | A61B-0005/0079 | A61B-0005/749 | G06F-0003/005 | G06F-0003/017 | G06F-0003/041 | G06T-0011/60 | A45D-2044/007 | A61B-2017/00207 | G09G-2340/12","G09G-005/00","G09G-005/00 | A61B-005/00 | A45D-044/00 | G06F-003/00 | G06F-003/01 | G06F-003/041 | G06T-011/60 | A61B-017/00","","","","","","4919035001021"
"US","US","P","B2","Method and system for biometric recognition","High quality, high contrast images of an iris and the face of a person are acquired in rapid succession in either sequence by a single sensor and one or more illuminators, preferably within less than one second of each other, by changing the data acquisition settings or illumination settings between each acquisition.","1. A system for acquiring iris and face biometric features, the system comprising: a depth measurement sensor configured to determine a distance of an image sensor from a subject;at least one light source; andthe image sensor, the image sensor configured to: acquire, at a first time instant, a first image comprising a biometric feature of a face of the subject, the face illuminated by light of a first wavelength from the at least one light source set to a first intensity magnitude suitable for acquiring the first image at the determined distance; andacquire, at a second time instant, a second image comprising a biometric feature of an iris of the subject, the iris illuminated by light of a second wavelength from the at least one light source set to a second intensity magnitude suitable for acquiring the second image at the determined distance, wherein the second time instant is within a predetermined time period of the first time instant sufficient to link the first image and the second image to the same subject.","20","15/962629","2018-04-25","2019-0005307","2019-01-03","10395097","2019-08-27","GLOBAL RAINMAKERS INC.","Keith J.  Hanna","","","","G06K-0009/00255","G06K-0009/00255 | A61B-0005/117 | G06F-0021/32 | G06K-0009/00248 | G06K-0009/00261 | G06K-0009/00288 | G06K-0009/00604 | G06K-0009/00617 | G06K-0009/00892 | G06K-0009/3208 | G06T-0007/521 | G06T-0007/74 | H04N-0005/2256 | H04N-0005/2352 | H04N-0005/23296","G06K-009/00","G06K-009/00 | A61B-005/117 | H04N-005/225 | H04N-005/232 | H04N-005/235 | G06K-009/32 | G06T-007/73 | G06T-007/521 | G06F-021/32","","","","","","4919035005327"
"US","US","P","B2","Mobile monitoring and patient management system","A patient management system is provided herein. The system can include: communications circuitry configured to receive first physiological information relating to a first at least one patient from at least one therapeutic medical device and second physiological information relating to a second at least one patient from at least one monitoring medical device. The system further includes a computing device, which can include a user interface. The user interface can be configured to display the first and second physiological information according to a user selection.","1. A patient management system, comprising: communications circuitry configured to receive physiological information relating to a plurality of patients from a plurality of monitoring medical devices, each of which is worn by one of the plurality of patients; and a computing device communicatively coupled to the communications circuitry comprising a user interface and at least one processor configured to:receive the physiological information from the plurality of monitoring medical devices via the communications circuitry;process the received physiological information to associate physiological information received from the at least one of the plurality of monitoring medical devices with one of the plurality of patients;analyze the physiological information for the one of the plurality of patients to identify an appropriate course of treatment for the one of the plurality of patients; anddisplay, via the user interface, an indication regarding the identified appropriate course of treatment for the one of the plurality of patients, wherein the indication comprises information about whether the one of the plurality of patients will benefit from using a therapeutic medical device that is configured to deliver a therapy to the one of the plurality of patients upon detecting an underlying arrhythmia condition.","20","16/158682","2018-10-12","2019-0051393","2019-02-14","10395765","2019-08-27","ZOLL MEDICAL CORPORATION","Jason T.  Whiting | Gary A.  Freeman | Thomas E.  Kaib","","","","G16H-0010/65","G16H-0010/65 | A61B-0005/0015 | A61B-0005/6805 | A61B-0005/742 | A61N-0001/37247 | A61N-0001/39 | A61N-0001/3925 | A61N-0001/3993 | G06F-0019/00 | G06F-0019/3418 | G06Q-0050/22 | G16H-0010/60 | G16H-0040/67 | A61B-0005/021 | A61B-0005/024 | A61B-0005/11 | A61B-0005/14542 | A61B-0005/14551 | A61B-0005/746 | A61M-0016/0051 | A61M-0016/021 | A61M-2205/3375 | A61M-2205/3553 | A61M-2205/3569 | A61M-2205/3584 | A61M-2205/3592 | A61M-2205/505 | A61M-2205/52 | A61M-2209/088 | A61M-2230/04 | A61M-2230/06 | A61M-2230/201 | A61M-2230/205 | A61M-2230/30 | A61M-2230/42 | A61M-2230/50 | A61M-2230/63 | A61M-2230/65","G16H-010/65","G16H-010/65 | G06F-019/00 | A61N-001/39 | A61B-005/00 | A61N-001/372 | G06Q-050/22 | G16H-010/60 | G16H-040/67 | A61B-005/021 | A61B-005/11 | A61B-005/024 | A61B-005/145 | A61B-005/1455 | A61M-016/00","","","","","","4919035005991"
"US","US","P","B2","Tracking wearables or other devices for emoji stories","Systems, methods and computer program products to perform an operation comprising determining, based on interaction data stored in a first profile, that a first toy device communicated with a second toy device, wherein the first and second toy devices are within a predefined distance during the communication, determining at least one emotion reflected in an emotion data of the first profile, determining at least one activity reflected in an activity data of the first profile, and generating, based on the interaction data, the emotion data, and the activity data, a story depicting a plurality of emoji, wherein the plurality of emoji comprise a first emoji reflecting the first toy device communicating with the second toy device, a second emoji reflecting the at least one emotion, and a third emoji reflecting the at least one activity.","1. A method, comprising: determining, based on interaction data stored in a first profile, that a first toy device communicated with a second toy device, wherein the first and second toy devices are within a predefined distance during the communication;determining at least one emotion reflected in an emotion data of the first profile;determining at least one activity reflected in an activity data of the first profile; andgenerating, based on the interaction data, the emotion data, and the activity data, a story depicting a plurality of emoji, wherein the plurality of emoji comprise a first emoji reflecting the first toy device communicating with the second toy device, a second emoji reflecting the at least one emotion, and a third emoji reflecting the at least one activity.","20","15/716069","2017-09-26","2019-0098099","2019-03-28","10397350","2019-08-27","DISNEY ENTERPRISES, INC.","Michael P.  Goslin | Katherine M.  Bassett","","","","H04L-0067/22","H04L-0067/22 | G06F-0003/011 | G06K-0009/00892 | G06Q-0050/01 | H04L-0051/02 | A61B-0005/0205 | A61B-0005/165","G06F-003/00","G06F-003/00 | H04L-029/08 | G06F-003/01 | G06K-009/00 | G06Q-050/00 | H04L-012/58 | A61B-005/0205 | A61B-005/16","","","","","","4919035007564"
"US","US","P","B2","Utilizing athletic activities to augment audible compositions","Example embodiments relate to methods and systems for playback of adaptive music corresponding to an athletic activity. A user input is received from a user selecting an existing song for audible playback to the user, the song comprising a plurality of audio layers including at least a first layer, a second layer, and a third layer. Augmented playback of the existing song to the user is initiated by audibly providing the first layer but not the second layer. Physical activity information derived from a sensor corresponding to a real-time physical activity level of a user is received. If the physical activity level of the user is above a first activity level threshold, the augmented playback of the existing song is continued by audibly providing the first layer and the second layer to the user.","1. A computer-implemented method comprising: receiving a user input selecting an existing song for audible playback, the existing song comprising a plurality of audio layers comprising a first layer and a second layer, wherein the first layer includes audio information for a first musical instrument and the second layer includes audio information for a second musical instrument;initiating augmented playback of the existing song by audibly providing the first layer but not the second layer;receiving physical activity information derived from a sensor corresponding to a real-time physical activity level of a user;in response to determining that the real-time physical activity level of the user is above a first activity level threshold, adjusting the augmented playback of the existing song by audibly providing the first layer and the second layer;in response to reaching a predetermined segment in the adjusted augmented playback of the existing song and based on the determined real-time physical activity level, determining a transition segment of the existing song to transition to from a current segment of the existing song;determining a plurality of pathways to reach the transition segment without playing all segments between a current segment and the transition segment, wherein each pathway of the plurality of pathways comprises one or more segments of the existing song and a pathway score;selecting a first pathway of the plurality of pathways to arrive at the transition segment, wherein the first pathway is selected based on the respective pathway score; andaudibly providing the first pathway to arrive at the transition segment.","20","15/221224","2016-07-27","2017-0031650","2017-02-02","10387107","2019-08-20","RESOURCE/AMMIRATI, LLC | NIKE, INC.","Justin  Fraga | Harold L.  Lindstrom, Jr. | Willoughby H.  Walling | Christopher  Andon | Kristopher J.  Schultz | Eric S.  Mcgary","","","","G06F-0003/165","G06F-0003/165 | A61B-0005/024 | G06F-0003/04842 | G06F-0019/3481 | G10L-0025/21 | G10H-0001/0025 | G10H-2240/085 | G10H-2250/311 | H04S-0003/008","G06F-017/00","G06F-017/00 | G06F-003/16 | A61B-005/024 | G10L-025/21 | G06F-003/0484 | G06F-019/00 | G10H-001/00 | H04S-003/00","","","","","","4919034004553"
"US","US","P","B2","Methods and systems for compliance confirmation and incentives","Example methods, apparatus, and articles of manufacture for monitoring use of a research device is disclosed. The disclosed example includes producing monitored data by monitoring at least one of the user's heart activity, the user's breathing activity, the user's borborygmus (gastrointestinal noise), the user's vascular pattern, the user's facial and/or ear patterns, the user's fingerprint and/or handprint, and the user's retinal and/or iris pattern, and determining the user's compliance with a predetermined criterion for use of the portable research device based on the monitored data.","1. A system for monitoring use by a user of a portable research device, comprising: a monitor for producing monitored data by monitoring at least one of the user'ss heart activity, the user'ss breathing activity, the user'ss borborygmus (gastrointestinal noise), the user'ss vascular pattern, the user'ss facial and/or ear patterns, the user'ss fingerprint and/or handprint, and the user'ss retinal and/or iris pattern; anda processor communicatively coupled with the portable research device and coupled with the monitor to: receive the monitored data;determine at least one of a first level, a second level, or a third level of the user'ss compliance with use of the portable research device based on i) the monitored data and ii) the user'ss compliance with a predetermined criterion; andbased on determining that the user'ss compliance is associated with the first level, obtain, from the portable research device, research data indicative of exposure of the portable research device to media.","20","15/331510","2016-10-21","2017-0039337","2017-02-09","10387618","2019-08-20","THE NIELSEN COMPANY (US), LLC","Alan R.  Neuhauser | Jack C.  Crystal | Jack K.  Zhang | Eugene L.  Flanagan, III","","","","G06F-0019/3418","G06F-0019/3418 | A61B-0003/1216 | A61B-0003/14 | A61B-0005/0077 | A61B-0005/0205 | A61B-0005/1172 | A61B-0005/1176 | A61B-0005/489 | A61B-0005/4833 | A61B-0005/6898 | A61B-0007/003 | A61B-0007/008 | A61B-0007/02 | G06F-0019/321 | G06Q-0010/00 | G06Q-0010/101 | G06Q-0030/0201 | G16H-0010/60 | G16H-0040/20 | A61B-0005/02438 | A61B-0005/0816 | A61B-2503/12 | G06Q-0030/0203","A61B-005/00","A61B-005/00 | G06F-019/00 | G06Q-010/00 | G06Q-010/10 | G06Q-030/02 | A61B-003/12 | A61B-003/14 | A61B-005/0205 | A61B-005/1172 | A61B-005/1171 | A61B-007/00 | A61B-007/02 | G16H-010/60 | G16H-040/20 | A61B-005/024 | A61B-005/08","","","","","","4919034005063"
"US","US","P","B1","Device configured for functional diagnosis and updates","Devices, systems and methods for reconfigurable and/or updatable lightweight embedded devices or systems are disclosed. Via use of such a device, system, or method, various capabilities for a user are provided, simplified, secured, and/or made more convenient. The system may interact with various other devices or systems, including those that are cloud-based or communicate through the cloud, and may utilize various local sensors, in order to provide one or more of improved access, monitoring, diagnostics, and so forth.","1. A device attached to a user or the user'ss clothing, the device having a length, a width, and a thickness, the device comprising: electronic circuitry comprising a microprocessor for executing instructions; and a flash memory;a first power source;a display; andan FLM loader operable on the microprocessor, wherein the FLM loader loads an FLM file into the flash memory, and wherein the FLM file is formed from an input file by taking relevant relocation entries from all sections in the input file and ordering the relocation entries by relocation address;wherein the device receives data and transmits the data to a medical device after reformatting the data into a format compatible for the medical device.","26","15/256107","2016-09-02","","","10388411","2019-08-20","LIFE365, INC.","Kent  Dicks | Eric  Vandewater | Randolph  Strength","","","","G16H-0040/63","G16H-0040/63 | A61B-0005/0022 | A61B-0005/02055 | A61B-0005/0402 | A61B-0005/0476 | A61B-0005/18 | A61B-0005/6893 | A61M-0005/1723 | A61N-0001/365 | A61N-0001/39 | G06F-0019/328 | G06Q-0020/3223 | A61B-0005/01 | A61B-0005/024 | A61B-0005/02233 | A61B-0005/0533 | A61B-0005/082 | A61B-0005/087 | A61B-0005/1072 | A61B-0005/1112 | A61B-0005/14532 | A61B-0005/4266 | A61B-0005/4866 | A61B-2010/0009 | A61B-2560/0252 | A61B-2562/0219 | G06Q-2220/00 | H04M-0001/72519 | H04W-0004/80","A61B-005/00","A61B-005/00 | H04L-029/08 | G16H-040/63 | G06Q-020/32 | G06F-019/00 | A61B-005/0205 | A61B-005/0402 | A61B-005/0476 | A61B-005/18 | A61M-005/172 | A61N-001/365 | A61N-001/39 | H04M-001/725 | A61B-005/01 | A61B-005/022 | A61B-005/024 | A61B-005/053 | A61B-005/08 | A61B-005/087 | A61B-005/107 | A61B-005/11 | A61B-010/00 | A61B-005/145 | H04W-004/80","","","","","","4919034005848"
"US","US","P","B2","Rechargeable tool and battery status monitoring in an automated tool control system","An automated tool control system provides both inventory control of items stored in the system and monitoring of the charging status of rechargeable inventory items such as tools and batteries stored in the system. For these purposes, the tool control system includes storage locations for storing tools and other inventory items, and the storage locations include at least one storage location located in a charger operative to charge a rechargeable tool, battery, or battery pack disposed therein. In operation, the tool control system may monitor the charging status of any tool, battery, or battery pack disposed in the storage location of the charger through monitoring of battery status indicators of the tool, battery, battery pack, or charger; through monitoring of current or voltage drawn by the tool, battery, battery pack, or charger; or through wired or wireless communication with a communication enabled tool, battery, battery pack, or charger.","1. An automated tool control system comprising: a plurality of storage locations including one storage location configured to store a rechargeable inventory item and another storage location configured to store a tool;a charger associated with the one storage location of the plurality of storage locations and configured to charge the rechargeable inventory item when the rechargeable inventory item is present in the one storage location; anda processor and sensing device configured to determine the presence or absence of inventory items, including the rechargeable inventory item and the tool, in the plurality of storage locations,wherein the processor is configured to determine presence of the rechargeable inventory item including a removable rechargeable battery with a plurality of time stamps and the one storage location associated with the charger, to monitor a charging status of at least one rechargeable inventory item, to determine presence of the at least one rechargeable inventory item in the other storage location, and to selectively issue an alert to a user with the at least one rechargeable inventory item in the other storage location.","21","15/722494","2017-10-02","2018-0095138","2018-04-05","10379167","2019-08-13","SNAP-ON INCORPORATED","Jason  Newport | David C.  Fly | Preston C.  Phillips | Matthew J.  Lipsey | Frederick J.  Rogers | Joseph  Chwan | Andrew R.  Lobo | Sean W.  Ryan","","","","G01R-0031/3842","G01R-0031/3842 | A61N-0001/3931 | G01R-0031/3646 | G06K-0009/00 | G06K-0009/78 | G06Q-0010/087 | H01M-0010/48 | H02J-0007/0004","G06Q-010/08","G06Q-010/08 | G01R-031/3842 | G01R-031/36 | H01M-010/48 | A61N-001/39 | H02J-007/00 | G06K-009/78 | G06K-009/00","","","","","","4919033003998"
"US","US","P","B2","Line-of-sight measurement device, line-of-sight measurement method and line-of-sight measurement program","Provided are a line-of-sight measurement device and method, which perform automatic calibration of line-of-sight measurement for distance-gazing users. The device is provided with: an optical axis-calculating means for calculating the optical axes of both the left and right eyeballs when viewing two distant points; a discrepancy calculating means for calculating, with the visual axes of the left and right eyeballs during distance-gazing being parallel as a constraint, the discrepancies between the optical axes and the visual axes for both the left and right eyeballs; and a fixation point-calculating means for calculating the user's fixation point on the basis of the discrepancy between the optical axes and the visual axes. For the constraint, the outer product value of the respective vectors of the left and right eye visual axes is 0 or the inner product of the respective unit vectors of the left and right eye visual axes is 1.","1. A line-of-sight measurement device for use when a user gazes mainly at a distance, the user having a left eyeball and a right eyeball, the device comprising: a CPU;at least one light source in operational communication with the CPU;at least one camera in operational communication with the CPU;at least one program storage hardware component in operable communication with the CPU and storing at least a portion of a line-of-sight measurement program, the line-of-sight measurement program upon execution by the CPU performing a method that includes(a) calculating optical axes of both left and right eyeballs when at least two points at a distance of at least two meters away are being gazed upon;(b) calculating a discrepancy between the optical axis of the left eyeball and a visual axis of the left eyeball, and a discrepancy between the optical axis of right eyeball and a visual axis of the right eyeball, under a constraint that visual axes equivalent to lines-of-sight of both left and right eyeballs are parallel when a distant place is being gazed at; and(c) calculating a gazing point of said user based on a discrepancy between an optical axis and a visual axis;wherein said calculating optical axes includes acquiring an eyeball image including an image of an eyeball regarding a user in an occasion of gazing in the distance, and calculating an optical axis which connects a corneal curvature center or an eyeball rotation center and a pupil center of a pupil from said eyeball image.","17","14/891578","2014-05-22","2016-0086338","2016-03-24","10379609","2019-08-13","NATIONAL UNIVERSITY CORPORATION KOBE UNIVERSITY","Takashi  Nagamatsu | Tatsuhiko  Ueki","2013-108441","JP","2013-05-22","G06F-0003/013","G06F-0003/013 | B60K-0035/00 | G02B-0027/0093 | G06K-0009/00604 | G06T-0007/74 | G06T-0007/80 | G08B-0021/06 | H04N-0005/2256 | H04N-0005/247 | A61B-0003/113 | A61B-0005/18 | G02B-2027/014 | G06T-2207/30201","H04N-007/18","H04N-007/18 | H04N-009/47 | G06F-003/01 | B60K-035/00 | G08B-021/06 | G06K-009/00 | H04N-005/225 | H04N-005/247 | G06T-007/80 | G06T-007/73 | G02B-027/00 | A61B-003/113 | A61B-005/18 | G02B-027/01","","","","","","4919033004438"
"US","US","P","B2","Method and system for recommending optimal ergonomic position for a user of a computing device","The present disclosure relates to a method and system for recommending optimal ergonomic position for a user of a computing device by a recommendation system. The recommendation system receives user data from one or more data sources and extracts a profile of the user from a repository based on the user data. The recommendation system identifies one or more critical areas of the user, where each of the critical areas are associated with a plurality of pre-defined position parameters and also monitor the plurality of pre-defined position parameters of the user to determine corresponding values. The recommendation system compare the values of the plurality of pre-defined position parameters with predefined values of the pre-defined position parameters and identify deviations in one or more of the plurality of pre-defined position parameters based on the comparison and provide recommendations for correcting the deviations from the pre-defined position parameters to the user.","1. A method for recommending an optimal ergonomic position for a user of a computing device, the method comprising: receiving, by a recommendation system, user data from one or more data sources;extracting, by the recommendation system, a profile of the user from a repository based on the user data;identifying, by the recommendation system, one or more critical areas of the user based on the extracted profile and the user data, wherein each of the one or more critical areas are associated with a plurality of pre-defined position parameters;monitoring, by the recommendation system, the plurality of pre-defined position parameters of the user to determine corresponding values;comparing, by the recommendation system, pre-defined values of the plurality of pre-defined position parameters with determined corresponding values of the pre-defined position parameters and with specific user defined values identified from the profile of the user, wherein the specific user defined values are pre-defined for the user for at least one of the plurality of pre-defined position parameters;identifying, by the recommendation system, deviations in values of one or more of the plurality of pre-defined position parameters from a threshold range based on the comparison, over a time duration; andproviding, by the recommendation system, one or more recommendations for correcting the deviations to the user.","21","15/243994","2016-08-23","2018-0005386","2018-01-04","10380747","2019-08-13","WIPRO LIMITED","Anandaraj  Thangappan | Jayakumar  Panicker","201641022516","IN","2016-06-30","G06T-0007/251","G06T-0007/251 | A61B-0005/11 | A61B-0005/4561 | G06F-0003/011 | G06T-0007/285 | H04N-0005/23293 | G06T-2207/30196","G06T-007/246","G06T-007/246 | G06T-007/285 | A61B-005/11 | H04N-005/232 | A61B-005/00 | G06F-003/01","","","","","","4919033005564"
"US","US","P","B2","Method of and system for processing signals sensed from a user","A system for and a method of processing signals sensed from a user. The method comprises accessing positions of a line of sight of the user over a time frame, a first set of data associated with a first physiological signal and a second physiological signal. The method further comprises executing, by a processor, for at least one position of the positions of the line of sight of the user, identifying a first subset of data from the first set of data, identifying a second subset of data from the second set of data, associating the at least one position with the first subset of data and the second subset of data and causing to generate, by a machine-learning algorithm, a predicted value reflective of a pattern associated with the user. The method also comprises storing the predicted value associated with the at least one position.","1. A computer-implemented method of processing signals sensed from a user, the method comprising: accessing, from a non-transitory computer readable medium, positions of a line of sight of the user over a time frame;accessing, from the non-transitory computer readable medium, a first set of data associated with a first physiological signal sensed from the user over the time frame;accessing, from the non-transitory computer readable medium, a second set of data associated with a second physiological signal sensed from the user over the time frame;executing, by a processor, for at least one position of the positions of the line of sight of the user: identifying a first subset of data from the first set of data based on a first latency and a first duration, the first latency and the first duration being associated with the first physiological signal, the first latency and the first duration being dynamically determined based on a pattern category;identifying a second subset of data from the second set of data based on a second latency and a second duration, the second latency and the second duration being associated with the second physiological signal, the second latency and the second duration being dynamically determined based on the pattern category;associating the at least one position with the first subset of data and the second subset of data;causing to generate, by a machine-learning algorithm, a predicted value reflective of a pattern associated with the user, the predicted value being generated by the machine-learning algorithm based on the first subset of data and the second subset of data, the predicted value being associated with the at least one position; andstoring, in the non-transitory computer readable medium, the predicted value associated with the at least one position.","20","15/552788","2016-02-25","2018-0035886","2018-02-08","10368741","2019-08-06","VALORISATION GESTION, LIMITED PARTNERSHIP | VALORISATION-RECHERCHE, LIMITED PARTNERSHIP","Francois  Courtemanche | Marc  Fredette | Sylvain  Senecal | Pierre-Majorique  Leger | Aude  Dufresne | Vanessa  Georges | Elise  Labonte-Lemoyne","","","","A61B-0003/113","A61B-0003/113 | A61B-0003/0025 | A61B-0005/0205 | A61B-0005/16 | A61B-0005/163 | A61B-0005/7267 | G06F-0003/013 | G06F-0003/015 | G06N-0020/00 | G16H-0050/20","A61B-003/113","A61B-003/113 | A61B-003/00 | A61B-005/16 | A61B-005/00 | A61B-005/0205 | G06F-003/01 | G06N-020/00 | G16H-050/20","","","","","","4919032000952"
"US","US","P","B2","Indicator and analytics for sensor insertion in a continuous analyte monitoring system and related methods","The present embodiments provide systems and methods for, among others, tracking sensor insertion locations in a continuous analyte monitoring system. Data gathered from sensor sessions can be used in different ways, such as providing a user with a suggested rotation of insertion locations, correlating data from a given sensor session with sensor accuracy and/or sensor session length, and providing a user with a suggested next insertion location based upon past sensor accuracy and/or sensor session length at that location.","1. A method for continuous analyte monitoring including a continuous analyte monitoring system that uses a first sensor and a second sensor, the method comprising: initiating a first sensor session for the first sensor with a transmitter and a device having a display;displaying a diagram of a body on the display;receiving as an input, via the diagram, a location on the body where the first sensor was inserted into skin of a host;determining a recommended next insertion location for the second sensor based at least in part on the location of the body on which the sensor was inserted in the skin; anddisplaying the recommended next insertion location for the second sensor on the display.","18","15/991634","2018-05-29","2018-0271420","2018-09-27","10368786","2019-08-06","DEXCOM, INC.","Katherine Yerre  Koehler | Leif N.  Bowman | Rian  Draeger | Laura  Dunn | Eli  Reihman","","","","A61B-0005/14532","A61B-0005/14532 | A61B-0005/0022 | A61B-0005/684 | A61B-0005/743 | A61B-0005/748 | G06F-0003/0481 | G06T-0007/70 | G16H-0010/60 | G16H-0040/63 | G16H-0050/70 | H04L-0067/125 | H04N-0005/23293 | A61B-2560/0487 | G06F-0003/0488 | G06F-0003/04842 | G06F-0003/04883 | G06T-2207/30196 | Y02A-0090/26","A61B-005/145","A61B-005/145 | A61B-005/00 | G06F-003/0481 | H04L-029/08 | G06T-007/70 | H04N-005/232 | G16H-040/63 | G16H-010/60 | G16H-050/70 | G06F-003/0484 | G06F-003/0488","","","","","","4919032000997"
"US","US","P","B2","Methods and apparatus for monitoring and encouraging health and fitness","Methods and apparatus are provided for monitoring and encouraging health and fitness. In accordance with a first aspect, an apparatus is provided that is adapted to assist in weight loss and exercise. The apparatus comprises a personal digital assistant (PDA) having computer program code adapted to assist in at least one of calorie counting, meal selection, meal suggestion, weight monitoring, weight loss or gain monitoring, fat consumption monitoring, sugar consumption monitoring and salt consumption monitoring. The PDA also includes computer program code adapted to display historical data regarding at least one of calorie counting, meal selection, meal suggestion, weight monitoring, weight loss or gain monitoring, fat consumption monitoring, sugar consumption monitoring and salt consumption monitoring. Numerous other embodiments are provided, as are methods, systems and computer program products.","1. A system, comprising: a wearable monitor configured to monitor biometric information of a user as the user exercises, wherein the wearable monitor is configured to transmit the biometric information wirelessly as the user exercises; anda handheld electronic device associated with the user, the handheld electronic device being web-enabled, and having computer program code stored therein that, when executed by the handheld electronic device, causes the handheld electronic device to: receive the biometric information transmitted by the wearable monitor as the user exercises;determine exercise level information based on the received biometric information;transmit the exercise level information determined from the received biometric information to a remotely-located server;transmit geographic information about the user to the remotely-located server;receive input from the user indicating a diet and exercise goal;transmit the diet and exercise goal to the remotely-located server;obtain product information for a product determined by the remotely-located server to be consistent with the diet and exercise goal, such determination being based on the exercise level information transmitted to the remotely-located server; andpresent the product information to the user on the handheld electronic device as being consistent with the diet and exercise goal.","8","15/992170","2018-05-29","2018-0271433","2018-09-27","10368803","2019-08-06","Brian M. Dugan","Brian M.  Dugan","","","","A61B-0005/486","A61B-0005/486 | A61B-0005/0022 | A61B-0005/1112 | A61B-0005/4866 | A61B-0005/6824 | A61B-0005/6831 | A61B-0005/6898 | A61B-0005/7475 | A63B-0024/0062 | G06F-0019/00 | G06F-0019/3418 | G06F-0019/3475 | G06F-0019/3481 | G06F-0019/36 | G06Q-0010/087 | G06Q-0030/0621 | G06Q-0030/0623 | G06Q-0030/0631 | G06Q-0030/0633 | G09B-0005/00 | G09B-0005/02 | G09B-0019/0092 | G16H-0020/30 | G16H-0020/60 | G16H-0030/20 | G16H-0040/67 | H05K-0999/99 | A61B-2503/12 | A63B-2024/0068","A63B-024/00","A63B-024/00 | A61B-005/00 | G06F-019/00 | G06Q-010/08 | G06Q-030/06 | G09B-019/00 | G09B-005/00 | A61B-005/11 | G09B-005/02 | G16H-020/30 | G16H-040/67 | G16H-030/20 | G16H-020/60","","","","","","4919032001014"
"US","US","P","B2","Apparatus and method for vascular access","In an aspect, embodiments of the invention relate to the effective and accurate placement of intravascular devices such as central venous catheters, in particular such as peripherally inserted central catheters or PICC. One aspect of the present invention relates to vascular access. It describes devices and methods for imaging guided vascular access and more effective sterile packaging and handling of such devices. A second aspect of the present invention relates to the guidance, positioning and placement confirmation of intravascular devices without the help of X-ray imaging. A third aspect of the present invention relates to devices and methods for the skin securement of intravascular devices and post-placement verification of location of such devices. A forth aspect of the present invention relates to improvement of the workflow required for the placement of intravascular devices.","1. An endovascular device, comprising: a torquable elongate body sized for insertion into the vasculature, the torquable elongate body having a proximal end and a distal end terminating in a distal tip;a sensor on the distal end of the torquable elongate body, the sensor configured to measure a characteristic of blood flow within a blood vessel;a structure on or in the torquable elongate body that is configured to radially expand to move the distal tip of the torquable elongate body away from a peripheral inner surface of the blood vessel while maintaining blood flow within the blood vessel when the structure is radially expanded within the blood vessel; anda signal processor connected to the sensor and the structure, the signal processor being configured to: receive the measured characteristic of blood flow within the blood vessel,determine that the sensor is within a minimum lateral distance from the peripheral inner surface when the peripheral inner surface is peripheral of the sensor based on the measured characteristic of blood flow within the blood vessel, andcause active manipulation of the structure to move the distal tip of the torquable elongate body laterally away from the peripheral inner surface of the blood vessel to the minimum lateral distance to avoid measuring the characteristic of blood flow at a periphery of the blood vessel.","19","15/092588","2016-04-06","2016-0220226","2016-08-04","10368837","2019-08-06","ARROW INTERNATIONAL, INC.","Sorin  Grunwald | Fiona Maria  Sander | Wilfred J.  Samson | Bradley  Hill","","","","A61B-0008/12","A61B-0008/12 | A61B-0005/06 | A61B-0005/411 | A61B-0007/00 | A61B-0008/06 | A61B-0008/0841 | A61B-0008/42 | A61B-0008/445 | A61B-0090/11 | G06Q-0050/22 | A61B-0005/0402 | A61B-0005/1459 | A61B-0008/461 | A61B-0034/20 | A61B-2017/003 | A61B-2017/00106 | A61B-2090/378 | A61B-2090/3782 | A61B-2090/3929","A61B-008/06","A61B-008/06 | A61B-008/12 | A61B-005/06 | A61B-005/00 | A61B-007/00 | A61B-008/08 | A61B-008/00 | G06Q-050/22 | A61B-090/11 | A61B-005/0402 | A61B-005/1459 | A61B-017/00 | A61B-090/00 | A61B-034/20","","","","","","4919032001048"
"US","US","P","B2","Wearable athletic activity monitoring methods and systems","A method for monitoring an individual engaged in an athletic activity includes detecting movement of the individual at a first time, using a sensor module coupled to the individual, determining that the movement of the individual corresponds to a predetermined activation movement, entering an active state of the sensor module in response to the determination that the movement of the individual corresponds to the predetermined activation movement, and detecting movement of the individual at a second time, using the sensor module in the active state.","1. A method for determining reaction time of an individual performing an athletic activity, the method comprising: receiving, at a sensor module coupled to the individual, instructions to perform an instructed movement;sensing magnetic field data and acceleration data during a movement of the individual, using the sensor module;comparing the magnetic field data and the acceleration data with a lookup table including a movement data profile for the instructed movement;identifying, based on the comparison, that the movement corresponds to the movement data profile for the instructed movement; andcalculating a reaction time based on the elapsed time from receipt of the instructions to a point in time with reference to the movement of the individual.","20","15/351900","2016-11-15","2017-0056720","2017-03-02","10369410","2019-08-06","ADIDAS AG","Aurel  Coza | Christian  Dibenedetto | Jeffrey  Allen","","","","A63B-0024/0006","A63B-0024/0006 | A61B-0005/1112 | A61B-0005/162 | A63B-0071/0619 | G06F-0003/011 | G06K-0009/00342 | A61B-2503/10 | A63B-2220/40 | A63B-2220/62 | A63B-2220/836","A61B-005/11","A61B-005/11 | A63B-024/00 | G06F-003/01 | G06K-009/00 | A61B-005/16 | A63B-071/06","","","","","","4919032001619"
"US","US","P","B2","Method to support tumor response measurements","A method comprises the step of determining a minimum length of a lesion based on an imaging modality used to capture an image of the lesion and a slice thickness of the image, generating an extent cursor corresponding to the minimum size of the lesion, the extent cursor having a circular shape with a diameter corresponding to the minimum length and displaying the image of the lesion with the extent cursor positioned thereover.","1. A method, comprising: determining a minimum length of a measurable lesion according to a selected standard based on an imaging modality used to capture an image of a lesion and a slice thickness of the image;generating an extent cursor conforming with the minimum length of the measurable lesion according to the selected standard, the extent cursor having a circular shape with a diameter corresponding to the minimum length; anddisplaying the image of a lesion with the extent cursor positioned thereover.","22","15/028738","2014-10-13","2016-0275676","2016-09-22","10373309","2019-08-06","KONINKLIJKE PHILIPS N.V.","Frank Olaf  Thiele | Martin  Weibrecht","","","","G06T-0007/0012","G06T-0007/0012 | G06F-0003/0485 | G06F-0003/04812 | G06F-0003/04845 | G06T-0007/50 | G06T-0011/60 | A61B-0005/1075 | A61B-0006/12 | A61B-2576/00 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/10104 | G06T-2207/30096","A61B-006/12","A61B-006/12 | G06T-007/00 | G06T-007/50 | A61B-005/107 | G06T-011/60 | G06F-003/0481 | G06F-003/0484 | G06F-003/0485","","","","","","4919032005485"
"US","US","P","B2","Phase-to-amplitude/slope mapping","A method includes obtaining a signal that includes a plurality of cycles and generating a map that maps motion phases to the signal based on both an amplitude and a slope of the signal. A system includes a processor that identifies a set of motion signal timestamps, for a plurality of motion cycles in a motion signal indicative of cyclic motion of a moving object, based on a predetermined motion phase of interest and a phase-to-amplitude/slope mapping, wherein the set of motion signal timestamps correspond to a common signal amplitude. A method include identifying a peak of a plurality of peaks in a motion cycle of a noisy cyclic signal having irregular periodicity, wherein the peak corresponds to a point lying between two points with amplitudes below a predetermined threshold, comparing points before and after the peak with the peak, and identifying the peak as a local maximum when the peak is greater than the points.","1. A system, comprising: a processor configured to:identify a set of motion signal timestamps, for a plurality of motion cycles in a continuous cyclical motion signal indicative of cyclic motion of a moving object, based on a predetermined motion phase of interest and a phase-to-amplitude/slope mapping, wherein the set of motion signal timestamps correspond to a common signal amplitude, wherein each descending amplitude region and each ascending amplitude region of the continuous cyclical motion signal is mapped using a lesser of a mean maximum and a local maximum, and a greater of a mean minimum and a local minimum, and divided for at least one of the local maximum less than the mean maximum or the local minimum greater than the mean minimum; andgenerate volumetric image data based on data acquired by a scanner and the identified set of motion signal timestamps.","14","15/001286","2016-01-20","2016-0135718","2016-05-19","10362970","2019-07-30","KONINKLIJKE PHILIPS N.V","Adam Jacob  Covitch | Paul  Klahr","","","","A61B-0005/113","A61B-0005/113 | A61B-0006/527 | A61B-0006/5288 | A61B-0006/541 | G06F-0017/00 | G06K-0009/0053 | A61B-0005/7285","A61B-005/00","A61B-005/00 | A61B-006/00 | G06K-009/00 | A61B-005/113 | G06F-017/00","","","","","","4919031000783"
"US","US","P","B2","Video monitoring system","An asset tracking system includes a camera adapted to capture images and output signals representative of the images. The camera may include one or more depth sensors that detect distances between the depth sensor and objects positioned within the field of view of the one or more cameras. A computer device processes the image signals and or depth signals from cameras and determines any one or more of the following: (a) whether a patient care protocol has been properly followed; (b) what condition a patient is in; (c) whether an infection control protocol has been properly followed; and (d) whether steps have been taken to reduce the risk of a patient from falling. Alerts may be issued if any conditions of importance are detected.","1. A bed system for a patient care facility comprising: a bed comprising a base, a plurality of wheels coupled to the base, a brake for braking the wheels, and a patient support surface supported on the base and configured to support a patient thereon;a camera positioned within a room of the patient care facility and configured to capture images of a location within the room and output signals representative of the images;a database containing shape information regarding a shape of the bed and identity information regarding identities of staff of the patient care facility; anda computer device in communication with the camera, the database, and the bed, the computer device configured to use the signals and the shape information to determine when the bed is moved into the location, to use the signals and the identity information to identify a staff member accompanying the bed when the bed is moved into the location, to use the signals and the identity information to determine when the staff member departs from the room, and to automatically send a signal to the bed causing the bed to activate the brake on the bed if the staff member does not activate the brake.","20","15/926275","2018-03-20","2018-0227547","2018-08-09","10368039","2019-07-30","Stryker Corporation","Richard A.  Derenne | Richard Thomas  DeLuca | Jason James  Wroblewski | Sanjay  Dhall | Xiyu  Duan | Vishal P.  Lowalekar","","","","H04N-0007/185","H04N-0007/185 | A61B-0005/002 | A61B-0005/0013 | A61B-0005/0033 | A61B-0005/112 | A61B-0005/1113 | A61B-0005/1128 | A61B-0005/7445 | G01B-0011/026 | G06F-0019/3418 | G08B-0021/043 | G08B-0021/0476 | G08B-0021/245 | G16H-0040/20 | H04N-0005/33 | A61B-0005/1115 | A61B-0005/1117 | A61B-0005/1123 | A61B-0005/6889 | A61B-0005/6892 | A61B-0005/7475 | A61B-2505/03 | G06K-0009/00335 | G06K-0009/00771 | G06Q-0050/22 | G08B-0021/22","H04N-007/18","H04N-007/18 | A61B-005/00 | A61B-005/11 | G08B-021/04 | G08B-021/24 | G06F-019/00 | G01B-011/02 | H04N-005/33 | G16H-040/20 | G06K-009/00 | G08B-021/22 | G06Q-050/22","","","","","","4919031005819"
"US","US","P","B2","Variable indication estimator","A variable indication estimator which determines an output value representative of a set of input data. For example, the estimator can reduce input data to estimates of a desired signal, select a time, and determine an output value from the estimates and the time. In one embodiment, the time is selected using one or more adjustable signal confidence parameters determine where along the estimates the output value will be computed. By varying the parameters, the characteristics of the output value are variable. For example, when input signal confidence is low, the parameters are adjusted so that the output value is a smoothed representation of the input signal. When input signal confidence is high, the parameters are adjusted so that the output value has a faster and more accurate response to the input signal.","1. A pulse oximetry system, the pulse oximetry system comprising: an analog signal conditioning circuit that receives signals corresponding to attenuated red and infrared light transmitted through body tissue of a patient, the analog signal conditioning circuit comprising an analog-to-digital conversion circuit that provides first discrete signal values at a first time and second discrete signal values at a second time;a digital-to-analog conversion circuit that provides control signals to emitter current drivers to cause the red and infrared light to transmit through the body tissue; anda digital signal processor that: receives the first discrete signal values and the second discrete signal values from the analog signal conditioning circuit, the first discrete signal values having a first amount of noise greater than a second amount of noise of the second discrete signal values;outputs an emitter control signal to the digital-to-analog conversion circuit;calculates first oxygen saturation values based on the first discrete signal values and second oxygen saturation values based on the second discrete signal values, the first and second oxygen saturation values corresponding with oxygen saturation of the patient'ss blood;adjusts the first oxygen saturation values to produce first adjusted oxygen saturation values by smoothing the first oxygen saturation values, wherein the digital signal processor determines to use said smoothing based at least in part on the first amount of noise;adjusts the second oxygen saturation values to produce second adjusted oxygen saturation values by applying a curve-fit to the second oxygen saturation values, wherein the digital signal processor determines to use the curve-fit based at least in part on the second amount of noise; andoutputs the first and second adjusted oxygen saturation values to a display.","16","15/913044","2018-03-06","2018-0256113","2018-09-13","10357206","2019-07-23","MASIMO CORPORATION","Walter M.  Weber | Ammar  Al-Ali | Lorenzo  Cazzoli","","","","A61B-0005/7271","A61B-0005/7271 | A61B-0005/0002 | A61B-0005/021 | A61B-0005/14551 | A61B-0005/6826 | A61B-0005/6829 | A61B-0005/6838 | A61B-0005/72 | G06K-0009/0051 | A61B-0005/1455 | A61B-0005/7207 | A61B-0005/7239","A61B-005/00","A61B-005/00 | A61B-005/021 | A61B-005/1455 | G06K-009/00","","","","","","4919030000768"
"US","US","P","B2","Systems and methods for planning hair transplantation","Systems and methods for creating a treatment plan for cosmetic procedures are provided. The treatment plan automatically modifies or generates one or more proposed sites within a first body surface element based on one or more parameters in one or more second body surface elements. Various techniques and methods described in the application provide for improved planning of a procedure.","1. A method of planning for modification of a body surface element of a body surface, comprising: generating and displaying on a three-dimensional model of a body surface, at least two body surface elements, each of the respective body surface elements comprising one or more control points, the one or more control points having corresponding parameters associated therewith;associating, with a use of a processor, a first and a second of the at least two body surface elements with each other to form a body surface element group;generating or modifying at least one site within or on the first body surface element, based at least in part on the parameters of at least one of the one or more control points of the second body surface element.","28","15/943310","2018-04-02","2018-0221094","2018-08-09","10357316","2019-07-23","RESTORATION ROBOTICS, INC.","(Radhika) Mohan  Bodduluri | Hui  Zhang | Gabriele  Zingaretti | Theodore Thuong  Nguyen","","","","A61B-0034/10","A61B-0034/10 | A61F-0002/10 | G06F-0003/0482 | G06F-0003/04842 | G06T-0007/0012 | A61B-2034/105 | A61B-2034/107 | G06T-2200/24 | G06T-2207/20104 | G06T-2207/30088","A61B-005/00","A61B-005/00 | A61B-034/10 | A61F-002/10 | G06F-003/0482 | G06F-003/0484 | G06T-007/00","","","","","","4919030000878"
"US","US","P","B2","System and method for controlling a remote medical device guidance system in three-dimensions using gestures","A system for enabling a user to remotely control a robotic medical device system includes a motion capture apparatus to capture motion of a user in a sensing volume and generate indicative output data. The system includes a control unit configured to execute gesture recognition logic that recognizes a user gesture based on analysis of the indicative output data. The control unit executes interpreter logic that is configured to translate the recognized user gesture into a corresponding robotic medical device control command configured to control an aspect of the operation of the robotic medical device system.","1. A system for enabling a user to remotely control a robotic medical device system, comprising: a motion capture apparatus configured to capture motion of a user in a sensing volume and generate output data indicative of the captured user motion, wherein said output data includes fiducial point tracking data associated with a plurality of fiducial points;an electronic control unit including a processor and a memory;gesture recognition logic stored in said memory and configured to execute on said processor, said gesture recognition logic being configured to recognize a user gesture based on said output data from said motion capture apparatus, said gesture recognition logic being configured to compare a time-based motion of the fiducial points with a plurality of predefined gestures and to output the recognized user gesture when the time-based motion matches one of the plurality of gestures wherein said time-based motion of fiducial points comprises at least a sequence of time-based positions traversed by the fiducial points over a plurality of times; andinterpreter logic stored in said memory and configured to execute said processor, said interpreter logic being configured to translate the user gesture to a corresponding robotic medical device control command, said command being configured to control an aspect of the operation of the robotic medical device system that includes a medical device and a manipulator assembly including at least one electrically-operated actuation unit configured for one of translation, deflection and rotation of the medical device, said electronic control unit being configured to communicate said command to the robotic medical device system.","19","15/252500","2016-08-31","2017-0049524","2017-02-23","10357322","2019-07-23","ST. JUDE MEDICAL, ATRIAL FIBRILLATION DIVISION, INC.","Eric S.  Olson","","","","A61B-0034/74","A61B-0034/74 | A61B-0005/042 | A61B-0034/25 | A61B-0034/76 | B25J-0009/161 | G06F-0003/014 | G06F-0003/017 | G06F-0003/03545 | G06K-0009/00335 | G06T-0019/003 | A61B-0034/30 | A61B-2034/258 | A61B-2034/741 | G06T-2210/41","A61B-034/00","A61B-034/00 | A61B-005/00 | G06T-019/00 | G06F-003/01 | G06F-003/0354 | A61B-005/042 | B25J-009/16 | G06K-009/00 | A61B-034/30","","","","","","4919030000884"
"US","US","P","B2","Safe driving support via automotive hub","A method for providing safe-driving support of a vehicle includes obtaining occupant data and vehicle data received at a vehicle hub. The occupant data is related to an identity and health status of an occupant and the vehicle data is related to a status of the vehicle. The method also includes obtaining action data based on an application of the occupant data and vehicle data to a machine learning safe-driving model. The machine learning safe-driving model is associated with a user profile of the occupant that is identified from among a plurality of user profiles based on the occupant data. A server maintains a plurality of user profiles, each having a respective machine learning safe-driving model. The action data relates to an action to be performed by the vehicle while the occupant is located in the vehicle.","1. A method of providing safe-driving support of a vehicle, the method comprising: transmitting to a safe-driving server occupant data and vehicle data received at a vehicle hub of the vehicle, where the occupant data is related to an identity and health status of an occupant of the vehicle, and wherein the vehicle data is related to a status of the vehicle;receiving from the safe-driving server a machine learning safe-driving model associated with a user profile of the occupant, wherein the user profile is identified from among a plurality of user profiles based on the occupant data, and wherein the machine learning safe-driving model is one of a plurality of machine learning safe-driving models, each of the plurality of machine learning safe-driving models associated with a respective one of the plurality of user profiles maintained at the safe-driving server;applying the occupant data and the vehicle data to]the machine learning safe-driving model associated with the user profile of the occupant to generate action data, wherein the action data relates to an action to be performed by the vehicle while the occupant is located in the vehicle; andperforming the action based on the action data at the vehicle, wherein performing the action at the vehicle comprises at least one of: implementing a parental control related to the occupant of the vehicle, limiting cellular data access of a mobile device located within the vehicle, disabling of text messaging by the mobile device, limiting multimedia content available by an infotainment system of the vehicle, deactivating an engine of the vehicle, limiting a speed of the vehicle, providing a route via a navigation system of the vehicle, or providing a safe-driving recommendation to a driver of the vehicle.","24","15/461468","2017-03-16","2018-0265095","2018-09-20","10358142","2019-07-23","QUALCOMM INCORPORATED","Gregory Hobert  Joe | Arthur  James | Srdjan  Miocinovic | Sandipan  Kundu","","","","B60W-0050/0098","B60W-0050/0098 | A61B-0005/021 | A61B-0005/024 | A61B-0005/18 | A61B-0005/4845 | B60K-0028/02 | B60K-0028/06 | B60W-0010/04 | B60W-0010/30 | B60W-0040/04 | B60W-0040/06 | B60W-0040/08 | B60W-0040/09 | B60W-0050/14 | G06N-0020/00 | B60W-2040/089 | B60W-2040/0809 | B60W-2040/0818 | B60W-2040/0872 | B60W-2040/0881 | B60W-2420/42 | B60W-2540/22 | B60W-2540/24 | B60W-2540/26 | B60W-2540/28 | B60W-2540/30 | B60W-2550/12 | B60W-2550/40 | B60W-2550/408 | B60W-2710/06 | B60W-2710/30 | B60W-2720/10 | G01S-0019/13 | H04L-0067/12","B60W-040/08","B60W-040/08 | B60W-050/00 | B60W-010/04 | B60W-010/30 | B60W-050/14 | A61B-005/18 | A61B-005/00 | A61B-005/021 | A61B-005/024 | B60K-028/02 | B60K-028/06 | B60W-040/04 | B60W-040/06 | B60W-040/09 | G06N-020/00 | G01S-019/13 | H04L-029/08","","","","","","4919030001695"
"US","US","P","B2","Information processing system and information processing method","An information processing system includes: first and second information processing apparatuses; a detector that detects an eye-gaze direction of a user that uses the first information processing apparatus; a gaze point information generator that generates, on the basis of the eye-gaze direction, gaze point information indicating a position at which the user gazes on first screen information commonly displayed on the first and second information processing apparatuses; and a display controller that controls a display image to be displayed on the second information processing apparatus when calibration for determining a correspondence relation between the eye-gaze direction of the user and an actual gaze position is executed. The display image is generated on the first screen information and includes a second image displayed at a position indicated by the gaze point information and a third image displayed at a gaze instruction position at which the user is made to gaze.","1. An information processing system comprising: a first information processing apparatus including a first display, a sensor and a first processor, the first processor configured to, detect an eye-gaze direction of a first user that uses the first information processing apparatus based on data from the sensor, andgenerate, basis on the eye-gaze direction, gaze point information indicating an actual gaze position at which the first user actually gazes within coordinates of a first copy of first screen information displayed on the first display associated with the first information processing apparatus; anda second information processing apparatus communicable with the first information processing apparatus, the second information processing apparatus including a second display and a second processor, the second processor configured to calibrate a correspondence relation between the eye-gaze direction of the first user and the actual gaze position of the first user by, determining a position at which the first user is expected to gaze within the coordinates of the first screen information displayed on the first display as a gaze instruction position,superimposing both the actual gaze position and the gaze instruction position of the first user on a second copy of the first screen information to generate a superimposed screen information, andcontrolling, the second display, to display the superimposed screen information such that the first screen information is commonly displayed with the first copy thereof being displayed on the first display and the second copy including the superimposed screen information being displayed on the second display associated with a second user.","19","14/848817","2015-09-09","2016-0077585","2016-03-17","10359842","2019-07-23","RICOH COMPANY, LIMITED","Takuya  Mizuhara","2014-188295 | 2015-174042","JP | JP","2014-09-16 | 2015-09-03","G06F-0003/013","G06F-0003/013 | A61B-0003/113 | A61B-0005/00 | G06F-0003/0482 | G06F-0003/04842 | A61B-0003/00 | G06K-0009/00604","A61B-003/113","A61B-003/113 | A61B-005/00 | G06F-003/0482 | G06F-003/01 | G06F-003/0484 | G06K-009/00 | A61B-003/00","","","","","","4919030003383"
"US","US","P","B2","System and method for generating pseudo electrogram","Provided are a system and method for generating a pseudo electrogram. The system for generating the pseudo electrogram includes a unipolar electrogram generation unit which generates a unipolar electrogram according to an action potential calculated from an electric physiological model of the heart using a pseudo electrode in which a cross-sectional area is adjusted, and a pseudo electrogram generation unit which generates a pseudo electrogram using the unipolar electrogram.","1. A system for generating a pseudo electrogram comprising: a computer configured to have a unipolar electrogram generation unit configured to generate a unipolar electrogram according to an action potential calculated from an electric physiological model of the heart using a pseudo electrode in which a cross-sectional area is adjusted,the cross-sectional area of the pseudo electrode is set to increase in accordance with electrode contact states of the pseudo electrode,the electrode contact states of the pseudo electrode are classified into three states of a good state, a normal state, and a non-good state,the cross-sectional area of the pseudo electrode in the normal state is four times the cross-sectional area of the pseudo electrode in the non-good state, andthe cross-sectional area of the pseudo electrode in the good state is twice the cross-sectional area of the pseudo electrode in the normal state; anda pseudo electrogram generation unit configured to generate a pseudo electrogram using the unipolar electrogram, the pseudo electrode comprises a first electrode and a second electrode,the unipolar electrogram generation unit generates the unipolar electrogram according to the following equation wherein S1: the cross-sectional area of the pseudo electrode,S2: a cross-sectional area of a unit cell,x0: a location of a tip of the pseudo electrode on an x-axis,k: the number of cells occupied by the electrode on the x-axis,y0: a location of a tip of the pseudo electrode on a y-axis,l: the number of cells occupied by the electrode on the y-axis,V(x,y): the action potential being a unipolar potential for the tip of the pseudo electrode at the location on the x-axis and the y-axis.","6","14/426400","2013-09-06","2015-0242587","2015-08-27","10360281","2019-07-23","INDUSTRY-ACADEMIC COOPERATION FOUNDATION, YONSEI UNIVERSITY","Hui Nam  Pak | Yong Hyeon  Yun","10-2012-0099076","KR","2012-09-07","G06F-0017/11","G06F-0017/11 | A61B-0005/04021 | A61B-0005/7278 | G06F-0019/00 | G16H-0050/50 | A61N-0001/365","G06F-017/11","G06F-017/11 | G06F-017/50 | A61B-005/0402 | A61B-005/00 | G16H-050/50 | G06F-019/00 | A61N-001/365","","","","","","4919030003818"
"US","US","P","B2","Methods and systems for automatically analyzing clinical images using rules and image analytics","Methods and systems for automatically analyzing clinical images using rules and image analytics. One system includes a server including an electronic processor and an interface for communicating with at least one data source. The electronic processor is configured to receive training information from the at least one data source over the interface. The training information includes a plurality of images and graphical reporting associated with each of the plurality of images. The electronic processor is also configured to perform machine learning to develop a model using the training information and receive an image for analysis. The electronic processor is also configured to determine a set of rules for the image and automatically process the image using the model and the set of rules to generate a diagnosis for the image.","1. A system for automatically analyzing clinical images using rules and image analytics developed using graphical reporting associated with previously-analyzed clinical images, the system comprising: a server including an electronic processor and an interface for communicating with at least one data source, the electronic processor configured to receive training information from the at least one data source over the interface, the training information including a plurality of images and graphical reporting associated with each of the plurality of images, each graphical reporting including a graphical marker designating a portion of one of the plurality of images and diagnostic information associated with the portion of the one of the plurality of images,perform machine learning to develop a model using the training information,receive an image for analysis,determine a set of rules for the image, andautomatically process the image using the model and the set of rules to generate a diagnosis for the image.","17","15/179506","2016-06-10","2016-0364631","2016-12-15","10360675","2019-07-23","INTERNATIONAL BUSINESS MACHINES CORPORATION","Murray A.  Reicher | Jon T.  DeVries | Michael W.  Ferro, Jr. | Marwan  Sati","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/0033 | A61B-0005/7267 | A61B-0010/02 | A61B-0034/10 | G06F-0003/0482 | G06F-0003/0488 | G06F-0017/241 | G06F-0017/2705 | G06F-0019/00 | G06F-0019/321 | G06F-0019/36 | G06K-0009/627 | G06K-0009/6227 | G06K-0009/6232 | G06K-0009/6256 | G06K-0009/6262 | G06K-0009/6269 | G06K-0009/66 | G06N-0020/00 | G06T-0007/0014 | G06T-0011/008 | G16H-0010/20 | G16H-0015/00 | G16H-0030/20 | G16H-0050/20 | G16H-0050/50 | A61B-0005/0077 | A61B-0005/015 | A61B-0005/0402 | A61B-0005/055 | A61B-0005/4312 | A61B-0005/441 | A61B-2034/108 | A61B-2090/373 | A61B-2090/374 | A61B-2090/378 | A61B-2090/3762 | G06K-2209/051 | G06T-2200/24 | G06T-2207/10088 | G06T-2207/20081 | G06T-2207/30004 | G06T-2207/30008 | G06T-2207/30016 | G06T-2207/30052 | G06T-2207/30061 | G06T-2207/30068 | G06T-2207/30088","G06K-009/00","G06K-009/00 | G06T-007/00 | G06F-019/00 | G16H-050/50 | G16H-015/00 | G16H-050/20 | G06N-020/00 | A61B-005/00 | G06F-003/0488 | G06K-009/62 | A61B-034/10 | G06F-003/0482 | A61B-010/02 | G06T-011/00 | G06F-017/24 | G06F-017/27 | G06K-009/66 | G16H-030/20 | G16H-010/20 | A61B-090/00 | A61B-005/01 | A61B-005/0402 | A61B-005/055","","","","","","4919030004210"
"US","US","P","B2","Methods and systems for journaling and coaching using a wearable device","A method to create autonomous decision logic (ADL) may include receiving a request to create the ADL. The request includes a selection of an input and a selection of an output. When executed by a client device, the ADL is configured to provide the output based at least partially on an identification of the input. The method further includes electronically packaging the input and the output to generate the ADL. The method includes sending the ADL via a transport layer to the client device for execution of the ADL on the client device. The client device is configured to generate encrypted data pertaining to the execution of the ADL. The method includes receiving, from the client device, the encrypted data pertaining to the execution of the ADL. The method further includes decrypting the encrypted data. The method includes presenting at least some of the decrypted data on a display.","1. A method comprising: receiving a request to create autonomous decision logic (ADL), wherein the request includes a selection of an input, a selection of an output, a selection of a security setting that includes encryption information for data generated by the ADL; and an expiration condition for the ADL, where the expiration condition is a pre-determined time or condition, and wherein when executed by a client device, the ADL is configured to provide the output based at least partially on an identification of the input;electronically packaging the input, the output, and the security setting to generate the ADL;sending the ADL via a transport layer to the client device for execution of the ADL on the client device, wherein the client device is configured to generate encrypted data pertaining to the execution of the ADL and based on the security setting;receiving, from the client device, the encrypted data pertaining to the execution of the ADL;decrypting the encrypted data;presenting at least some of the decrypted data on a display; andstopping execution of the ADL or deleting the ADL from the client device based on a satisfaction of the expiration condition.","20","15/194145","2016-06-27","2017-0374036","2017-12-28","10362002","2019-07-23","BIOINTELLISENSE, INC.","Mark A.  Ross | David Jonq  Wang","","","","H04L-0063/0428","H04L-0063/0428 | A61B-0005/0002 | A61B-0005/02 | A61B-0005/021 | A61B-0005/0205 | A61B-0005/1118 | G06F-0001/163 | G06N-0005/02","H04L-029/06","H04L-029/06 | G06N-005/02 | A61B-005/00 | A61B-005/02 | A61B-005/0205 | A61B-005/021 | A61B-005/11 | G06F-001/16","","","","","","4919030005526"
"US","US","P","B2","Method of detecting boundary between iris and sclera","A method of detecting the boundary between the iris and the sclera, particularly, a method of detecting the boundary between the iris and the sclera from part of a captured image of a user's eye area, is provided. According to this method, the boundary between the iris and the sclera can be quickly and precisely detected, compared to when using an existing circular boundary detector.","1. A method of detecting the boundary between the iris and the sclera, comprising: receiving a captured image of a user'ss eye area;selecting pixels included in a predefined region of the received image;selecting pixels in the same direction with respect to the center of the pupil from among the selected pixels from the predefined region;creating one or more pixel groups by selecting a predefined number of pixels from among the selected pixels in the same direction with respect to the center of the pupil;calculating a feature value of each of the pixel groups by comparing brightnesses of each pair of adjacent pixels included in a corresponding pixel group;selecting a pixel group having a largest feature value and calculating a first sum of brightnesses of pixels to the left of each pixel in the selected pixel group and a second sum of brightnesses of pixels to the right of a corresponding pixel, starting from a pixel at the center of the selected pixel group and proceeding in sequence to the pixels to the left of the center pixel; anddetermining one or more pixels having a larger first sum than a second sum as pixels corresponding to the boundary between the iris and the sclera.","10","15/632876","2017-06-26","2018-0168446","2018-06-21","10349832","2019-07-16","3E CO., LTD.","Min Ho  Kim","10-2016-0175219","KR","2016-12-21","A61B-0003/12","A61B-0003/12 | A61B-0005/1171 | G06F-0021/32 | G06K-0009/00597 | G06K-0009/00906 | G06K-0009/4609 | G06K-0009/52 | G07C-0009/00158 | A61B-0005/117 | G06K-0009/00","A61B-003/12","A61B-003/12 | G06K-009/00 | G06K-009/46 | G06K-009/52 | G07C-009/00 | A61B-005/117 | G06F-021/32 | A61B-005/1171","","","","","","4919029000900"
"US","US","P","B2","Method and system for verifying panoramic images of implants","A pre-planning interface displaying step of a method for verifying panoramic images of implants is for displaying a picture, a menu and a cursor on a screen. An implant trajectory pattern adding step is for moving the cursor to select an implant adding item by a user and then generating the implant trajectory pattern in the picture. An implant trajectory pattern adjusting step is for controlling the cursor to adjust a position of the implant trajectory pattern and then move the implant trajectory pattern from a starting position to a target position in the picture. A panoramic image verifying step is for rotating the surgical site pattern around the implant trajectory pattern at a viewing angle according to the target position and the implant trajectory pattern as a central axis, and the viewing angle is greater than 0 degrees and smaller than or equal to 180 degrees.","1. A method for verifying panoramic images of implants and checking a relative position between an implant trajectory pattern and a surgical site pattern, the method comprising: providing a pre-planning interface displaying step, wherein the pre-planning interface displaying step is for displaying at least one picture, a menu and a cursor on a screen, and the picture has the surgical site pattern;providing an implant trajectory pattern adding step, wherein the implant trajectory pattern adding step is for moving the cursor to select an implant adding item of the menu by a user and then generating the implant trajectory pattern in the picture, and the implant trajectory pattern is located at a starting position;providing an implant trajectory pattern adjusting step, wherein the implant trajectory pattern adjusting step is for controlling the cursor to adjust a position of the implant trajectory pattern and then move the implant trajectory pattern from the starting position to a target position in the picture; andproviding a panoramic image verifying step, wherein the panoramic image verifying step is for rotating the surgical site pattern around the implant trajectory pattern at a viewing angle according to the target position and the implant trajectory pattern as a central axis, and the viewing angle is greater than 0 degrees and smaller than or equal to 180 degrees;wherein the viewing angle θ is sequentially changed from 0 degrees to 180 degrees according to a time interval and an angular interval.","20","15/663817","2017-07-30","2018-0132940","2018-05-17","10350010","2019-07-16","INTAI TECHNOLOGY CORP.","Kuo-Tung  Kao | Chen-Tai  Lin | Ying-Yi  Cheng | Shih-Chang  Chuang | Chih-Yen  Chiang","2017-10281546","CN","2017-04-26","A61B-0034/10","A61B-0034/10 | A61B-0017/7001 | A61B-0090/37 | G06F-0003/0482 | G06F-0003/04845 | G06T-0003/4038 | G06T-0003/60 | A61B-2017/568 | A61B-2034/107 | A61B-2090/364 | A61B-2560/0487 | G06F-0003/04815 | G06T-2200/24 | G06T-2210/41","G06K-009/00","G06K-009/00 | A61B-034/10 | A61B-017/70 | A61B-090/00 | G06F-003/0482 | G06F-003/0484 | G06T-003/60 | G06T-003/40 | G06F-003/0481 | A61B-017/56","","","","","","4919029001078"
"US","US","P","B2","Method and apparatus for mapping a region of a body","A method of generating a topographic map of a region of a body for the manufacture of a body fitting article to be fitted to the region of the body. The method allows for the resultant topographical map of the body feature to be coupled to an anatomical and functional datum on the body. The method involves use of a contact probe which is configured to generate positional data which defines the surface it is drawn across. The method comprises the steps of urging a contact probe towards the outer surface of the body such that the contact probe is touching the outer surface of the body or separated from the outer surface of the body only by a barrier layer which is flattened against the outer surface of the body by the probe. The contact probe is drawn over the region of the body where the body fitting article is to be located such that the contact probe generates 3D positional data of the surface of the outer surface of the body in the region of the body where the body fitting article is to be located.","1. A method comprising: placing a contact probe in contact with either an outer surface of a region of a body or a barrier layer which is flattened against the outer surface of the region of the body by the contact probe, the contact probe being configured to generate, while the contact probe is drawn over the outer surface of the region of the body, a first set of 3D positional data which defines the outer surface of the region of the body, wherein a body fitting article is to be fitted over the outer surface of the region of the body;drawing the contact probe over the region of the outer surface of the region of the body where the body fitting article is to be fitted, such that the contact probe generates the first set of 3D positional data;touching a pre-determined datum location on a reference fixture with the contact probe to generate a second set of 3D positional data which defines a datum position on the body spaced apart from the region of the body where the body fitting article is to be fitted, wherein the first and second sets of 3D position data are different; andcausing a computer aided design (CAD) tool to process a surface map based on the first and second sets of 3D positional data such that the surface map conforms to a shape of the region of the body where the body fitting article is to be fitted, orcausing a manufacturing tool to manufacture the body fitting article according to the surface map, orboth.","15","15/125748","2015-03-10","2017-0010603","2017-01-12","10353377","2019-07-16","BAE SYSTEMS PLC","Martyn  Ingleton | Jordan Henry Walker  Jenkins | Tom Hon Pan  Yip | Raife Edwin Thompson  Norman","2014-275061 | 2014004527","EP | GB","2014-03-14 | 2014-03-14","G05B-0019/4099","G05B-0019/4099 | A61B-0005/1077 | G01B-0005/20 | G01B-0007/003 | G06F-0003/0346 | G06F-0017/50 | A42C-0002/007 | A61B-0005/6843 | G05B-2219/49023","G06F-019/00","G06F-019/00 | G05B-019/4099 | A61B-005/107 | G01B-005/20 | G06F-003/0346 | G01B-007/00 | G06F-017/50 | A42C-002/00 | A61B-005/00","","","","","","4919029004429"
"US","US","P","B2","Eye and head tracking device","An apparatus and method of use for tracking eye and head movement comprising (1) at least one optoelectronic array sensor or optical flow sensor formed of a plurality of optoelectronic sensor cells; (2) a body configured to support the optoelectronic array sensor with focusing means along with a source of light with collimating means in front of and in proximity to an eye of a user; (3) an optical focusing means to focus an image of the ocular surface of the user on the optoelectronic array sensor; (4) a focusing lens with a source of light; (5) a means to detect blinking; (6) a driver configured to receive signals from the sensor array to generate coordinate signals corresponding to changes in the position of the ocular surface relative to the sensor array; and (7) a means to detect user's additional input and gestures.","1. An apparatus for tracking eye and head movement comprising: a. at least one optoelectronic array sensor or optical flow sensor formed of a plurality of optoelectronic sensor cells and comprising an image sensor chip connected to a processor programmed to run an optical flow algorithm or a vision chip including an integrated circuit having both an image sensor and a processor on a same die;b. a body configured to support the at least one optoelectronic array sensor with focusing means along with a source of light with collimating means in front of and in proximity to an eye of a user and configured to adjust a distance between the at least one optoelectronic array sensor and the eye of the user to allow for proper focusing of the at least one optoelectronic array sensor;c. an optical focusing means to focus an image of the ocular surface of the user on the at least one optoelectronic array sensor in front of the eye of the user at a proximate distance corresponding to a focusing power of the optical focusing means such that an eyelash of the user does not reach to the optical focusing means in front of the eye, wherein a focusing distance to the at least one optoelectronic array sensor is adjustable to maintain a focused image of the ocular surface including an optical texture of the ocular surface formed by irregularities comprising one or more of the group consisting of optical imperfections, conjunctival blood vessels, conjunctival glands and uneven thickness of the tear film, the focused image of the ocular surface forming a corresponding image on the at least one optoelectronic array sensor with distinct shadows;d. a focusing lens with a source of light;e. a means to detect blinking;f. a driver configured to receive signals from the sensor array to generate coordinate signals corresponding to changes in the position of the ocular surface relative to the sensor array;g. a means to detect user'ss additional input and gestures and one or more of the group comprising a sound activated switch; a motion-activated switch facing the eyebrows and attached to the body of the apparatus; a voice recognition module configured to receive voice commands from the user; an airflow-activated switch attached via mechanical means to the body of the apparatus and facing the mouth of the user; a mechanical switch; a front facing camera attached to the body of the apparatus; a back facing camera attached to the body of the apparatus; a feedback device attached to the body of the apparatus; and combinations thereof; andh. wherein the apparatus is computer controlled and provides an output indicative of an amount and direction of eye movements in an orbit of the eye to move a cursor on a computer screen as a pointing device for the user to control a computer device, enabling the user to use the apparatus to perform one or more of the group consisting of moving a computer cursor to point to an icon on a screen to activate the icon, selecting different options on a video display, and using gestures to control the computer device.","20","15/114904","2015-01-28","2016-0342206","2016-11-24","10353460","2019-07-16","Tarek A Shazly | Salwa A Abdelwahed","Tarek A  Shazly | Salwa A  Abdelwahed","","","","G06F-0003/013","G06F-0003/013 | A61B-0003/113 | A61B-0005/1114 | G02C-0011/10 | G06F-0003/012 | G06F-0003/017 | G06F-0003/0304 | G06K-0009/00335 | G06K-0009/00604 | G06T-0011/60 | A61B-0005/0077 | A61B-2562/0219 | G02B-2027/0178 | G06T-2207/30204","G06F-003/01","G06F-003/01 | A61B-003/113 | A61B-005/11 | G02C-011/00 | G06F-003/03 | G06K-009/00 | G06T-011/60 | G02B-027/01 | A61B-005/00","","","","","","4919029004511"
"US","US","P","B2","Technology to facilitate and promote the use of environmentally-friendly transport","The present invention provides a portable processing device comprising a journey type determining module, a journey length determining module and a communication module. The journey type determining module is operable to determine whether a journey undertaken by a person carrying the portable processing device is an environmentally-friendly journey comprising a journey undertaken in an environmentally-friendly vehicle, a journey undertaken using self-propelled means or a journey undertaken on foot. The journey length determining module is operable to determine a length of a said environmentally-friendly journey undertaken by the person carrying the portable processing device. The communication module is operable to transmit journey data to record management apparatus defining the length of the environmentally-friendly journey undertaken by the person carrying the portable processing device.","1. A portable processing device, comprising: a journey type determining module operable to determine whether a journey undertaken by a person carrying the portable processing device is an environmentally-friendly journey comprising a journey undertaken in an environmentally-friendly vehicle, a journey undertaken using self-propelled means or a journey undertaken on foot, wherein an environmentally-friendly vehicle comprises a vehicle wherein at least one of: (i) its emissions are below an environmental emissions threshold value, and (ii) at least a threshold amount of its energy comes from renewable sources, and wherein the journey type determining module is configured to detect a signal transmitted by an identification device carried in an environmentally-friendly vehicle;a journey length determining module operable to determine a length of a said environmentally-friendly journey undertaken by the person carrying the portable processing device, wherein for a journey undertaken in an environmentally-friendly vehicle, the journey length determining module is configured to repeatedly determine whether the journey type determining module has received a signal from a said identification device and to determine a journey length based on a duration over which the journey type determining module has received signals from said identification device; anda communication module operable to transmit journey data to record management apparatus defining the length of the environmentally-friendly journey undertaken by the person carrying the portable processing device.","19","15/515917","2015-09-25","2017-0311132","2017-10-26","10356563","2019-07-16","SENSYNE HEALTH GROUP LIMITED","Paul Rudd  Drayson | Manuel  Pinuela Rangel","","","","H04W-0004/046","H04W-0004/046 | A61B-0005/1123 | A61B-0005/681 | G06F-0019/3481 | G06Q-0010/10 | A61B-2560/0242 | G06F-0016/23 | G06Q-0030/0233 | Y02A-0090/26","G06Q-010/10","G06Q-010/10 | A61B-005/11 | H04W-004/04 | A61B-005/00 | G06F-019/00 | G06F-016/23 | G06Q-030/02","","","","","","4919029007600"
"US","US","P","B2","Wireless implantable data communication system, method and sensing device","Disclosed herein is a wireless implantable communication system, method and sensing device, wherein an implantable data conversion module is adapted for operative coupling to a distinct or integrated implantable sensing device for the conversion of a characteristic signal for transmission thereof to an external receiver, e.g. by way of an inductive element. Upon positioning an external inductive element in the vicinity of the implanted device, a corresponding signal is induced within the external element allowing for reconstruction of the converted signal, and thereby allowing for recovery of the characteristic signal. Embodiments for the communication of data across a biological barrier, including communications from an external transmitter to an implanted receiver, an implanted transmitter to an external receiver, and an implanted transmitter/receiver pair are also disclosed.","1. A system for communicating data across a biological barrier, the system comprising: an implantable device suitable for implantation in a body and comprising a sensing device for generating a characteristic signal representative of an internal characteristic of the body, a signal conversion module operatively coupled to said sensing device for converting said characteristic signal into an encoded signal defined by successive width-encoded pulses representative of said characteristic signal, wherein each width-encoded pulse comprises a substantially square wave signal having a rise, a substantially constant value, and a fall, and an implantable inductor operatively coupled to said signal conversion module for propagation therethrough of said encoded signal,wherein each said rise and fall in said encoded signal is defined to induce a corresponding positive pulse and negative pulse, respectively, on an external inductor for external reconstruction, and the substantially constant value of each width-encoded pulse being of a width that causes the induced positive and negative pulses to be separated by a flat zero signal.","17","15/823121","2017-11-27","2018-0078137","2018-03-22","10342426","2019-07-09","MYNDTEC INC.","Milos R.  Popovic | Massimo  Tarulli | Aleksandar  Prodic | Santa Concepcion  Huerta Olivares","","","","A61B-0005/0022","A61B-0005/0022 | A61B-0005/0006 | A61B-0005/0031 | A61B-0005/14552 | A61B-0005/7225 | A61F-0002/08 | A61F-0002/72 | A61M-0005/172 | A61N-0001/3606 | A61N-0001/36036 | A61N-0001/37217 | G06F-0003/015 | A61B-0005/04 | A61F-2002/0894 | A61N-0001/0534 | A61N-0001/36064 | A61N-0001/36067 | A61N-0001/36082 | A61N-0001/36125 | A61N-0001/37223 | H04B-0005/0031 | H04B-0005/0037 | H04B-0005/0081","A61B-005/00","A61B-005/00 | A61B-005/04 | A61F-002/08 | A61F-002/72 | A61N-001/05 | A61N-001/36 | G06F-003/01 | H04B-005/00 | A61M-005/172 | A61N-001/372 | A61B-005/1455","","","","","","4919028000922"
"US","US","P","B2","Sensor-controlled display output for dialysis machines","A medical apparatus, such as a dialysis machine (e.g. a hemodialysis machine or a peritoneal dialysis machine), includes a plurality of components, one or more sensors corresponding to the components and configured to detect signals, a display and a control unit. The control unit is configured to: receive signals from the one or more sensors, determine, from the signals, a status of the medical apparatus, and determine control commands for the display based on the determined status for status-dependent control of the display. The described apparatus improves the human-machine interface in terms of set-up time, operating time and freedom from errors. Depending upon the determined status, different status-specific menus may be illustrated on the display in order to assist the user when operating the apparatus or advise the user about any errors or subsequent steps.","1. A medical apparatus, comprising: a plurality of components;one or more sensors corresponding to one or more of the plurality of components, configured to detect signals;a display; anda controller, configured to: receive signals from the one or more sensors,determine, from the signals, a current status of the medical apparatus,determine, based on the current status of the medical apparatus, a predicted status of the medical apparatus, anddetermine control commands for the display based on the determined predicted status for status-dependent control of the display;wherein the display is configured to display the determined control commands;wherein the current status of the medical apparatus comprises the medical apparatus being open; andwherein determining the predicted status of the medical apparatus comprises determining that the medical apparatus will undergo maintenance based on the medical apparatus being open and further based on maintenance planning data.","17","15/360324","2016-11-23","2017-0172695","2017-06-22","10342634","2019-07-09","FRESENIUS MEDICAL CARE DEUTSCHLAND GMBH","Pia Nora  Daniel","10-2015-122347","DE","2015-12-21","A61B-0090/37","A61B-0090/37 | A61M-0001/14 | A61M-0001/16 | A61M-0001/1652 | A61M-0001/3672 | G06F-0003/0482 | G06F-0003/04842 | G06F-0003/04847 | G06F-0003/14 | G06F-0009/453 | G16H-0040/63 | A61M-2205/3327 | A61M-2205/3592 | A61M-2205/502 | A61M-2205/505 | A61M-2205/583","G06F-003/0484","G06F-003/0484 | A61M-001/14 | A61B-090/00 | G06F-009/451 | A61M-001/36 | G06F-003/0482 | G06F-003/14 | A61M-001/16 | G16H-040/63","","","","","","4919028001129"
"US","US","P","B2","System and method for determining target stimulation volumes","A system and method may include determining a target stimulation volume based on modifying a patient population image for which an efficacious volume had been determined. A system and method for suggesting stimulation devices may include determining which stimulation device is capable of producing an output volume of activation that most closely matches the target volume. A system and method for facilitating selection of stimulation parameters may include graphically identifying a maximum volume in which tissue is stimulatable by an implanted stimulation device. A system and method may pre-compute volumes of activation that result from a predetermined modification of programming settings. A system and method may transmit stimulation programming settings from a stimulation programming module to a stimulation generating device.","1. A system of selecting a stimulation device combination, comprising: a computer processor configured to: receive information pertaining to a position for implantation of each of a plurality of stimulation devices within an anatomical region of a subject patient, wherein each of the stimulation devices comprises a leadwire comprising i) at least one set of multiple electrodes disposed around a perimeter of the leadwire at a same longitudinal level of the leadwire and ii) a non-electrode marker disposed at a different level of the leadwire and formed of a same material as the electrodes and arranged on the leadwire so that a rotational position of the non-electrode marker coincides with a rotational position of one of the electrodes of at least one of the at least one set, wherein, for each of the stimulation devices, the information pertaining to a position for implantation of each of a plurality of stimulation devices comprises at least one axial CT slice of the leadwire at the level of the non-electrode marker and at least one axial CT slice of the leadwire at a level of one of the at least one set of multiple electrodes, wherein the axial CT slices indicate a rotational orientation of the leadwire;receive information pertaining to a target volume of activation;determine, by the computer processor and based on the positions for implantation of the plurality of stimulation devices, which of the plurality of stimulation devices is capable of producing an output volume of activation that, compared to volumes of activation producible by others of the plurality of stimulation devices, most closely matches the target volume of activation when in the position;output an identification of the determined stimulation device and the corresponding position for implantation;receive a set of stimulation programming settings;determine, based on the set of stimulation programming settings, an output volume of activation for the determined stimulation device;display, on a display, the output volume of activation; andtransmit the set of stimulation programming settings to an implantable pulse generator coupled to the leadwire to produce electrical stimulation according to the set of stimulation programming settings.","20","15/095536","2016-04-11","2016-0225152","2016-08-04","10342972","2019-07-09","BOSTON SCIENTIFIC NEUROMODULATION CORPORATION","David Arthur  Blum | Scott  Kokones | Michael A.  Moffitt | Jordan  Barnhorst | Keith  Carlton","","","","A61N-0001/08","A61N-0001/08 | A61B-0034/25 | A61N-0001/36128 | A61N-0001/37247 | G06F-0003/04815 | G06F-0003/04845 | G06F-0019/321 | G06K-0009/4642 | G06K-0009/6215 | G06T-0003/40 | G06T-0003/4038 | G06T-0007/0012 | G06T-0007/30 | G06T-0007/33 | G06T-0007/38 | G06T-0011/003 | G06T-0011/60 | G06T-0015/005 | G06T-0015/08 | G06T-0019/00 | G06T-0019/003 | F04C-2270/041 | G06F-0019/3481 | G06K-2009/4666 | G06T-2200/04 | G06T-2200/24 | G06T-2207/10064 | G06T-2207/10072 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/10092 | G06T-2207/30016 | G06T-2219/028","A61N-001/08","A61N-001/08 | A61B-034/00 | G06F-019/00 | G06T-019/00 | G06T-003/40 | G06F-003/0481 | G06F-003/0484 | G06T-007/00 | G06T-011/60 | A61N-001/36 | A61N-001/372 | G06T-015/08 | G06K-009/46 | G06K-009/62 | G06T-015/00 | G06T-011/00 | G06T-007/30 | G06T-007/33 | G06T-007/38","","","","","","4919028001464"
"US","US","P","B2","Noise reduced capacitive image sensor and method operating the same","A noised-reduced capacitive image sensor and a method operating the capacitive image sensor are provided. The capacitive image sensor includes: a number of capacitive sensing units forming an array, each capacitive sensing unit for transforming a distance between a portion of a surface of an approaching finger and a top surface thereof into an output electric potential, wherein a value of the output electric potential is changed by a driving signal applied to the sensing unit; at least one sample-and-hold circuit for capturing and retaining different output electric potentials; at least one signal conditioning circuit, each comprising at least one differential amplifier for amplifying a difference between two electric potentials retained by the sample-and-hold circuit; and a driving source, for providing the driving signal to the capacitive sensing units.","1. A capacitive image sensor, comprising: a plurality of capacitive sensing units forming an array, each capacitive sensing unit for transforming a distance between a portion of a surface of an approaching finger and a top surface thereof into an output electric potential, wherein a value of the output electric potential is changed by a driving signal applied to the capacitive sensing unit;at least one sample-and-hold circuit for capturing and retaining different output electric potentials;at least one signal conditioning circuit, each comprising at least one differential amplifier for amplifying a difference between two electric potentials retained by the sample-and-hold circuit; anda driving source, for providing the driving signal to the capacitive sensing units,wherein the driving signal is a potential change or potential changes, caused by a positive waveform and/or a negative waveform provided by the driving source; the electric potential at each part of the capacitive sensing units is set to a constant value during reset stages; the difference between two output electric potentials retained in the sample-and-hold circuit is a noise-reduced value representing a distance between the capacitive sensing unit and the portion surface of the finger above the capacitive sensing unit; the sample-and-hold circuit retains at least a first and a second output electric potentials under a corresponding positive waveform or negative waveform; the capacitive image sensor sequentially collects the noise-reduced values under the corresponding positive waveform and negative waveform for each pixel, and maps the noise-reduced values to corresponding locations of the capacitive sensing units to obtain a noise-reduced image of the finger,wherein the capacitive sensing unit further comprises: a sensing electrode;a voltage follower, wherein an input node of the voltage follower is connected to the sensing electrode, and an output node of the voltage follower is connected to the sample-and-hold circuit;a comparative capacitor, wherein one node of the comparative capacitor is electrically connected to the voltage follower, and the other node thereof is electrically connected to the driving source; anda bias voltage supply circuit, for providing different bias voltages to the sensing electrode, andwherein the comparative capacitor, a portion of the bias voltage supply circuit, and the voltage follower are MOS devices formed in an isolated well.","11","15/607703","2017-05-30","2018-0349662","2018-12-06","10346665","2019-07-09","SUNASIC TECHNOLOGIES, INC.","Chi Chou  Lin | Zheng Ping  He","","","","G06K-0009/0002","G06K-0009/0002 | A61B-0005/1172 | A61B-0005/7225 | G06F-0003/044 | G06F-0003/0416 | G06K-0009/40 | A61B-0005/04284 | A61B-2562/0214 | A61B-2562/046 | G06F-2203/04103","G06K-009/00","G06K-009/00 | G06K-009/40 | A61B-005/1172 | G06F-003/044 | G06F-003/041 | A61B-005/00 | A61B-005/0428","","","","","","4919028005134"
"US","US","P","B2","Kinetic assessment and alignment of the muscular-skeletal system and method therefor","A system is disclosed herein for providing a kinetic assessment and preparation of a prosthetic joint comprising one or more prosthetic components. The system comprises a prosthetic component including sensors and circuitry configured to measure load, position of load, and joint alignment. The system further includes a remote system for receiving, processing, and displaying quantitative measurements from the sensors. The kinetic assessment measures joint alignment under loading that will be similar to that of a final joint installation. The kinetic assessment can use trial or permanent prosthetic components. Furthermore, adjustments can be made to the applied load magnitude, position of load, and joint alignment by various means to fine-tune an installation. The kinetic assessment increases both performance and reliability of the installed joint by reducing error that is introduced by elements that load or modify the joint dynamics not taken into account by prior assessment methods.","1. An orthopedic measurement system for kinetic assessment comprising: a device having a surface configured to couple to a joint of a musculoskeletal system comprising at least one sensor configured to measure one or more parameters wherein the device includes a tracking system;a computer configured to receive measurement data from the at least one sensor and the tracking system;a display coupled to the computer, wherein the display includes a graphical user interface, wherein a memory and one or more processors are configured to execute one or more programs stored in the memory, wherein the computer is configured to receive measurement data from the at least one sensor of the device, wherein the graphical user interface includes a graphical depiction of a portion of a surface of the device that is configured to couple to the joint, wherein a contact point is displayed on the graphical depiction of the portion of the surface of the device, wherein the computer is configured to use the measurement data to calculate a contact point location on the graphical depiction of the portion of the surface of the device, and wherein the contact point is configured to move in real-time corresponding to movement of the joint.","19","15/636549","2017-06-28","2018-0000380","2018-01-04","10335055","2019-07-02","Orthosensor Inc.","Marc  Stein | Martin  Roche","","","","A61B-0005/103","A61B-0005/103 | A61B-0005/1036 | A61B-0005/1072 | A61B-0005/1121 | A61B-0005/45 | A61B-0005/4528 | A61B-0005/4571 | A61B-0005/4585 | A61B-0005/4851 | A61B-0005/686 | A61B-0017/154 | A61B-0017/155 | A61B-0017/157 | A61B-0017/1764 | A61B-0034/10 | A61B-0034/20 | A61B-0034/25 | A61B-0090/37 | A61F-0002/3836 | A61F-0002/461 | A61F-0002/4657 | A61F-0002/4684 | G06F-0003/0481 | A61B-0005/4887 | A61B-2034/102 | A61B-2034/104 | A61B-2034/105 | A61F-0002/38 | A61F-2002/4658 | A61F-2002/4668","A61B-005/103","A61B-005/103 | A61B-005/00 | A61B-017/15 | A61B-034/20 | A61B-034/00 | A61B-090/00 | A61B-005/11 | A61B-017/17 | A61F-002/46 | A61F-002/38 | A61B-005/107 | A61B-034/10 | G06F-003/0481","","","","","","4919027000967"
"US","US","P","B2","User interface for custom patterned electrical stimulation","A neurostimulation system includes a programming control circuit and a user interface. The programming control circuit may be configured to generate a plurality of stimulation parameters controlling delivery of neurostimulation pulses according to one or more neurostimulation programs each specifying a pattern of the neurostimulation pulses. The user interface includes a display screen, a user input device, and a neurostimulation program circuit. The neurostimulation program circuit may be configured to allow for construction of one or more pulse trains (PTs) and one or more train groupings (TGs) of the one or more neurostimulation programs, and to allow for scheduling of delivery of the one or more neurostimulation programs, using the display screen and the user input device. Each PT includes one or more pulse blocks each including a plurality of pulses of the neurostimulation pulses. Each TG includes one or more PTs.","1. A neurostimulation system, comprising: a stimulation device configured to deliver neurostimulation pulses and to control the delivery of the neurostimulation pulses using a plurality of stimulation parameters;a programming device configured to transmit the plurality of stimulation parameters to the stimulation device, the programming device including a programming control circuit configured to generate the plurality of stimulation parameters according to scheduled one or more neurostimulation programs each specifying a pattern of the neurostimulation pulses; anda user interface coupled to the programming control circuit and including a display screen, a user input device, and a neurostimulation program circuit coupled to the display screen and the user input device, the neurostimulation program circuit configured to display a program creation area including a pulse train (PT) construction area and a train grouping (TG) construction area on the display screen, to create building blocks of the one or more neurostimulation programs including constructing PTs by temporally arranging one or more pulse blocks (PBs) in the PT construction area using the user input device and constructing TGs by temporally arranging one or more PTs selected from the constructed PTs in the TG construction area using the user input device, wherein constructing the TGs further includes receiving an order and a number of repetitions of the one or more PBs in each PT of the one or more PTs in the TG construction area using the user input device, to display a program scheduling area on the display screen, to schedule the one or more neurostimulation programs by temporally arranging one or more TGs selected from the constructed TGs for each program of the one or more neurostimulation programs and specifying one or more delivery times for the each program in the program scheduling area using the user input device, and to transmit the scheduled one or more neurostimulation programs to the programming device, the one or more PBs each including a plurality of pulses of the neurostimulation pulses.","20","15/180980","2016-06-13","2017-0050033","2017-02-23","10335601","2019-07-02","BOSTON SCIENTIFIC NEUROMODULATION CORPORATION","David Ernest  Wechter","","","","A61N-0001/37247","A61N-0001/37247 | A61B-0005/04001 | A61N-0001/0556 | A61N-0001/36053 | A61N-0001/36114 | A61N-0001/37264 | G06F-0003/0483 | G06F-0003/0488 | G06F-0003/04842 | G06F-0019/00 | G16H-0040/63 | A61B-0005/4035 | A61B-0005/7475","A61N-001/372","A61N-001/372 | A61N-001/05 | A61N-001/36 | G06F-003/0483 | G06F-003/0484 | G06F-003/0488 | A61B-005/04 | G16H-040/63 | G06F-019/00 | A61B-005/00","","","","","","4919027001511"
"US","US","P","B2","Intravascular data visualization and interface systems and methods","In part, the disclosure relates to intravascular data collection systems and the software-based visualization and display of intravascular data relating to detected side branches and detected stent struts. Levels of stent malapposition can be defined using a user interface such as a slider, toggle, button, field, or other interface to specify how indicia are displayed relative to detected stent struts. In addition, the disclosure relates to methods to automatically provide a two or three-dimensional visualization suitable for assessing side branch and/or guide wire location during stenting. The method can use one or more a computed side branch location, a branch takeoff angle, one or more stent strut locations, and one or more lumen contours.","1. A method of visualizing intravascular information obtained using an intravascular data collection probe, the method comprising the steps of: receiving intravascular data for a blood vessel, the data comprising a plurality of image frames;storing the intravascular data in a memory device of an intravascular data collection system;detecting one or more side branches on a per image frame basis;detecting a lumen boundary on a per image frame basis;estimating side branch orientation by fitting a model constrained by a side branch arc;determining a first viewing angle for at least one of the side branch or lumen;selecting orientation of fitted model; anddisplaying a three-dimensional visualization for at least one of the side branch or lumen.","16","15/219197","2016-07-25","2017-0024532","2017-01-26","10338795","2019-07-02","LIGHTLAB IMAGING, INC.","Ajay  Gopinath | Denis  Dion | Christopher E.  Griffin | Desmond  Adler","","","","G06F-0003/04847","G06F-0003/04847 | A61B-0005/0066 | A61B-0005/0084 | A61B-0005/02007 | A61B-0005/6876 | A61B-0005/743 | A61B-0005/7435 | A61B-0008/12 | A61B-0034/10 | A61B-0034/20 | G06F-0003/04815 | G06T-0007/0012 | G06T-0015/08 | G06T-0019/003 | G16H-0020/40 | G16H-0030/40 | G16H-0050/20 | A61B-0005/6852 | A61B-2034/105 | A61B-2034/2055 | A61B-2034/2063 | G06T-2200/24","G06T-007/00","G06T-007/00 | G06F-003/0484 | A61B-034/10 | A61B-005/00 | A61B-034/20 | A61B-008/12 | G06T-015/08 | G06T-019/00 | G06F-003/0481 | A61B-005/02 | G16H-030/40 | G16H-050/20 | G16H-020/40","","","","","","4919027004681"
"US","US","P","B2","Method and system for hybrid mesh segmentation","A computer-implemented method for generating a digital model of an individual intraoral component from a digital model of a patient's dentition obtains a 3-D digital mesh model of the patient's dentition and performs automatic tooth component segmentation operation on the obtained mesh model. Automated segmentation results display. Interactive segmentation of the automated segmentation results is performed according to an operator instruction. Segmentation results are displayed and stored.","1. A computer-implemented method for generating a digital model of an individual intraoral component from a digital model of a patient'ss dentition, the method comprising: obtaining a 3-D digital mesh model of the patient'ss dentition;performing a first automatic tooth component segmentation on the obtained 3-D digital mesh model and displaying first automated tooth segmentation results;performing a second interactive tooth segmentation on said displayed first automated tooth segmentation results according to an operator instruction to adjust a segmentation parameter of the first automatic tooth component segmentation method;displaying and storing second tooth segmentation results that combine the first automatic tooth component segmentation and the second interactive tooth segmentation;performing a third interactive tooth segmentation on said second tooth segmentation results according to at least one second operator instruction to select a different second type segmentation method and adjust a segmentation parameter of the different second type segmentation method;displaying and storing third tooth segmentation results that combine the first automatic tooth component segmentation, the second interactive tooth segmentation, and the third interactive tooth segmentation;accepting a third operator instruction to modify the displayed third segmentation results and then perform a fourth interactive tooth component segmentation using the modified third segmentation results; anddisplaying and storing combined segmentation results that combine the first automatic tooth component segmentation, the second interactive tooth component segmentation, the third interactive tooth component segmentation, and the fourth interactive tooth component segmentation.","15","14/851332","2015-09-11","2017-0076443","2017-03-16","10339649","2019-07-02","CARESTREAM DENTAL TECHNOLOGY TOPCO LIMITED","Wei  Ye | Shoupu  Chen | Xavier  Ripoche | Delphine  Reynard","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/0084 | A61B-0005/0088 | A61B-0005/4547 | A61B-0005/7271 | A61B-0005/742 | A61C-0007/002 | G06F-0003/0482 | G06F-0003/04847 | G06T-0007/12 | G06T-0007/155 | G06T-0017/20 | A61C-2007/004 | G06T-2200/04 | G06T-2207/20152 | G06T-2207/30036 | G06T-2207/30041","A61B-005/00","A61B-005/00 | A61C-007/00 | G06T-007/00 | G06T-007/12 | G06T-017/20 | G06T-007/155 | G06F-003/0482 | G06F-003/0484 | G06K-009/00","","","","","","4919027005529"
"US","US","P","B2","Method for control of camera module based on physiological signal","A portable communication device is provided for generating a panorama image. The portable communication device includes a touchscreen display; a fingerprint sensor; an image sensor; and a processor adapted to display, via the touchscreen display, a preview image obtained via the image sensor; receive, via the fingerprint sensor, a user input while the preview image is presented; and in response to the user input, generate a panorama image using the image sensor.","1. A portable communication device, comprising: a touchscreen display disposed in a front surface of the portable communication device;a fingerprint sensor disposed in a rear surface of the portable communication device;an image sensor; anda processor adapted to: display, via the touchscreen display, a preview image being obtained via the image sensor;receive, via the fingerprint sensor, a user input while the preview image is displayed; andperform photographing of a panorama image based at least in part on the user input, the performing including: displaying a guide indication indicative of a specified direction;capturing, using the image sensor, a plurality of images based at least in part on a determination that a movement of the portable communication device corresponds to the specified direction; andgenerating the panorama image using the plurality of images.","20","16/033906","2018-07-12","2018-0324353","2018-11-08","10341554","2019-07-02","Samsung Electronics Co., Ltd","Namjin  Kim | Sora  Hyun | Hyunho  Seo | Changhyun  Chun | Yunemo  Koo | Gaeyoun  Kim | Geonsoo  Kim | Heedeog  Kim | Sunghyuk  Shin | Kihuk  Lee | Chulhwan  Lee | Cheolho  Cheong | Seungmin  Choi","10-2014-0116510","KR","2014-09-02","H04N-0005/23216","H04N-0005/23216 | A61B-0005/024 | A61B-0005/0205 | A61B-0005/02416 | A61B-0005/02438 | A61B-0005/1172 | A61B-0005/14551 | A61B-0005/165 | A61B-0005/6898 | G03B-0015/00 | G06F-0001/169 | G06F-0001/1694 | G06F-0003/011 | G06K-0009/00013 | H04N-0005/232 | H04N-0005/23212 | H04N-0005/23293 | H04N-0009/73 | A61B-0005/02405","H04N-005/232","H04N-005/232 | A61B-005/117 | G06K-009/20 | G03B-015/00 | A61B-005/024 | A61B-005/0205 | A61B-005/1455 | H04N-009/73 | A61B-005/00 | G06F-003/01 | A61B-005/16 | A61B-005/1172 | G06K-009/00 | G06F-001/16","","","","","","4919027007425"
"US","US","P","B2","Control method of information terminal and computer-readable recording medium","A control method of an information terminal according to the present disclosure causes a display to display a display screen which includes a first display region displaying an object medical image and a second display region displaying M number of similar medical images. When one instruction for magnifying any one similar medical image among the M number of similar medical images is sensed, with respect to the M number of or fewer similar medical images in the M number of ranges that are displayed in the second display region upon sensing the one instruction, a corresponding region of interest in each of the M number of or fewer similar medical images is magnified so as to match a position corresponding to a center of each of individual regions in the second display region while maintaining a size of each of the individual regions at a same size.","1. A control method for an information terminal, the information terminal including a display and being connected to a case retrieval system, the control method comprising: displaying, on the display, an object medical image which is a medical image of a diagnostic interpretation object selected from diagnostic interpretation object candidates,disease name information not being set in additional information of the object medical image;detecting first specification information indicating a region of interest in the object medical image;receiving a first number of similar medical images, each of the similar medical images having a prescribed degree of similarity with a feature quantity of the region of interest indicated by the first specification information, each of the similar medical images being retrieved from the case retrieval system in accordance with the region of interest, disease name information being set in additional information of the similar medical images, each of the similar medical images including a corresponding region of interest that corresponds to the region of interest in the object medical image and including second specification information indicating the corresponding region of interest in each of the similar medical images;displaying, on the display, a display screen which includes a first display region and a second display region, the first display region displaying the object medical image, the second display region displaying a second number of the similar medical images, the second display region including a third number of individual regions for displaying the second number of similar medical images, the display screen including one or more instruction buttons, the instruction buttons being common to the second number of the similar medical images for changing a display size of the second number of the similar medical images, the instruction buttons including a first instruction button, the first instruction button being for causing each corresponding region of interest included in the second number of the similar medical images to be magnified and displayed at a predetermined magnification ratio with respect to a reference thumbnail, the predetermined magnification ratio being predetermined to bring a size of each magnified corresponding region of interest to be smaller than a size of each of the individual regions, the predetermined magnification ratio being different for each similar medical image; andwhen detecting an instruction from the first instruction button, changing a display size of each corresponding region of interest included in the second number of the similar medical images in accordance with a size of the corresponding region of interest of the reference thumbnail, a size of the corresponding region of interest indicated by the second specification information, and a magnification ratio of the reference thumbnail, while maintaining the size of each of the individual regions in the second display region,wherein the first number is an integer at least equal to 2,the second number is an integer at least equal to 1 and at most equal to the first number, andthe third number is an integer at least equal to the second number and at most equal to the first number.","4","14/800025","2015-07-15","2015-0317452","2015-11-05","10327640","2019-06-25","PANASONIC CORPORATION","Kazuki  Kozuka | Kazutoyo  Takata | Kenji  Kondo | Hirohiko  Kimura | Toyohiko  Sakai","","","","A61B-0005/0022","A61B-0005/0022 | A61B-0005/743 | A61B-0005/7425 | G06F-0003/0482 | G06F-0003/04842 | G06F-0003/04855 | G06F-0017/30268 | G06F-0019/00 | G06F-0019/321 | G16H-0015/00 | G16H-0050/70 | A61B-0005/055 | A61B-0005/08 | A61B-0006/032 | A61B-0006/463 | G09G-2340/0407","G16H-050/70","G16H-050/70 | G16H-015/00 | A61B-005/00 | G06F-017/30 | G06F-003/0485 | G06F-003/0484 | G06F-003/0482 | G06F-019/00 | A61B-005/055 | A61B-005/08 | A61B-006/03 | A61B-006/00","","","","","","4919026000926"
"US","US","P","B1","Authorized remote control","Some embodiments provide a vehicle navigation system which can navigate a vehicle through an environment based on driving commands received from a remote control system based on manual operator interaction with an interface of the remote control system. Remote driving control can be engaged based on determination, via processing vehicle sensor data, of a health emergency associated with one or more occupants of the vehicle, and the remote control system can generate remote driving commands which cause the vehicle to be navigated to a particular location without requiring the occupant associated with the health emergency to manually navigate the vehicle. The remote control system can monitor the occupant via communicated vehicle sensor data and can control remote control devices included in the vehicle to provide external indication that the vehicle is being navigated according to remote driving control.","1. An apparatus, comprising: a vehicle navigation system configured to be installed in a vehicle and control one or more sets of vehicle control elements installed in the vehicle to cause the vehicle to be navigated through an environment in which the vehicle is located based on remote driving commands received from a remote control system, wherein the vehicle navigation system is configured to: transmit a remote control request signal, to the remote control system, based at least in part upon a determination that an occupant of an interior of the vehicle is associated with a health state which meets at least one threshold;receive a remote control authorization request message from the remote control system; andauthorize the remote control system for remote driving control of the vehicle, based at least in part on a determination that the remote control authorization request message includes authentication data for the vehicle.","21","15/275147","2016-09-23","","","10328897","2019-06-25","APPLE INC.","Bartholomeus C.  Nabbe | Tie-Qi  Chen | Benjamin B.  Lyon","","","","B60R-0025/2018","B60R-0025/2018 | G01C-0021/26 | G05D-0001/0011 | G06F-0021/305 | A61B-0005/18 | B60R-0099/00 | G05D-0001/0022 | G06Q-0010/06 | G07C-0005/00 | G07C-0005/008","B60R-025/20","B60R-025/20 | G05D-001/00 | G01C-021/26 | G06F-021/30 | B60R-099/00 | A61B-005/18 | G07C-005/00 | G06Q-010/06","","","","","","4919026002174"
"US","US","P","B2","Providing answers to questions including assembling answers from multiple document segments","A method, system and computer program product for generating answers to questions. In one embodiment, the method comprises receiving an input query, identifying a plurality of candidate answers to the query; and for at least one of these candidate answers, identifying at least one proof of the answer. This proof includes a series of premises, and a multitude of documents are identified that include references to the premises. A set of these documents is selected that include references to all of the premises. This set of documents is used to generate one or more scores for the one of the candidate answers. A defined procedure is applied to the candidate answers to determine a ranking for the answers, and this includes using the one or more scores for the at least one of the candidate answers in the defined procedure to determine the ranking for this one candidate answer.","1. A computer-implemented method of generating a score for a candidate answer to an input query, the method comprising: receiving an input query at a computer processor system;identifying, by the computer processor system, a candidate answer to the input query;identifying, by the computer processor system, a logical proof of the candidate answer, the logical proof including a conclusion and a sequence of premises that logically prove the conclusion, including using the candidate answer as the conclusion of the logical proof;searching, by the computer processor system, through a group of documents to identify a sub-group of documents of the group of documents, each document of the sub-group of documents including one or more of the premises of the logical proof, and wherein each of the premises of the logical proof is included in at least one of the documents of the sub-group of documents;using, by the computer processor system, an iterative process, including a sequence of steps, to select, from said sub-group of documents, a set of documents that establish all the premises of the logical proof, including at each of the steps of the iterative process, selecting for said set of documents one of the documents that, of the documents of said sub-group of documents, has the largest number of the premises of the logical proof that, at the time of said each step, are not included in any of the documents in the set of documents; andusing, by the computer processor system, the set of documents to generate a score for the candidate answer.","20","15/966191","2018-04-30","2018-0246890","2018-08-30","10331663","2019-06-25","INTERNATIONAL BUSINESS MACHINES CORPORATION","Eric W.  Brown | Jennifer  Chu-Carroll | David A.  Ferrucci | James W.  Murdock, IV","","","","G06F-0016/24522","G06F-0016/24522 | A61B-0005/00 | A61B-0034/10 | G06F-0003/048 | G06F-0016/2428 | G06F-0016/2455 | G06F-0016/31 | G06F-0016/334 | G06F-0016/532 | G06F-0016/90335 | G06F-0016/93 | G06F-0017/2235 | G06F-0017/241 | G06F-0019/00 | G06F-0019/325 | G06N-0005/027 | G06Q-0050/22 | G16H-0010/20 | G16H-0010/60 | G16H-0015/00 | G16H-0050/20 | G16H-0050/70 | G16H-0070/00 | G06F-0017/271 | Y02A-0090/22 | Y02A-0090/26","G06F-017/30","G06F-017/30 | G06F-016/2452 | G06F-003/048 | G06N-005/02 | G16H-050/70 | G16H-010/20 | G16H-050/20 | G06F-016/31 | G06F-016/93 | G06F-016/33 | G06F-016/532 | G06F-016/242 | G06F-016/2455 | G06F-016/903 | A61B-005/00 | G06F-019/00 | G06Q-050/22 | G06F-017/22 | G06F-017/24 | A61B-034/10 | G16H-070/00 | G16H-010/60 | G16H-015/00 | G06F-017/27","","","","","","4919026004916"
"US","US","P","B2","Systems and methods for specifying and formulating customized topical agents","Systems and methods for determining a customized cosmetic formulation. In one method, a user is guided to capture an image of a skin region with known lighting and color characteristics, and the image is processed to provide calibrated skin color information. A customized cosmetic formulation is automatically determined for the user based on the calibrated skin color information. In another method, a user is interactively guided through capture of one or more skin region images using a device having an image sensor. The skin region images are processed to provide calibrated skin color information, which is compared to a ground truth data set to identify a set of closest known values in the ground truth data set. A customized cosmetic formulation is automatically determined for the user based on the comparison.","1. A method of determining a customized cosmetic formulation, the method comprising: interactively guiding a user to capture one or more images using a device having an image sensor, each image comprising a skin regions of the user;determining calibrated skin color information based at least in part on embedded data in at least one of the images captured and/or based at least in part on one of the images captured having a skin region of known characteristics; andautomatically determining a customized cosmetic formulation for the user by identifying, using the calibrated skin color information, a reference specification associated with a particular cosmetic formulation.","23","14/836399","2015-08-26","2016-0174690","2016-06-23","10321748","2019-06-18","SHISEIDO AMERICAS CORPORATION","David A.  Howell | David B.  Gross | Leslie Y.  Harvill","","","","A45D-0044/005","A45D-0044/005 | A61B-0005/441 | G01J-0003/463 | G01J-0003/50 | G06K-0009/00221 | G06K-0009/00234 | G06K-0009/00362 | G06Q-0050/22 | H04N-0017/002 | A45D-2044/007 | A61B-0005/1032","H04N-007/18","H04N-007/18 | A45D-044/00 | G06K-009/00 | H04N-017/00 | A61B-005/00 | G01J-003/46 | G01J-003/50 | G06Q-050/22 | A61B-005/103","","","","","","4919025000653"
"US","US","P","B2","Eye imaging in head worn computing","Head-worn computers with eye-imaging systems include a camera system positioned in a head-worn computer, wherein the camera system is further positioned to capture eye-image light that originates as reflections from a user's eye, wherein the camera system is further positioned to capture eye-image light as a reflection from a partially reflective surface that is positioned in front of an image display in the head-worn computer, wherein image light, from the image display, is transmitted through the partially reflective surface. A processor is adapted to cause the camera system to capture the eye-image light. The processor is further adapted to cause a comparison of the captured eye-image light with a pre-stored eye image of a known user of the head-worn computer. In the event the comparison confirms the identity of the known user, the user is granted permission to view content to be presented in a display of the head-worn computer.","1. A head-worn computer with an eye-imaging system, comprising: a camera system positioned in a head-worn computer, wherein the camera system is further positioned to capture eye-image light that originates as reflections from an eye of a user, wherein the camera system is further positioned to capture the eye-image light as a reflection from a partially reflective surface that is positioned in front of an image display in the head-worn computer, wherein image light, from the image display, is transmitted through the partially reflective surface; anda processor adapted to cause the camera system to capture the eye-image light,wherein the processor is further adapted to cause a comparison of the captured eye-image light with a pre-stored eye image of a known user of the head-worn computer, andwherein, in the event the comparison confirms the identity of the known user, the user is granted permission to view content to be presented in a display of the head-worn computer.","12","15/456619","2017-03-13","2017-0185755","2017-06-29","10321821","2019-06-18","MENTOR ACQUISITION ONE, LLC | OSTERHOUT GROUP, INC.","John N.  Border | John  Haddick | Joseph  Bietry","","","","A61B-0003/14","A61B-0003/14 | A61B-0003/0008 | A61B-0003/0025 | A61B-0003/0041 | A61B-0003/113 | A61B-0003/12 | A61B-0005/117 | A61B-0005/1171 | G02B-0027/017 | G02B-0027/0172 | G02C-0011/10 | G06F-0003/013 | G06F-0021/10 | G06F-0021/32 | G06K-0009/0061 | G06K-0009/00604 | G06K-0009/00617 | G02B-2027/014 | G02B-2027/0138 | G02B-2027/0178 | G02B-2027/0187","G02B-027/14","G02B-027/14 | G09G-005/00 | A61B-003/14 | A61B-003/113 | A61B-003/00 | G02C-011/00 | A61B-005/1171 | G02B-027/01 | G06F-003/01 | G06K-009/00 | A61B-003/12 | A61B-005/117 | G06F-021/10 | G06F-021/32","","","","","","4919025000725"
"US","US","P","B2","User condition evaluation system through touch screen device usage pattern change","Technology for use with a touchscreen user interface device that uses gesture swipe data to provide an early potential indication of onset of Parkinson's disease. Technology for use with a touchscreen user interface device that uses gesture swipe data to provide an information about motor skill development of a child. Technology for use with a touchscreen user interface device that uses gesture swipe data to provide an information about reading ability development of a child.","1. A computer-implemented method for use with a pressure sensitive touchscreen user interface device, the method comprising: receiving a Parkinson'ss Disease (PD) potential indication module including a set of machine logic based rules for determining when changes in gesture pressure patterns of touchscreen gesture instances correspond to a potential indication of early onset of PD;receiving a plurality of touchscreen gesture data sets, with each touchscreen gesture data set including information indicative of: (i) pressure levels throughout an instance of a gesture swipe made by a user on the pressure sensitive touchscreen user interface device, and (ii) a time that the instance of the touchscreen gesture swipe occurred;detecting a first change in pressure levels throughout the user'ss gestures over time by comparing touchscreen gesture data sets of the plurality of touchscreen gesture data sets with each other;applying the machine logic based rules of the PD potential indication module to determine that the detection of the first change in pressure corresponds to a potential indication of PD;accessing location data for the pressure sensitive touchscreen user interface device;modifying results of the application of the machine logic based rules of the PD potential indication module based, at least in part, on the accessed location data for the pressure sensitive touchscreen user interface device, andsending a communication indicating a potential indication of PD for the user.","17","15/708322","2017-09-19","2019-0083006","2019-03-21","10314521","2019-06-11","INTERNATIONAL BUSINESS MACHINES CORPORATION","Harini  Jagannathan | Fang  Lu | Anca  Sailer | Chin Ngai  Sze | Jingwei  Yang","","","","A61B-0005/1124","A61B-0005/1124 | A61B-0005/0022 | A61B-0005/1101 | A61B-0005/4082 | A61B-0005/6897 | G06F-0003/04883 | G06N-0005/046 | G09B-0005/02 | G09B-0017/003 | G16H-0050/20 | A61B-2503/06","A61B-005/00","A61B-005/00 | A61B-005/11 | G06F-003/0488 | G06N-005/04 | G09B-005/02 | G09B-017/00 | G16H-050/20","","","","","","4919024000918"
"US","US","P","B2","Method, apparatus and computer program for activity sensor data processing","According to one aspect there is provided a method comprising: loading, with an application, a webpage comprising an embedded activity recognition module; causing collection of activity sensor data from at least one sensor of a mobile device with a sensor polling module; causing transmission of the activity sensor data to the embedded activity recognition module; causing processing of the collected sensor data with the embedded activity recognition module to form processed activity sensor data; and receiving the processed activity sensor data from the activity recognition module.","1. An apparatus comprising: at least one processor; andat least one memory having computer program code stored thereon, the at least one memory and computer program code being configured to, when run on the at least one processor, cause the apparatus to:load, with an application, a webpage comprising an embedded activity recognition module comprising a plurality of activity recognition algorithms or a plurality of implementations of an activity recognition algorithm;in response to information provided by the application, select a respective activity recognition algorithm or a respective implementation of the activity recognition algorithm based upon one or more factors including network connectivity, wherein a first version of the respective activity recognition algorithm or a first version of the respective implementation of the activity recognition algorithm is selected based upon a first network connectivity condition, and wherein the apparatus is caused to switch from the first version of the respective activity recognition algorithm or the first version of the respective implementation of the activity recognition algorithm to a second version of the respective activity recognition algorithm or a second version of the respective implementation of the activity recognition algorithm based upon a change from the first network connectivity condition to a second network connectivity condition, the second network connectivity conditions being different from the first network connectivity condition;cause collection of activity sensor data from at least one sensor of a mobile device with a sensor polling module;cause transmission of the activity sensor data to the embedded activity recognition module;cause processing of the collected sensor data with the respective activity recognition algorithm or the respective implementation of the activity recognition algorithm of the embedded activity recognition module that has been selected to form processed activity sensor data; andreceive the processed activity sensor data from the activity recognition module.","21","14/828282","2015-08-17","2016-0051199","2016-02-25","10314544","2019-06-11","NOKIA TECHNOLOGIES OY","Oleg  Tishutin | Marc James Ashton  Bailey","20140133946","RU","2014-08-19","A61B-0005/6898","A61B-0005/6898 | G06F-0009/4843 | H04L-0067/10 | H04L-0067/12","A61B-005/145","A61B-005/145 | A61B-005/00 | G06F-009/48 | H04L-029/08","","","","","","4919024000941"
"US","US","P","B2","Method for medical image processing","An image processing method applied by a medical imaging device is proposed, including at least one camera and at least one display screen on which is displayed a medical image showing a region of interest of a patient, the method being characterized in that the region of interest is determined by the following steps, the screen and the camera being laid out so as to be facing a practitioner simultaneously, acquisition by the camera of at least one tracking image containing the eyes of the practitioner, analysis of the tracking image so as to localize in the medical image at least one pixel of interest contemplated by the practitioner on the screen from the orientation of the eyes of the practitioner, processing the medical image so as to select the region of interest from the localized pixel of interest.","1. An image processing method applied by a medical imaging device comprising at least one camera and at least one display screen on which is displayed a medical image of a patient, the method comprising: determining a region of interest within the medical image by: arranging the display screen and the camera to simultaneously face a practitioner;acquiring with the camera at least one tracking image referencing and/or showing the eyes of the practitioner;analyzing the tracking image and localizing, within the medical image, at least one pixel of interest being contemplated by the practitioner based on an orientation of the eyes of the practitioner relative to the display screen;processing the medical image to select the region of interest within the medical image based on the localized at least one pixel of interest; andwherein the above steps are repeated for a plurality of medical images successively displayed on the display screen, and the method further comprises:storing in memory a plurality of regions of interest determined for the plurality of displayed medical images;detecting at least one persistent pixel comprised in each region of interest of said plurality; andapplying a local processing algorithm achieved in at least one following medical image, the realtime processing algorithm being restricted to a portion of the following medical image containing the persistent pixel.","9","15/108032","2014-09-10","2016-0317245","2016-11-03","10314665","2019-06-11","GENERAL ELECTRIC COMPANY","Vincent  Bismuth | Regis  Vaillant | Sebastien  Gorges | Maxime  Cazalas | Liliane  Ramus","2013-063558","FR","2013-12-24","A61B-0090/361","A61B-0090/361 | A61B-0034/25 | A61B-0090/37 | G06F-0003/013 | G06T-0003/4038 | G06T-0005/008 | G06T-0007/0012 | G06T-0007/74 | A61B-2017/00216 | G06T-2200/32 | G06T-2207/20104 | G06T-2207/20208 | G06T-2207/20221 | G06T-2207/30201","G06F-003/01","G06F-003/01 | A61B-090/00 | A61B-034/00 | G06T-003/40 | G06T-005/00 | G06T-007/00 | G06T-007/73 | A61B-017/00","","","","","","4919024001061"
"US","US","P","B2","Integrated media jukebox and physiologic data handling application","A method is provided to operate a computer to interoperate with a portable media player. The method includes processing signals provided from the portable media player to the computer that are indicative of whether an accessory has been connected to the portable media player, to determine whether the accessory has been connected to the portable media player. Based on a determination that the accessory has been connected to the portable media player, physiologic data of a user that was provided to the portable media player from a wireless physiologic data gathering device, is received from the portable media player, into the computer, via the accessory.","1. A method, comprising: in a host computer, performing operations for:storing a workout playlist of songs for a workout template, the workout template comprising audio cues for a corresponding workout;processing the workout template, including playing songs in the workout playlist and playing the audio cues during the playing of the songs; andbased on physiologic data indicative of user behavior, modifying the audio cues played during the playing of the songs.","20","15/871775","2018-01-15","2018-0133573","2018-05-17","10315087","2019-06-11","Apple Inc.","Christopher R.  Wysocki | David  Heller | Amandeep  Jawa | Sandeep  Gupta | Greg  Marriott | Max  Sprauer | David A.  Shayer | John Wesley  Archibald | Shannon E.  Wells","","","","A63B-0069/0028","A63B-0069/0028 | A63B-0071/0686 | G06F-0003/002 | G06F-0016/4387 | G06F-0017/30053 | G06F-0019/00 | G06Q-0050/22 | A63B-0071/0622 | A63B-2071/0625 | A63B-2225/20 | A63B-2225/50","G06F-003/00","G06F-003/00 | G06F-013/12 | A63B-071/00 | G01H-007/00 | A61B-005/00 | A61B-006/04 | A63B-069/00 | G06F-016/438 | A63B-071/06 | G06Q-050/22 | G06F-017/30 | G06F-019/00","","","","","","4919024001481"
"US","US","P","B2","Managing telemetry communication modes of a device","Systems, apparatus, methods and computer-readable storage media facilitating management of operation of an implantable medical device (""IMD"") using a number of communication modes are provided. An IMD is configured to operate in a disabled mode wherein radio frequency (RF) telemetry communication is disabled, or operate in a first advertising mode using the RF telemetry communication. The IMD receives a clinician session request from a clinician device via an induction telemetry protocol while operating in the disabled mode or the first advertising mode, and transitions to operating from the disabled mode or the first advertising mode to operating in a second advertising mode based on receiving the clinician session request. From the second advertising mode, the IMD can establish a clinician telemetry session with the clinician device using the RF telemetry communication and a unique security mechanism facilitated by an identifier for the clinician device included in the clinician session request.","1. A device comprising: a communication component configured to facilitate telemetry communication between the device and a second device using a first telemetry communication protocol to communicate data; anda communication mode management component configured to control operation of the device in a plurality of communication modes, the plurality of communication modes including: a first advertising mode configured to facilitate establishment of a first type of telemetry communication session between the device and the second device using the first telemetry communication protocol; anda second advertising mode configured to facilitate establishment of a second type of telemetry communication session between the device and the second device using the first telemetry communication protocol,wherein the device transitions from the first advertising mode to the second advertising mode in response to receiving a request for the second type of telemetry communication session.","21","15/918033","2018-03-12","2018-0200525","2018-07-19","10307599","2019-06-04","MEDTRONIC, INC.","Eric A.  Schilling | Christopher T.  House | Gary P.  Kivi | Karen J.  Kleckner | John W.  Komp | Nicholas C.  Wine | Matthew R.  Yoder | Bo  Zhang","","","","A61N-0001/37223","A61N-0001/37223 | A61B-0005/0031 | A61N-0001/362 | A61N-0001/37217 | A61N-0001/37252 | A61N-0001/37276 | G16H-0040/63 | G16H-0040/67 | H04L-0067/12 | H04L-0067/125 | H04L-0067/142 | H04W-0004/80 | H04W-0012/08 | H04W-0052/028 | H04W-0080/10 | H04L-0063/0876 | H04L-0063/101 | H04L-2209/88 | Y02A-0090/26 | Y02D-0070/00 | Y02D-0070/10 | Y02D-0070/14 | Y02D-0070/142 | Y02D-0070/144 | Y02D-0070/162 | Y02D-0070/166 | Y02D-0070/26","A61N-001/00","A61N-001/00 | A61N-001/372 | H04W-004/80 | A61B-005/00 | A61N-001/362 | H04W-012/08 | H04L-029/08 | H04W-052/02 | H04W-080/10 | G16H-040/63 | G16H-040/67 | H04L-029/06","","","","","","4919023001502"
"US","US","P","B2","Athletic team integrated communication, notification, and scheduling system","An apparatus that displays an athletic activity notification user interface having a first display level that stacks athletic activity notifications along a first axis, and a second display level that positions athletic activity notifications along a second axis, perpendicular to the first axis, and whereby navigating through the user interface transitions athletic activity notifications from the second display leveled first display level.","1. An apparatus comprising: a processor;a non-transitory computer-readable medium comprising computer-executable instructions that when executed by the processor cause the processor to at least: generate a user interface for display on a display device, the user interface comprising: a UI display surface having a length extending between a first end and a second end along a first axis, and a width extending between a first side and a second side along a second axis perpendicular to the first axis, the width of the UI display surface configured to be equal to a width of the display device along the second axis;a first display level positioned between the first end and a transition point, and having a first plurality of display positions stacked along the first axis;a second display level positioned between the transition point and the second end, and having a second plurality of display positions aligned along the second axis,receive athletic activity notifications comprising at least a first athletic activity notification from a first device associated with a first user and a second athletic activity notification from a second device associated with a second user, where the athletic activity notifications comprise a proposed future scheduled time and location of a group athletic activity and are received in chronological order and wherein the first athletic activity notification includes a first preferred position and the second athletic activity notification includes a second preferred position,determine the first athletic activity notification and the second athletic notification comprise the same proposed future scheduled time and location of the group athletic activity, and in response,populating the first plurality of display positions with the first athletic activity notification and the second athletic activity notification received from the first user and the second user in chronological order, with the most recently-received athletic activity notification positioned at the first end, anddetermining that the first plurality of display positions are all populated, and in response, individually populating the second plurality of display positions with athletic activity notifications received from the first user and second user in a chronological order, with the most recently received athletic activity notification populating the second plurality of display positions positioned at the first side, such that the athletic activity notifications populating the second plurality of display positions are configured to be displayed perpendicular to the athletic activity notifications populating the first plurality of display positions; andreceive a user input through the user interface in a direction along the first axis towards the second end, and in response, display older athletic activity notifications by transitioning one or more athletic activity notifications from the second display level to the first display level and removing one or more newer athletic activity notifications from the user interface.","20","14/796425","2015-07-10","2016-0012294","2016-01-14","10307643","2019-06-04","NIKE, INC.","John  Bouck","","","","A63B-0024/0075","A63B-0024/0075 | A63B-0024/0062 | A63B-0071/0619 | G06F-0001/163 | G06K-0009/00342 | G06K-0009/00348 | G06K-0009/00724 | G06Q-0010/06 | G06Q-0010/1093 | G06Q-0050/01 | G06T-0007/20 | A63B-2024/0065 | A63B-2024/0068 | A63B-2024/0081 | G06K-2209/03 | G06K-2209/27 | G06Q-0010/109 | G06T-2207/30221","A63B-024/00","A63B-024/00 | H04H-020/04 | G06F-003/048 | G06Q-010/10 | A61B-005/00 | G06F-016/245 | G06F-003/02 | G06F-019/00 | G06F-003/01 | G06K-009/00 | G06T-007/20 | G06Q-050/00 | A63B-071/06 | G06Q-010/06 | G06F-001/16","","","","","","4919023001546"
"US","US","P","B2","Swing diagnosis apparatus, swing diagnosis system, swing diagnosis method, and recording medium","A swing diagnosis apparatus includes a level calculation section that calculates a level on the basis of a relationship between an incidence angle of a ball hitting portion of an exercise appliance at impact, and an inclination of the ball hitting portion of the exercise appliance at impact.","1. A swing diagnosis apparatus for use with an exercise appliance, the swing diagnosis apparatus comprising: a sensor; anda processor programmed to: measure, via the sensor, an incidence angle of a ball hitting portion of the exercise appliance at impact, and an inclination of the ball hitting portion of the exercise appliance at impact, andcalculate a level on the basis of a relationship between the incidence angle, and the inclination, whereinthe inclination of the ball hitting portion is a difference between: (i) a face angle formed between an outer edge of a hitting surface of the ball hitting portion and a virtual straight line orthogonal to the target hit ball direction, and (ii) the incidence angle, in a plan view.","17","15/211772","2016-07-15","2017-0028254","2017-02-02","10307656","2019-06-04","SEIKO EPSON CORPORATION","Tsuyoshi  Ito | Kenya  Kodaira | Norihisa  Hagiwara | Kazuhiro  Ito","2015-148641","JP","2015-07-28","A63B-0069/36","A63B-0069/36 | A61B-0005/11 | A61B-0005/1121 | A61B-0005/6895 | G06Q-0010/0639 | G09B-0019/0038 | A61B-2503/10 | G06F-0019/3481 | G06K-0009/00335","A63B-069/36","A63B-069/36 | A61B-005/00 | A61B-005/11 | G06Q-010/06 | G09B-019/00 | G06F-019/00 | G06K-009/00","","","","","","4919023001559"
"US","US","P","B2","Apparatus and method for surface and subsurface tactile sensation imaging","A tactile sensor, computer readable medium, methods of using and manufacturing the tactile sensor, and methods and apparatuses for processing the information generated by the tactile sensor. The tactile sensor includes a planar optical waveguide comprised of a flexible and transparent layer; a light configured to direct light into the optical waveguide; a light sensor or an imager facing the optical waveguide and configured to generate signals from light scattered out of the optical waveguide; and a controller which may be configured to generate an image of the object and characteristics of the object. The waveguide may be configured so that some of the light directed into the optical waveguide is scattered out of the waveguide if the waveguide is deformed by being pressed against the object. A finite element and a neural network are used to estimate mechanical characteristics of the objects.","1. A tactile sensor for generating an image of an object, the tactile sensor comprising: an optical waveguide comprised of at least a first portion that is flexible and a second portion that is adjacent to the first portion and provides the optical waveguide with rigidity, wherein at least part of the first portion is transparent so as to permit light to pass out of the first portion and into the second portion;at least two sources of light configured to direct light into the optical waveguide, one of the light sources being mounted to a side of the waveguide opposite from the other light source such that when activated each of the light sources directs light into the waveguide toward the other light source; anda light sensor facing the optical waveguide and configured to generate signals from light scattered out of the optical waveguide,wherein the waveguide is configured so that at least some of the light directed into the optical waveguide is scattered out of the first portion when the first portion is deformed, and wherein the first portion is deformed by the tactile sensor being pressed against the object.","24","15/914317","2018-03-07","2018-0330208","2018-11-15","10311343","2019-06-04","TEMPLE UNIVERSITY - OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION","Chang-Hee  Won","","","","G06K-0009/78","G06K-0009/78 | A61B-0005/0053 | A61B-0005/442 | A61B-0005/444 | G01L-0001/247 | G02B-0006/0013 | G02B-0006/0045 | G02B-0006/12002 | A61B-0005/0077 | A61B-0005/7267 | A61B-2562/0233 | G01L-0001/24 | G06F-0003/016 | G06F-0003/0414 | H04N-0007/18","A61B-005/00","A61B-005/00 | G06K-009/78 | G02B-006/12 | G01L-001/24 | F21V-008/00 | G06F-003/01 | H04N-007/18 | G06F-003/041","","","","","","4919023005220"
"US","US","P","B2","Music streaming for athletic activities","Example embodiments relate to systems, methods, apparatuses, and computer readable media relating to a user interface, that may for example, initiate transmission of a stream of audio data comprising a plurality of audio tracks from a music streaming service, and receive athletic activity data relating to a performance of an athletic activity by a user during an activity time period that includes a plurality of time intervals. For each of the plurality of time intervals, an athletic activity level is determined from the athletic activity data, a target audio track intensity corresponding to the athletic activity level is determined, and a playback of a streamed audio track corresponding to the target audio track intensity is initiated.","1. A method performed by a personal training system comprising: receiving, at a processor associated with a user device, a first stream of audio data from a music streaming application, the first stream of audio data including at least a first audio track configured for playback on the user device, wherein the first audio track is selected from the music streaming application based on user settings specific to a type of athletic activity;receiving, at the processor, athletic activity data from a sensor of the user device as a user is performing an athletic activity during an activity time period, wherein the activity time period includes at least one time interval corresponding to playback of the first audio track;analyzing, at the processor, the received athletic activity data to determine an athletic activity level of the athletic activity data during the at least one time interval;determining, at the processor, a target audio track intensity corresponding to an activity time period subsequent to the at least one time interval and based on the athletic activity level during the at least one time interval;transmitting, to the music streaming application, the determined target audio track intensity;receiving, at the processor, a second stream of audio data from the music streaming application responsive to transmitting the determined target audio track intensity, the second stream of audio data including at least a second audio track configured for playback on the user device, the second audio track corresponding to the target audio track intensity and selected from a plurality of audio tracks in accordance with one or more playback rules of the music streaming application and one or more user preference settings in the music streaming application;generating, on a display of the user device, an activity performance display of athletic activity data specific to the playback of the first audio track and the second audio track, the activity performance display including an indication of the target audio track intensity; andupdating, in the music streaming application, the user settings specific to the type of athletic activity based on the received athletic activity data and the selected second audio track.","18","14/723670","2015-05-28","2016-0346604","2016-12-01","10311462","2019-06-04","NIKE, INC.","Harold L.  Lindstrom, Jr. | Willoughby H.  Walling | Christopher L.  Andon","","","","G06Q-0030/0241","G06Q-0030/0241 | A61B-0005/1118 | A61B-0005/486 | G06F-0017/30749 | A61B-0005/0022 | A61B-0005/0024 | A61B-0005/024 | A61B-0005/1112 | A61B-0005/6804 | A61B-0005/6807 | A61B-2503/10 | G06F-0001/163 | G06F-0019/3481","A61B-005/00","A61B-005/00 | A61B-005/11 | G06F-017/30 | G06Q-030/02 | G06F-001/16 | A61B-005/024 | G06F-019/00","","","","","","4919023005339"
"US","US","P","B2","Method and system for patient specific planning of cardiac therapies on preoperative clinical data and medical images","A method and system for patient-specific planning of cardiac therapy, such as cardiac resynchronization therapy (CRT), based on preoperative clinical data and medical images, such as ECG data, magnetic resonance imaging (MRI) data, and ultrasound data, is disclosed. A patient-specific anatomical model of the left and right ventricles is generated from medical image data of a patient. A patient-specific computational heart model, which comprises cardiac electrophysiology, biomechanics and hemodynamics, is generated based on the patient-specific anatomical model of the left and right ventricles and clinical data. Simulations of cardiac therapies, such as CRT at one or more anatomical locations are performed using the patient-specific computational heart model. Changes in clinical cardiac parameters are then computed from the patient-specific model, constituting predictors of therapy outcome useful for therapy planning and optimization.","1. A method for patient-specific cardiac therapy planning, comprising: generating a patient-specific anatomical model of left and right ventricles from medical image data of a patient;generating a patient-specific computational heart model based on the patient-specific anatomical model of the left and right ventricles and patient-specific clinical data, wherein generating a patient-specific computational heart model based on the patient-specific anatomical model of the left and right ventricles and patient-specific clinical data comprises: determining patient-specific parameters of the computational heart model based on the patient-specific anatomical model of the left and right ventricles and the patient-specific clinical data by: simulating heart function using the computational heart model, andadjusting parameters of the computational heart model to control simulated clinical parameters resulting from the simulation of heart function using the computational heart model to match corresponding measured clinical parameters for the patient; andsimulating cardiac resynchronization therapy (CRT) at one or more anatomical locations using the patient-specific computational heart model by, wherein the computational heart model includes a cardiac electrophysiology module that simulates cardiac electrophysiology, a cardiac biomechanical module, and a cardiac boundary conditions module and the step of simulating CRT at one or more anatomical locations using the patient-specific computational heart model comprises: simulating heart function with the patient-specific computational heart model with a stimulated current introduced at the one or more anatomical locations in the cardiac electrophysiological module of the computational heart model.","24","13/754174","2013-01-30","2013-0197881","2013-08-01","10311978","2019-06-04","SIEMENS HEALTHCARE GMBH","Tommaso  Mansi | Bogdan  Georgescu | Xudong  Zheng | Ali  Kamen | Dorin  Comaniciu","","","","G16H-0050/50","G16H-0050/50 | A61B-0005/0044 | A61N-0001/3627 | A61N-0001/36514 | A61N-0001/36585 | G06F-0019/00 | G06T-0017/00 | G09B-0023/30 | A61B-0005/055 | A61B-0008/0883 | A61B-2576/023 | G06T-2210/41","G06F-017/50","G06F-017/50 | A61B-005/055 | A61N-001/362 | A61N-001/365 | G06F-019/00 | G06T-017/00 | G09B-023/30 | G16H-050/50 | A61B-005/00 | A61B-008/08","","","","","","4919023005851"
"US","US","P","B2","Remote display","A system includes a portable device and an external device connected wirelessly. Graphical user interface data determines a user interface functionality to be executed in a user interface of the external device in the portable apparatus, and is transmitted to the external device. The user interface functionality includes presenting at least one graphical interaction element on the user interface and receiving user input as a response to the user interacting with the graphical interaction element. The input data received from the user interface is used in the portable device to control a computer process relating to physiological data.","1. A wrist unit comprising: at least one memory storing computer program code;a communication circuitry configured to provide the wrist unit with wireless communication capability;a user interface comprising a display that displays a parameter related to an exercise performed by a user; anda processing circuitry configured to perform operations comprising:providing a first user interface functionality on the user interface of the wrist unit;determining graphical user interface data, wherein the graphical user interface data determines a second user interface functionality to be executed in a user interface of an exercise machine, wherein the second user interface functionality comprises presenting at least one graphical interaction element on the user interface of the exercise machine and receiving a user input in response to the user interacting with the graphical interaction element;transmitting wirelessly the determined graphical user interface data to the user interface of the exercise machine to provide the second user interface functionality on the user interface of the exercise machine, wherein the first user interface functionality and the second user interface functionality are similar to each other;receiving wirelessly input data corresponding to the user input; andcontrolling a computer process relating to physiological data with the input data, wherein the input data triggers at least one of the following: starting an exercise mode, stopping an exercise mode, selecting a training program.","19","14/917828","2013-09-13","2016-0226945","2016-08-04","10313420","2019-06-04","POLAR ELECTRO OY","Niclas  Granqvist | Mika  Erkkila | Olli  Komulainen","","","","H04L-0067/02","H04L-0067/02 | A61B-0005/02438 | A61B-0005/681 | A61B-0005/7435 | G06F-0003/04842 | G06F-0017/212 | G06F-0019/3418 | H04L-0067/42 | A61B-0005/6823 | A61B-0005/6824 | A61B-0005/7475 | G06F-0019/3481","H04L-029/08","H04L-029/08 | G06F-017/21 | G06F-003/0484 | H04L-029/06 | G06F-019/00 | A61B-005/00 | A61B-005/024","","","","","","4919023007282"
"US","US","P","B2","Athletic performance sensing and/or tracking systems and methods","Athletic performance sensing and/or tracking systems include components for measuring or sensing athletic performance data and/or for storing and/or displaying desired information associated with the athletic performance to the user (or others). Such systems can allow users a wide variety of options in creating workouts, selecting and presenting media content during the athletic performance, etc., e.g., to help keep users entertained and motivated. In some instances, user feedback may be used, optionally in combination with objective data relating to a workout, to control features of the workout routine, to control the music or other media content selected and/or presented, and/or to control features of future workout routines and/or the presented media content.","1. A method comprising: storing, within a memory, a first plurality of motivational songs of a first motivational song library associated with a first device of a first user;communicating with a second device to identify a plurality of motivational song libraries that include at least one of the first plurality of motivational songs;receiving a second plurality of motivational songs from the second device, wherein the second plurality of motivational songs include all of the motivational songs within the plurality of motivational song libraries that are not included in the first motivational song library;filtering, at a processor associated with the first device, the second plurality of motivational songs based on a characteristic;displaying the filtered second plurality of motivational songs on a display associated with the first device; andreceiving an indication that the first user desires to add at least one song from the filtered second plurality of motivational songs to the first motivational song library.","7","15/621220","2017-06-13","2017-0274265","2017-09-28","10303426","2019-05-28","NIKE, INC.","Raymond W.  Riley | Kevin W.  Hoffer | William E.  Berner | Allan M.  Schrock | James A.  Niegowski | William F.  Rauchholz","","","","G06F-0003/165","G06F-0003/165 | A61B-0005/1118 | A61B-0005/74 | A61B-0005/7405 | A63B-0024/0006 | A63B-0024/0062 | A63B-0024/0075 | A63B-0071/06 | A63B-0071/0616 | A63B-0071/0622 | A63B-0071/0686 | G05B-0015/02 | G06F-0016/4387 | G06F-0017/30053 | G06F-0019/00 | G06F-0019/3481 | G06Q-0010/0639 | G09B-0005/02 | G09B-0005/04 | G16H-0020/30 | A61B-2503/10 | A63B-0024/0059 | A63B-0069/0028 | A63B-0069/16 | A63B-2024/0065 | A63B-2024/0068 | A63B-2024/0071 | A63B-2071/0625 | A63B-2071/0694 | A63B-2220/00 | A63B-2220/12 | A63B-2220/17 | A63B-2220/20 | A63B-2220/30 | A63B-2220/836 | A63B-2225/20 | A63B-2230/06 | G06F-0016/68 | G06F-0017/30749","G06F-003/16","G06F-003/16 | G06F-016/438 | G16H-020/30 | A63B-024/00 | G06F-019/00 | A63B-071/06 | G06Q-010/06 | G05B-015/02 | G09B-005/02 | G09B-005/04 | A61B-005/11 | A61B-005/00 | G06F-017/30 | G06F-016/68 | A63B-069/00 | A63B-069/16","","","","","","4919022004703"
"US","US","P","B2","Decision support tool for use with a medical monitor-defibrillator","Work flows are modeled as a graph of interdependent tasks to be performed. The tasks to be performed are set by a task file module configured to enable interactions between tasks and including modules for event viewing, protocol assistance, smart messaging, smart indices, reference material lookup. A decision support manager module is configured to construct data and model profiles for storage in a data and model profile bank, events for storage in a decision support events bank, and protocols for storage in a decision support protocol bank. Configuration files are provided to specify a configuration for execution of one of the tasks. Data entered through a user interface or from a network via a wireless or wired communication module may define task files in the task files module, configuration files in the configuration files module, as well as data, events, and protocols to be used for a defibrillation procedure. A decision support manager module is configured to construct a dependency graph of tasks as specified in at least one of the configuration files and to execute the dependency graph.","1. For use in a medical device for providing decision support to a caregiver: a defibrillation processor configured to control an administration of an electrical charge as part of a defibrillation administration; anda decision support module configured to provide decision support to the caregiver during operation of the medical device, the decision support module comprising: a task file module configured to manage one or more task files, the task files defining a workflow of one or more interdependent tasks to be performed and defining and enabling interactions between the interdependent tasks;a configuration file module configured to manage one or more configuration files, the configuration files specifying a configuration for execution of the one or more interdependent tasks by providing configurations for data and data flows for a task defined by the task files of the task file module;a bank configured to provide one or more of: data, model profiles, events, and protocols to the decision support module, the bank fed with medical data from the medical device;a decision support manager module configured to construct a dependency graph modeling the workflow of interdependent tasks defined by the task files of the task file module using configurations for each interdependent task provided by the configuration file module; anda dashboard generator configured to provide a visual, audio, or audio-visual display, based on the dependency graph constructed by the decision support manager module, the visual, audio, or audio-visual display configured to provide enhanced coaching to the caregiver to cause the caregiver to perform at least one of a treatment or monitoring, at least one of the treatment including administration of a treatment via the defibrillation processor.","52","13/836769","2013-03-15","2014-0272860","2014-09-18","10303852","2019-05-28","PHYSIO-CONTROL, INC.","Ken  Peterson | Mitchell A  Smith | Denny Craig  Edwards | Nathaniel Paul  Barcelos | James  Wootten | Clayton  Young | Randy L.  Merry | Dana S  Lewis | John C  Daynes | Paul R  Juhasz | David  Okey | Steven  Witters | Ira M  Turner","","","","G06F-0019/345","G06F-0019/345 | A61B-0005/002 | A61B-0005/02055 | A61B-0005/0402 | A61B-0005/4836 | A61N-0001/3993 | A61B-0005/021 | A61B-0005/0836 | A61B-0005/14551 | A61B-0005/7282","G06F-017/00","G06F-017/00 | G06N-005/02 | G06F-019/00 | A61B-005/00 | A61B-005/0205 | A61B-005/0402 | A61N-001/39 | A61B-005/021 | A61B-005/083 | A61B-005/1455","","","","","","4919022005125"
"US","US","P","B2","Image classification by brain computer interface","A method of classifying an image is disclosed. The method comprises: applying a computer vision procedure to the image to detect therein candidate image regions suspected as being occupied by a target; presenting to an observer each candidate image region as a visual stimulus, while collecting neurophysiological signals from a brain of the observer; processing the neurophysiological signals to identify a neurophysiological event indicative of a detection of the target by the observer; and determining an existence of the target in the image is based, at least in part, on the identification of the neurophysiological event.","1. A method of classifying an image, comprising: applying a computer vision procedure to the image to detect a target therein, and assigning a computer detection score to the image using said computer vision procedure;presenting the image to an observer as a visual stimulus, while collecting neurophysiological signals from a brain of said observer;processing said neurophysiological signals to identify a neurophysiological event indicative of a detection of the target by said observer, and assigning to the image a neurophysiological detection score, based on said identification;determining an existence of said target in the image based on both said computer detection score and said neurophysiological detection score;determining a mismatch between said computer detection score and said neurophysiological detection score; andwhen said mismatch is detected, re-presenting said image to said observer.","21","15/579226","2016-06-02","2018-0089531","2018-03-29","10303971","2019-05-28","INNEREYE LTD.","Amir B.  Geva | Leon Y.  Deouell | Sergey  Vaisman | Omri  Harish | Ran El  Manor | Eitan  Netzer | Shani  Shalgi","239191","IL","2015-06-03","G06K-0009/4628","G06K-0009/4628 | A61B-0005/04017 | A61B-0005/04842 | A61B-0005/1103 | A61B-0005/486 | A61B-0005/7264 | G06F-0003/01 | G06K-0009/00671 | G06K-0009/2054 | G06K-0009/627 | G06K-0009/6247 | G06K-0009/6272 | G06N-0003/0454 | G06N-0003/088 | G06F-0003/015 | G06N-0003/04 | G06N-0003/08 | G06N-0007/005 | G16H-0030/40","A61B-005/00","A61B-005/00 | G06F-003/01 | G06K-009/46 | A61B-005/04 | A61B-005/0484 | A61B-005/11 | G06K-009/20 | G06K-009/62 | G06N-003/04 | G06N-003/08 | G06K-009/00 | G16H-030/40 | G06N-007/00","","","","","","4919022005244"
"US","US","P","B2","Determining player performance statistics using gaze data","Systems, methods, and computer-readable media are disclosed for capturing gaze data for a sports participant over the course of a sports match, identifying a key performance indicator (KPI) corresponding to a sports domain with which the sports match is associated, and generating KPI data corresponding to the KPI. Report data indicative of the KPI data may be generated and presented to the sports participant in-match or post-match. KPI data for a player may be aggregated across multiple sports domain KPIs and multiple sports matches and analyzed to determine player activity patterns. The player activity patterns may indicate statistical differences in KPIs for the player in relation to different in-match scenarios. Recommendations may be provided to the player for improving the player's performance with respect to various KPIs.","1. A computer-implemented method for determining player performance statistics using gaze parameter data, the method comprising: capturing, by an image sensor over a period of time, the gaze parameter data, wherein the gaze parameter data is associated with a participant in a sports match, wherein capturing the gaze parameter data comprises: capturing, at a particular frame rate, a series of image frames of a head of the participant;determining, for each image frame, a respective angle between the head of the participant and the image sensor; anddetermining a scan path based at least in part on the respective angle between the head of the participant and the image sensor determined for each image frame, wherein the scan path indicates a change in gaze direction of the participant over a time period during which the series of image frames are captured;identifying, by a computer processor, a sports domain associated with the sports match;identifying, by the computer processor, a key performance indicator (KPI) corresponding to sports domain;identifying, by the computer processor, one or more sports domain rules associated with the KPI;filtering, by the computer processor, the gaze parameter data to obtain a location/time series of the gaze parameter data that satisfies the one or more sports domain rules;generating, by the computer processor, KPI data associated with the KPI based at least in part on the location/time series of the gaze parameter data; andgenerating, by the computer processor, report data based at least in part on the KPI data.","19","15/184229","2016-06-16","2017-0361157","2017-12-21","10304022","2019-05-28","INTERNATIONAL BUSINESS MACHINES CORPORATION","Karan  Ahuja | Kuntal  Dey | Seema  Nagar | Roman  Vaculin","","","","G06Q-0010/06393","G06Q-0010/06393 | A61B-0005/00 | G06F-0003/013","G06Q-010/06","G06Q-010/06 | A61B-005/00 | G06F-003/01","","","","","","4919022005294"
"US","US","P","B2","Image processing apparatus, method of controlling the same, and storage medium","An image processing apparatus comprises a moving object detection unit configured to detect a moving object from a moving image; a detection unit configured to detect from the moving image a line corresponding to the moving object; and a determination unit configured to determine, based on a detection result of the detection unit, whether the moving object is a self-moving object.","1. An image processing apparatus comprising: a computer executing instructions that, when executed by the computer, cause the computer to function as: a moving object detection unit configured to detect a moving object from a moving image;a detection unit configured to detect from the moving image a line corresponding to the moving object, wherein the line is a line in which one of end points of the line corresponds to a leading end position of the moving object; anda determination unit configured to determine, based on a detection result of the detection unit, whether the moving object is a self-moving object.","18","15/481961","2017-04-07","2017-0301106","2017-10-19","10304205","2019-05-28","CANON KABUSHIKI KAISHA","Hisashi  Kawabayashi","2016-082351","JP","2016-04-15","G06T-0007/70","G06T-0007/70 | G06T-0007/13 | G06T-0007/20 | G06T-0007/60","A61B-005/00","A61B-005/00 | G06T-007/70 | G06T-007/20 | G06T-007/13 | G06T-007/60 | G06F-003/00","","","","","","4919022005474"
"US","US","P","B2","Decomposition of non-stationary signals into functional components","A method of signal processing and, in particular, a method of decomposing non-stationary signals representative of a physiological phenomenon into functional components, and to estimate parameters characterizing each of those functional components. The method utilises means for estimating dynamic and baseline trends in the time course of the signal, means for dividing the non-stationary signal into the segments over which the functional components are developed and means for compensating for overlap from QGK matched to preceding functional components to form an ECK. The compensation comprises means for transforming the ECK to a frequency domain, means for estimating the weight and dispersion parameters of the QGK, and validation of the parameter reliability, means for estimating the onset time of the QGK, means for expansion of the model of the non-stationary signal after each cycle of recursion, means for removal of unfavourable QGKs and rearrangement of remaining QGKs and means for creating partial models of the non-stationary signal with parameters belonging to predefined classes.","1. A computer implemented method of extracting functional components of a non-stationary biomedical signal selected from one or more of an electrocardiogram (ECG) signal, an electroencephalogram (EEG) signal and an electromyogram signal, with a Quasi-Gaussian Kernel as a basis element, thereby enabling improved detection and analysis of clinical and/or functional information contained therein, and for estimating parameters characterizing respective functional components, the method comprising the steps of: (a) applying multiple-pass moving average filters to estimate dynamic and baseline trends in a time course of the biomedical signal;(b) using the dynamic and baseline trends to construct a guide function indicative of signal fragments over which the functional components are developed;(c) adaptive segmenting of the guide function using zero-crossings and global and local minimums of a modulus of the guide function as segmentation points;(d) dividing the non-stationary biomedical signal into regions of component development, the non-stationary biomedical signal being segmented at points corresponding to the points of segmentation of the guide function;(e) compensating for overlap from Quasi-Gaussian Kernels matched to preceding functional components to form an Empirical Component Kernel, using the recursive sub-steps of: (i) transforming the Empirical Component Kernel to a frequency domain using a similar basis function algorithm;(ii) estimating weight and distribution parameters and validating parameter reliability in terms of predefined categorical grades by finding and assessing a best match between a normalized amplitude spectrum of the Empirical Component Kernel and the frequency domain template with a Gaussian profile; and(iii) estimating an onset time of the Quasi-Gaussian Kernel with the estimated weight and distribution parameters from an imaginary part of the Empirical Component Kernel complex spectrum by finding characteristic points that correspond to defined values of the phase spectrum;(f) on completion of the preceding cycles of recursion, expanding a model of the non-stationary biomedical signal composed from the sum of Quasi-Gaussian Kernels identified on the preceding cycles of recursion by adding the newly identified Quasi-Gaussian Kernel;(g) determining a categorization parameter (ξ) for each of the Quasi-Gaussian Kernels, wherein the categorization parameter for each Quasi-Gaussian Kernel is dependent upon an amplitude spectrum at a boundary angular frequency for the same Quasi-Gaussian Kernel;(h) removal of unfavorable Quasi-Gaussian Kernels using the categorization parameter (ξ) for assessment of identification results;(i) re-arranging the remaining identified components; and(j) creating a partial non-stationary signal model by selection of Quasi-Gaussian Kernel ensembles the parameters of which belong to the predefined categorical grades .","8","15/029301","2014-10-13","2016-0224757","2016-08-04","10304568","2019-05-28","KAOSKEY PTY LIMITED","Dmitri  Melkonyan","2013-903948","AU","2013-10-14","G16H-0050/50","G16H-0050/50 | A61B-0005/04 | A61B-0005/7246 | A61B-0005/7253 | A61B-0005/7264 | G01R-0023/167 | G06F-0017/11 | G06F-0017/14 | G06F-0019/00 | G06K-0009/0055","A61B-005/00","A61B-005/00 | A61B-005/04 | G06K-009/00 | G06F-017/11 | G06F-017/14 | G16H-050/50 | G01R-023/167 | G06F-019/00","","","","","","4919022005836"
"US","US","P","B2","System for supply chain management","A system for tracking a product from origin to destination is disclosed. The system includes a probe that comprises two plates, a power source and a processor. The power source is controlled by the processor to produce an oscillating output at the plates. Using the oscillating voltage, the probe interrogates a device through capacitive coupling. The device includes a control unit, a memory unit, and first and second materials physically associated with the device for communication using capacitive coupling. Information associated with the device is transferred from the device to the probe through capacitive coupling between the first and second materials and the first and second plates, respectively.","1. An ingestible device configured to be tested using a probe located external from the ingestible device, the ingestible device comprising: a substrate comprising a control unit and a memory for storing information; andfirst and second materials physically associated with the substrate, the first and second materials being dissimilar materials;a third material deposited on a surface of the first material, the third material being an electrically conductive material;an electrically insulative layer formed on the first material and the substrate; anda fourth material physically associated with the substrate and disposed on the electrically insulative layer, the fourth material being an electrically conductive material;wherein third material is configured to communicatively couple to a first probe plate and the fourth material is configured to communicatively couple to a second probe plate, such that information can be communicated between the third material and the first probe plate and information can be communicated between the fourth material and the second probe plate, wherein the first and second probe plates are located external from the ingestible device.","20","15/492716","2017-04-20","2017-0215761","2017-08-03","10305544","2019-05-28","PROTEUS DIGITAL HEALTH, INC.","Mark J.  Zdeblick","","","","H04B-0005/0012","H04B-0005/0012 | A61B-0005/061 | G06K-0007/01 | G06Q-0010/06","G06K-007/01","G06K-007/01 | H04B-005/00 | G06Q-010/06 | A61B-005/06","","","","","","4919022006802"
"US","US","P","B2","Signal detection device and signal detection method","A signal detection device according to an aspect of the invention includes a laminated structure of a first circuit layer (201) in which a plurality of electrodes brought into contact with a subject is formed, a second circuit layer (202) in which a plurality of amplifiers having an input portion capacitively coupled to the plurality of electrodes, respectively, is formed, and a third circuit layer (203) in which a plurality of transistors for reading outputs of the plurality of amplifiers is formed, an insulation layer which seals the second circuit layer is formed between the plurality of electrodes formed in the first circuit layer and the second circuit layer, and the plurality of electrodes and the input portions of the plurality of amplifiers are capacitively coupled to each other via the insulation layer.","1. A signal detection device which detects a signal generated from a subject, the device having a Young'ss modulus of less than 1 kPa and comprising a laminated structure of: a first circuit layer in which a plurality of electrodes brought into contact with the subject is formed;a second circuit layer in which a plurality of amplifiers having an input portion capacitively coupled to the plurality of electrodes, respectively, is formed; anda third circuit layer in which a plurality of transistors for reading outputs of the plurality of amplifiers is formed;wherein an insulating layer which seals the second circuit layer is formed between the plurality of electrodes formed in the first circuit layer and the second circuit layer, and the plurality of electrodes and the input portions of the plurality of amplifiers are capacitively coupled to each other through the insulating layer, andwherein the first circuit layer and the second circuit layer, and the second circuit layer and the third circuit layer, are each electrically connected through a conductive sheet, wherein the first circuit layer and the third circuit layer have a same bending rigidity.","11","14/432572","2013-09-30","2015-0276430","2015-10-01","10295367","2019-05-21","JAPAN SCIENCE AND TECHNOLOGY AGENCY","Tsuyoshi  Sekitani | Takao  Someya","2012-220427","JP","2012-10-02","G01D-0003/028","G01D-0003/028 | A61B-0005/0478 | A61B-0005/04085 | A61B-0005/7203 | G06F-0003/044 | H01L-0023/48 | H01L-0025/18 | A61B-0005/0408 | A61B-2562/0209 | H01L-0025/0657 | H01L-0028/20 | H01L-0028/40 | H01L-2224/32145","A61B-005/04","A61B-005/04 | G01D-003/028 | A61B-005/0478 | G06F-003/044 | H01L-023/48 | H01L-025/18 | A61B-005/0408 | A61B-005/00 | A61N-001/00 | H01L-025/065 | H01L-049/02","","","","","","4919021003713"
"US","US","P","B1","Associating cosmetic products to skin tone color","A system allows people to more easily find products matching their skin tone. The system includes a database that categorizes cosmetic products according to a skin tone color set. The system includes a scanning device to scan one or more spots of a person's skin. For example, three different spots can be scanned. The scan determines a skin-tone identifier for the person's skin. With this skin-tone identifier, the customer can view products that match their skin tone.","1. A system comprising: a database of cosmetic products, arranged by a product manufacturer classification, wherein the database of cosmetic products includes a plurality of cosmetic manufacturers;a skin tone color space; anda database of cosmetic products with skin tones comprising:a first field reserved in the database, wherein the first field identifies a first analyzed cosmetic product; anda second field reserved in the database, wherein the second field identifies the first analyzed cosmetic product, and each cosmetic product of the database of cosmetic products at least one match to a skin tone identifier in the skin tone color space,for an analyzed cosmetic product, a record includes the analyzed cosmetic product in the database of cosmetic products with skin tones,for a record associated with an analyzed cosmetic product having only a single color in the database of cosmetic products with skin tones, there are at least two fields storing different skin tone identifiers associated with the analyzed cosmetic product,a first determined skin tone identifier is stored in the first field associating the first determined skin tone identifier with a first analyzed cosmetic product, anda second determined skin tone identifier is stored in the second field associating the second determined skin tone identifier with the first analyzed cosmetic product,wherein a query of the database of cosmetic products comprises determining from a received user skin tone identifier, obtained from an optical scanner, whether the received user skin tone identifier matches at least one of the first determined skin tone identifier or the second determined skin tone identifier,the database of cosmetic products with skin tones is stored on nontransitory computer-readable media.","22","15/264530","2016-09-13","","","10296958","2019-05-21","SEPHORA USA, INC.","Lucie  Tuan | Savio  Thattil | David  Stauffer | Ryan  Poplawski | Meghan  Cochran | Marcy  Zelmar | Venkat  Gopalan | Julie  Bornstein | Margarita  Arriagada | Christine  Rose","","","","G06Q-0030/0627","G06Q-0030/0627 | A61B-0005/44 | G06F-0017/30867 | G06Q-0030/0641","G06F-007/00","G06F-007/00 | G06F-017/30 | G06Q-030/06 | A61B-005/00","","","","","","4919021005293"
"US","US","P","B2","Device configuration","A system and method for configuring a device include determining a plurality of configuration settings for the device. The configuration settings are saved in a configuration file, and a sales order for the device is generated. The configuration file is assigned to the sales order. Based on the sales order, the configuration file is retrieved and applied to the configuration settings to the device.","1. A method for configuring a vital signs monitor device, comprising: determining a plurality of configuration settings for the vital signs monitor device, the plurality of configuration settings including: location settings defining a clinical location at which the vital signs monitor device will be used; andone or more clinical workflows for the vital signs monitor device associated with the clinical location, wherein the one or more clinical workflows provide different functionalities of the vital signs monitor device;saving the configuration settings in a configuration file;generating a sales order for the vital signs monitor device;assigning the configuration file to the sales order; andapplying the configuration settings to the vital signs monitor device.","12","14/535576","2014-11-07","2016-0132957","2016-05-12","10296965","2019-05-21","WELCH ALLYN, INC.","Shawn C.  St. Pierre","","","","G06Q-0030/0635","G06Q-0030/0635 | A61B-0005/01 | A61B-0005/021 | A61B-0005/7475 | G06F-0009/44505 | A61B-0005/0816 | A61B-0005/14542 | A61B-2562/12","G06Q-030/06","G06Q-030/06 | G06F-009/445 | A61B-005/00 | A61B-005/01 | A61B-005/021 | A61B-005/08 | A61B-005/145","","","","","","4919021005300"
"US","US","P","B2","Method and system for analysis of volumetric data","A method is provided for modeling complex shapes from volumetric data utilizing spherical wave decomposition (SWD) by combining angular-only basis functions of the SPHARM with radial basis functions obtained by asymptotic expansion as a series of sine and cosine Fourier transforms to form the complete 3D basis. The 3D basis is used to expand the volumetric data. The resulting 3D volume representation allows construction of images of both surface and internal structures of the target object.","1. A method for generating a three-dimensional model of brain morphology, comprising: acquiring, via an imaging system, volumetric MRI data for a subject'ss brain, the volumetric MRI data comprising three-dimensional datapoints comprising Cartesian coordinates;inputting the volumetric MRI data into a computer processor having instructions stored therein for causing the computer processor to execute the steps of: transforming the volumetric MRI data into spherical coordinates comprising radial and angular variables and computing spherical wave decomposition by;expanding the transformed spherical coordinates into 3D basis functions by: expanding angular variables into angular-only spherical harmonic basis functions having preselected angular degree to determine angular coefficients; andexpanding the radial variables into radial basis functions having preselected radial degrees by asymptotic expansion as a series of sine and cosine Fourier transforms to determine radial coefficients, wherein the series of sine and cosine Fourier transforms have the form where [x] denotes the largest integer that does not exceed x, and Pl(N) is a series of Legendre polynomials;combining angular coefficients and radial coefficients to construct a signature for a 3D volume representation of the brain morphology in spherical coordinates;transforming the signature into a 3D volume representation of the brain morphology into Cartesian coordinates; anddisplaying the transformed 3D volume representation of the brain morphology on a graphical user interface.","15","15/021678","2014-09-15","2016-0225146","2016-08-04","10297022","2019-05-21","THE REGENTS OF THE UNIVERSITY OF CALIFORNIA | THE UNITED STATES OF AMERICA AS REPRESENTED BY THE DEPARTMENT OF VETERANS AFFAIRS, OFFICE OF THE GENERAL COUNSEL","Lawrence R.  Frank | Vitaly  Galinsky","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/0042 | A61B-0005/055 | G01R-0033/5608 | G06F-0017/5009 | G06T-0011/003 | G06T-0011/008 | A61B-0005/0044 | A61B-2576/023 | A61B-2576/026 | G01R-0033/56341 | G06T-2200/04 | G06T-2200/24 | G06T-2207/10088 | G06T-2207/30016","A61B-005/00","A61B-005/00 | G06T-007/00 | A61B-005/055 | G01R-033/56 | G06F-017/50 | G06T-011/00 | G01R-033/563","","","","","","4919021005356"
"US","US","P","B2","Using physiological data in a medical device","Systems and methods for using physiological data in a medical device are disclosed. The physiological data may be measured by a vital sign reader and received by a processing circuit associated with the medical device. The processing circuit may automatically adjust the operation of the medical device during a medical procedure based on the physiological data. In some implementations, the processing circuit may mirror a memory partition to a redundant storage device, allowing for uninterrupted execution of the medical procedure in the event of a memory failure condition.","1. A method for using physiological data to control an apheresis machine, the apheresis machine comprising a processing circuit including a processor and a memory, the processor configured to execute instructions stored in the memory, the memory including a first memory partition including a control module for generating commands for controlling the apheresis machine and a first procedure data module storing a medical procedure routine, and a second memory partition including a second procedure data module, the method comprising: generating a start procedure command at the control module based on the medical procedure routine;causing the apheresis machine to begin a medical procedure on a subject based on the start procedure command generated at the control module, wherein the medical procedure is an apheresis procedure;in response to causing the medical device to begin the medical procedure and receiving a data change request, determining whether the medical procedure routine is executing and whether the data change request is received from the medical procedure routine;in response to determining that the medical procedure routine is executing and the data change request is received from the medical procedure routine, changing data stored in the first memory partition while the medical procedure routine is executing;storing, in the second procedure data module, physiological data received from a measurement device, the physiological data being indicative of a physiological condition of the subject during the medical procedure, the physiological data including at least one of a measured blood pressure, body temperature, respiratory rate, or pulse rate of the subject;analyzing, by the control module, the physiological data;generating, by the control module, a control command for the apheresis machine based in part on the analyzed physiological data, wherein the control command causes the apheresis machine to adjust a flow rate of blood through the apheresis machine;modifying operation of the medical procedure by the apheresis machine based on the control command by adjusting the flow rate of blood through the apheresis machine.","13","13/743922","2013-01-17","2013-0190674","2013-07-25","10286148","2019-05-14","FENWAL, INC.","Brian C.  Case | Jonathan  Prendergast | Joseph M.  Foster | Witold  Moskal","","","","A61M-0005/1723","A61M-0005/1723 | A61M-0001/30 | G06F-0019/3418 | G06F-0019/3481","G06Q-050/00","G06Q-050/00 | A61M-005/172 | A61M-001/30 | G06F-019/00 | G06Q-010/00","","","","","","4919020001449"
"US","US","P","B2","Driver assistance apparatus and control method for the same","Disclosed are driver assistance apparatus and a control method for the same. The driver assistance apparatus includes a sensing unit configured to acquire information regarding an object outside a vehicle, the object including a first other vehicle being driven in the vicinity of the vehicle, and a processor configured to judge whether the first other vehicle is a dangerous vehicle based on at least one of the information regarding the object, user input provided from a driver of the vehicle, information regarding the state of the driver, and information regarding the first other vehicle provided from a second other vehicle being driven in the vicinity of the vehicle, and to execute at least one predetermined operation upon judging that the first other vehicle is a dangerous vehicle.","1. A driver assistance apparatus comprising: a sensing unit configured to acquire information regarding an object outside a vehicle, wherein the object includes a first other vehicle being driven in the vicinity of the vehicle;a processor configured to: judge whether the first other vehicle is a dangerous vehicle based on at least one of the information regarding the object, user input provided from a driver of the vehicle, a state of the driver, or information regarding the first other vehicle provided from a second other vehicle being driven in the vicinity of the vehicle,execute at least one predetermined operation based on judging that the first other vehicle is a dangerous vehicle,process a plurality of driving images provided from at least one camera of the vehicle into a first driving image that includes the first other vehicle and a second driving image that does not include the first other vehicle, andseparately store the first driving image and the second driving image; anda memory that includes a folder configured to separately store the first driving image from the second driving image.","18","15/225985","2016-08-02","2017-0036673","2017-02-09","10286905","2019-05-14","LG ELECTRONICS INC.","Choil  Lee","10-2015-0109599","KR","2015-08-03","B60W-0030/09","B60W-0030/09 | A61B-0003/112 | A61B-0005/024 | A61B-0005/165 | A61B-0005/18 | B60W-0030/0956 | B60W-0030/182 | B60W-0050/12 | G05D-0001/0223 | G05D-0001/0246 | G06F-0003/017 | G06F-0003/14 | G06K-0009/00805 | G06K-0009/00845 | G08G-0001/166 | B60W-2050/146 | B60W-2420/42 | B60W-2520/06 | B60W-2520/105 | B60W-2520/125 | B60W-2540/22 | B60W-2600/00","A61B-003/11","A61B-003/11 | G05D-001/02 | A61B-005/024 | B60W-030/09 | G06K-009/00 | A61B-005/16 | A61B-005/18 | B60W-030/095 | B60W-030/182 | B60W-050/12 | G06F-003/01 | G06F-003/14 | G08G-001/16 | B60W-050/14","","","","","","4919020002203"
"US","US","P","B2","Wearable interface for remote monitoring and control of a medical device","A wearable interface device, such as a head-mounted display, provides an augmented reality and/or display system and may be used in accordance with medical devices and the performance of medical treatments, particularly a dialysis machine and a dialysis treatment. The wearable interface device may be worn by a user, such as a health care practitioner (HCP), in connection with remotely monitoring and/or controlling the dialysis machine during the dialysis treatment. The HCP may receive alerts and/or other information concerning the dialysis treatment from the dialysis machine that are displayed on the wearable interface device and may use the wearable interface device to control the dialysis machine via the exchange of wireless signals with the dialysis machine. The wearable interface device may recognize commands from the HCP, such as gestures, to provide non-contact operation of the wearable interface device and remote control of the dialysis machine by the HCP.","1. A method of remotely interfacing with a medical device, comprising: providing a wearable interface device that enables remote interfacing with the medical device by a user wearing the wearable interface device, wherein the wearable interface device includes a command recognition device that recognizes and interprets commands in connection with operation of the wearable interface device, and wherein the wearable interface device includes a first screen for displaying information and a second screen for displaying information that provides a view through the wearable interface device that is unobstructed by a visual display during use of the wearable medical device, wherein the second screen functions independently of the first screen and wherein information corresponding to treatment being performed is displayed on the first screen and an alert symbol is displayed on the second screen, the alert symbol remotely alerting the user that the medical device is near an end of the treatment being performed;providing a display on the medical device, wherein the display includes touch screen features that accept commands for controlling the medical device;wirelessly exchanging signals between the wearable interface device and the medical device, wherein the signals correspond to a treatment performed using the medical device and wherein at least one processing device of the medical device that is processing signals received from the wearable interface device is given focus to enable the wearable interface device to control the medical device via the at least one processing device in a mode that excludes control of the medical device by other devices different from the wearable interface device while the signals are being processed;processing at least one of the signals at the wearable interface device to generate information corresponding to the treatment performed using the medical device;displaying the information on at least one of the first screen and the second screen of the wearable interface device; andrecognizing, using the command recognition device, at least one non-contact gesture input by the user, wherein control of treatment using the wearable interface device is different from control of treatment using the touch screen of the medical device.","22","13/804761","2013-03-14","2014-0266983","2014-09-18","10288881","2019-05-14","FRESENIUS MEDICAL CARE HOLDINGS, INC.","Peter  Christensen","","","","G02B-0027/017","G02B-0027/017 | A61M-0001/1601 | A61M-0001/34 | A61M-0001/3403 | A61M-0001/3607 | A61M-0001/3609 | G06F-0019/00 | G16H-0040/63 | A61M-2205/3368 | A61M-2205/3561 | A61M-2205/3592 | A61M-2205/50 | A61M-2205/502 | A61M-2205/505 | A61M-2205/507 | G02B-2027/014 | G02B-2027/0178 | G02B-2027/0187","G06F-003/01","G06F-003/01 | G06K-009/00 | G02B-027/01 | A61M-001/16 | A61M-001/36 | A61M-001/34 | G16H-040/63 | G06F-019/00","","","","","","4919020004168"
"US","US","P","B2","Method and apparatus for generating mood-based haptic feedback","A method and apparatus for generating mood-based haptic feedback are disclosed. A haptic system includes a sensing device, a digital processing unit, and a haptic generator. The sensing device, in one embodiment, is configured to detect user's modalities in accordance with mood information collected by one or more sensors and capable of issuing a sensing signal in response to the user's modalities. The digital processing unit is capable of identifying a user's condition in accordance with the sensing signal and providing a haptic signal in response to the user's condition. The user's condition, in one aspect, indicates user's mood and/or user's psychological conditions. The haptic generator generates haptic feedback in accordance with the haptic signal.","1. A haptic system, comprising: a sensing device, including at least one sensor, to sense mood information for a user of the haptic system;a haptic generator to generate haptic feedback in accordance with a haptic signal, the haptic feedback being vibrotactile feedback that indicates at least one of a level of fatigue, a level of alertness, a level of distraction, or a level of sobriety;a memory; anda processor, coupled to the sensing device, the haptic generator and the memory, configured to: receive the mood information from the sensing device,identify a mood of the user from the mood information,generate the haptic signal based on the mood, andsend the haptic signal to the haptic generator.","20","15/822649","2017-11-27","2018-0143692","2018-05-24","10289201","2019-05-14","IMMERSION CORPORATION","Juan Manuel  Cruz-Hernandez","","","","G06F-0003/016","G06F-0003/016 | A61B-0005/02438 | A61B-0005/165 | A61B-0005/6898 | A61B-0005/7455 | G06F-0003/015 | G06F-0017/30002 | A63F-2300/1012 | A63F-2300/6027 | G06F-2203/011 | H04M-2250/12","G06F-003/01","G06F-003/01 | A61B-005/00 | A61B-005/16 | A61B-005/024 | G06F-017/30","","","","","","4919020004484"
"US","US","P","B2","Free-form drawing and health applications","Various systems and methods for implementing free-form drawing for health applications are described herein. A system for implementing a health application includes a user interface module to receive, at a user device, a plurality of parameters including a free-form gesture path, the free-form gesture path representing an air gesture performed by a user of the user device; and a control module to adjust a fitness routine of the user based on the plurality of parameters.","1. A system for implementing a health application, the system comprising: a user interface module to receive, at a user device, a plurality of parameters including a free-form gesture path, the free-form gesture path representing an air gesture performed by a user of the user device; anda control module to adjust a fitness routine of the user based on the plurality of parameters,wherein to adjust the fitness routine for the user the control module is to: analyze the free-form gesture path to obtain a path morphology, parameterize the free-form gesture path into a coordinate system to produce a parameterized free-form path, and use the shape of the free-form path in the x-y plane to parameterize an intensity over time of an exercise session;use the path morphology to determine a navigation route and fit the parameterized free-form path to a route with similar geographical topology; andpresent the navigation route to the user.","24","14/975362","2015-12-18","2017-0177086","2017-06-22","10289206","2019-05-14","INTEL CORPORATION","Kathy  Yuen | Lenitra M.  Durham | Giuseppe  Raffa | Glen J.  Anderson | Daniel S.  Lake","","","","G06F-0003/017","G06F-0003/017 | A61B-0005/681 | G01C-0021/20 | G01C-0021/3664 | G06F-0003/014 | G06F-0003/0304 | G06F-0003/0346 | G06F-0003/04847 | G06F-0016/436 | A63B-0022/0076 | A63B-0022/02 | A63B-0022/0605 | A63B-0024/0087 | A63B-0069/0028 | A63B-0069/16 | A63B-0071/0622 | A63B-2071/0625 | A63B-2071/0636 | A63B-2220/12 | A63B-2220/40 | A63B-2220/806 | A63B-2220/807 | A63B-2220/833 | A63B-2220/836 | A63B-2225/50","G06F-017/30","G06F-017/30 | G01C-021/36 | G01C-021/20 | G06F-003/0346 | G06F-003/0484 | G06F-003/01 | G06F-003/03 | A61B-005/00 | G06F-016/435 | A63B-071/06 | A63B-022/00 | A63B-022/02 | A63B-022/06 | A63B-024/00 | A63B-069/00 | A63B-069/16","","","","","","4919020004489"
"US","US","P","B2","Information processing apparatus, information processing method, and recording medium","There is provided an information processing apparatus including a data acquiring unit configured to acquire content to which metadata is attached and the metadata attached to the content, the metadata being generated from data obtained from a sensor mounted on a subject, and a display control unit configured to reflect contents of the metadata acquired by the data acquiring unit in display of the content to which the metadata acquired by the data acquiring unit is attached.","1. A non-transitory computer-readable medium having embodied thereon a program, which when executed by a computer causes the computer to execute a method, the method comprising: receiving content associated with metadata and the metadata which is generated from data obtained from a sensor mounted on a subject while performing one or more contacting strikes of a sports movement; andcontrolling a display of the received metadata and the received content,wherein the metadata includes information related to an impact,wherein the content includes an image of an impact position,wherein the image of the impact position is controlled to be changed in color according to the information related to the impact,wherein the content further includes a depiction of a degree of proximity of the impact position to a sweet spot for each time the one or more contacting strikes of the sports movement is performed and an image of sports equipment, andwherein the image of the impact position and the depiction of the degree of proximity of the impact position to the sweet spot are displayed to overlap on the image of the sports equipment simultaneously.","14","16/030030","2018-07-09","2018-0314341","2018-11-01","10289209","2019-05-14","SONY CORPORATION","Yoshihiro  Nakanishi | Kosei  Yamashita | Ryo  Mukaiyama | Takaomi  Kimura | Hideyuki  Matsunaga | Naofumi  Fukasawa","2012-247885","JP","2012-11-09","G06F-0003/017","G06F-0003/017 | A61B-0005/743 | G06K-0009/00342 | G09G-0005/003 | H04N-0009/8205 | H04N-0021/41407 | H04N-0021/4223 | H04N-0021/42201 | H04N-0021/4334 | H04N-0021/47217 | H04N-0021/84 | H04N-0021/8456 | A61B-2562/0219","G06F-003/01","G06F-003/01 | H04N-009/82 | H04N-021/414 | H04N-021/422 | H04N-021/4223 | H04N-021/433 | H04N-021/472 | H04N-021/84 | H04N-021/845 | G06K-009/00 | G09G-005/00 | A61B-005/00","","","","","","4919020004492"
"US","US","P","B2","Method and system for automated retail checkout using context recognition","A gestural checkout system includes a sensor-equipped server programmed with a gestural context application that authenticates a customer's identity upon entry to a retail store. The sensors include cameras. The sensors are identify products and detect gestures of the customer indicating a purchase decisions. Gestures include product pick-up, product movement and product-commit-to-container actions. For bulk items, an Implicit Gestural Scale communicates product identity and volumetric data wirelessly to the implicit gestural checkout. Recognition of shopper locomotion, past a line of demarcation near the exit, automatically authorizes electronic payment.","1. A method for enabling a customer having an identity to purchase goods from a retail store through the use of implicit gestures and a customer financial account, comprising: providing a server in communication with the retail store, the retail store including a demarcation zone, for enabling check-out, wherein the server includes one or more processors, computer memory with software, the software being programmed for enabling operation of the server to communicate with a plurality of sensors;providing a first and second plurality of sensors, in operable communication with the server, wherein the first plurality of sensors are optical sensors, and the second plurality of sensors are different from the first plurality of sensors;sensing biometric information of the customer with the first plurality of sensors and converting at least some of the biometric information into topological variations, communicating the biometric information to the server to enable the server to authenticate customer identity;tracking movement of the customer within the retail store with the second plurality of sensors;recognizing gestures indicating a purchase decision;tracking the purchase decision in an electronic shopping cart;the topological variations are then animated within a gaming engine having a virtual camera, where the gaming engine'ss virtual camera is used to capture multiple points-of-view from various locations around the customer, these points of view correspond to the perspectives taken from the first plurality of sensors;and enabling a checkout procedure when the customer is passing the demarcation zone by charging the customer financial account based on the purchase decision.","21","14/322204","2014-07-02","2015-0039458","2015-02-05","10290031","2019-05-14","VOLITIONAL PARTNERS, INC.","Gregorio  Reid","","","","G06Q-0030/0601","G06Q-0030/0601 | A61B-0005/117 | G06K-0009/00335 | G06K-0009/00771 | G06Q-0020/206 | G06Q-0020/40145 | G07G-0001/0036 | A61B-0005/112 | A61B-0005/1176","G06Q-030/00","G06Q-030/00 | G06Q-030/06 | A61B-005/117 | G06K-009/00 | G07G-001/00 | G06Q-020/20 | G06Q-020/40 | A61B-005/1171 | A61B-005/11","","","","","","4919020005313"
"US","US","P","B2","System and method for integrating data with guidelines to generate displays containing the guidelines and data","A system and method for automatically integrating data with guidelines to generate displays containing the guidelines and data. The automated system and method can integrate patient data with treatment guidelines to assist a healthcare provider, such as a physician or the like, in providing treatment to the patient. The system and method employ a data storage component, adapted to store guideline data representing guidelines for assessing a condition of an entity, guidelines for taking action on the entity, or both, and to store feature data representing at least one feature of the entity. The system and method further employ an output device, adapted to output at least one diagram representing the guideline data, with the diagram including at least one component representing a relationship of at least a portion of the feature data to at least a portion of the guideline data.","1. A method for integrating guidelines with data in a medical condition management system, comprising: storing general guideline data in a database representing at least one of guidelines for assessing a condition of a patient and guidelines for taking action on said patient;obtaining patient specific data with a medical instrument configured to measure any one of blood pressure, pulse rate, cholesterol level, and HbAlc level;automatically inputting said patient specific data from said medical instrument into a patient terminal;storing patient specific data received from the patient terminal in said database representing at least one physical aspect of said patient measured by said medical instrument;outputting at least one branching graphical pathway diagram on a display of said medical condition management system representing said guideline data, said branching graphical pathway diagram comprising a plurality of diagnosis boxes comprising data elements corresponding to data ranges, the diagnosis boxes connected by decision pathways corresponding to the data ranges, one such data range being highlighted to reflect measured patient data being within the data range,automatically determining at least one decision for at least one decision pathway based on the stored patient specific data, andautomatically enhancing the diagnosis boxes of said branching graphical pathway diagram on said display to represent said general guideline data enhanced with said patient specific data integrated into the determined decision pathway to represent a relationship of at least a portion of said patient specific data to at least a portion of said general guideline data.","34","12/232907","2008-09-25","2009-0099872","2009-04-16","10290070","2019-05-14","Becton, Dickinson and Company","Tim H.  Gordon | Janet  Davidson | Nancy A.  Dunne | Roger  Mazze | Rachel  Robinson | Gregg  Simonson | Paul A.  Upham | Todd  Weaver","","","","G06Q-0050/22","G06Q-0050/22 | G06F-0016/972 | G06F-0019/325 | G06F-0019/326 | G06F-0019/3418 | G06F-0019/3481 | G06Q-0050/24 | G16H-0010/60 | G16H-0015/00","G16H-010/60","G16H-010/60 | G06Q-050/22 | G06F-019/00 | G06Q-050/24 | G16H-015/00 | G06F-016/958","","","","","","4919020005352"
"US","US","P","B2","Time series data display control device, method for operating the same, program, and system","A main display region 41 in which medical care data on a plurality of items is displayed is provided on a display screen 15. The main display region 41 may be displayed in two display modes of a two-dimensional display mode and a three-dimensional display mode in which a time scale is longer than a time axis of the two-dimensional display mode and a two-dimensional plane on which time series data is displayed is three-dimensionally displayed using the laws of perspective by which a plurality of straight lines parallel to the time axis in the two-dimensional display mode are drawn to be converged toward the past on the time axis.","1. A time series data display control device comprising: a processor configured to execute: a screen data generating unit that generates a time series data display screen on which a plurality of pieces of time series data are displayed; anda screen display control unit that performs switching between display modes of the time series data display screen, in which the display modes include two display modes of a two-dimensional display mode in which the time series data is displayed on a two-dimensional plane formed by two axes of a time axis of the plurality of pieces of time series data and a data array axis orthogonal to the time axis, on which the plurality of pieces of time series data are arrayed, and a three-dimensional display mode in which a time scale is set to be longer than a time axis of the two-dimensional display mode and the two-dimensional plane is three-dimensionally displayed using the laws of perspective by which a plurality of straight lines parallel to the time axis in the two-dimensional display mode are drawn to be converged toward the past on the time axis,wherein the three-dimensional display mode is a display mode in which the two-dimensional plane in the two-dimensional display mode is virtually rotated around a rotation axis orthogonal to the time axis, andwherein in the three-dimensional display mode, a part of a display period of the time series data is able to be two-dimensionally displayed,wherein a rotation angle of the two-dimensional plane is changeable,wherein the time scale of the time axis becomes longer as the rotation angle becomes larger,wherein in the two-dimensional display mode, a transverse axis of the time series data display screen is set as the time axis, and a longitudinal axis thereof is set as the data array axis,wherein in the three-dimensional display mode, the rotation axis and the longitudinal axis coincides with each other,wherein the time series data display screen includes two time axes of a first time axis which is two-dimensionally displayed similar to the two-dimensional display mode even in the three-dimensional display mode, and a second time axis which is provided in the two-dimensional plane on which the time series data is displayed and is three-dimensionally displayed similar to the two-dimensional plane, andwherein a display period of the first time axis is changed in conjunction with a display period of the second time axis which is changed depending on the rotation angle of the two-dimensional plane.","16","15/498496","2017-04-27","2017-0228900","2017-08-10","10290131","2019-05-14","FUJIFILM CORPORATION","Yuuki  Okabe | Yasuyo  Nenoki","2014-237155","JP","2014-11-21","G06T-0011/206","G06T-0011/206 | A61B-0005/743 | A61B-0005/7435 | G06F-0017/18 | G06T-0003/00 | G06T-0015/20 | G06F-0019/321 | G06F-0019/324 | G06T-0003/60 | G06T-0011/60 | G16H-0040/63 | H04L-0067/42","G06T-011/20","G06T-011/20 | A61B-005/00 | G06T-015/20 | G06T-003/00 | G06F-017/18 | G16H-040/63 | G06F-019/00 | G06T-003/60 | G06T-011/60 | H04L-029/06","","","","","","4919020005412"
"US","US","P","B2","Interactive placement of anatomical atlas structures in patient images","This disclosure describes systems, devices, and techniques for adjusting an anatomical atlas to patient anatomy. In one example, a system may include processing circuitry configured to generate, for display at a user interface, a representation of an anatomical region of a patient, generate, for display at the user interface, a representation of one or more atlas-defined anatomical structures at a first position over the representation of the anatomical region of the patient, receive a user annotation that defines an adjustment to at least one atlas-defined anatomical structure relative to the representation of the anatomical region of the patient, and adjust, based on the adjustment, the first position of the representation of the one or more atlas-defined anatomical structures to a second position of the representation of the one or more atlas-defined anatomical structures over the representation of the anatomical region of the patient.","1. A method comprising: generating, by one or more processors and for display at a user interface, a representation of an anatomical region of a patient;generating, by the one or more processors and for display at the user interface, a representation of one or more atlas-defined anatomical structures at a first position over the representation of the anatomical region of the patient;receiving, by the one or more processors, a user annotation that defines an adjustment to at least one atlas-defined anatomical structure of the one or more atlas-defined anatomical structures relative to the representation of the anatomical region of the patient;determining, by the one or more processors and based on the adjustment defined by the user annotation, one or more adjustments of the representation of the one or more atlas-defined anatomical structures by one or more movement amounts;selecting, by the one or more processors, one of the one or more adjustments that decreases a distance between the representation of the one or more atlas-defined anatomical structures and the annotation by a greatest amount;performing, by the one or more processors, the one of the one or more adjustments that decreases the distance between the representation of the one or more atlas-defined anatomical structures and the annotation by the greatest amount to move the representation of the one or more atlas-defined anatomical structures to a second position over the representation of the anatomical region of the patient; andcontrolling, by the one or more processors, the user interface to display the representation of the one or more atlas-defined anatomical structures at the second position over the representation of the anatomical region of the patient.","25","15/625414","2017-06-16","2017-0365103","2017-12-21","10290157","2019-05-14","MEDTRONIC BAKKEN RESEARCH CENTER B.V.","Rutger  Nijlunsing | Stefan  Marien","","","","G06T-0019/20","G06T-0019/20 | A61B-0005/0478 | A61B-0005/6868 | A61N-0001/0534 | A61N-0001/3605 | A61N-0001/36128 | A61N-0001/37247 | G06T-0007/30 | A61B-2090/364 | A61B-2576/026 | A61N-0001/36003 | A61N-0001/36007 | A61N-0001/36062 | A61N-0001/36064 | A61N-0001/36067 | A61N-0001/36071 | A61N-0001/36085 | A61N-0001/36107 | A61N-0001/36185 | G06F-0003/0486 | G06T-2210/41 | G06T-2219/004 | G06T-2219/028 | G06T-2219/2016","A61N-001/00","A61N-001/00 | G06T-019/20 | A61N-001/05 | A61N-001/36 | A61N-001/372 | A61B-005/00 | A61B-005/0478 | G06T-007/30 | G06F-003/0486 | A61B-090/00","","","","","","4919020005438"
"US","US","P","B2","Method and apparatus for remote sensing of objects utilizing radiation speckle","Disclosed are systems and methods to extract information about the size and shape of an object by observing variations of the radiation pattern caused by illuminating the object with coherent radiation sources and changing the wavelengths of the source. Sensing and image-reconstruction systems and methods are described for recovering the image of an object utilizing projected and transparent reference points and radiation sources such as tunable lasers. Sensing and image-reconstruction systems and methods are also described for rapid sensing of such radiation patterns. A computational system and method is also described for sensing and reconstructing the image from its autocorrelation. This computational approach uses the fact that the autocorrelation is the weighted sum of shifted copies of an image, where the shifts are obtained by sequentially placing each individual scattering cell of the object at the origin of the autocorrelation space.","1. A system for constructing a representation of an object from an autocorrelation, said system comprising: an autocorrelation comprising a copy wherein said copy comprises autocorrelation points representing an object;said autocorrelation further comprising autocorrelation points that lie on said copy and autocorrelation points that do not lie on said copy; anda processor comprising means to shift and compare said autocorrelation points eliminating said autocorrelation points that do not lie on said copy constructing a representation of said object from said autocorrelation points that lie on said copy.","16","15/420555","2017-01-31","2017-0138722","2017-05-18","10281257","2019-05-07","Lyle G. Shirley","Lyle G.  Shirley","","","","G01B-0009/02094","G01B-0009/02094 | A61B-0005/117 | G01B-0009/02004 | G01B-0009/02005 | G01B-0009/02069 | G01B-0009/02083 | G01B-0009/02096 | G01B-0011/14 | G01B-0011/2441 | G06F-0021/32 | G06K-0009/2018 | G06K-0009/629 | G06T-0007/521 | G06T-0007/55 | A61B-0005/0077 | A61B-2576/00 | G06T-2207/10152","G01B-011/02","G01B-011/02 | G01B-009/02 | G01B-011/24 | A61B-005/117 | G06F-021/32 | G06K-009/20 | G06K-009/62 | G06T-007/521 | G06T-007/55 | G01B-011/14 | A61B-005/00","","","","","","4919019003598"
"US","US","P","B2","Graphical user interface for medical instruments","The invention provides for medical instrument (200, 300) comprising a medical imaging system (202, 302) for acquiring medical image data (236) from an imaging zone (204) and a treatment system (206, 322) for depositing energy into a treatment zone (208). A processor executing instructions receives (100) a selection of a reference location and one or more anatomical references. The instructions cause the processor to repeatedly: deposit energy into the subject using a treatment system; acquire medical imaging data with the medical imaging system; determine a cumulative dosage data from the medical image data; determine (112) a first registration (242) for the reference location; determine (114) a second registration (244) for the one or more anatomical references; render (116) the medical image, the one or more anatomical references, and the cumulative dosage data (270) in the graphical user interface; and halt the deposition of energy into the subject if a halt command is received from the graphical user interface.","1. A medical instrument comprising: a medical imaging system for acquiring medical image data from an imaging zone;a treatment system for depositing energy into a treatment zone, wherein the treatment zone is within the imaging zone, wherein the treatment system is operable for depositing energy into a subject;a display for displaying a graphical user interface to an operator, wherein the graphical user interface is operable for receiving a halt command;a processor for controlling the medical instrument; anda computer storage for storing machine executable instructions for execution by the processor, wherein execution of the instructions causes the processor to receive a selection of a reference location; wherein execution of the instructions further causes the processor to receive a selection of one or more anatomical references, wherein execution of the instructions further causes the processor to repeatedly: control the treatment system depositing the energy into the subject in accordance with a treatment plan;control the medical imaging system to acquire the medical image data;reconstruct a medical image using the medical image data;determine cumulative dosage data at least partially from controlling the treatment system depositing the energy into the subject, wherein the cumulative dosage data are registered to the medical image;determine a first registration which registers the reference location to the medical image;determine a second registration which registers the one or more anatomical references to the medical image;render the medical image in the graphical user interface using the first registration to place the reference location in a predetermined position in the graphical user interface, such that the first registration enables the reference location to be displayed on a same position in the graphical user interface if the subject moves;render a representation of the one or more anatomical references in the graphical user interface using the second registration;render the cumulative dosage data in the graphical user interface, wherein the cumulative dosage data is superimposed on the medical image; andcontrol the treatment system to halt the depositing the energy into the subject if the halt command is received from the graphical user interface.","20","14/407831","2013-05-31","2015-0169836","2015-06-18","10282064","2019-05-07","KONINKLIJKE PHILIPS N.V.","Erkki Tapani  Vahala | Mika Petri  Ylihautala | Melanie Suzanne  Kotys","2012-181954","EP","2012-08-28","G06F-0003/0484","G06F-0003/0484 | A61B-0005/015 | A61B-0005/055 | A61B-0005/7435 | A61B-0008/13 | A61B-0008/465 | A61B-0018/12 | A61B-0018/1815 | A61B-0018/20 | A61B-0034/25 | A61F-0007/00 | A61N-0005/00 | A61N-0005/1084 | A61N-0007/00 | A61N-0007/02 | G01R-0033/4808 | G01R-0033/546 | G06F-0019/00 | G16H-0040/63 | A61B-2018/00577 | A61B-2034/254 | A61B-2090/374 | F04C-2270/041 | G01R-0033/4814","G06F-019/00","G06F-019/00 | A61B-005/055 | A61B-005/00 | A61B-008/00 | A61B-005/01 | A61B-008/13 | A61N-005/10 | A61B-018/20 | A61B-018/18 | A61B-018/12 | A61N-007/00 | A61N-005/00 | A61F-007/00 | G06F-003/0484 | A61N-007/02 | G01R-033/48 | G01R-033/54 | A61B-034/00 | G16H-040/63 | A61B-018/00 | A61B-090/00","","","","","","4919019004400"
"US","US","P","B2","Activity and workout updates","The present disclosure generally relates to navigating, viewing, and sharing activity and workout data and interacting with workout and/or activity applications. In some examples, scrolling of activity data is based on the content being displayed. In some examples, friends' activity data may be viewed. In some examples, a notification and workout data for a friend's completed workout is received and displayed. In some example, the activity data received from friends is viewed and managed. In some examples, workout data for a multi-segment workout is displayed in a three-dimensional stack on a map. In some examples, a workout application operates in a limited mode until a touch input is received with a characteristic intensity that is greater than a threshold intensity.","1. A method comprising: at a portable electronic device having a display: generating, for output on the display, a graphical representation of activity data, wherein the graphical representation includes a goal portion and a workout portion, wherein the goal portion and the workout portion each extend beyond a displayable area of the display, wherein the goal portion includes a first goal graphical element for a first goal metric, and wherein the workout portion includes a first workout graphical element for a first workout metric;displaying a first portion of the graphical representation on the display, wherein the displayed first portion includes a first graphical element;in response to receiving a first scroll input: while the displayed first portion is of the goal portion, replacing the display of the first graphical element with a display of the first goal graphical element; andwhile the displayed first portion is not of the goal portion, translating the first graphical element by an amount based on a magnitude of the first scroll input and displaying at least portion of the first workout graphical element.","27","15/616480","2017-06-07","2017-0354845","2017-12-14","10272294","2019-04-30","APPLE INC.","Aled Hywel  Williams | David Chance  Graham | Christopher  Wilson","","","","A63B-0024/0062","A63B-0024/0062 | A61B-0005/00 | A61B-0005/11 | A63B-0024/0084 | A63B-0071/0622 | G06F-0003/0485 | G06F-0003/04845 | G06F-0003/04883 | G06K-0009/00342 | G06T-0011/60 | A63B-2024/0068 | A63B-2071/0655 | A63B-2071/0691 | A63B-2220/12 | A63B-2220/20 | A63B-2220/40 | A63B-2220/62 | A63B-2220/805 | A63B-2220/806 | A63B-2220/807 | A63B-2225/50 | A63B-2230/06 | A63B-2230/75","G06F-003/048","G06F-003/048 | A63B-024/00 | A63B-071/06 | G06F-003/0484 | G06F-003/0485 | G06F-003/0488 | A61B-005/00 | A61B-005/11 | G06K-009/00 | G06T-011/60","","","","","","4919018001480"
"US","US","P","B2","Emergency video camera system","A surveillance system includes one or more camera systems at least some of the camera systems including a camera element comprising optical components to capture and process light to produce images, camera processing circuitry that receives the light and processes the light into electrical signals and encodes the signals into a defined format, power management circuitry to power the camera system, the power management system including first and second power interfaces and first and second video output interfaces.","1. A camera system comprises: a camera comprising: optical components to capture and process optical energy to produce images, and camera processing circuitry that receives the optical energy and processes the optical energy into electrical signals and encodes the signals into a defined format; andpower management circuitry to power the camera system, the power management system comprising:a first power interface that receives building supplied input power;a second, different power interface that receives back-up power in the event of loss of building power;a third, different power interface that is configured to connect to a fire panel; andcircuitry to switch from the first power interface to the second power interface upon detection of loss or imminent loss of power from the first interface, and to switch from the first or the second power interface to the third power interface in response to a signal received by the circuitry, which signal indicates an emergency event.","20","15/843124","2017-12-15","2018-0107492","2018-04-19","10275263","2019-04-30","TYCO FIRE & SECURITY GMBH","Stewart E.  Hall","","","","G06F-0009/4416","G06F-0009/4416 | A61B-0017/00 | G01S-0005/02 | G01S-0005/0236 | G01S-0005/0284 | G01S-0013/765 | G01S-0013/876 | G08B-0013/19634 | G08B-0025/009 | G08B-0029/181 | G08B-0029/188 | H04L-0009/004 | H04L-0012/4625 | H04L-0012/6418 | H04L-0061/106 | H04L-0067/104 | H04L-0067/12 | H04L-0067/34 | H04N-0005/76 | H04W-0008/26 | H04W-0016/26 | H04W-0088/04 | G08B-0013/19608 | G08B-0025/007 | H04L-0043/0805 | H04L-0061/6013 | H04L-0061/6072 | H04L-0067/1051 | H04L-0067/1093 | H04W-0004/006 | H04W-0004/38 | H04W-0084/18 | H04W-0092/02 | Y04S-0040/168 | Y04S-0040/18","H04N-005/232","H04N-005/232 | G06F-009/4401 | H04L-012/46 | H04N-005/76 | H04W-016/26 | H04L-012/64 | H04L-029/08 | H04L-029/12 | A61B-017/00 | G01S-005/02 | G01S-013/76 | G08B-025/00 | H04L-009/00 | H04W-008/26 | G01S-013/87 | G08B-029/18 | H04W-088/04 | G08B-013/196 | H04W-004/38 | H04W-092/02 | H04L-012/26 | H04W-004/00 | H04W-084/18","","","","","","4919018004433"
"US","US","P","B2","Biometric authentication apparatus and biometric authentication method","A biometric authentication apparatus 10 according to the present invention can be installed in facilities such as airports in order to improve the reliability of biometric authentication to ensure a high level of security. The biometric authentication apparatus 10 includes a illumination unit 11 which irradiates a human finger with light; an image acquisition unit 13 which acquires a plurality of images indicating changes in luminance by receiving light scattered at the human finger that is a part of the light with which the human finger is irradiated by the illumination unit 11 and converting the received light to luminance information according to the intensity of the light; an image-to-biometric-information conversion unit 14 which converts the plurality of images acquired by the image acquisition unit 13 to biometric information indicating a pulse wave in the human finger; and a biometric authentication unit 16 which performs biometric authentication when a pulse wave signal which is the biometric information resulting from the conversion by the image-to-biometric-information conversion unit 14 is greater than a predetermined threshold.","1. A biometric authentication apparatus comprising: a memory storing instructions; andone or more processors coupled to the memory and configured to execute the instructions to:irradiate a human finger with light generated by a light source;acquire, via an image acquisition device, a plurality of images indicating changes in luminance by receiving light scattered at the human finger that is a part of the light with which the human finger is irradiated and converting the received light to luminance information according to the intensity of the received light;convert the acquired plurality of images to biometric information indicating a pulse wave in the human finger; andperform automatically biometric authentication when the amplitude of a pulse wave signal is greater than a predetermined threshold, the pulse wave signal being the biometric information resulting from conversion.","8","15/523057","2015-10-20","2017-0337414","2017-11-23","10268874","2019-04-23","NEC CORPORATION","Yuji  Ohno | Masahiro  Kubo | Katsumi  Abe | Takeshi  Akagawa | Kimiyasu  Takoh | Ersin  Altintas | Tetsuri  Ariyama","2014-219806","JP","2014-10-29","G06K-0009/0012","G06K-0009/0012 | A61B-0005/02416 | A61B-0005/1172 | G01J-0003/10 | G01J-0003/2823 | G06F-0017/30256 | G06F-0021/32 | G06K-0009/0002 | G06K-0009/00013 | G06K-0009/00087","G06K-009/00","G06K-009/00 | A61B-005/024 | A61B-005/1172 | G01J-003/10 | G01J-003/28 | G06F-017/30 | G06F-021/32","","","","","","4919017004751"
"US","US","P","B2","Optical fingerprint sensor under a display","An optical sensor system includes: an input surface providing a sensing region for a biometric object; a plurality of display elements, disposed beneath the input surface, configured to emit light to provide a display; an aperture layer, disposed beneath the plurality of display elements; a collimator layer, disposed beneath the aperture layer; and a plurality of light sensing elements, disposed beneath the collimator layer, wherein the plurality of light sensing elements are configured to detect light from the sensing region that has passed through the aperture layer and the collimator layer.","1. An optical sensor system, comprising: an input surface providing a sensing region for a biometric object;a plurality of display elements, disposed beneath the input surface, configured to emit light to provide a display, wherein the plurality of display elements are formed on a thin-film transistor (TFT) layer;an aperture layer, disposed beneath the plurality of display elements;a collimator layer, disposed beneath the aperture layer; anda plurality of light sensing elements, disposed beneath the collimator layer, wherein the plurality of light sensing elements are configured to detect light from the sensing region that has passed through the aperture layer and the collimator layer;wherein the TFT layer comprises apertures in addition to apertures of the aperture layer.","27","15/199774","2016-06-30","2017-0220844","2017-08-03","10268884","2019-04-23","SYNAPTICS INCORPORATED","Eric  Jones | Paul  Wickboldt | Patrick  Smith | Young Seen  Lee | Alvin  Jee | Richard Andrew  Klenkler | Bob Lee  Mackey","","","","G06K-0009/0053","G06K-0009/0053 | A61B-0005/0059 | A61B-0005/1172 | G02B-0013/24 | G02B-0027/286 | G02B-0027/30 | G06F-0003/0412 | G06F-0003/0421 | G06K-0009/0004 | G06K-0009/00013 | G06K-0009/00026 | H01L-0027/3234 | H04N-0005/2253 | H04N-0005/2254 | A61B-0005/0261 | A61B-0005/14552 | G02B-2207/123 | G06F-2203/0338 | G06F-2203/04103 | G06K-0009/0008 | G06K-2009/0006 | G06K-2009/00939","G06K-009/00","G06K-009/00 | G06F-003/041 | G02B-027/30 | G02B-027/28 | A61B-005/1172 | H01L-027/32 | H04N-005/225 | A61B-005/00 | G02B-013/24 | G06F-003/042 | A61B-005/1455 | A61B-005/026","","","","","","4919017004761"
"US","US","P","B2","Sweat sensing device communication security and compliance","The invention addresses confounding difficulties involving continuous sweat analyte measurement. Specifically, the present invention provides: at least one component capable of monitoring whether a sweat sensing device is in sufficient contact with a wearer's skin to allow proper device operation; at least one component capable of monitoring whether the device is operating on a wearer's skin; at least one means of determining whether the device wearer is a target individual within a probability range; at least one component capable of generating and communicating alert messages to the device user(s) related to: wearer safety, wearer physiological condition, compliance with a requirement to wear a device, device operation; compliance with a behavior requirement, or other purposes that may be derived from sweat sensor data; and the ability to utilize aggregated sweat sensor data that may be correlated with information external to the device to enhance the predictive capabilities of the device.","1. A device comprising: a sensor apparatus for sensing and analyzing at least one fluid, wherein the sensor apparatus includes: a first layer;an electronic layer comprising a microcontroller, a transceiver antenna coil, and at least one sensor, wherein the at least one sensor includes at least one electrode, wherein the electronic layer is adhered to the first layer; anda microfluidic layer adhered to the first layer, wherein the microfluidic layer is positioned on a same plane as the electronic layer and surrounds the at least one sensor of the electronic layer;wherein the first layer is operable to allow a fluid to flow through the first layer and to the at least one sensor;wherein the at least one electrode of the at least one sensor is operable to generate at least one measurement characterizing a biomarker present in the fluid; andwherein the sensor apparatus uses the at least one measurement to calculate at least one output associated with the biomarker of the fluid.","19","15/362303","2016-11-28","2017-0100072","2017-04-13","10258262","2019-04-16","UNIVERSITY OF CINCINNATI, A UNIVERSITY OF THE STATE OF OHIO","Jason  Heikenfeld | Daniel P.  Rose | Ian  Papautsky | Wenjing  Kang | Xiao  Wang | Michael  Ratterman","","","","A61B-0005/14517","A61B-0005/14517 | A61B-0005/0002 | A61B-0005/0022 | A61B-0005/0205 | A61B-0005/0531 | A61B-0005/112 | A61B-0005/117 | A61B-0005/1477 | A61B-0005/14521 | A61B-0005/14546 | A61B-0005/14551 | A61B-0005/4266 | A61B-0005/4833 | A61B-0005/4845 | A61B-0005/6802 | A61B-0005/6833 | A61B-0005/6843 | A61B-0005/7275 | A61B-0005/742 | A61B-0005/746 | A61B-0005/7475 | B05D-0001/30 | B05D-0003/007 | B32B-0037/12 | G06F-0019/00 | G06K-0009/00892 | G06N-0005/04 | H04L-0067/18 | H04Q-0009/00 | A61B-0005/024 | A61B-0005/0533 | A61B-2560/0252 | A61B-2562/0214 | A61B-2562/0219 | A61B-2562/08 | A61B-2562/125 | A61B-2562/164 | B32B-2535/00 | G06K-2009/00939 | G16H-0050/20 | H04Q-2209/40 | Y02A-0090/26 | Y10T-0029/49155","A61B-005/1468","A61B-005/1468 | A61B-005/145 | A61B-005/00 | A61B-005/053 | A61B-005/11 | A61B-005/1455 | A61B-005/1477 | A61B-005/117 | H04Q-009/00 | B05D-001/30 | B05D-003/00 | B32B-037/12 | A61B-005/0205 | G06N-005/04 | H04L-029/08 | G06K-009/00 | G06F-019/00 | A61B-005/024 | G16H-050/20","","","","","","4919016000992"
"US","US","P","B2","System and method for virtual reality data integration and visualization for 3D imaging and instrument position data","Systems and methods for virtual reality or augmented reality (VR/AR) visualization of 3D medical images using a VR/AR visualization system are disclosed. The VR/AR visualization system includes a computing device operatively coupled to a VR/AR device, and the VR/AR device includes a holographic display and at least one sensor. The holographic display is configured to display a holographic image to an operator. The computing device is configured to receive at least one stored 3D image of a subject's anatomy and at least one real-time 3D position of at least one surgical instrument. The computing device is further configured to register the at least one real-time 3D position of the at least one surgical instrument to correspond to the at least one 3D image of the subject's anatomy, and to generate the holographic image comprising the at least one real-time position of the at least one surgical instrument overlaid on the at least one 3D image of the subject's anatomy.","1. A system comprising: a catheter configured to be inserted inside a cardiovascular organ of a subject, the catheter comprising one or more sensors generating a first set of sensor data;a head-mounted display (HMD) configured to be worn by an operator and to display an electroanatomic visualization representing the cardiovascular organ in 3D in a field of view of the operator in response to receiving 3D images, wherein the 3D images include at least a first 3D image and a second 3D image;an input device configured to generate a second set of sensor data responsive to a motion of the operator; andone or more computers communicatively coupled to the catheter to receive the first set of sensor data, communicatively coupled to the input device to receive the second set of sensor data, and communicatively coupled to the HMD via a wireless data exchange protocol, wherein the one or more computers comprises one or more processors and computer program instructions that when executed cause the one or more processors to: generate the first 3D image by processing the first set of sensor data;provide the first 3D image to the HMD;receive the second set of sensor data responsive to the motion of the operator to interact with the electroanatomic visualization;determine a path of the motion of the operator by processing the second set of sensor data;determine an angle of rotation for the electroanatomic visualization based on the path of the motion; andprovide the second 3D image to the HMD to update the display of the electroanatomic visualization by rotating the cardiovascular organ by the angle of rotation in the field of view of the operator.","30","15/918418","2018-03-12","2018-0200018","2018-07-19","10258426","2019-04-16","WASHINGTON UNIVERSITY","Jonathan  Silva | Jennifer  Silva","","","","A61B-0090/37","A61B-0090/37 | A61B-0005/042 | A61B-0005/066 | A61B-0005/743 | A61B-0005/745 | A61B-0034/20 | A61B-0090/361 | G06F-0003/017 | G06F-0019/00 | G06T-0015/205 | G06T-0017/20 | G06T-0019/00 | G06T-0019/006 | A61B-0018/02 | A61B-0018/1492 | A61B-2018/00351 | A61B-2018/00577 | A61B-2018/00642 | A61B-2018/00839 | A61B-2018/0212 | A61B-2034/2051 | A61B-2034/2063 | A61B-2034/2065 | A61B-2090/365 | A61B-2090/367 | A61B-2090/368 | A61B-2090/376 | A61B-2090/3782 | G06T-2210/41 | G06T-2219/004 | G06T-2219/024","A61B-090/00","A61B-090/00 | G06T-015/20 | G06T-017/20 | G06F-003/01 | G06T-019/00 | A61B-005/042 | A61B-034/20 | A61B-005/00 | A61B-005/06 | G06F-019/00 | A61B-018/02 | A61B-018/14 | A61B-018/00","","","","","","4919016001156"
"US","US","P","B2","Patient directed therapy control","A patient controls the delivery of therapy through volitional inputs that are detected by a biosignal within the brain. The volitional patient input may be directed towards performing a specific physical or mental activity, such as moving a muscle or performing a mathematical calculation. In one embodiment, a biosignal detection module monitors an electroencephalogram (EEG) signal from within the brain of the patient and determines whether the EEG signal includes the biosignal. In one embodiment, the biosignal detection module analyzes one or more frequency components of the EEG signal. In this manner, the patient may adjust therapy delivery by providing a volitional input that is detected by brain signals, wherein the volitional input may not require the interaction with another device, thereby eliminating the need for an external programmer to adjust therapy delivery. Example therapies include electrical stimulation, drug delivery, and delivery of sensory cues.","1. A system comprising: a biosignal detection module configured to detect at least one biosignal from one or more muscles of a patient indicative of a volitional activity; anda processor configured to control a therapy module to deliver electrical stimulation therapy to the patient, wherein the processor is configured to control the therapy module by controlling adjustment of a parameter of the electrical stimulation therapy based on the detected at least one biosignal, wherein the parameter of the electrical stimulation therapy comprises one or more of:a current amplitude or a voltage amplitude of the electrical stimulation therapy;a pulse width of the electrical stimulation therapy;a pulse frequency of the electrical stimulation therapy;an electrode combination of the electrical stimulation therapy; oran electrode polarity of one or more electrodes of the electrical stimulation therapy.","24","15/012646","2016-02-01","2016-0158553","2016-06-09","10258798","2019-04-16","MEDTRONIC, INC.","Eric J.  Panken | Timothy J.  Denison | Gregory F.  Molnar","","","","A61N-0001/36139","A61N-0001/36139 | A61B-0005/7475 | A61M-0005/14276 | A61M-0005/1723 | A61N-0001/3605 | A61N-0001/3606 | A61N-0001/36014 | A61N-0001/37252 | G06F-0003/015 | A61B-0005/048 | A61B-0005/4082 | A61M-2210/0693 | A61N-0001/36017 | A61N-0001/36021 | A61N-0001/36025 | A61N-0001/36071 | A61N-0001/36082","A61N-001/36","A61N-001/36 | A61B-005/00 | A61M-005/142 | A61M-005/172 | A61N-001/372 | G06F-003/01 | A61B-005/048","","","","","","4919016001527"
"US","US","P","B2","Method and device for determining input information","The present application provides a method and device for determining input information, and relates to the field of a wearable device. The method comprises in response to a first part of a body of a user executing an action, acquiring target blood-flow information about the first part or a second part that corresponds to the first part; and determining input information according to the target blood-flow information and reference information. According to the method and device, the body of the user is used as an input interface, to cause an interaction area to be increased, which helps to improve input efficiency and user experience.","1. A method for determining input information, wherein the method comprises: in response to an action part of a body of a user executing an action, acquiring target Doppler measurement information about the action part or an acquisition part that corresponds to the action part, the target Doppler measurement information is blood-flow information;determining target-velocity-related information corresponding to the target Doppler measurement information;determining the action part and/or the action according to the target-velocity-related information and reference information; anddetermining input information according to the action part and/or the action.","23","15/548462","2016-01-07","2018-0018015","2018-01-18","10261577","2019-04-16","BEIJING ZHIGU RUI TUO TECH CO., LTD.","Yuanchun  Shi | Yuntao  Wang | Chun  Yu | Lin  Du","2015-10069927","CN","2015-02-10","G06F-0003/011","G06F-0003/011 | A61B-0005/0261 | A61B-0005/6826 | A61B-0008/06 | A61B-0008/488 | G06F-0001/163 | A61B-0008/5223 | A61B-2503/12 | G06F-0003/017 | G06K-0009/0053 | G06K-0009/00355 | G06K-0009/00543","G09G-005/00","G09G-005/00 | G06F-003/01 | A61B-008/06 | G06F-001/16 | A61B-008/08 | A61B-005/026 | A61B-005/00 | G06K-009/00","","","","","","4919016004282"
"US","US","P","B2","Curved line correction apparatus, method, and medium","A curved line correction apparatus includes a correction target receiving unit that receives selection of a correction target point when an instruction mark is placed on an arbitrary point on a curved line composed of a plurality of arranged points, a correction target range setting unit that sets a certain range of the curved line, including the correction target point, as a correction target range, and a correction unit that corrects a portion of the curved line within the correction target range by moving the correction target point and a point within the correction target range when movement of the instruction mark is received, in which the correction target range setting unit changes the size of the correction target range when an instruction input to change the range is received with the instruction mark being placed on the correction target point.","1. A curved line correction apparatus, comprising a memory storing computer executable instructions and a processor configured to execute the stored instructions, which when executed by the processor cause the processor to perform the following operations: receive a correction target point when an instruction mark is placed on an arbitrary point on a curved line composed of a plurality of arranged points displayed on a display unit;set a certain range of the curved line, including the correction target point, as a correction target range;correct a portion of the curved line within the correction target range by moving the correction target point and a point within the correction target range when movement of the instruction mark is received; andchange the size of the correction target range when an instruction input to change the range is received with the instruction mark being placed on the correction target point, the instruction input being based on a user'ss action on an input device and being received before receiving the movement of the instruction mark,wherein the correction target range is a point group range on the curved line included in a range defined by a central angle of a circular arc formed by taking the correction target point as a central point thereof, and the processor changes the size of the correction target range by changing the central angle of the circular arc.","16","14/804794","2015-07-21","2016-0035071","2016-02-04","10262402","2019-04-16","FUJIFILM CORPORATION","Kenta  Yamada","2014-156625","JP","2014-07-31","G06T-0005/20","G06T-0005/20 | A61B-0005/055 | A61B-0006/032 | A61B-0006/461 | A61B-0006/468 | A61B-0006/469 | A61B-0006/503 | A61B-0006/5217 | G06F-0003/04842 | G06F-0003/04845 | G06K-0009/46 | G06K-0009/6254 | G06T-0007/0012 | G06T-0007/12 | A61B-2576/023 | G06K-2209/051 | G06T-2200/04 | G06T-2207/10072 | G06T-2207/10081 | G06T-2207/20096 | G06T-2207/20104 | G06T-2207/30048 | G06T-2210/41 | G06T-2211/40","G06T-007/12","G06T-007/12 | G06T-005/20 | A61B-005/055 | A61B-006/03 | A61B-006/00 | G06K-009/46 | G06T-007/00 | G06F-003/0484 | G06K-009/62","","","","","","4919016005098"
"US","US","P","B2","Enhanced pathology diagnosis","A system includes a microscope configured to magnify a pathology sample, a camera positioned to record magnified pathology images from the microscope, a pathology database including reference pathology images, and a display configured to show the magnified pathology images. A processing apparatus is coupled to the camera, the pathology database, and the display. The processing apparatus includes instructions that when executed by the processing apparatus cause the system to perform operations. The operations include comparing the magnified pathology images to the reference pathology images included in the pathology database; identifying one or more regions of interest in the magnified pathology images; and alerting, using the display, a user of the microscope to the one or more regions of interest in the magnified pathology images while the pathology sample is being magnified with the microscope.","1. A system, comprising: a microscope configured to magnify a pathology sample;a camera positioned to record magnified pathology images from the microscope;a pathology database including reference pathology images;a display configured to show the magnified pathology images; anda processing apparatus coupled to the camera, the pathology database, and the display, wherein the processing apparatus includes a machine learning algorithm disposed in logic, and wherein the processing apparatus includes instructions that when executed by the processing apparatus cause the system to perform operations, including: comparing the magnified pathology images to the reference pathology images included in the pathology database;identifying, using the machine learning algorithm, one or more regions of interest in the magnified pathology images by comparing the magnified pathology images to the reference pathology images; andalerting, using the display, a user of the microscope to the one or more regions of interest in the magnified pathology images while the pathology sample is being magnified with the microscope, wherein alerting the user includes informing the user of a diagnosis, and a confidence interval for the diagnosis, of a structure in the one or more regions of interest.","17","16/008809","2018-06-14","2018-0301217","2018-10-18","10262757","2019-04-16","Verily Life Sciences LLC","Joelle K.  Barral","","","","G16H-0030/40","G16H-0030/40 | A61B-0005/7264 | G06F-0017/30265 | G06F-0019/00 | G06F-0019/321 | G06K-0009/00147 | G06K-0009/00597 | G06K-0009/3233 | G06K-0009/6255 | G06N-0099/005 | G06T-0007/0014 | G16H-0030/20 | G16H-0050/20 | G06K-2209/27 | G06T-2207/10056 | G06T-2207/20081 | G06T-2207/30024","G06K-009/00","G06K-009/00 | G16H-030/40 | G16H-050/20 | G06F-017/30 | G06F-019/00 | G06K-009/32 | G06K-009/62 | G06N-099/00 | G06T-007/00 | A61B-005/00 | G16H-030/20","","","","","","4919016005452"
"US","US","P","B2","Robotized surgery system with improved control","A robotized surgery system (10) comprises at least one robot arm (11) which acts under the control of a control console (12) intended for the surgeon. The console (12) comprises an eye tracking system (21) for detecting the direction of the surgeon's gaze and for entering commands depending on the directions of the gaze detected. The console (22) comprises advantageously a screen (23) with at least one zone (23) for viewing the operating field and, among the commands which can be performed depending on the gaze directions, there is advantageously an automatic command for enabling or disabling the movement of the robot arm (11) when a gaze direction which falls within or outside of said zone (23) of the screen is detected.","1. A method of controlling a robotic surgery system, comprising: providing a surgical system comprising a robotic arm, an endoscopic camera moveable by the robotic arm, a surgeon console including a screen displaying an image from the endoscopic camera and an eye tracking system configured to determine a zone of a surgeon'ss gaze on an image on the screen and to determine a distance of the surgeon'ss eyes from the screen;detecting movement of a surgeon'ss eyes towards or away from the screen using the eye tracking system, andcausing the robotic arm to move the camera to enlarge or diminish the image on the screen in response to the detected eye movement.","9","15/149512","2016-05-09","2016-0249992","2016-09-01","10251713","2019-04-09","TRANSENTERIX ITALIA S.R.L.","Emilio  Ruiz Morales | Damien  Brasset | Paolo  Invernizzi","MI2010-000579","IT","2010-04-07","A61B-0034/30","A61B-0034/30 | A61B-0017/00 | G06F-0003/013 | G06F-0003/0482 | G06F-0003/04842 | G06F-0003/04847 | G06K-0009/00604 | A61B-0003/113 | A61B-0005/11 | A61B-0034/37 | A61B-0090/361 | A61B-2017/00216","A61B-034/30","A61B-034/30 | A61B-017/00 | G06F-003/01 | G06F-003/0482 | G06F-003/0484 | G06K-009/00 | A61B-003/113 | A61B-005/11 | A61B-090/00 | A61B-034/37","","","","","","4919015001082"
"US","US","P","B2","Puncture planning apparatus and puncture system","A puncture planning apparatus has: a simulation unit that simulates movement of an organ and a puncture needle by simulation using an organ model; and a planning unit that plans, based on the simulation result, how to move the puncture needle when an actual organ is punctured. The simulation unit executes a plurality of times of the simulation of an operation to advance the puncture needle while correcting an angle of the puncture needle so as to follow the movement of the target segment due to deformation of the organ, conditions of an advancement speed of the puncture needle are changed for each of the plurality times of the simulation, and the planning unit performs planning using the best simulation result out of the plurality of simulation results acquired under different conditions of the advancement speed.","1. A puncture system comprising: a simulation unit that performs simulation of movement of an organ and a puncture needle when the puncture needle is inserted into the organ and advanced toward a target segment inside the organ, by simulation using an organ model;a planning unit that plans a movement of the puncture needle when an actual organ is punctured, and outputs a planning result; anda control unit that controls the movement of the puncture needle on a basis of the planning result,wherein the simulation unit executes a plurality of times of the simulation in which conditions of an advancement speed of the puncture needle are mutually different and generates a plurality of simulation results, andwherein the planning unit plans the movement of the puncture needle on a basis of a selected one of the plurality of simulation results, at least one puncture error and puncture time period of which meets a predetermined criteria,wherein the simulation unit performs speed adjustment in performing the simulation, so as to reduce the advancement speed of the puncture needle in accordance with a puncture reaction force, which is a force that the puncture needle receives from the organ,wherein the simulation unit adjusts the advancement speed of the puncture needle by multiplying a predetermined initial value of the advancement speed by a speed gain which is determined in accordance with the puncture reaction force,wherein the speed gain is determined by the following expressions, andthe simulation unit executes the plurality of times of simulation while changing, as the condition, a value of a parameter ak in the following expressions: where Kf is a speed gain, Fn is a puncture reaction force, Fnmin is a predetermined threshold, ak is a parameter to determine the reduction rate of the speed gain, and Kfmin is a predetermined minimum value of the speed gain.","6","14/791602","2015-07-06","2016-0008082","2016-01-14","10255247","2019-04-09","CANON KABUSHIKI KAISHA","Kiyoshi  Takagi","2014-142425 | 2015-083663","JP | JP","2014-07-10 | 2015-04-15","G06F-0017/10","G06F-0017/10 | A61B-0017/3403 | A61B-0034/10 | A61B-0034/30 | G06F-0019/00 | G16H-0050/50 | A61B-0005/065 | A61B-0008/0841 | A61B-0017/3478 | A61B-0034/20 | A61B-0090/11 | A61B-2017/3413 | A61B-2034/104 | A61B-2034/107 | G01R-0033/287","A61B-017/34","A61B-017/34 | G06F-017/10 | A61B-034/30 | A61B-034/10 | G16H-050/50 | G06F-019/00 | A61B-008/08 | A61B-090/11 | A61B-005/06 | A61B-034/20 | G01R-033/28","","","","","","4919015004584"
"US","US","P","B2","Method and system for assessing facial skin health from a mobile selfie image","A method, non-transitory computer readable medium and apparatus for transmitting an assessment of facial skin health of a customer are disclosed. For example, the method includes receiving an image of a customer from a mobile endpoint device of the customer, analyzing one or more parameters of a facial skin of the customer in the image of the customer, determining the assessment of facial skin health of the customer based on the one or more parameters of the facial skin that are analyzed and transmitting the assessment of facial skin health to the mobile endpoint device of the customer to cause the mobile endpoint device to automatically display the assessment of facial skin health.","1. A method for transmitting an assessment of facial skin health of a customer, comprising: receiving, by a processor, an image of the customer from a mobile endpoint device of the customer;analyzing, by the processor, one or more parameters of a facial skin of the customer in each pixel of the image of the customer;determining, by the processor, the assessment of facial skin health of the each pixel of the image of the customer based on the one or more parameters of the facial skin that are analyzed;associating, by the processor, a corresponding color to the each pixel based on the assessment of facial skin health that is determined for the each pixel;generating, by the processor, a visual map based on the corresponding color that is associated with the each pixel based on the assessment of facial skin health that is determined for the each pixel, wherein the visual map comprises a plurality of facial regions that include concentric areas having a different color based on the corresponding color that is associated with the each pixel; andtransmitting, by the processor, the assessment of facial skin health that includes the visual map to the mobile endpoint device of the customer to cause the mobile endpoint device to automatically display the assessment of facial skin health.","17","15/414095","2017-01-24","2017-0270350","2017-09-21","10255484","2019-04-09","PROCTER & GAMBLE COMPANY","Martin S.  Maltz | Matthew Adam  Shreve | Luisa Fernanda  Polania Cabrera | Stephen C.  Morgana | Raja  Bala | Paul Jonathan  Matts | Ankur  Purwar","","","","G06K-0009/00281","G06K-0009/00281 | A61B-0005/0022 | A61B-0005/0077 | A61B-0005/443 | A61B-0005/486 | A61B-0005/742 | G06Q-0030/0631 | G06T-0007/40 | G06T-0007/90 | G09B-0019/00 | G06K-2009/4666 | G06T-2207/10024 | G06T-2207/30201 | H04N-0001/00106","G06K-009/00","G06K-009/00 | G09B-019/00 | A61B-005/00 | G06Q-030/06 | G06T-007/40 | G06T-007/90 | H04N-001/00 | G06K-009/46","","","","","","4919015004819"
"US","US","P","B2","Field of view (FOV) throttling of virtual reality (VR) content in a head mounted display","A method for reducing discomfort when viewing virtual reality (VR) content for use in head mounted displays (HMDs). The method includes accessing a model that identifies a plurality of learned patterns associated with the generation of corresponding baseline VR content that is likely to cause discomfort. The method includes processing a first application to generate data associated with simulated user interactions with first VR content of the first application. The method includes comparing the data to the model to identify a pattern in the data matching at least one of the learned patterns, such that the identified pattern is likely to cause discomfort. The method includes identifying a zone in the first application corresponding to identified pattern. The method includes applying a discomfort reduction filter effect within the zone for purposes of reducing potential discomfort in a user.","1. A method for reducing discomfort when viewing virtual reality (VR) content for use in head mounted displays (HMDs), comprising: executing an application to generate VR content in association with user interaction;detecting a pattern in the VR content identified as likely to cause discomfort in users;applying a discomfort reduction filter effect for purposes of reducing potential discomfort in the user, wherein the discomfort reduction filter effect comprises a reduction in a size of a clarity region of a FOV of the VR content, wherein the clarity region has a highest amount of resolution for an image presented in the FOV, and a first region outside of the clarity region has decreased resolution; andmaintaining a size of the FOV concurrent with the reduction in the clarity region.","20","15/471466","2017-03-28","2018-0096518","2018-04-05","10255715","2019-04-09","SONY INTERACTIVE ENTERTAINMENT INC.","Dominic S.  Mallinson","","","","G06T-0015/20","G06T-0015/20 | A61B-0005/024 | A61B-0005/04884 | A61B-0005/0531 | A61M-0021/00 | A63F-0013/53 | G02B-0027/017 | G06F-0003/011 | G06F-0003/012 | G06N-0003/02 | G06N-0003/04 | G06N-0003/08 | G06N-0005/04 | G06T-0019/006 | G06T-0019/20 | A61M-2021/005 | A61M-2021/0044 | A61M-2205/507 | A63F-2300/303 | G02B-0027/0093 | G02B-2027/014 | G06F-0003/013 | G06F-0003/015 | G06T-2200/04 | G06T-2200/24 | G06T-2207/20024 | G06T-2207/20092","A63F-013/53","A63F-013/53 | G06N-003/02 | G06N-005/04 | G06T-015/20 | G06T-019/20 | A61B-005/024 | A61B-005/0488 | A61B-005/053 | G06F-003/01 | G06N-003/04 | G06N-003/08 | G06T-019/00 | A61M-021/00 | G02B-027/01 | G02B-027/00","","","","","","4919015005049"
"US","US","P","B2","Planning, navigation and simulation systems and methods for minimally invasive therapy","Disclosed herein are planning, navigation and simulation systems and methods for minimally invasive therapy in which the planning method and system uses patient specific pre-operative images. The planning system allows for multiple paths to be developed from the pre-operative images, and scores the paths depending on desired surgical outcome of the surgery and the navigation systems allow for minimally invasive port based surgical procedures, as well as craniotomies in the particular case of brain surgery.","1. A computer implemented method for planning a pathway to a target location in tissue within a patient'ss body, the computer implemented method executed within a computer system comprising a computer processor connected to a storage medium, and a user interface having a user terminal, the method comprising the steps of: producing, at the user terminal, at least one pre-operative image data set image of a 3D volume of a patient'ss body containing potential entry points into the tissue and one or more targets to be treated;receiving through the user interface of the user terminal, inputs to be stored in the storage medium including a list of one or more entry points into the tissue, one or more target locations to be treated, a first target location to be approached first, and a surgical outcome criteria to be satisfied by one or more surgical trajectory paths from the one or more entry points to the first one of the one or more targets;computing, at the user terminal, one or more point-wise surgical trajectory paths from the one or more designated entry points to the first target location consistent with the surgical outcome criteria;storing the one or more point-wise surgical trajectory paths in the storage medium;assigning a score to the one or more trajectory paths, at the user terminal, to quantify how well the one or more trajectory paths satisfy the surgical outcome criteria;storing the assigned scores in the storage medium; andvisually displaying selected surgical trajectory paths at the user interface.","20","15/646946","2017-07-11","2017-0309069","2017-10-26","10255723","2019-04-09","SYNAPTIVE MEDICAL (BARBADOS) INC.","Monroe M.  Thomas | Gal  Sela | Cameron  Piron | Joshua  Richmond | Murugathas  Yuwaraj | Wes  Hodges | Simon  Alexander | David  Gallop | William  Lau | Sheryl  Thingvold | Kelly  Dyer","","","","G06T-0019/003","G06T-0019/003 | A61B-0005/0042 | A61B-0005/055 | A61B-0006/032 | A61B-0006/037 | A61B-0006/501 | A61B-0008/0808 | A61B-0034/10 | A61B-0034/20 | G06F-0003/04815 | G06F-0003/04842 | G06F-0003/04847 | G06T-0001/60 | G06T-0007/0012 | G06T-0011/20 | G06T-0017/00 | G06T-0019/20 | A61B-0008/00 | A61B-2034/105 | A61B-2034/107 | A61B-2034/2051 | A61B-2034/2055 | A61B-2090/378 | A61B-2090/3735 | G06T-2200/04 | G06T-2200/24 | G06T-2207/10088 | G06T-2207/20101 | G06T-2207/30016 | G06T-2207/30241 | G06T-2210/41 | G06T-2219/028","G06K-009/00","G06K-009/00 | G06T-019/00 | G06T-019/20 | G06T-011/20 | A61B-034/20 | A61B-006/03 | A61B-005/00 | A61B-006/00 | A61B-008/08 | G06F-003/0481 | G06T-001/60 | G06T-017/00 | G06T-007/00 | G06F-003/0484 | A61B-005/055 | A61B-005/05 | A61B-090/00 | A61B-034/10 | A61B-008/00","","","","","","4919015005057"
"US","US","P","B2","Systems and methods for credit-based usage of surgical instruments and components thereof","Systems and methods for credit-based usage of surgical instruments include one or more surgical instruments having associated therewith a usage amount, a pre-determined maximum usage amount, and an available usage credit amount that is less than the pre-determined maximum usage amount. The systems implement and the methods include comparing the usage amount to the pre-determined maximum usage amount and inhibiting further use of the at least one reusable component when the usage amount is equal to the pre-determined maximum usage amount, and identifying the available usage credit amount and inhibiting further use of the at least one reusable component when there is no available usage credit remaining.","1. A surgical system, comprising: a plurality of surgical instruments, each of the plurality of surgical instruments including: a reusable component;a processor;a non-transitory computer-readable storage medium storing instructions that, when executed by the processor, cause the processor to monitor usage of the reusable component; anda local memory,wherein an overall available usage credit is stored in the local memory of each of the plurality of surgical instruments; anda central device in communication with each of the plurality of surgical instruments, the central device including a central memory storing the overall available usage credit, a central processor, and a central non-transitory computer-readable storage medium storing instructions that, when executed by the central processor, cause the central processor to communicate with the processor of each of the plurality of surgical instruments such that, upon use of the reusable component of any one of the plurality of surgical instruments, the overall available usage credit stored in the central memory and in each of the local memories is decreased accordingly.","13","15/482897","2017-04-10","2017-0212995","2017-07-27","10255995","2019-04-09","COVIDIEN LP","Michael D.  Ingmanson","","","","G16H-0040/63","G16H-0040/63 | A61B-0017/07207 | A61B-0090/98 | G06F-0019/00 | G16H-0040/20 | A61B-0001/00062 | A61B-2017/0046 | A61B-2017/00199 | A61B-2017/00221 | A61B-2017/00734 | A61B-2090/0803 | A61B-2090/0808 | A61B-2090/0814 | G06F-0019/328 | G06Q-0010/20 | G06Q-0020/14 | G06Q-0020/145 | G06Q-0020/22 | G06Q-0020/28 | G06Q-0030/04 | G06Q-0050/22","G16H-040/63","G16H-040/63 | A61B-017/072 | A61B-090/98 | G16H-040/20 | G06F-019/00 | A61B-090/00 | G06Q-030/04 | A61B-001/00 | A61B-017/00 | G06Q-010/00 | G06Q-020/14 | G06Q-020/22 | G06Q-020/28 | G06Q-050/22","","","","","","4919015005328"
"US","US","P","B2","Short imagery task (SIT) research method","The present disclosure relates to biologically and behaviorally based methods of measuring audience response to a short stimulus.","1. A system comprising: a first sensor to measure first biometric data from a first subject exposed to a first stimulus via a stimulus presentation device;a second sensor to measure second biometric data from a second subject exposed to the first stimulus, the first subject and the second subject forming an audience;a memory including machine executable instructions; andat least one processor to execute the instructions to: control the stimulus presentation device to present the first stimulus based on activation of the first sensor;synchronize the first biometric data and the second biometric data, the first biometric data and the second biometric data time-stamped with respective time indicators indicative of a window of exposure of the first subject and the second subject to the first stimulus;generate a synchrony score for the first stimulus based on the synchronization;determine a first response score for the first subject based on the time-stamped first biometric data;determine a second response score for the second subject based on the time-stamped second biometric data;reconcile differences in frequencies between the first sensor and the second sensor by determining a combined response score for the window based on the first response score and the second response score;calculate an engagement score for the first stimulus based on the synchrony score and the combined response score;estimate an effectiveness of the first stimulus based on the engagement score; andcause at least one of (1) at least a portion of the first stimulus or (2) a second stimulus to be presented based on the estimate.","20","15/238333","2016-08-16","2016-0357256","2016-12-08","10248195","2019-04-02","THE NIELSEN COMPANY (US), LLC.","Caleb J.  Siefert","","","","G06F-0003/013","G06F-0003/013 | A61B-0003/112 | A61B-0005/0205 | A61B-0005/162 | A61B-0005/165 | G06F-0019/36 | G06K-0009/00892 | G09B-0005/065 | G09B-0005/10 | G09B-0007/073 | A61B-0005/024 | A61B-0005/0531 | A61B-0005/0816","G09B-005/00","G09B-005/00 | G06F-003/01 | G09B-007/073 | G09B-005/10 | G06F-019/00 | A61B-003/11 | A61B-005/0205 | A61B-005/16 | G06K-009/00 | G09B-005/06 | A61B-005/024 | A61B-005/053 | A61B-005/08","","","","","","4919014004191"
"US","US","P","B2","Scheduling customizable electronic notifications","An alarm application is described. A user interface of the alarm application may be presented that includes a generic alarm option and a sleep alarm option. A first view of the user interface may be presented that includes generic alarm related options when the generic alarm option is selected. A second view of the user interface may be presented that includes sleep alarm related options when the sleep alarm option is selected.","1. A computer-implemented method, comprising: presenting, at least in response to a first user input, an alarm graphical user interface on a device, the alarm graphical user interface comprising: a generic alarm selector that, when selected, enables interaction with one or more generic alarms; anda sleep alarm selector that, when selected, enables interaction with a sleep alarm;receiving a second user input that identifies selection of the sleep alarm selector;presenting, at least in response to the second user input, a sleep alarm view of the alarm graphical user interface on the device;receiving sleep configuration information;determining, based at least in part on the sleep configuration information, a first future time corresponding to a suggested bedtime; andpresenting, on the device, a sleep alert based at least in part on the first future time, the sleep alert comprising a bedtime reminder for presentation prior to the suggested bedtime.","26","15/273865","2016-09-23","2017-0357419","2017-12-14","10248302","2019-04-02","APPLE INC.","Roy J. E. M.  Raymann | Jay C.  Blahnik | Stephanie M.  Greer | Aroon  Pahwa | Jonathan T.  Varbel","","","","G06F-0003/04847","G06F-0003/04847 | A61B-0005/4806 | G06F-0003/048 | G06F-0003/04842 | G06F-0009/451 | G06Q-0010/109 | G08B-0021/06","G06F-003/048","G06F-003/048 | G06F-009/451 | A61B-005/00 | G06F-003/0484 | G06Q-010/10 | G08B-021/06","","","","","","4919014004298"
"US","US","P","B2","Fraudulent application detection system and method of use","The present invention provides a system and a method for detecting or determining possible fraudulent information provided by a subject using the subject's behavioral biometric during an application filing process using an electronic input device. The method involves comparing the subject's electronic input device usage characteristic with a control electronic input device usage characteristic data to determine a fraud potential of the subject's input or answer to the question.","1. A real-time fraud detection method during data entry in an electronic application filing process by a subject, said method comprising: passively collecting in real-time an electronic input device usage characteristic of a subject during said subject'ss data entry in an electronic application filing process;(ii) calculating a confidence score against a baseline model comprised of both the subject'ss electronic input device usage characteristic data and population input device usage characteristic data; and(iii) on the basis of the confidence score, determining in real-time a fraud potential of said subject by comparing said subject'ss electronic input device usage characteristic data with a control electronic input device usage characteristic data.","17","15/109623","2015-01-30","2016-0328572","2016-11-10","10248804","2019-04-02","THE ARIZONA BOARD OF REGENTS ON BEHALF OF THE UNIVERSITY OF ARIZONA | BRIGHAM YOUNG UNIVERSITY","Joseph  Valacich | Jeffrey  Jenkins","","","","G06F-0021/6218","G06F-0021/6218 | A61B-0005/164 | A61B-0005/7475 | G06F-0021/32 | G06Q-0010/10","G06F-021/62","G06F-021/62 | A61B-005/00 | A61B-005/16 | G06F-021/32 | G06Q-010/10","","","","","","4919014004797"
"US","US","P","B2","Alert system for MRI technologist and caregiver","An alert system for providing the capability for a care giver or technologist in a medical procedure room such as the magnet room of an MRI installation to send an alert signal to personnel outside the magnet room. The system includes an alert device in the procedure room with an alert switch, and a wireless signal transmitter for generating encoded alert signals upon activation of the alert switch. An alert control system in the control room of the installation includes a signal receiver, an audio transducer and a controller, the controller responsive to alert signals received from the alert device to generate alert signals including generating audio signals from the audio transducer. In one embodiment, the alert device includes a microphone, with one-way or two-way communication between the alert device and the control system.","1. An alert system for providing the capability for a care giver or technologist in a medical procedure room to send an alert signal concerning a patient undergoing the medical procedure to personnel in a control room outside the procedure room, the system comprising: an alert device carried by or available to the care giver or technologist in the procedure room, the device including an alert switch configured for manual activation by the care giver or technologist, a microphone for capturing audio signals including the care giver'ss or technologist'ss voice, and a wireless signal transmitter for generating alert signals upon activation of the alert switch, and wherein the alert device is substantially non-magnetic;a base station disposed in the procedure room, the base station comprising a receiver for receiving the alert signals, a decoder or data converter responsive to the received signal, and a transmitter for sending the signals from the decoder or data converter to the receiver of an alert control system;the alert control system in the control room, comprising a signal receiver, an audio transducer and a controller, the alert control system responsive to the signals transmitted from the base station to generate alert signals, and to generate audio signals from the audio transducer corresponding to the audio signals captured by the alert device; andwherein the alert device and the alert control system are configured to provide one-way or two-way voice communication between the alert device and the control system.","21","16/122714","2018-09-05","2019-0005804","2019-01-03","10249176","2019-04-02","RESONANCE TECHNOLOGIY, INC. | RESONANCE TECHNOLOGY, INC.","Mokhtar  Ziarati | Parisa  Ziarati","","","","G08B-0025/12","G08B-0025/12 | A61B-0005/747 | A61B-0005/7465 | A61N-0001/3993 | G08B-0003/10 | G08B-0005/36 | G08B-0021/0453 | G08B-0025/10 | H04L-0067/12 | H04W-0004/80","A61N-001/08","A61N-001/08 | G08B-025/12 | A61B-005/00 | A61N-001/39 | G08B-003/10 | G08B-005/36 | G08B-021/04 | G08B-025/10 | H04L-029/08 | H04W-004/80","","","","","","4919014005167"
"US","US","P","B2","System for interacting with a cell","Disclosed is a system for interacting with a cell and further communicating over a communication network is provided. The system includes a controller, a frequency generator, a first electrode, and a cell-chip circuitry. The frequency generator provides modulated alternating electric field with variable frequency. The controller releases routing instructions and further communicates through the communication network. The first electrode receives alternating electric field charges from the controller. The cell-chip circuitry is capacitively coupled to the first electrode. The cell-chip circuitry includes a second electrode, a harvester, a processor, a pulser, an analog switch matrix, a bi-directional communication unit, a pit, an inherent artificial intelligence interpreter, a analyzer, a nano needle, a third electrode. The cell-chip circuitry measures the field strength of the received charges from the harvester and generates pulsed intervals depending upon the field strength. The cell-chip circuitry further measures and communicates data with the controller through the e-field. The pit receives the cell. The cell reacts to the e-field. The inherent artificial intelligence interpreter performs successive approximation to monitor the reaction on the cell inside the pit on receiving instructions from the controller. The analyzer measures analog values of the e-field on the cell under the command of the inherent artificial intelligence interpreter; the analyzer communicates data to the bi-directional communication unit. The nano needle is inserted in the pit for bi-directionally communicating the e-field on the cell, and the third electrode is configured to provide space for the pit and floats against the ground.","1. A system for interacting with a cell in a living organism, further the system communicates over a communication network, the system comprising: a controller for releasing routing instructions, further the controller communicates through the communication network;a frequency generator connected to the controller for providing modulated alternating electric field with variable frequency;a first electrode configured to receive alternating electric field charges from the controller;one or more cell-chip circuitries, wherein at least one cell-chip circuitry is capacitvely coupled to the first electrode, the one or more cell-chip circuitries comprising:a second electrode coupled to the first electrode and configured to receive mirror alternating charges of the first electrode'ss alternating electric field charges; a harvester converts the alternating electric field into DC power and further extracts clock signals synchronized with the e-field alternating electric field frequency;a processor that processes external operation commands and data received from the controller;a pulser configured to measure alternating electric field strength of the received alternating electric field charges from the harvester and generates pulsed intervals depending upon the alternating electric field strength;an analog digital switch matrix configured to receive routing instructions from the controller for making conditional temporary connections under the control of the processor, further the analog digital switch matrix routes pulsed intervals;a bi-directional communication unit is configured to modulate commands and bi-directionally communicate data with the controller through the alternating electric e-field;a pit having insulated walls, wherein the pit is configured to receive the cell;a third electrode configured to provide a space for the pit and floats against ground, wherein the pit is formed through the space;an inherent artificial intelligence interpreter is configured to perform successive approximation to monitor the cell inside the pit based on receiving instructions from the controller;an analyzer for measuring analog values of the alternating electric e-field on the cell under the command of the inherent artificial intelligence interpreter, the analyzer communicates data to the bi-directional communication unit;a charge chamber for switching polarized charges into the pit to ionize the cell;a nano needle is configured to be inserted through the third electrode and into the pit for bi-directionally communicating the alternating electric e-field on the cell; andwherein, the charge chamber receives signal from the inherent artificial intelligence interpreter to determine the amount of charge potential for treatment of the cell.","14","15/258568","2016-09-07","2018-0067100","2018-03-08","10241104","2019-03-26","EPIC SEMICONDUCTORS INC.","Wolfgang  Richter | Faranak  Zadeh","","","","G01N-0033/48728","G01N-0033/48728 | A61B-0005/0538 | A61B-0005/4836 | A61N-0001/025 | A61N-0001/37282 | A61N-0001/40 | G01N-0027/60 | H04L-0067/10","A61N-001/02","A61N-001/02 | A61B-005/053 | G01N-033/487 | G01N-027/06 | G01N-027/60 | A61N-001/40 | A61N-001/372 | A61B-005/00 | H04L-029/08","","","","","","4919013003687"
"US","US","P","B2","Direct neural interface system and method","A direct neural interface system comprises: a signal acquisition subsystem for acquiring electrophysiological signals representative of neuronal activity of a subject's brain; and a processing unit for representing electrophysiological signals acquired over an observation time window in the form of a N-way data tensor, N being greater than or equal to two, and generating command signals for a machine by applying a regression model over the data tensor; wherein the processing unit is configured or programmed for generating command signals for a machine by applying Generalized Linear regression, with a nonlinear link function, over the data tensor. A method of interfacing a subject's brain to a machine by using such a direct neural interface system is provided.","1. A direct neural interface system comprising: a signal acquisition subsystem for acquiring electrophysiological signals s(t) representative of neuronal activity of a subject'ss brain; anda processing unit for representing electrophysiological signals acquired over an observation time window in the form of a N-way data tensor (x(t)), N being greater than or equal to one, and generating command signals (S(t)) for a machine by applying a regression model over said data tensor,wherein said processing unit is configured or programmed for generating command signals for a machine by applying Generalized Linear regression, with a nonlinear link function, over said data tensor,wherein said processing unit is configured or programmed for detecting and correcting outlier elements of said data tensor before applying said Generalized Linear regression, andwherein said processing unit is configured or programmed for generating command signals for a machine by applying Generalized Additive Linear regression over said data tensor, said Generalized Additive Linear regression making use of additive functions fi(xi) of the form: where xi is an element of said data tensor x(t) and f1,i and f2,i are different functions.","15","15/032546","2013-10-31","2016-0282941","2016-09-29","10241575","2019-03-26","COMMISSARIAT A L'ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES","Tetiana  Aksenova | Andriy  Yelisyeyev","","","","G06F-0003/015","G06F-0003/015 | A61B-0005/04001 | A61B-0005/04012 | A61B-0005/0476 | A61B-0005/7203 | G06K-0009/00536","G05D-017/00","G05D-017/00 | G06F-003/01 | A61B-005/00 | A61B-005/04 | A61B-005/0476 | G06K-009/00","","","","","","4919013004156"
"US","US","P","B2","Method for making a surgical guide for bone harvesting","A method for making a surgical guide for bone harvesting identifying in a three-dimensional image of a bone one or more sensitive anatomic structures and a volume of bone suitable for being removed. The volume is delimited by a portion of an outer surface of the bone defining a perimeter and by a mantle extending from the perimeter inside of the bone. The method also includes designing the surgical guide which includes defining a guide surface including a work area delimited by guide walls. The method also includes angling at least one of the guide walls so that the guide wall includes a face that constitutes a geometrical extension of a portion of the mantle when the guide is rested on the outer surface of the bone such that the face includes at least one segment forming a predetermined angle with respect to the guide surface.","1. A method for designing a surgical guide for performing bone harvesting, including: providing a three-dimensional image of at least one portion of a bone of a patient where bone harvesting is to be performed, said bone defining an outer surface;identifying in said three-dimensional image one or more sensitive anatomic structures to be avoided during said bone harvesting;identifying in said three-dimensional image a volume of bone suitable for being removed in said bone harvesting, said volume excluding said sensitive anatomic structures, and said volume being delimited by a portion of said outer surface of said bone defining a perimeter and by a mantle extending from said perimeter inside said bone, said mantle including, for each point of said perimeter, a mantle segment forming a predetermined angle with said portion of said outer surface, said angle corresponding to a cutting direction inside said bone identified in said three-dimensional image;and establishing the parameters of said surgical guide, including: defining a guide surface suitable for facing said outer surface of said bone, said guide surface comprising a work area delimited by guide walls;and angling at least one of said guide walls with respect to said guide surface, so that said guide wall includes a face that constitutes a geometrical extension of a portion of said mantle of said bone volume when said surgical guide faces said portion of outer surface of bone, so that said face includes, for each point of said perimeter of work area, a guide segment forming a predetermined angle with respect to said guide surface, said guide segment extending a length from said guide surface to define a stop surface, said stop surface adapted to contact an aspect of a bone-harvesting tool to set a working depth of the bone-harvesting tool, said working depth being less than a distance along said cutting direction to said one or more sensitive anatomical structures from said guide surface.","16","14/892840","2014-05-22","2016-0106513","2016-04-21","10242127","2019-03-26","NOBEL BIOCARE SERVICES AG","Luca  De Stavola | Andrea  Fincato","MI2013-000831","IT","2013-05-22","G06F-0017/50","G06F-0017/50 | A61B-0017/15 | A61B-0017/152 | A61B-0034/10 | G06T-0007/0012 | G06T-0007/62 | A61B-0017/1635 | A61B-0017/176 | A61B-2017/00526 | A61B-2017/568 | A61B-2034/108 | A61B-2090/034 | G06T-2207/10012 | G06T-2207/30008","G06T-007/00","G06T-007/00 | G06F-017/50 | G06F-007/60 | A61B-017/15 | G06T-007/62 | A61B-017/16 | A61B-017/17 | A61B-017/00 | A61B-017/56 | A61B-090/00 | A61B-034/10","","","","","","4919013004703"
"US","US","P","B2","Apparatus and method for registering images in real-time","The invention relates to a device for superimposing known patterns, characteristic of a region, on (real) images of said region. The device comprises, a memory in which patterns are stored, which are representative of a selected region, of known position and orientation with relation to a common reference and processing means, for determining a pattern representative of the selected portion in the memory, on receipt of the designation of at least one portion of an observed image of the selected region, taken at a selected angle and at least one representative attribute of said region, taking account of the attribute selected, then superimposing the determined pattern on the selected portion of the image taking account of the selected angle.","1. An apparatus comprising: an image capturing device configured to capture images of a selected region at a selected angle;a display device configured to display the captured images received from the image capturing devices;a user interface configured to successively receive a plurality of user designations comprising designations of portions of the captured images and attributes corresponding to the designated portions; anda registration device configured to register a predetermined pattern to the captured images by minimizing a criterion constructed from a plurality of measurement equations determined from the plurality of user designations and the selected angle to select an optimized pattern, wherein the display device is further configured to display an image of the predetermined pattern superimposed on the captured images.","16","15/345488","2016-11-07","2017-0049358","2017-02-23","10231642","2019-03-19","INTUITIVE SURGICAL OPERATIONS, INC.","Eve  Coste-Maniere | Thierry  Vieville | Fabien  Mourgues","2003-006176","FR","2003-05-22","A61B-0005/066","A61B-0005/066 | A61B-0001/00009 | A61B-0001/04 | A61B-0005/055 | A61B-0005/749 | A61B-0034/10 | A61B-0034/30 | G06T-0007/30 | G06T-0007/60 | A61B-2034/107 | A61B-2034/301 | A61B-2090/365 | A61B-2090/373 | A61B-2090/374 | G06F-0003/0484 | G06T-2200/24 | G06T-2207/10068 | G06T-2207/10072 | G06T-2207/20092 | G06T-2207/30048 | G06T-2207/30101 | Y10S-0128/922","A61B-005/06","A61B-005/06 | A61B-001/00 | A61B-005/055 | A61B-034/30 | A61B-034/10 | G06T-007/30 | A61B-001/04 | A61B-005/00 | G06T-007/60 | A61B-090/00 | G06F-003/0484","","","","","","4919012000895"
"US","US","P","B2","Cadence determination and media content selection","Systems, devices, apparatuses, components, methods, and techniques for cadence determination and media content selection are provided. An example media-playback device comprises a media-output device that plays media content items, a cadence-acquiring device, and a cadence-based media content selection engine. The cadence-acquiring device includes an accelerometer and a cadence-determination engine configured to determine a cadence based on acceleration data captured by the accelerometer. The cadence-based media content selection engine is configured to identify a media content item based on the cadence determined by the cadence-determining engine and cause the media-output device to playback the identified media content item.","1. An apparatus for identifying a cadence of a repetitive motion activity, the apparatus comprising: at least one accelerometer; anda cadence-determination engine configured to: obtain a series of measurements from the at least one accelerometer;calculate at least one value based on the series of measurements; anddetect a stable cadence within fifteen steps of the repetitive motion activity by determining whether the at least one value meets at least one stability criterion.","23","15/361716","2016-11-28","2017-0235540","2017-08-17","10235127","2019-03-19","SPOTIFY AB","Tristan  Jehan | Sten  Garmark | Dariusz  Dziuk | Rahul  Sen | Owen  Smith | Lars Christian  Olofsson | Nikolaos  Toumpelis","","","","G06F-0003/165","G06F-0003/165 | A61B-0005/112 | A61B-0005/1118 | A61B-0005/742 | A61B-0005/7405 | G10H-0001/0008 | G10H-0001/40 | G11B-0020/10527 | A61B-2503/10 | A61B-2503/12 | A61B-2562/0219 | G10H-2210/076 | G10H-2220/091 | G10H-2220/351 | G10H-2220/355 | G10H-2220/395 | G10H-2230/015 | G10H-2240/131","G06F-017/00","G06F-017/00 | G06F-003/16 | G11B-020/10 | G10H-001/00 | A61B-005/11 | A61B-005/00 | G10H-001/40","","","","","","4919012004362"
"US","US","P","B2","Fluid containers and systems and methods for detecting a fluid level therein","Fluid containers having a volume marking(s) and conductive element(s) disposed at the volume marking(s) and a common conductive element are provided. For example, the fluid container has a wall forming the volume. The conductive element(s) and the common conductive element have a portion disposed within the volume and a portion external to the volume. The container further has a RFID tag, where the conductive element(s) and the common conductive element are connected thereto via respective conductive wires. A fluid detection system having the fluid containers is also provided. The system comprises one or more containers and a patient site monitor having a RF reader that interrogates the RFID tag at a preset interval. Responsive to the signal, the tag supplies a predetermined current to the conductive element and the common conductive element and detects a voltage and generates an alert based on the same.","1. A fluid container comprising: a wall forming a volume for holding a fluid, the wall having a plurality of volume marking indicating a plurality of volume levels;a plurality of integral conductive elements, each disposed at a particular volume level, each of the conductive elements having a portion disposed within the volume and a portion external to the volume;a RFID tag; andan integral common conductive element having a portion disposed within the volume and a portion external to the volume, the common conductive element being connected to the RFID tag via a conductive wire, the conductive element being connected to the RFID tag via another conductive wire.","21","15/476202","2017-03-31","2018-0280236","2018-10-04","10219981","2019-03-05","INTEGRA LIFESCIENCES SWITZERLAND S?RL","Lev  Ludin | Michael A.  DeFusco","","","","A61J-0001/18","A61J-0001/18 | A61M-0001/0001 | A61M-0001/0019 | A61M-0027/006 | G01F-0023/242 | G01F-0023/243 | G06K-0007/10366 | G06K-0019/07773 | G06K-0019/07779 | A61B-0005/208 | A61F-0005/44 | A61J-2200/76 | A61J-2205/60 | A61M-0005/168 | A61M-0005/1684 | A61M-2205/3317 | A61M-2205/3389 | A61M-2205/3561 | A61M-2205/3592","G06K-019/00","G06K-019/00 | A61J-001/18 | A61M-027/00 | G06K-007/10 | G06K-019/077 | A61M-001/00 | G01F-023/24 | A61M-005/168 | A61B-005/20 | A61F-005/44","","","","","","4919010001245"
"US","US","P","B2","Image processing apparatus, image processing method, and computer-readable recording medium extracting one or more representative images","An image processing apparatus includes: a detection unit configured to detect images of interest including regions of interest that are estimated as an object to be detected, from a group of a series of images acquired by sequentially imaging a lumen of a living body; an image-of-interest group extracting unit configured to extract a group of images of interest including an identical region of interest, from the images of interest detected by the detection unit; and a representative image extracting unit configured to extract one or more representative images from the group of images of interest, based on at least one of correlation of the regions of interest with the object to be detected, and visibility of the regions of interest.","1. An image processing apparatus comprising: a processor comprising hardware, wherein the processor is configured to: detect images of interest including regions of interest that are estimated as an object to be detected, from a series of images acquired by sequentially imaging a lumen of a living body;extract a group of images of interest including an identical region of interest, from the images of interest detected;detect a bleeding source shown in the images of interest belonging to the group of images of interest; andextract one or more predetermined number of representative images from the group of images of interest, wherein the one or more predetermined number of representative images comprises images of interest showing the bleeding source detected,wherein each of the one or more predetermined number of representative images is an image of interest that is higher in at least one of correlation of the regions of interest with the object to be detected and visibility of the regions of interest than a remaining one or more remaining images of interest in the group of images of interest, andwherein a region of interest having a higher likelihood of being the bleeding source is considered to have a higher correlation with the object to be detected for the purpose of extracting the one or more predetermined number of representative images from the group of images of interest.","21","15/263421","2016-09-13","2016-0379363","2016-12-29","10223785","2019-03-05","OLYMPUS CORPORATION","Makoto  Kitamura | Yamato  Kanda","2014-052613","JP","2014-03-14","G06T-0007/0012","G06T-0007/0012 | A61B-0001/00 | A61B-0001/0005 | A61B-0001/00009 | A61B-0001/04 | A61B-0001/041 | A61B-0005/02042 | G06F-0017/30799 | G06K-0009/4652 | G06K-2209/05 | G06T-2207/10016 | G06T-2207/10024 | G06T-2207/10068 | G06T-2207/30092","G06K-009/00","G06K-009/00 | G06T-007/00 | G06F-017/30 | A61B-001/00 | A61B-001/04 | A61B-005/02 | G06K-009/46","","","","","","4919010005009"
"US","US","P","B1","Voice search assistant","Systems and methods for assisting voice searches are provided. An example method commences with receiving a voice query from a user and transmitting the voice query to a plurality of natural language processing systems. The method may continue with receiving a plurality of search parameter sets generated by the plurality of natural language processing systems based on the voice query. The method may further include transmitting at least one of the plurality of search parameter sets to a plurality of information search systems. The method may continue with receiving a plurality of responses from the plurality of information search systems. The plurality of responses may be generated by the plurality of information search systems based on the at least one of the plurality of search parameter sets. The method may conclude with providing at least one response of the plurality of responses to the user.","1. A system for assisting voice searches, the system comprising: a processor configured to: receive a voice query from a user;transmit the voice query to a plurality of natural language processing systems;receive a plurality of search parameter sets from the plurality of natural language processing systems, the plurality of search parameter sets being generated by the plurality of natural language processing systems based on the voice query;transmit at least one of the plurality of search parameter sets to a plurality of information search systems;receive a plurality of responses from the plurality of information search systems, the plurality of responses being generated by the plurality of information search systems based on the at least one of the plurality of search parameter sets;score each of the plurality of responses based on predetermined scoring criteria;rank the plurality of responses based on the score to select at least one response of the plurality of responses;assign weights to each of the plurality of responses based on the score; andprovide the at least one response of the plurality of responses to the user, wherein the at least one response is a combination of the plurality of responses received from the plurality of information search systems based on the assigned weights; anda database communicatively coupled to the processor, the database storing instructions executable by the processor.","17","16/120357","2018-09-03","","","10224035","2019-03-05","PRIMO LLC","Eric  Koenig | David  Borish | Jonathan  Khoo","","","","G10L-0015/22","G10L-0015/22 | A61B-0005/02055 | G06F-0017/30864 | G06N-0099/005 | G06T-0011/60 | G10L-0015/1815 | G10L-0015/30 | A61B-0005/0042 | A61B-0005/021 | A61B-0005/024 | A61B-0005/0402 | A61B-0005/14532 | A61B-0005/14542 | A61B-2503/12 | G10L-2015/088 | G10L-2015/223","G10L-015/26","G10L-015/26 | G10L-015/22 | G06T-011/60 | G10L-015/30 | A61B-005/0205 | G06N-099/00 | G06F-017/30 | G10L-015/18 | G10L-015/08 | A61B-005/00 | A61B-005/021 | A61B-005/024 | A61B-005/0402 | A61B-005/145","","","","","","4919010005255"
"US","US","P","B2","Systems and methods for assessing human cognition, including a quantitative approach to assessing executive function","Methods, systems, and apparatus, including medium-encoded computer program products, for analyzing data include: receiving data including a person's responses regarding judgments of semantic similarities between items selected from a group of items falling into a same categorical level; processing the data to determine a measure of distance within a generated representation of the person's responses regarding the judgments of semantic similarities; and generating a score of degree of cognitive impairment for the person based at least in part on the determined measure of distance within the generated representation.","1. A computer-implemented method comprising: receiving data comprising (i) a person'ss responses regarding judgments of semantic similarities between items selected from a group of items falling into a same categorical level, and (ii) delayed free recall responses by the person of items presented for the judgments of semantic similarities, wherein the responses regarding the judgments of semantic similarities are responses to triadic comparisons;processing the data to determine a measure of distance within a generated representation of the person'ss responses regarding the judgments of semantic similarities, wherein the processing comprises transforming the responses regarding the judgments of semantic similarities into a spatial representation and applying a spatial randomness metric to the spatial representation, and wherein the spatial randomness metric comprises a ratio of observed mean nearest neighbor distance for the responses represented in the spatial representation to a mean nearest neighbor distance expected for random responses within the spatial representation; andgenerating a quantitative score of executive function for the person based at least in part on the determined measure of distance within the generated representation regarding the judgments of semantic similarities, and providing the quantitative score of executive function, to a user device of a human cognition assessment system comprising one or more computers, for use by a clinician in assessing cognitive impairment of the person, wherein the generating comprises:determining the measure of distance within the generated representation using distance values calculated for the responses to the triadic comparisons within the generated representation;determining an additional measure for the delayed free recall responses using the calculated distance values for the responses to the triadic comparisons; andcomparing the measure of distance with the additional measure to assess an interaction between judgment and associative memory when preparing the score; andwherein the generating comprises using (i) measured degrees of spatial randomness for responses of one or more groups of people to judgments of semantic similarities and (ii) delayed free recall responses by the one or more groups of people of items presented for judgments of semantic similarities.","25","15/309419","2015-05-08","2017-0181685","2017-06-29","10213149","2019-02-26","MEDICAL CARE CORPORATION","Michael D.  Lee | William Rodman  Shankle","","","","A61B-0005/4088","A61B-0005/4088 | A61B-0005/16 | A61B-0005/165 | A61B-0005/168 | A61B-0005/7264 | G06F-0019/00 | G06K-0009/6251 | G06N-0005/025 | G06N-0005/043 | G06N-0005/046 | G16H-0050/20 | G16H-0050/50 | G06F-0017/2785 | G16H-0050/30 | G16H-0050/70","A61B-005/00","A61B-005/00 | A61B-005/0484 | G06F-019/00 | G16H-050/50 | G16H-050/20 | A61B-005/16 | G06K-009/62 | G06N-005/02 | G06N-005/04 | G16H-050/70 | G06F-017/27 | G16H-050/30","","","","","","4919009000967"
"US","US","P","B2","Deformable articulating templates","A system for generating a patient-specific implant is described which includes a means for generating a three dimensional electronic representation of a human anatomical feature including size and curvature features matching the human anatomical feature, a means for selecting a prosthetic implant template from a database of prosthetic implant templates, the database being formed of the prosthetic implant templates by a means for generating a series of the virtual implant templates, a means for designing the patient-specific implant to imitate the size and curvature features based at least in part on the selected prosthetic implant template, and a means for virtually testing fit of the patient-specific implant using the three dimensional electronic representation of the human anatomical feature.","1. A system for generating a patient-specific implant, the system comprising: a means for generating a three-dimensional electronic representation of a human anatomical feature including size and curvature features matching the human anatomical feature;a means for selecting a virtual implant template from a database of virtual implant templates generated by a means for generating a series of the virtual implant templates;a means for designing a patient-specific prosthetic implant to imitate the size and curvature features based at least in part on the selected virtual implant template; anda means for virtually testing fit of the patient-specific prosthetic implant using the three-dimensional electronic representation of the human anatomical feature.","24","15/264488","2016-09-13","2017-0000615","2017-01-05","10213311","2019-02-26","ZIMMER INC.","Mohamed Rashwan  Mahfouz","","","","A61F-0002/30942","A61F-0002/30942 | A61B-0008/4245 | A61B-0034/10 | A61F-0002/3094 | A61F-0002/3601 | A61F-0002/389 | A61F-0002/3859 | A61F-0002/4003 | G06F-0017/18 | G06F-0019/00 | G06T-0019/00 | G16H-0050/50 | A61B-2034/102 | A61B-2034/108 | A61F-0002/38 | A61F-2002/30943 | A61F-2002/30948 | A61F-2002/3863 | A61F-2002/3895 | G06K-0009/00 | G06T-2210/41","A61F-002/30","A61F-002/30 | G06T-019/00 | A61F-002/38 | G06F-017/18 | A61B-008/00 | A61B-034/10 | A61F-002/36 | A61F-002/40 | G16H-050/50 | G06F-019/00 | G06K-009/00","","","","","","4919009001129"
"US","US","P","B2","Management system for skin condition measurement analysis information and management method for skin condition measurement analysis information","Service can be offered free of charge and the cost of a skin condition measuring device can be reduced by effectively using data on the occasion of obtaining an analysis result by transmitting measurement data by the skin condition measuring device to a server of a company providing a service of analyzing the measurement data. When a request is made from a contractor client to acquire data registered in a measurement data database, authentication is executed based on a contractor ID input from the contractor client. Additionally, when the measurement data database is searched from a contractor database based on the contractor ID, a search level and an access level are obtained. The contractor client is permitted to search the measurement data database within a range of the search level and the access level.","1. A management system for managing skin condition measurement analysis information, comprising: a user client used by a user of a skin condition measuring device, connected to the skin condition measuring device so as to be able to transmit data to and receive data from the skin condition measuring device, and also connected to a network to transmit and receive data;a data management server configured to transmit data to and receive data from the user client via the network, to store information related to the user, and to provide information to the user as a primary user of the information and a secondary user of the information who is different from the primary user;an analysis result outputting unit configured to receive analysis result data of a skin condition obtained by analyzing measurement data measured by the skin measuring device, and to output the analysis result data to be displayable on the user client; anda secondary user client used by the secondary user, configured to transmit data to and receive data from the data measurement server, and to be provided with information related to the user,wherein the user client includes:a user data transmitting unit configured to transmit user data to the data management server for each user in correlation to a unique and non-duplicative client ID, the user data being input by the user and including personal information leading to specification of individual of the user and accompanying information excluding the personal information of the user;a measurement data transmitting unit configured to transmit the input measurement data correlated to the client ID to the data measurement server when the measurement data of the user measured by the skin condition measuring device is received from the skin condition measuring device; anda display unit configured to display the analysis result data when the analysis result data with respect to the measurement data is received from the analysis result outputting unit,wherein the data management server includes:(a) a database in which: i) the personal information received from each of a plurality of user clients is registered, correlated to the client ID;ii) the accompanying information received from each of a plurality of user clients is registered in correlation to the client ID, and acquisition time of the accompanying information is also registered; andiii) the measurement data received from each of a plurality of user clients is registered in correlation to the client ID, and acquisition time of the measurement data is also registered,(b) a data providing unit which, when acquisition of the data registered in the database is requested by the secondary user client, can extract a group of data consisting of the measurement data and the acquisition time of the measurement data, and/or a group of data consisting of the accompanying information and the acquisition time of the accompanying information, all designated by the secondary user client from the database, and transmit the extracted data to the secondary user client, andwherein the secondary user client includes:a data requesting unit configured to transmit the secondary user ID set for each secondary user, and to request data registered in the database from the data management server;a receiving/storing unit configured to receive and store a group of data consisting of the accompanying information and the acquisition time of the accompanying information, and/or a group of data consisting of measurement data and the acquisition time of the measurement data, all in accordance with the request of data requesting unit.","21","15/597578","2017-05-17","2017-0245939","2017-08-31","10216697","2019-02-26","MAXELL HOLDINGS, LTD.","Fumie  Kusumoto | Masashi  Yoshimura | Eiji  Sakata | Hironobu  Nagano | Kenji  Matsuoka | Kengo  Miura","2012-030020 | 2012-265857","JP | JP","2012-02-15 | 2012-12-04","G06F-0016/951","G06F-0016/951 | A61B-0005/0022 | A61B-0005/14532 | A61B-0005/441 | A61B-0005/442 | A61B-0005/4836 | G01N-0021/17 | G06F-0016/25 | G06F-0019/00 | G06F-0019/3418 | G06Q-0030/0631 | H04L-0067/10 | H04L-0067/42 | G01N-2021/1765","G06F-017/30","G06F-017/30 | G06F-016/951 | A61B-005/00 | A61B-005/145 | G06F-016/25 | G06Q-030/06 | G01N-021/17 | H04L-029/08 | H04L-029/06 | G06F-019/00","","","","","","4919009004490"
"US","US","P","B2","Health monitoring","Technical solutions are described for monitoring health of a user by a healthcare system. An example computer-implemented method includes accessing a current image of the user. The computer-implemented method also includes determining a healthcare routine for the user. The computer-implemented method also includes generating a modified image of the user, where the modified image includes a predicted effect of the healthcare routine. The computer-implemented method also includes displaying, for viewing by the user, the modified image, and information about the healthcare routine.","1. A system for monitoring a health of a user, the system comprising: an image capture device configured to capture multispectral images;a memory; anda processor coupled with the memory and the image capture device, wherein the processor is configured to: in response to an occurrence of a scheduled activity time of the user: determine a geographic location of the user; andselect a first exercise routine for the user from a list of exercise routines that is specifically populated for the user based on a health record of the user, the first exercise routine is selected based on a key performance indicator of the first exercise routine being the maximum among the exercise routines from the list of exercise routines, the key performance indicator based on the geographic location;receive activity-tracking data of the user from a wearable computing device;determine a calorie outtake of the user based on the activity-tracking data, which includes calories used for the first exercise routine;in response to an occurrence of a scheduled eating time of the user: determine a geographic location of the user;determine a number of calories to be consumed by the user based on the calorie outtake of the user; andidentify an eating place for the user within a predetermined vicinity of the geographic location, the eating place serving a food-item with the number of calories to be consumed by the user;capture a multispectral image of a food-item;determine a caloric-value of the food-item based on the multispectral image of the food-item;output the caloric-value of the food-item as calorie-intake of the user;access a current image of the user that comprises a picture of a body of the user;generate a modified image of the user, wherein the modified image of the user reflects a predicted change in the body of the user based on the calorie-intake caused by consuming the food-item using a metabolic model of the user based on health records of the user; anddisplay the modified image of the user.","19","15/184257","2016-06-16","2017-0365048","2017-12-21","10216909","2019-02-26","INTERNATIONAL BUSINESS MACHINES CORPORATION","Rick A.  Hamilton, II | James R.  Kozloski | Brian M.  O'Connell | Ninad D.  Sathaye","","","","G06F-0019/3481","G06F-0019/3481 | A61B-0005/0022 | A61B-0005/01 | A61B-0005/024 | A61B-0005/1112 | A61B-0005/1118 | A61B-0005/486 | A61B-0005/4866 | A61B-0005/681 | G06F-0017/30528 | G06F-0019/00 | G06F-0019/321 | G06F-0019/328 | G06K-0009/4604 | G06T-0007/0004 | G16H-0010/60 | H04N-0005/332 | G06T-2207/30128","G06F-019/00","G06F-019/00 | G16H-010/60 | A61B-005/11 | A61B-005/00 | G06F-017/30 | G06K-009/46 | G06T-007/00 | H04N-005/33 | A61B-005/01 | A61B-005/024","","","","","","4919009004702"
"US","US","P","B2","Methods of operating a motor vehicle","A method of operating a motor vehicle includes detecting at least one motor vehicle driver response, producing a perception model based on the detected motor vehicle driver response, and analyzing the perception model to at avoid least one motor vehicle driver response by adjusting a parameter of the motor vehicle. Analysis of the perception model can also be carried out to predict a motor vehicle driver response, in particular during the generation of new control software for the vehicle.","1. A method of operating a motor vehicle comprising: detecting a negative driver response to a vehicle state parameter;producing a perception model correlating the negative driver response with the vehicle state parameter;analyzing the perception model; andadjusting a parameter of a motor vehicle function to avoid future occurrences of driving situations that, based on the analysis of the perception model, would cause a second negative driver response.","9","15/498092","2017-04-26","2017-0316625","2017-11-02","10217298","2019-02-26","FORD GLOBAL TECHNOLOGIES, LLC","Frederic  Stefan | Alain Marie Roger  Chevalier | Evangelos  Bitsanis | Michael  Marbaix","10-2016-207356","DE","2016-04-29","G07C-0005/0841","G07C-0005/0841 | A61B-0005/024 | A61B-0005/0205 | A61B-0005/0531 | A61B-0005/0816 | A61B-0005/11 | A61B-0005/165 | A61B-0005/18 | A61B-0005/6893 | A61B-0005/749 | G06F-0003/167 | G06N-0005/04 | G06N-0099/005 | G09B-0007/02 | G09B-0007/10 | G09B-0019/16 | G09B-0019/167 | A61B-0003/112 | A61B-0003/113 | A61B-2503/22 | G07C-0005/008","G07C-005/08","G07C-005/08 | A61B-005/0205 | A61B-005/024 | A61B-005/053 | A61B-005/08 | A61B-005/11 | A61B-005/18 | G06F-003/16 | G06N-005/04 | G06N-099/00 | G09B-007/02 | G09B-007/10 | A61B-005/00 | A61B-005/16 | G09B-019/16 | A61B-003/113 | G07C-005/00 | A61B-003/11","","","","","","4919009005087"
"US","US","P","B2","Integrated deep learning and clinical image viewing and reporting","Integrated deep learning and clinical image viewing and reporting are provided. In some embodiments, a clinical image is received. An annotated image is generated from the clinical image by application of a deep learning system. At least one clinical finding is generated from the clinical image by application of the deep learning system. The annotated image and the at least one clinical finding are provided to a user. A structured report is generated based on the annotated image and the at least one clinical finding.","1. A method comprising: receiving a clinical image;generating an annotated image from the clinical image by application of a deep learning system;generating at least one clinical finding based on the clinical image by application of the deep learning system;providing the annotated image and the at least one clinical finding to a user;generating a structured report based on the annotated image and the at least one clinical finding.","20","15/258872","2016-09-07","2018-0068438","2018-03-08","10210609","2019-02-19","INTERNATIONAL BUSINESS MACHINES CORPORATION","Jon  DeVries","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/055 | A61B-0006/032 | A61B-0006/037 | G06F-0017/241 | G06K-0009/4671 | G06K-0009/66","G06K-009/66","G06K-009/66 | G06T-007/00 | G06K-009/46 | A61B-006/03 | A61B-005/055 | G06F-017/24","","","","","","4919008004933"
"US","US","P","B2","Display apparatus and method of manufacturing the same","A display apparatus includes a first pixel, a second pixel, a light sensor, and a light shield. The first pixel has a first light-emitting device which includes a first emission layer that emits light in a first wavelength band in a first direction. The second pixel has a second light-emitting device which includes a second emission layer to emit light in a second wavelength band in a second direction different from the first direction. The second emission layer is below the first emission layer of the first light-emitting device. The light sensor senses light in the second wavelength band emitted from the second pixel and reflected by an object. The light shield is arranged along a light path incident to the light sensor.","1. A display apparatus, comprising: a substrate;a first pixel on the substrate, the first pixel including a first light-emitting diode, the first light-emitting diode including a first electrode, a second electrode, and a first emission layer between the first and second electrodes, the first emission layer to emit light in a first wavelength band, the first electrode of the first light-emitting diode to reflect the light of the first emission layer in a first direction;a second pixel on the substrate, the second pixel including a second light-emitting diode, the second light-emitting diode including a third electrode, a fourth electrode, and a second emission layer between the third and fourth electrodes, the second emission layer to emit light in a second wavelength band, the fourth electrode of the second light-emitting diode to reflect the light of the second emission layer in a second direction opposite to the first direction, the second emission layer of the second light-emitting diode below the first emission layer of the first light-emitting diode;a light sensor on the substrate to sense the light in the second wavelength band emitted from the second pixel and reflected by an object; anda light shield adjacent to the light sensor on the substrate, whereinthe first electrode of the first light-emitting diode and the fourth electrode of the second light-emitting diode are adjacent to each other in a horizontal direction.","24","15/372427","2016-12-08","2017-0278909","2017-09-28","10211265","2019-02-19","SAMSUNG DISPLAY CO., LTD.","Bogeon  Jeon | Taeyoung  Ahn | Sangwook  Lee | Eunjeong  Cho","10-2016-0036130","KR","2016-03-25","H01L-0027/3227","H01L-0027/3227 | A61B-0005/0077 | A61B-0005/1171 | A61B-0005/1172 | A61B-0005/14552 | A61B-0005/6898 | G06F-0003/0421 | G06K-0009/00013 | G06K-0009/00067 | H01L-0027/3248 | H01L-0027/3262 | H01L-0027/3272 | G06F-2203/04103 | G06K-2009/00932","H01L-027/32","H01L-027/32 | G06F-003/042 | G06K-009/00 | A61B-005/1171 | A61B-005/00 | A61B-005/1172 | A61B-005/1455","","","","","","4919008005585"
"US","US","P","B2","Method and system for capturing images for wound assessment with self color compensation","A wound image capture method that uses self color compensation to improve color consistency of the captured image and reliability of color-based wound detection. The method uses the skin tone of parts of the patient's own body for color calibration and compensation. In a data registration process, multiple parts of a new patient's body are imaged as baseline images and color data of the baseline images are registered in the system as reference color data. During subsequent wound image capture and wound assessment process, the same parts of the patient's body are imaged again as baseline images, and the wound and its surrounding areas are also imaged. Color data of the newly capture baseline images are compared to the registered reference color data and used to perform color compensation for the wound image.","1. A method implemented in a system including an image capture device for using color images to assess a wound of a patient, comprising: during an initial registration stage:(a) displaying first messages which indicate parts of the patient'ss body as one or more baseline regions to be imaged, and capturing one or more first images containing the one or more baseline regions which are parts of the patient'ss body;(b) storing, in a database, the one or more first images and/or color data of the one or more first images;during a wound assessment stage subsequent to the initial registration stage:(c) retrieving, from the database, the one or more first images and/or color data of the one or more first images;(d) displaying second messages which indicate the same one or more baseline regions of the patient'ss body to be imaged, and capturing one or more second images containing the same one or more baseline regions of the same patient'ss body;(e) capturing a third image containing the wound and its surrounding area on the same patient'ss body;(f) calculate color compensation data by comparing color data of the second images and corresponding color data of the first images, and compensating color values of the third image based on the calculated color compensation data, the first, second and third images having been captured from the same patient'ss body; and(g) assessing the wound using the compensated third image containing the wound and its surrounding area.","18","15/251968","2016-08-30","2018-0055440","2018-03-01","10201306","2019-02-12","KONICA MINOLTA LABORATORY U.S.A., INC.","Wei  Ming","","","","A61B-0005/445","A61B-0005/445 | A61B-0005/0013 | A61B-0005/0077 | A61B-0005/1032 | A61B-0005/7282 | G06F-0017/3025 | G06F-0017/30268 | G06K-0009/6202 | G06T-0007/0024 | G16H-0050/00 | H04N-0013/204 | H04N-0013/257 | A61B-2576/00 | G06T-2210/41","H04N-013/257","H04N-013/257 | G06T-007/00 | A61B-005/00 | H04N-013/204 | A61B-005/103 | G06F-017/30 | G06K-009/62 | G16H-050/00","","","","","","4919007000722"
"US","US","P","B2","Combined episodic and continuous parameter monitoring","A method for displaying physiological data on a medical display device includes receiving one or more first units of physiological data from a first monitoring device. At least one of the first units of physiological data is received on a continuous basis. Each first unit of physiological data corresponds to a medical parameter being monitored by the first monitoring device. One or more second units of physiological data are received from a second monitoring device. At least one of the second units of physiological data is received on a non-continuous basis. Each second unit of physiological data corresponds to a medical parameter being monitored by the second monitoring device. The first and second units of physiological data are displayed on a single display screen of the medical display device.","1. A method for displaying physiological data on a medical display device, the method comprising: receiving physiological data of a first patient from a first monitoring device, wherein the physiological data of the first patient is received at a first frequency;on the medical display device, displaying the physiological data of the first patient on a first tile, wherein the first tile has a first data presentation format;determining, after a first time period expires without receiving the physiological data of the first patient at the first frequency, that the physiological data of the first patient has changed from the first frequency to a second frequency;based on determining that the physiological data of the first patient has changed from the first frequency to the second frequency, converting the first data presentation format to a second data presentation format, wherein the second data presentation format includes at least some of the physiological data of the first patient received at the first frequency;determining, after a second time period, that the physiological data of the first patient has changed from the second frequency to a third frequency;based on determining that the physiological data of the first patient has changed from the second frequency to the third frequency, converting the second data presentation format to a third data presentation format, wherein the second data presentation format includes at least some of the received physiological data of the first patient;receiving physiological data of a second patient from a second monitoring device, wherein the physiological data of the first patient is received at the first frequency;on the medical display device, displaying the physiological data of the second patient on a second tile, wherein the second tile has the first data presentation format;determining, after the first time period expires without receiving the physiological data of the second patient at the first frequency, that the physiological data of the second patient has changed from the first frequency to the second frequency; andbased on determining that the physiological data of the second patient has changed from the first frequency to the second frequency, converting the first data presentation format to the second data presentation format, wherein the second data presentation format includes at least some of the received physiological data of the second patient.","17","14/955172","2015-12-01","2016-0085942","2016-03-24","10204081","2019-02-12","WELCH ALLYN, INC.","John Raymond  Vann | Robert Paul  Wilmington | Thomas A.  Myers | Gregory P.  Vassallo | Edward  Imboden","","","","G06F-0017/212","G06F-0017/212 | G06F-0003/0484 | G06F-0019/00 | G16H-0015/00 | G16H-0040/63 | A61B-0005/7445 | A61B-2505/03 | G09G-2380/08","G09G-005/00","G09G-005/00 | G06F-017/21 | G06F-003/0484 | G16H-040/63 | G16H-015/00 | G06F-019/00 | A61B-005/00","","","","","","4919007003467"
"US","US","P","B2","Method and system for brain activity signal-based treatment and/or control of user devices","A method for characterizing a brain electrical signal comprising forming a temporo-spectral decomposition of the signal to form a plurality of time resolved frequency signal values, associating each instance of the signal value with a predetermined function approximating a neurological signal to form a table of coefficients collectively representative of the brain electrical signal.","1. A system for translating analog event-related desynchronization (ERD) signals from a user into an identifiable intended activity (IA), the system comprising: a. at least one input to receive one or more ERD signals;b. at least one output to send device action instructions to a user device to carry out a device action corresponding to the IA; andc. a controller to communicate with the at least one input and the at least one output of the user device, the controller including at least one special purpose processor configured to run at least one computer program: i. to record an ERD signal received from the at least one input, the ERD signal corresponding to an uncharacterized IA of the user for each time value of one or more successive time values,ii. for each time value: 1. to access one or more ERD templates of coefficients for one or more characterized IA'ss, the ERD templates of coefficients being formed by correlating a plurality of time resolved frequency ERD signal values with a function approximating a synthetic ERD signal;2. to update an ERD table for the uncharacterized IA and to compare the updated ERD table with the ERD templates to determine whether the uncharacterized IA is an instance of one of the characterized IA'ss; andiii. to initiate a corresponding device action instruction on at the at least one output after a minimum number of time values necessary to determine whether the uncharacterized IA is an instance of one of the characterized IA'ss.","17","15/450839","2017-03-06","2017-0172497","2017-06-22","10194858","2019-02-05","UNIVERSITY HEALTH NETWORK","Cesar  Marquez Chin | Kathryn  Atwell | Milos R.  Popovic","","","","A61B-0005/4851","A61B-0005/4851 | A61B-0005/04008 | A61B-0005/048 | A61B-0005/0478 | A61B-0005/1468 | A61B-0005/4836 | A61B-0005/7246 | A61F-0002/72 | A61F-0005/01 | A61N-0001/36003 | G06F-0003/015 | A61H-2230/105 | A63B-2230/105","A61F-002/72","A61F-002/72 | A61B-005/00 | A61B-005/0478 | A61N-001/36 | A61B-005/04 | A61B-005/1468 | A61F-005/01 | G06F-003/01 | A61B-005/048","","","","","","4919006000909"
"US","US","P","B2","Method and apparatus for training a team by employing brainwave monitoring and synchronized attention levels of team trainees","Training methods and apparatus wherein a training environment is activated only when a trainee is in a focused attention state. A brainwave monitor is employed for determining level of attention. The training environment is activated when the level of attention of the trainee is at or above a predetermined attention threshold. Activation of the training environment provides feedback to the trainee that he or she is in a focused attention state, and at the same time provides the incentive to remain in the focused attention state. A focused attention state is important if not required for training/learning success. The method and apparatus may be employed for training individual trainees, as well as for training team member trainees.","1. An apparatus for training a team including at least two team member trainees, comprising: a training environment for teaching a skill beyond merely maintaining a particular brainwave state, said training environment having not-activated and activated states, the trainee not being allowed to proceed in said training environment when said training environment is in the not-activated state, and the trainee being allowed to actively participate in said training environment when said training environment is in the activated state;a brainwave monitor for each trainee for monitoring electrical activity within the brain of each trainee, and determining each trainee'ss level of attention; andan activation device connected to said brainwave monitors and to said training environment, and operable to activate said training environment to the activated state when the levels of attention of all team member trainees are simultaneously at or above a predetermined attention threshold.","4","12/112528","2008-04-30","2008-0275358","2008-11-06","10198958","2019-02-05","FREER LOGIC, LLC","Peter A.  Freer | Stephen J.  Scanzoni","","","","G09B-0007/02","G09B-0007/02 | G09B-0019/00 | A61B-0005/04001 | A61B-0005/0476 | A61B-0005/0482 | A61B-0005/1118 | A61B-0005/16 | A61B-0005/18 | A61B-0005/7285 | A61M-0005/1723 | A61N-0001/0531 | A61N-0001/36139 | G06F-0019/00","A61B-005/0476","A61B-005/0476 | A61B-005/0482 | G09B-019/00 | G09B-023/28 | G06F-015/18 | G06F-017/00 | G09B-025/00 | G09B-007/02 | A61B-005/11 | A61M-005/172 | A61N-001/36 | A61B-005/16 | A61B-005/00 | A61B-005/04 | G06F-019/00 | A61N-001/05 | A61B-005/18","","","","","","4919006004990"
"US","US","P","B2","Electrocardiogram (ECG) signal based authentication apparatus and method","An authentication apparatus includes one or more processors configured to temporally implement a neural network, used to extract a feature value from hidden nodes, that is connected to input nodes to which an electrocardiogram (ECG) signal is input so as to share a weight set with the input nodes, and to match the ECG signal and the extracted feature value to a user for registration.","1. An authentication apparatus comprising: one or more processors configured to implement a neural network comprising an input layer comprising N input nodes and a hidden layer comprising hidden nodes, wherein the hidden layer is connected to the input layer;group the input nodes into input node sets comprising M input nodes, wherein M is less than N,wherein each input node set is connected to a single respective hidden node, andwherein each hidden node of the hidden nodes is connected to a single respective input node set;assign a first weight set comprising weights to each input node set of the input node sets; calculate a respective feature value for each hidden node based on the respective input node set connected to the each hidden node and the first weight set;determine at least one output feature value based on the respective feature value for each hidden node; andregister a user in association with an input electrocardiogram (ECG) signal and the at least one output feature value,wherein the first weight set is the same weight set applied to every input node set of the input node sets.","8","15/246712","2016-08-25","2017-0215806","2017-08-03","10188351","2019-01-29","SAMSUNG ELECTRONICS CO., LTD. | KOREA ADVANCED INSTITUTE OF SCIENCE AND TECHNOLOGY","Chisung  Bae | Jin Woo  Shin | Sung-Soo  Ahn | Sang Joon  Kim","10-2016-0012179","KR","2016-02-01","A61B-0005/7264","A61B-0005/7264 | A61B-0005/0452 | A61B-0005/117 | G06F-0021/32 | A61B-0005/6898 | G06K-2009/00939","A61B-005/117","A61B-005/117 | A61B-005/00 | A61B-005/0452 | G06F-021/32 | G06K-009/00","","","","","","4919005000967"
"US","US","P","B2","Devices and methods for reshaping cartilage structures","Described are methods of reshaping a cartilage structure. One such method comprises creating a virtual three dimensional image of the cartilage structure; manipulating the virtual three dimensional image of the cartilage structure so as to obtain a virtual three dimensional image of a desired final shape of the cartilage structure; creating a virtual prototype of a device to hold the cartilage structure in the desired final shape of the cartilage structure; manufacturing the device; lasing the cartilage structure; and fitting the manufactured device to the cartilage structure (e.g., ear).","1. A method of shaping a subject'ss ear to a desired final shape and/or position, the method comprising: lasing the subject'ss ear so as to stimulate chondrogenesis in the ear;fitting to the subject'ss lased ear an integral device comprising: a first surface configured to fit against and be adhered to the subject'ss head behind the lased ear, anda second surface configured to retain the lased ear in a desired final shape and/or position;wherein, upon fitting of the integral device onto the subject'ss head and lased ear, the lased ear is maintained in the desired shape and/or position with respect to the subject'ss head; andmaintaining the integral device on the lased ear until the ear is reshaped to the desired final shape and/or position.","19","15/344961","2016-11-07","2017-0049626","2017-02-23","10188553","2019-01-29","Chondrocyte, LLC","Pascal  Servell | Serge  Mordon | Jack  Savage","","","","A61F-0011/004","A61F-0011/004 | A61B-0005/1079 | A61F-0002/186 | H04L-0029/06 | H04L-0067/00 | A61B-2017/00792 | A61F-2002/183 | B33Y-0080/00 | H04L-0067/42 | H04L-0069/329","A61F-011/00","A61F-011/00 | A61F-002/18 | A61B-005/107 | H04L-029/08 | B33Y-080/00 | H04L-029/06 | A61B-017/00","","","","","","4919005001169"
"US","US","P","B2","Capturing data for individual physiological monitoring","A method for capturing images of an individual to determine wellness for such individual, including establishing baseline physiological data for the individual, and baseline capture condition data for the individual; detecting and identifying the presence of the individual in the image capture environment; providing semantic data associated with the individual; capturing one or more images of the individual during a capture event and determining the capture conditions present during the capture event; using the event capture conditions, the baseline physiological data for the individual and the baseline capture condition data to determine the acceptability of event captured images; and using the acceptable images and the semantic data in determining the wellness of the individual.","1. A method comprising: receiving, via a processor, health data, semantic data, and identification data from a subject;receiving, via the processor, subject image data;measuring, via the processor, environmental factors;perform, via the processor, data analysis on the health data, semantic data, and identification data received and the environmental factors;determining, via the processor, nominal input capture parameters and wellness parameters;preparing, via the processor, a reference image based on the determined nominal input capture parameters, wellness parameters, and data analysis; andcomparing a received image with the reference image, and determining possible causes and interventions of identified health issues based on comparing the received image with the reference image.","16","15/059786","2016-03-03","2016-0188831","2016-06-30","10192033","2019-01-29","MONUMENT PEAK VENTURES, LLC","Andrew F.  Kurtz | Kevin M.  Gobeyn | Donald E.  Olson | John N.  Border","","","","G06F-0019/3418","G06F-0019/3418 | A61B-0003/10 | A61B-0005/0059 | A61B-0005/411 | A61B-0005/442 | A61B-0005/444 | A61B-0005/445 | G06F-0017/30256 | G06F-0019/321 | G16H-0010/60 | G16H-0015/00 | G16H-0050/20 | G16H-0050/30 | A61B-0003/113 | A61B-0005/1038 | A61B-0005/1176 | A61B-0005/4547","G06K-009/00","G06K-009/00 | G06F-019/00 | A61B-003/10 | A61B-005/00 | G06F-017/30 | G16H-010/60 | G16H-050/30 | G16H-050/20 | G16H-015/00 | A61B-003/113 | A61B-005/103 | A61B-005/1171","","","","","","4919005004634"
"US","US","P","B2","Electronic apparatus and method for controlling functions in the electronic apparatus using a bio-metric sensor","According to various embodiments of the present disclosure, an electronic device may include a biometric sensor configured to detect a contact signal from at least two biometric electrodes and a processor configured to determine whether the contact signal received from the biometric sensor has biological characteristics. When the processor determines that the contact signal is a biometric input having biological characteristics, the processor executes a biometric information function. When the processor determines that the contact signal does not include the biological characteristics, the processor executes a general function related to an application.","1. An electronic device comprising: a biometric sensor configured to detect at least one contact signal from at least one biometric electrode; anda processor configured to: determine whether the at least one contact signal received from the biometric sensor includes biological characteristics,execute a biometric function in response to a determination that the contact signal is a biometric input including the biological characteristics,execute an application function of the electronic device in response to a determination that the contact signal is an electrode input when the contact signal does not include the biological characteristics,identify, when the contact signal does not include the biological characteristics, a position of a biometric electrode in which the contact signal is generated, andidentify the application function mapped to the identified position.","17","15/192952","2016-06-24","2016-0378965","2016-12-29","10192044","2019-01-29","SAMSUNG ELECTRONICS CO., LTD","Chaekyu  Choe | Hyungrock  Jung | Sungmin  Park | Jeongje  Park | Cheolho  Cheong | Jaewoong  Chun | Wonsuk  Choi","10-2015-0091566","KR","2015-06-26","G06F-0021/32","G06F-0021/32 | A61B-0005/0245 | A61B-0005/0404 | A61B-0005/0456 | A61B-0005/117 | A61B-0005/165 | G06F-0001/1626 | G06F-0001/1656 | G06F-0001/1684 | G06F-0003/011 | G06F-0003/015 | G06K-0009/00892 | H04N-0005/232 | H04N-0005/23216 | H04N-0005/23219 | H04N-0005/23245 | G06F-2203/011 | G06K-2009/00939","G06F-021/32","G06F-021/32 | A61B-005/0245 | G06F-003/01 | G06K-009/00 | H04N-005/232 | A61B-005/0404 | A61B-005/0456 | A61B-005/117 | A61B-005/16 | G06F-001/16","","","","","","4919005004645"
"US","US","P","B2","Mobile terminal and method for controlling same","The present invention relates to a mobile terminal capable of a new type of user input, comprising: a backside input unit including a plurality of buttons and exposed to the backside of the mobile terminal; a memory for storing relationships between combinations of the plurality of buttons and control instructions of the mobile terminal and biometric information; a sensor unit, arranged on the backside of the mobile terminal and adjacent to the backside input unit, for sensing a user's bio signal; and a control unit for, upon receiving a user input in accordance with a particular combination of the plurality of buttons, controlling the sensor unit to sense the user's bio signal, and authenticating the user using the sensed bio signal and the stored biometric information.","1. A mobile terminal, comprising: a rear input unit including a plurality of buttons exposed at a rear side of the mobile terminal, the rear input unit comprising a fingerprint sensor for detecting a fingerprint of a user;a memory for storing relationships between combinations of the plurality of buttons for determining a predetermined order and control commands of the mobile terminal and biometric information;a sensor unit for sensing a biometric signal of the user, wherein the sensor unit is adjacent to a bottom portion of the rear input unit such that the sensor unit senses the biometric signal when the user'ss finger is on the rear input unit, the sensor unit comprising: a light source for emitting light to the finger of the user; andan image sensor for sensing the biometric signal from light reflected from the finger; anda controller,wherein when a user input corresponding to a specific combination of the plurality of the buttons is received, the controller controls the rear input unit to sense the user'ss fingerprint and controls the sensor unit to sense the biometric signal of the user according to the predetermined order, wherein the predetermined order is determined by matching the specific combination of the plurality of buttons to the stored relationships between the combinations of the plurality of buttons, andwherein when the fingerprint and biometric signal of the user are sensed, the controller authenticates the user by using the sensed fingerprint and biometric signal and the stored biometric information.","10","15/322083","2015-01-09","2017-0161577","2017-06-08","10185883","2019-01-22","LG ELECTRONICS INC.","Junhak  Lee | Yonghan  Lee | Byeongkil  Ahn | Donghyeon  Kim | Hyungchul  Won","10-2014-0079475","KR","2014-06-27","G06K-0009/00892","G06K-0009/00892 | A61B-0005/0261 | A61B-0005/1032 | A61B-0005/1172 | A61B-0005/489 | A61B-0005/6897 | G06F-0021/32 | G06K-0009/0004 | G06K-0009/00087 | G06K-0009/00899 | H04B-0001/40 | G06K-2009/00932 | G06K-2009/00939","G06K-007/00","G06K-007/00 | G06K-009/00 | G05B-019/00 | G06F-021/32 | H04B-001/40 | A61B-005/026 | A61B-005/103 | A61B-005/1172 | A61B-005/00","","","","","","4919004003873"
"US","US","P","B2","Vehicle use and performance restrictions based on detected users","There are provided systems and methods for vehicle use and performance restrictions based on detected users. A user may check-in to a vehicle so that the vehicle identifies the user, such as through providing identification to the vehicle using biometrics, logins, or other information. Using the identification, the vehicle may determine parameters and restrictions on use of the vehicle by the user. Parameters may include information about the user, such as age, health, or other statistic stored with the identification for the user, and may be utilized to determine restrictions on use of the vehicle by the user, such as a speed of the vehicle and passengers allowed in the vehicle. Restrictions may also be set for the user, including speeds of travel, routes of travel, and usage of media players in the vehicle. The usage of the vehicle may be monitored and enforced using the restrictions.","1. A system comprising: a non-transitory memory; andone or more hardware processors coupled to the non-transitory memory and configured to read instructions from the non-transitory memory to cause the system to perform operations comprising: detecting that a first computing device is within a threshold distance of a vehicle using short range wireless communications with the first computing device;in response to detecting that the first computing device is within the threshold distance of the vehicle, determining whether one or more vehicle use restrictions are associated with the first computing device;in response to determining that the one or more vehicle use restrictions are associated with the first computing device, applying the one or more vehicle use restrictions to an onboard computing device of the vehicle;detecting a use of the onboard computing device of the vehicle during operation of the vehicle;in response to determining that a second computing device associated with the vehicle is outside of the threshold distance for the short range wireless communications, communicating a notification of the use to the second computing device over a network connection with the second computing device;receiving a change to the one or more vehicle use restrictions from the second computing device over the network connection during the operation of the vehicle; andapplying, by the system, the change on the one or more vehicle use restrictions with the onboard computing device during the operation of the vehicle.","20","15/451159","2017-03-06","2017-0291614","2017-10-12","10179591","2019-01-15","PAYPAL, INC.","Michael Charles  Todasco | Dennis Michael  Driscoll | Jeremy Leigh  Cattone | Amit Reuven  Menipaz","","","","B60W-0050/12","B60W-0050/12 | A61B-0005/00 | A61B-0005/117 | A61B-0005/6893 | B60W-0040/08 | B60W-0040/09 | G01C-0021/36 | G01C-0021/3617 | H04W-0004/02 | H04W-0004/40 | H04W-0004/48 | A61B-2503/22 | B60R-0025/241 | B60W-0050/00 | B60W-2040/0809 | B60W-2040/0881 | B60W-2050/0014 | H04L-0067/18 | H04L-0067/22 | H04L-0067/306 | H04W-0004/00 | H04W-0004/023 | H04W-0004/025 | H04W-0004/027 | H04W-0004/80","B60W-050/12","B60W-050/12 | G06F-017/00 | B60R-025/24 | B60W-040/08 | B60W-040/09 | G01C-021/36 | A61B-005/117 | A61B-005/00 | H04W-004/02 | H04W-004/48 | H04W-004/40 | B60W-050/00 | H04W-004/80 | H04W-004/00 | H04L-029/08","","","","","","4919003001159"
"US","US","P","B2","Intelligent truthfulness indicator association","Methods, computer program products, and systems are presented. The method computer program products, and systems can include, for instance: obtaining speech based message data and biometric data of a speaker user of a messaging system, the speech based message data being input into a computer device by the speaker user and the biometric data indicating one or more aspect of a physical condition of the speaker user during the input of the speech based message data into the computer device; processing data to determine a truthfulness parameter of the speech based message data, the processing data to determine a truthfulness parameter including processing the biometric data; and associating the truthfulness parameter to the speech based message data, wherein the associating includes tagging the speech based message data with the truthfulness parameter.","1. A method comprising: obtaining speech based message data and biometric data of a speaker user of a messaging system, the speech based message data being input into a computer device by the speaker user and the biometric data indicating one or more aspect of a physical condition of the speaker user during the input of the speech based message data into the computer device;processing data to determine a truthfulness parameter of the speech based message data, the processing data to determine a truthfulness parameter including processing the biometric data, the truthfulness parameter indicating a probability that the speech based message data is knowingly untruthful; andassociating the truthfulness parameter to the speech based message data, wherein the associating includes tagging the speech based message data with the truthfulness parameter, wherein the processing includes performing a preliminary truthfulness determining process, the preliminary truthfulness determining process based on examining of biometric data, and wherein the processing includes performing a fact check process to determine factual correctness of content of the message data conditionally on the condition that the preliminary truthfulness determining process satisfies a criteria.","19","15/478263","2017-04-04","2018-0286429","2018-10-04","10181333","2019-01-15","INTERNATIONAL BUSINESS MACHINES CORPORATION","James E.  Bostick | John M.  Ganci, Jr. | Sarbajit  Rakshit | Gandhi  Sivakumar","","","","G10L-0025/63","G10L-0025/63 | A61B-0005/0205 | G06F-0017/2775 | A61B-0005/021 | A61B-0005/024 | A61B-0005/053 | A61B-0005/08","G10L-017/26","G10L-017/26 | G06Q-050/22 | G10L-025/63 | G06F-017/27 | A61B-005/0205 | A61B-005/021 | A61B-005/024 | A61B-005/08 | A61B-005/053","","","","","","4919003002893"
"US","US","P","B2","Wearable device and method for providing feedback information through vein authentication","Disclosed herein are a wearable device and method for providing feedback information through vein authentication or the measurement of a body composition. In an aspect, the wearable device may include a measurement module configured to measure the pattern of veins of a user, a communication module configured to send unique bio information about the user measured by the measurement module to a management server along with authentication information and to receive feedback information for the transmitted information from the management server, and a memory module configured to store the pattern of the veins of the user.","1. A wearable device for vein authentication, comprising: a measurement module configured to measure a pattern of veins of a user;a communication module configured to send unique bio information about the user measured by the measurement module to a management server along with authentication information and to receive feedback information for the transmitted information from the management server; anda memory module configured to store the pattern of the veins of the user,wherein the measurement module comprisesa current measurement device configured to measure the pattern of the veins of the user by passing a fine current through the veins of the user, anda current transmission device configured to measure a body composition of the user by passing a current through cells within the body of the user,wherein the feedback information provides at least one of fitness equipment information, sporting goods information, food information, and a coupon information corresponding to the body composition of the user.","7","15/299092","2016-10-20","2017-0119276","2017-05-04","10172535","2019-01-08","SK PLANET CO., LTD.","Daewoo  Lee | Seulmaro  Jeon","10-2015-0150322 | 10-2015-0150977 | 10-2015-0152109","KR | KR | KR","2015-10-28 | 2015-10-29 | 2015-10-30","A61B-0005/0537","A61B-0005/0537 | A61B-0005/112 | A61B-0005/1171 | G06F-0019/3418 | G06F-0021/32 | A61B-0005/0022 | A61B-0005/1112 | A61B-0005/1118 | A61B-0005/1123 | G06K-0009/00348 | G06K-2009/00932 | G16H-0040/63","G06F-019/00","G06F-019/00 | A61B-005/053 | A61B-005/1171 | G06F-021/32 | A61B-005/00 | A61B-005/11 | G06K-009/00 | G16H-040/63","","","","","","4919002000907"
"US","US","P","B2","Multi-activity platform and interface","A multi-activity system may be configured to receive, upload, synchronize and process data for a variety of different activity types and/or recorded using multiple types of activity monitoring devices. In one example, an application interface may be defined with a multiple functions that are each useable by various types of devices and for processing multiple types of data. Additionally or alternatively, data for different activity types and/or recorded using different types of monitoring devices may be processed differently. Synchronization of data may further be handled on a device-by-device basis, device-type basis and/or activity-type basis using various tracking parameters.","1. A method performed by an athletic tracking system comprising: receiving physical activity data from a plurality of activity monitoring devices, each activity monitoring device including a sensor configured to measure physical activity data of a user;categorizing the received physical activity data based on type of activity monitoring device and based on type of physical activity;storing, in a first storage area, a first portion of the physical activity data corresponding to a first type of activity monitoring device and a first type of physical activity;storing, in a second storage area, a second portion of the physical activity data corresponding to a second type of activity monitoring device and a second type of physical activity;determining, based on the first type of activity monitoring device and the first type of physical activity, a first synchronization offset configured to specify a point at which synchronization of the first portion of the physical activity data is to begin; anddetermining, based on the second type of activity monitoring device and the second type of physical activity, a second synchronization offset configured to specify a point at which synchronization of the second portion of the physical activity data is to begin;responsive to receiving an instruction to synchronize data, modifying the physical activity data such that the first portion of the physical activity data is modified by the first synchronization offset and the second portion of the physical activity data is modified by the second synchronization offset; anddisplaying, by a display unit, a synchronized data display including the modified physical activity data.","20","15/072058","2016-03-16","2016-0296798","2016-10-13","10172540","2019-01-08","NIKE, INC. | R/GA","Ashok  Balakrishnan | Christopher W.  Davis | Jefferson  Lyman | Sridhar  Setti | Wade  Convay | Tara  Greer | Gaurabh  Mathure | Christopher C.  Thorwarth","","","","A61B-0005/1118","A61B-0005/1118 | A61B-0005/1112 | G06F-0017/40 | G06F-0019/3481 | G16H-0015/00 | H04L-0067/1095 | H04L-0067/12 | A61B-0005/4866 | A61B-0005/681 | A61B-0005/7435 | A61B-2503/10 | F04C-2270/0421","A61B-005/00","A61B-005/00 | A61B-005/11 | G06F-017/40 | G16H-015/00 | H04L-029/08 | G06F-019/00","","","","","","4919002000912"
"US","US","P","B2","Implant design analysis suite","A method for anatomical analysis and joint implant design. Embodiments provide users with the ability to anatomically analyze a single bone or a series of bones that exist in a database, evaluate surgical landmarks and axes, identify differences among specific characteristics of a given population, and modify existing implants or create new implant designs based on anatomical analyzes.,","1. A method of designing an orthopaedic implant, comprising the steps of: (a) obtaining three dimensional data corresponding to a multi-piece existing or prototype orthopaedic implant;(b) obtaining three dimensional data sets for a first bone and a second bone cooperating to form a joint;(c) associating the three dimensional data corresponding to the multi-piece existing or prototype orthopaedic implant with a three dimensional data set for the first bone and the second bone to comprise a virtual joint replacement;(d) taking the virtual joint replacement through a virtual range of motion and recording kinematic data; and(e) responsive to the recorded kinematic data, modifying the existing or prototype orthopaedic implant.","10","15/098379","2016-04-14","2016-0220312","2016-08-04","10172675","2019-01-08","ZIMMER INC.","Mohamed Rashwan  Mahfouz","","","","A61B-0034/10","A61B-0034/10 | A61F-0002/4657 | G06F-0017/16 | G06F-0017/30598 | G06F-0019/00 | G06K-0009/52 | G06K-0009/6267 | G06T-0007/0012 | G06T-0007/20 | G06T-0007/33 | G06T-0007/35 | G06T-0007/70 | G16H-0050/50 | A61B-2034/104 | A61B-2034/105 | A61B-2034/107 | A61B-2034/108 | A61B-2034/256 | A61F-0002/3094 | G06T-2200/04 | G06T-2207/10072 | G06T-2207/10088 | G06T-2207/30008 | G06T-2207/30052","G06K-009/00","G06K-009/00 | A61B-034/10 | G06F-017/30 | A61F-002/46 | G06F-017/16 | G06K-009/52 | G06K-009/62 | G06T-007/00 | G06T-007/20 | G06T-007/33 | G06T-007/35 | G06T-007/70 | G16H-050/50 | G06F-019/00 | A61F-002/30 | A61B-034/00","","","","","","4919002001046"
"US","US","P","B2","Device and method for the computer-assisted simulation of surgical interventions","A first interface for reading image data of an anatomical region obtained by means of a medical imaging method is provided. A modeling module serves for establishing a volumetric biomechanical structure model of the anatomical region on the basis of the image data. Moreover, provision is made of a tracking module, couplable with a camera, for video-based registration of spatial gestures of a user. Furthermore, a simulation module, based on the biomechanical structure model, serves to assign a registered gesture to a simulated mechanical effect on the anatomical region, simulate a mechanical reaction of the anatomical region to the simulated mechanical effect, and modify the biomechanical structure model in accordance with the simulated mechanical reaction. Moreover, provision is made for a visualization module for the volumetric visualization of the biomechanical structure model.","1. A device for the computer-assisted simulation of surgical interventions, comprising a) a first interface for reading image data of an anatomical region obtained by means of a medical imaging method,b) a modeling module for establishing a volumetric biomechanical structure model of the anatomical region on the basis of the image data,c) a tracking module, couplable with a camera, for video-based registration of spatial gestures of a user,d) a simulation module for assigning a gesture registered in each case to a simulated mechanical effect on the anatomical region on the basis of the biomechanical structure model,for simulating a mechanical reaction of the anatomical region to the simulated mechanical effect on the basis of the biomechanical structure model, andfor modifying the biomechanical structure model in accordance with the simulated mechanical reaction, ande) a visualization module for the volumetric visualization of the biomechanical structure model.","14","15/150607","2016-05-10","2016-0331464","2016-11-17","10172676","2019-01-08","SIEMENS HEALTHCARE GMBH","Olivier  Ecabert | Klaus  Engel | Tommaso  Mansi | Ingmar  Voigt","10-2015-208804","DE","2015-05-12","A61B-0034/10","A61B-0034/10 | A61B-0005/1128 | A61B-0090/37 | G06F-0003/016 | G06F-0003/017 | G06F-0003/0304 | G06F-0019/00 | G06K-0009/00355 | G06K-0009/00671 | G16H-0050/50 | A61B-0005/0037 | A61B-0005/0044 | A61B-0005/0073 | A61B-0005/055 | A61B-0034/76 | A61B-2017/00207 | A61B-2034/104 | A61B-2034/105 | A61B-2034/2057 | A61B-2034/2065 | A61B-2090/365 | A61B-2576/00 | G06K-0009/627 | G06K-0009/6257 | G06K-2209/05","A61B-005/055","A61B-005/055 | A61B-034/10 | A61B-090/00 | G06F-003/01 | G06F-003/03 | G06K-009/00 | A61B-005/11 | G16H-050/50 | G06F-019/00 | A61B-034/00 | A61B-017/00 | A61B-034/20 | G06K-009/62 | A61B-005/00","","","","","","4919002001047"
"US","US","P","B2","Method of virtual reality system and implementing such method","Virtual reality method intended to be implemented in a virtual reality system, the method including the production of a stimulus in the system during a period of stimulation, the stimulus including: a projection of an image sequence; a production of a first sound signal including a soundtrack linked to the progress of the image sequence; a production of a second sound signal having a first frequency and a third sound signal having a second frequency, the second sound signal being audible from one ear and the third sound signal being audible from the other ear of the user; a production of a fourth sound signal including a spoken presentation; during an initial portion of said predetermined period, the stimulus further including an induction signal; and during a final portion of said predetermined period, the intensity of the sound signals decreasing in intensity until a zero intensity, and the image sequence decreasing in intensity until a zero intensity.","1. Virtual reality method intended to be implemented in a virtual reality system, the method including the production of a stimulus in the system during a period of stimulation, wherein the period of stimulation comprises an initial portion, a median portion subsequent to the initial portion and preceding a final portion, the stimulus including, during the initial, median and final portions: a projection of an image sequence;a production of a first sound signal including a soundtrack linked to the progress of the image sequence;a production of a second sound signal having a first frequency and a third sound signal having a second frequency, the second sound signal being audible from one ear and the third sound signal being audible from the other ear of the user; anda production of a fourth sound signal including a spoken presentation;during the initial portion of said period of stimulation, the stimulus further including an induction signal; andduring the final portion of said period of stimulation, the intensity of the sound signals decreasing in intensity until a zero intensity, and the image sequence decreasing in intensity until a zero intensity.","29","15/347544","2016-11-09","2018-0046432","2018-02-15","10175935","2019-01-08","E-PNOGRAPHIC S?RL","Louis  Derungs","2016-001031","CH","2016-08-10","G06F-0003/165","G06F-0003/165 | A61B-0005/02 | A61M-0021/02 | G02B-0027/0172 | A61M-0021/0094 | A61M-2021/005 | A61M-2021/0011 | A61M-2021/0027 | A61M-2205/507 | A61M-2230/04 | A61M-2230/63 | G02B-2027/014 | G02B-2027/0141 | G02B-2027/0178","G06F-017/00","G06F-017/00 | G06F-003/16 | A61B-005/02 | G02B-027/01 | A61M-021/02 | A61M-021/00","","","","","","4919002004293"
"US","US","P","B2","System and method for generating and employing short length iris codes","A system and method for generating compact iris representations based on a database of iris images includes providing full-length iris codes for iris images in a database, where the full-length iris code includes a plurality of portions corresponding to circumferential rings in an associated iris image. Genuine and imposter score distributions are computed for the full-length iris codes, and code portions are identified that have a contribution that provides separation between imposter and genuine distributions relative to a threshold. A correlation between remaining code portions is measured. A subset of code portions having low correlations within the subset is generated to produce a compact iris representation.","1. A non-transitory computer readable storage medium comprising a computer readable program for generating compact iris representations based on a database of iris images, wherein the computer readable program when executed on a computer causes the computer to perform the steps of: computing genuine and imposter score distributions for full-length iris codes for iris images in a database, where the full-length iris codes include a plurality of portions corresponding to circumferential rings in an associated iris image;identifying and retaining code portions that have a contribution that provides separation between imposter and genuine distributions relative to a threshold;measuring a correlation between remaining code portions; andgenerating a subset of the remaining code portions having low correlations within the subset to produce a compact iris representation.","20","15/277903","2016-09-27","2017-0017843","2017-01-19","10176376","2019-01-08","INTERNATIONAL BUSINESS MACHINES CORPORATION","Jonathan H.  Connell, II | James E.  Gentile | Nalini K.  Ratha","","","","G06K-0009/00617","G06K-0009/00617 | G06F-0017/3028 | G06F-0017/30256 | G06K-0009/00899 | G06K-0009/4671 | G06K-0009/52 | G06K-0009/623 | G06T-0007/11 | G06K-2009/4666 | G06T-2207/20112 | G06T-2207/30196","G06K-009/00","G06K-009/00 | G06K-009/62 | G06F-017/30 | G06K-009/46 | G06K-009/52 | G06T-007/11","","","","","","4919002004730"
"US","US","P","B2","Method for determining the final length of stents before the positioning thereof","The invention relates to a new method for determining the change in length of a stent which will occur after it has been implanted inside a vascular structure. Said determining process is carried out based on the relationship between said change in length and the morphological characteristics of the vascular structure of interest.","1. A method for determining the final length of a stent before it is positioned in a vascular structure which comprises: a) obtaining an angiographic three-dimensional image of the vascular structure in which the stent will be positioned, and tracing, by a computer, a centreline of said vascular structure in the three-dimensional image, defining the exact location of the an initial point at which said stent will be positioned and dividing said centreline of the vascular structure into small segments;b) measuring, by the computer, on the three-dimensional image descriptor parameters of a morphology of said vascular structure for a first segment which starts from said initial point at which said stent will be positioned in said vascular structure;c) calculating, by the computer, a length of the stent for said first segment using an indicator ratio of the change in length of the stent as a function of a local morphology of the vascular structure;d) subtracting, by the computer, said length of the segment calculated in step c) from the nominal length of the stent to obtain a new nominal length; if said new nominal length is different from 0 then steps b) to d) will be repeated for the segment contiguous with the preceding segment; if the new nominal length is 0, all the distances of each segment will be added together, and this sum will be the final length of said stent after positioning.","5","14/911938","2014-10-03","2016-0232659","2016-08-11","10176566","2019-01-08","GALGO MEDICAL, S.L.","Ignacio  Larrabide","10-2013-031605","ES","2013-10-31","G06T-0007/0012","G06T-0007/0012 | A61B-0006/12 | A61B-0008/0841 | A61B-0034/10 | A61F-0002/82 | G01N-0015/088 | G06F-0019/00 | G06T-0007/60 | G16H-0050/50 | A61B-0005/20 | A61B-0005/6862 | A61B-2034/102 | A61B-2034/108 | A61F-0002/86 | A61F-2240/002 | G06F-0017/50 | G06T-2200/04","G06F-007/60","G06F-007/60 | G06F-017/10 | G06T-007/00 | A61B-006/12 | A61B-008/08 | A61B-034/10 | G01N-015/08 | A61F-002/82 | G06T-007/60 | G16H-050/50 | G06F-019/00 | G06F-017/50 | A61B-005/00 | A61F-002/86 | A61B-005/20","","","","","","4919002004920"
"US","US","P","B2","Architecture for field upgrade of a health monitoring system","An architecture allows individual system components to be developed and tested individually, i.e., as distinct modules, and to be subsequently combined through standardized electrical and communication interfaces. Any combination of these modules can be implemented to form different products that provide any number of functions, such as an integrated system for monitoring a health condition and/or delivering a medication. The architecture also provides an approach for dynamically updating the product and offering its users the latest generation of technology even after the users have already purchased the product. In particular, the embodiments employ the communication interfaces to also provide connection to a remote network that can update or upgrade the product's software when the product is out in the field.","1. A system for managing healthcare data, comprising: a first module circuit providing a first healthcare function, the first module circuit being a blood glucose meter including: a sensor-receiving module disposed within a housing configured to receive a test sensor therein;a reaction-detection system disposed within the housing, the reaction-detection system being configured to be coupled with the test sensor received within the housing to detect a reaction caused by a blood sample being received by the test sensor; andat least one processor that executes program instructions to determine a glucose concentration of the blood sample based at least in part on the detected reaction;a first central circuit controlling the first module circuit;a second module circuit providing a second healthcare function;a second central circuit controlling the second module circuit; anda communication interface providing a connection between the first central circuit and the second central circuit;an external device storing one or more upgraded software components, the communication interface providing a connection between the external device and the second central circuit;a download engine configured to receive the one or more upgraded software components from the external device, via the communication interface, to upgrade upgradable software stored in a memory area of the second module circuit by replacing a first version of the upgradable software with an upgraded second version of the upgradable software, wherein the healthcare function provided by the blood glucose meter continues to operate as expected while the download engine upgrades the upgradable software stored in the memory area of the second module circuit; anda data validation component coupled to the first module circuit and the second module circuit, the data validation component being configured to validate the upgrade of the upgradable software, wherein the upgrade of the upgradable software is conducted without affecting the first module circuit.","20","15/270780","2016-09-20","2017-0010882","2017-01-12","10176888","2019-01-08","ASCENSIA DIABETES CARE HOLDINGS AG","Steven  Charlton | Jun  Chen | Lin  Chen | Qiang  Fu | Igor  Gofman | Steven B.  Harris | Gary J.  Johnson | Paul L.  Inman | Qiong  Li | Harris  Lieber | Derek  Lok | Tony  Nguyen | Paul M.  Ripley | Gregory  Stefkovic | Hoi-Cheong Steve  Sun","","","","G16H-0010/60","G16H-0010/60 | A61B-0005/14532 | G06F-0001/16 | G06F-0001/1605 | G06F-0001/266 | G06F-0008/65 | G06F-0008/71 | G06F-0013/385 | G06F-0013/4081 | G06F-0017/30312 | G06F-0019/00 | G06Q-0050/22 | G16H-0040/40 | G16H-0040/63 | G06F-0008/61 | G06Q-0030/02 | G06Q-0050/24 | H04L-0029/06 | H04L-0029/08072","G06F-009/44","G06F-009/44 | G16H-010/60 | G06F-008/65 | G16H-040/63 | G16H-040/40 | G06Q-050/22 | A61B-005/145 | G06F-001/16 | G06F-001/26 | G06F-013/38 | G06F-013/40 | G06F-008/71 | G06F-017/30 | G06F-019/00 | H04L-029/08 | G06F-008/61 | G06Q-030/02 | G06Q-050/24 | H04L-029/06","","","","","","4919002005241"
"US","US","P","B2","Patient specific bone preparation for consistent effective fixation feature engagement","An optimized press-fit between a resected bone and an articular implant may, for instance, reduce undesirable qualities, including excess micromotion, stress transmission, and/or strain. By taking into account heterogeneous bone properties, the parameters of a bone resection can be determined as to optimize the press-fit between a resected bone and an articular implant. An optimized press-fit is obtained by determining ideal engagement characteristics corresponding to the fit between the fixation features of an articular implant and a bone. Then, taking into account a bone's heterogeneous properties, the parameters of a bone resection that would substantially achieve the determined ideal engagement characteristics are determined.","1. A method of performing surgery comprising: providing a prosthesis for implanting onto a bone of a joint of a patient, the prosthesis including a fixation peg having a peg radius and a peg length;providing a mass of bone designed to be displaced by the fixation peg upon implantation of the prosthesis;obtaining bone density data of a fixation area of the bone of the joint adapted to receive the fixation peg;resecting a bore hole in the fixation area of the bone to receive the fixation peg, the bore hole having bore radius and a bore length, wherein the bore length is equal to the peg length and bore radius is based upon the obtained bone density data of the fixation area and the mass of bone designed to be displaced; andimplanting the prosthesis on the bone by inserting the fixation peg into the resected bore hole.","9","14/489884","2014-09-18","2015-0080717","2015-03-19","10166109","2019-01-01","STRYKER CORPORATION","Michael C.  Ferko","","","","A61F-0002/38","A61F-0002/38 | A61B-0005/0073 | A61B-0005/4509 | A61B-0005/4528 | A61B-0006/032 | A61B-0017/17 | A61F-0002/28 | A61F-0002/30942 | G06F-0017/5009 | A61B-0006/505 | A61F-0002/389 | A61F-0002/3859 | A61F-2002/30006 | A61F-2002/30014 | A61F-2002/3095 | A61F-2002/30943 | A61F-2002/30948 | G16H-0050/50","A61F-002/38","A61F-002/38 | A61B-005/00 | A61B-017/17 | A61F-002/28 | G06F-017/50 | A61B-006/03 | A61F-002/30 | A61B-006/00 | G16H-050/50","","","","","","4919001001011"
"US","US","P","B2","Display device and controlling method thereof","A display device including a touch screen configured to display an analog watch screen; a wireless communication unit configured to receive data from an external device; a sensing unit configured to sense at least one of a motion of the display device and biometric state information of a user; and a controller configured to switch the analog watch screen to a digital watch screen in response to at least one of a predetermined touch input on the touch screen, an amount of data received from the external device, a specific motion of the display device sensed by the sensing unit, and specific biometric state information of the user sensed by the sensing unit.","1. A display device, comprising: a touch screen;a wireless communication unit configured to receive data from an external device;a sensing unit configured to sense at least one of a motion of the display device and biometric state information of a user; anda controller configured to:display an analog watch screen displaying a first number of icons related to the data received from the external device on the touch screen if a number of the data received from the external device is smaller than a predetermined number of data received from the external device, andswitch the analog watch screen to a digital watch screen displaying a second number of icons related to the data received from the external device if the number of data received from the external device corresponds to the predetermined number of data, wherein the second number of icons in the digital watch screen includes the first number of icons in the analog watch screen,wherein each icon related to the data received from the external device is displayed together with a sender of the data at a location on the analog watch screen mapped to a reception time of the received data, andwherein each icon has a different size based on an importance of the sender.","16","14/858805","2015-09-18","2016-0357386","2016-12-08","10168891","2019-01-01","LG ELECTRONICS INC.","Kyungdong  Choi","10-2015-0078378","KR","2015-06-03","G06F-0003/0488","G06F-0003/0488 | A61B-0005/02438 | A61B-0005/4806 | A61B-0005/681 | A61B-0005/742 | G04G-0009/0064 | G04G-0021/08 | G06F-0003/016 | G06F-0003/0412 | G06F-0003/0416 | G06F-0003/0421 | G06F-0003/04817 | G06K-0009/00013 | G06K-0009/00885 | H04M-0001/72519 | G06F-0001/163 | H04B-2001/3861 | H04M-0001/7253 | H04M-0001/72547 | H04M-0001/72597 | H04M-2250/12 | H04M-2250/60","G06F-003/0488","G06F-003/0488 | G04G-009/00 | H04M-001/725 | G06F-003/0481 | G06F-003/01 | G06F-003/041 | G06F-003/042 | G06K-009/00 | G04G-021/08 | A61B-005/00 | A61B-005/024 | G06F-001/16 | H04B-001/3827","","","","","","4919001003770"
"US","US","P","B2","Diagnosing autism spectrum disorder using natural language processing","Embodiments herein include a natural language computing system that provides a diagnosis for a participant in the conversation which indicates the likelihood that the participant exhibited a symptom of autism. To provide the diagnosis, the computing system includes a diagnosis system that performs a training process to generate a machine learning model which is then used to evaluate a textual representation of the conversation. For example, the diagnosis system may receive one or more examples of baseline conversations that exhibit symptoms of autisms and those that do not. The diagnosis system may annotate and the baseline conversations and identify features that are used to identify the symptoms of autism. The system generates a machine learning model that weights the features according to whether the identified features are, or are not, an indicator of autism.","1. A method for evaluating a textual conversation, comprising: generating a machine learning (ML) model using training data comprising a first plurality of training examples, each example being a text of a conversation labeled as exhibiting at least one characteristic of autism;receiving text of an ongoing conversation between a plurality of participants;annotating the text of the conversation using natural language processing;identifying features in the conversation using the annotations;evaluating the features using the ML model to determine a measure of probability that a first one of the plurality of participants in the conversation falls on the autism spectrum; andbased on the measure of probability, outputting for display, during the conversation, a notice indicating that the first participant has exhibited a characteristic of autism.","7","14/862815","2015-09-23","2016-0179786","2016-06-23","10169323","2019-01-01","INTERNATIONAL BUSINESS MACHINES CORPORATION","Adam T.  Clark | Brian J.  Cragun | Anthony W.  Eichenlaub | John E.  Petri | John C.  Unterholzner","","","","G06F-0017/2765","G06F-0017/2765 | A61B-0005/168 | G06F-0017/30663 | G06F-0017/30976 | G06F-0019/00 | G06N-0007/005 | G06N-0099/005 | G16H-0050/20 | G10L-0015/26","A61B-005/16","A61B-005/16 | G06N-007/00 | G06F-017/27 | G06F-017/30 | G06F-019/00 | G06N-099/00 | G10L-015/26 | G16H-050/20","","","","","","4919001004201"
"US","US","P","B1","Filtering document search results using contextual metadata","Receiving contextual data including a facial movement associated with an active document. A response associated with the active document is detected and associated with the received contextual data. A contextual metadata tag is generated based on the detected response to the active document. A contextual keyword is created that corresponds to the contextual metadata tag. Search results received in response to the query are filtered based on the contextual metadata tag.","1. A computer-implemented method for filtering document search results, the computer-implemented method comprising: receiving contextual data comprising a facial movement associated with an active document, an image of a face of a user reading the active document, a location where the user read the active document, a timestamp indicating when the user read the active document; and a timestamp indicating when the user edited the active document, wherein the contextual data is based, at least in part, on physical contexts of the user, wherein the physical contexts include movement of hands, movement of eyes, posture of the user, motion of the user'ss body, location of the user, facial expressions, identities of people proximate the user, and environmental characteristics;detecting an emotional response associated with the active document based on the contextual data, wherein the emotional response is detected based, at least in part, on the shape and position of the mouth, nose, eyebrows, and facial lines in the forehead in relation to one another;generating a contextual metadata tag based on the contextual data and the detected response to the active document, the contextual metadata tag including a movement tag indicating a movement of a device while the active document was read by the user and a movement of the device while the active document was edited by the user;receiving a query comprising a contextual keyword corresponding to the contextual metadata tag;filtering search results received in response to the query based on the contextual metadata tag; anddisplaying a list of the filtered search results.","1","15/910129","2018-03-02","2019-0005034","2019-01-03","10169342","2019-01-01","INTERNATIONAL BUSINESS MACHINES CORPORATION","Yoav  Ben-Yair | Gil  Fuchs | Itai  Gordon | Ilan D.  Prager","","","","G06F-0017/30011","G06F-0017/30011 | A61B-0005/1114 | G06F-0017/30525 | G06F-0017/30864 | G06F-0017/30991 | G06F-0017/30997 | G06K-0009/00315","G06F-017/30","G06F-017/30 | G06K-009/00 | A61B-005/11","","","","","","4919001004220"
"US","US","P","B2","Recording dose data from drug injection devices using optical character recognition (OCR)","A method of recording a medicament dose using a data collection device comprises capturing an image of a medicament dose indicator of a medicament delivery device, adjusting a scale of said image, adjusting said image for skew of one or more characters displayed by the medicament dose indicator, determining the position of at least one of said one or more characters in the image, identifying the at least one character using optical character recognition and determining a medicament dose indicator by the medicament dose indicator based on a result of the optical character recognition. The method may be performed using a handheld electronic device comprising a camera, such as a cellphone, a tablet computer or other device. A computer program for controlling a data collection device to perform the method may be provided in the form of a software application or ""app"".","1. A method of recording a medicament dose using a handheld data collection device, the method comprising: capturing, by a camera of the handheld data collection device positioned at a distance from a medicament dose indicator of a medicament delivery device, an image of the medicament dose indicator, wherein the distance between the camera and the medicament dose indicator is variable;adjusting a scale of said image;adjusting said image for skew of one or more characters displayed by the medicament dose indicator;determining a position of at least one of said one or more characters in the image;identifying the at least one character using optical character recognition; anddetermining a medicament dose indicated by the medicament dose indicator based on a result of said optical character recognition.","17","15/520057","2015-10-15","2017-0316158","2017-11-02","10169536","2019-01-01","SANOFI-AVENTIS DEUTSCHLAND GMBH","Thomas  Klemm | Dietmar  Hammen","2014-189705","EP","2014-10-21","G06F-0019/321","G06F-0019/321 | A61M-0005/24 | A61M-0005/315 | A61M-0005/31525 | G06F-0019/00 | G06F-0019/3468 | G06K-0009/32 | G06K-0009/3283 | G06T-0005/50 | H04N-0005/235 | A61M-2005/3126 | A61M-2205/3306 | A61M-2205/505 | A61M-2205/52 | A61M-2205/6081 | H04N-0005/23229","G06K-007/10","G06K-007/10 | G06F-019/00 | A61M-005/24 | A61M-005/315 | G06K-009/32 | G06T-005/50 | H04N-005/235 | A61M-005/31 | H04N-005/232","","","","","","4919001004414"
"US","US","P","B2","Data backfilling for continuous glucose monitoring","Methods and apparatus, including computer program products, are provided for backfilling. In some example embodiments, there is provided a method that includes receiving, at a receiver, backfill data representative of sensor data stored, at a continuous blood glucose sensor and transmitter assembly, due to a loss of a wireless link between the receiver and the continuous blood glucose sensor and transmitter assembly; generating, at the receiver, at least one of a notification or a graphically distinct indicator for presentation at a display of the receiver, the at least one of the notification or the graphically distinct indicator enabling the backfill data to be graphically distinguished, when presented at the display, from non-backfill data; and generating, at the receiver, a view including the backfill data, the non-backfill data, and the generated at least one of the notification or the graphically distinct indicator. Related systems, methods, and articles of manufacture are also described.","1. A method comprising: transmitting, by a user equipment, a data connection request to the analyte sensor system;establishing the data connection with the analyte sensor system;checking, by the user equipment, for private data stored at the user equipment and associated with the analyte sensor system, the private data encrypted to inhibit access by the user equipment;when the checking identifies private data associated with the analyte sensor system, requesting private data from the analyte sensor system;when the checking does not identify private data associated with the analyte sensor system, requesting, from the analyte sensor system, manifest data for the private data, andrequesting, in response to receiving the manifest data, private data from the analyte sensor system; andreceiving the requested private data to enable storage before forwarding to a server.","13","15/287581","2016-10-06","2017-0124350","2017-05-04","10169539","2019-01-01","DEXCOM, INC.","Eli  Reihman | Sebastian  Bohm | Leif N.  Bowman | Katherine Yerre  Koehler | Disha B.  Sheth | Peter C.  Simpson | Jim Stephen  Amidei | Douglas William  Burnette | Michael Robert  Mensinger | Eric  Cohen | Hari  Hampapuram | Phil  Mayou","","","","G06F-0019/3406","G06F-0019/3406 | A61B-0005/0004 | A61B-0005/14532 | A61B-0005/7275 | A61B-0005/746 | G06F-0003/1415 | G06F-0019/3418 | G06F-0021/6245 | G16H-0010/60 | G16H-0015/00 | G16H-0040/63 | G06F-0017/30867 | G06F-0017/30979 | G06Q-2220/10 | G06T-0011/001 | G06T-0011/206 | G09G-0005/377 | G09G-2354/00 | G09G-2370/10 | G09G-2370/16 | H04W-0012/02 | H04W-0012/06","G06F-019/00","G06F-019/00 | G16H-040/63 | A61B-005/00 | A61B-005/145 | G06F-021/62 | G06F-003/14 | G16H-010/60 | G16H-015/00 | G06T-011/00 | G09G-005/377 | G06T-011/20 | H04W-012/06 | G06F-017/30 | H04W-012/02","","","","","","4919001004417"
"US","US","P","B2","Biometric interface system and method","A system includes a wearable device having at least one sensor configured to determine a user's fingerprint data, at least one data storage device containing authentication data, and at least one processor configured to compare the user's fingerprint data with the authentication data to authenticate a user. A method of authenticating a wearable device includes producing a fingerprint, determining fingerprint data derived from the fingerprint with one or more sensors, comparing the fingerprint data with authentication data on one or more data storage devices, and authenticating the user if the fingerprint data and the authentication data match.","1. An earpiece for authenticating users using stored finger print authentication data, the earpiece comprising: an earpiece housing;at least one speaker;at least one microphone;a processor disposed within the earpiece housing and operatively connected to the at least one speaker and the at least one microphone, wherein once authentication occurs all or portions of earpiece operation or programming become accessible to a user;a plurality of sensors operatively connected to the processor;a data storage device disposed within the earpiece housing and operatively connected to the processor, wherein a first portion of the stored finger print authentication data is stored on the data storage device;a radio transceiver disposed within the earpiece housing and operatively connected to the processor, wherein a second portion of the stored fingerprint authentication data is stored at a remote location and accessible over a network through the radio transceiver;wherein the processor is configured to receive fingerprint data from a first sensor at a fingerprint contact surface on the earpiece housing and analyze the fingerprint data using the first portion of the stored fingerprint authentication data and the second portion of the stored fingerprint authentication data; andwherein the processor is configured to receive users biometric data from a second sensor and make an authentication decision based on the fingerprint data and the biometric data.","19","15/951063","2018-04-11","2018-0232512","2018-08-16","10169561","2019-01-01","BRAGI GMBH","Mohamed Ali  Razouane | Peter Vincent  Boesen","","","","G06F-0021/32","G06F-0021/32 | A61B-0005/02416 | A61B-0005/117 | A61B-0005/1172 | A61B-0005/6803 | G06F-0017/30289 | G06F-0021/40 | G06F-0021/83 | G07C-0009/00071 | G07C-0009/00158 | H04R-0001/1016 | H04R-0005/04 | A61B-0005/02405 | A61B-0005/11 | G05B-0019/00 | G06F-0003/017 | G06F-0017/30294 | G06F-0017/30595 | G06F-0021/34 | G06F-2221/2147 | H04Q-0009/00","G06F-021/32","G06F-021/32 | A61B-005/1172 | G07C-009/00 | G06F-021/83 | A61B-005/117 | A61B-005/00 | H04R-001/10 | G06F-021/40 | H04R-005/04 | G06F-017/30 | H04Q-009/00 | A61B-005/024 | A61B-005/11 | G06F-003/01 | G05B-019/00 | G06F-021/34","","","","","","4919001004439"
"US","US","P","B2","Medical image processing and diagnostic image generation device for predetermined types of diagnostic information","To provide a technique for supporting diagnosis by reducing a user's time and effort in quantitative diagnosis using a quantitative value acquired by a medical image acquisition apparatus. A user is allowed in advance to select only desired diagnostic information from vast amounts of diagnostic information such as images and numerical values. Only the selected diagnostic information is presented to the user in a user-friendly mode. The diagnostic information is calculated by using a physical property value necessary for the calculation of the diagnostic information in question and calculation information such as arithmetic functions and variables, the physical property value and calculation information being stored in advance.","1. A medical diagnostic imaging support apparatus comprising: a memory configured to store a plurality of types of diagnostic information in correspondence with a plurality of predetermined physical property values, a plurality of predetermined equations, and a plurality of predetermined values of variables of each of the predetermined equations; anda processor programmed by executable instructions in the memory to perform operations including:displaying a diagnostic information reception area;receiving, via the diagnostic information reception area, a selection of diagnostic information to be output from among the plurality of types of diagnostic information;calculating, upon receiving the selected diagnostic information via the diagnostic information reception area and receiving the measurement data acquired by a medical image acquisition apparatus, the predetermined physical property values corresponding to the selected diagnostic information from the measurement data acquired by the medical image acquisition apparatus by fitting the measurement data to a predetermined signal function and estimating the physical property values as variables of the signal function;calculating the selected diagnostic information by using the calculated physical property values and one of the predetermined equations and the predetermined values of variables of the one of the predetermined equations corresponding to the selected diagnostic information; andgenerating a display screen from the calculated diagnostic information and displaying the resultant display screen.","15","15/300830","2014-04-22","2017-0018080","2017-01-19","10169866","2019-01-01","HITACHI, LTD.","Suguru  Yokosawa | Yo  Taniguchi | Hisaaki  Ochi | Toru  Shirai | Shinji  Kurokawa","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/055 | A61B-0005/7435 | G06F-0003/04847 | G06T-0011/60 | A61B-0006/032 | A61B-0006/5217 | A61B-0008/485 | A61B-0008/5223 | G06T-2200/24 | G06T-2207/10088 | G06T-2207/30004","G06F-003/0484","G06F-003/0484 | G06T-007/00 | A61B-005/055 | G06T-011/60 | A61B-005/00 | A61B-006/03 | A61B-006/00 | A61B-008/08","","","","","","4919001004744"
"US","US","P","B2","Three dimensional imaging method of a limited zone of a patient's vasculature","This disclosure relates to a three dimensional visualization method for visualizing and/or displaying a limited zone of a patient's vasculature, the method comprising selecting an entry point within an imaged vasculature and three dimensionally visualizing a simulated contrast agent propagation from the selected entry point in a limited zone of the imaged vasculature.","1. An imaging method for generating a three dimensional visualization of a limited zone of a patient vasculature, comprising: providing an imaging system comprising an imager to generate an image and a display;injecting a real contrast agent into the vasculature at a first entry point; andoperating the imaging system to: image the vasculature to produce a set of two dimensional images, each image comprising real contrast agent propagation path information;generate a three dimensional visualization on the display of a propagation of the real contrast agent from the first entry point in said imaged vasculature from the set of two dimensional images;segment vessels of said imaged vasculature to confirm at least one vascular path;select a second entry point within said segmented imaged vasculature, the second entry point being different from the first entry point; andgenerate a three dimensional visualization on the display of a simulated propagation of contrast agent from the second entry point in a limited zone of said imaged vasculature to improve visualization of vessels in said limited zone.","16","15/109346","2013-12-31","2016-0328846","2016-11-10","10163205","2018-12-25","GENERAL ELECTRIC COMPANY","Yves Lucien  Trousset | Cyril  Riddell | Vincent Jonas  Bismuth","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/489 | A61B-0006/481 | A61B-0006/504 | G06F-0003/04842 | G06T-0019/003 | A61B-0006/032 | A61B-0006/466 | A61B-0006/486 | A61B-0006/5211 | G06T-2200/24","G06K-009/00","G06K-009/00 | G06T-007/00 | G06T-019/00 | A61B-005/00 | G06F-003/0484 | A61B-006/03 | A61B-006/00","","","","","","4918052004653"
"US","US","P","B2","Method for determining contact position parameters of a joint connecting two bones","A data processing method for determining six parameters, corresponding to six degrees of freedom, of a contact position of a joint which connects two bones, comprising the steps of acquiring a 3D model of each bone, acquiring four of the six parameters as a given parameters, selecting initial values for the two remaining parameters and varying the two remaining parameters virtually in order to achieve a virtual relative position between the two 3D models such that they are in contact with each other.","1. A computer implemented method for determining a contact position of a joint, which has six degrees of freedom, and which connects two bones and supports a range of relative movement between the two bones, comprising: acquiring a 3D model of each bone of the two bones;defining six parameters corresponding to the six degrees of freedom of the joint;acquiring four of the six parameters as fixed parameters;selecting initial values for the two remaining parameters of the six parameters, wherein the selecting of the initial values for the two remaining parameters is such that the 3D models of each bone are not in contact with each other;determining updated values of the two remaining parameters by varying the two remaining parameters of the six parameters from the selected initial values until achieving a relative position between the 3D models of each bone such that they are in contact with each other; anddetermining the contact position of the joint based on the four fixed parameters and the updated values of the two remaining parameters.","17","15/395247","2016-12-30","2017-0178413","2017-06-22","10163270","2018-12-25","BRAINLAB AG","Hubert  Gotte | Lars  Dohmen","PCT-EP2011-072323 | PCT-EP2011-072324","WO | WO","2011-12-09 | 2011-12-09","G06T-0019/20","G06T-0019/20 | A61B-0005/11 | A61B-0005/4528 | A61B-0005/4585 | A61B-0034/10 | A61F-0002/4657 | G06F-0017/50 | G06F-0019/00 | G06T-0013/40 | G16H-0050/50 | A61B-0005/103 | A61B-2034/105 | A61F-2002/4668 | G06T-2210/41 | G06T-2219/2004 | G06T-2219/2016","A61B-005/00","A61B-005/00 | A61B-005/103 | A61B-017/15 | G06F-017/50 | G06T-019/20 | G16H-050/50 | A61B-005/11 | G06T-013/40 | A61F-002/46 | A61B-034/10 | G06F-019/00","","","","","","4918052004718"
"US","US","P","B2","Determining user-interested information based on wearable device","This disclosure provides wearable-device based user-interested information determination methods, apparatuses and wearable devices. The method includes: receiving, by an electrocardiography (ECG) sensor associated with the wearable device, an ECG signal of a user, determining a feature set for the ECG signal, in which the feature set includes time-domain feature data of the ECG signal and frequency-domain feature data of the ECG signal, and determining the user-interested information based on similarity between the feature set and reference feature sets indicative of the user-interested information, in which the user-interested information includes health information associated with a disease. The wearable device includes an ECG sensor configured to receive an ECG signal and an FPGA system. The FPGA system includes modules for determine user-interested information based on the ECG signal. The apparatus includes a processor and a memory coupled to the processor. The memory is configured to store instructions to implement the method.","1. A method for determining a cardiovascular disease of a user using a wearable device, comprising: receiving, by an electrocardiography (ECG) sensor associated with the wearable device, an ECG signal of the user, the ECG signal corresponding a physical ECG signal of the user;determining a feature set for the ECG signal, wherein the feature set comprises time-domain feature data of the ECG signal and frequency-domain feature data of the ECG signal, the determining the feature set for the ECG signal comprising: determining wavelet coefficients for the ECG signal by performing a wavelet transform to the ECG signal;determining the wavelet coefficients as a first type of the frequency-domain feature data of the ECG signal;determining discrete cosine transform (DCT) coefficients by performing autocorrelation (AC) and DCT to the ECG signal filtered after the wavelet transform; anddetermining the DCT coefficients as a second type of the frequency-domain feature data of the ECG signal;determining whether the user has the cardiovascular disease based on a similarity between the feature set and reference feature sets of cardiovascular diseases; andon condition that the user is determined to have the cardiovascular disease, reporting to the user that the user has the cardiovascular disease.","16","15/584911","2017-05-02","2017-0242974","2017-08-24","10163528","2018-12-25","ANHUI HUAMI INFORMATION TECHNOLOGY CO., LTD.","Yajun  Zhao | Jixiang  Su | Fei  Wang | Ting  Chen | Hongda  Mao","2015-10795936 | 2015-10796544","CN | CN","2015-11-17 | 2015-11-17","G16H-0050/30","G16H-0050/30 | A61B-0005/0245 | A61B-0005/02438 | A61B-0005/04023 | A61B-0005/0452 | A61B-0005/726 | A61B-0005/7282 | G06F-0017/147 | G06F-0017/148 | G06F-0017/15 | G06F-0019/00 | G06F-0021/32 | G16H-0040/63 | G06F-0017/5027","A61B-005/04","A61B-005/04 | G16H-050/30 | A61B-005/0452 | G06F-021/32 | G16H-040/63 | A61B-005/024 | A61B-005/0245 | A61B-005/0402 | A61B-005/00 | G06F-017/14 | G06F-017/15 | G06F-019/00 | G06F-017/50","","","","","","4918052004969"
"US","US","P","B2","Surgical device guidance and monitoring devices, systems, and methods","Provided herein are systems, devices, assemblies, and methods for localization of one or more tags in a patient.","1. A system comprising: a) an attachment component comprising at least one location emitter, wherein said attachment component is configured to be attached to a hand-held medical device with a device tip;b) a display component attached to, or integral with, said attachment component, wherein said display component comprises a display screen, andc) a tag, said tag comprising an antenna, wherein said tag is physically separate from, and not physically linked to, any of: said attachment component, said display component, and said hand-held medical device; andwherein said display screen is configured to receive data about the position of said tag and said medical device from a computer system, wherein said computer system is configured to receive information from a plurality of witness stations and generate said data, andwherein said display screen displays: i) a tag indicator which corresponds to the physical location of said tag, andii) at least one of the following additional indictors: A) a total distance indicator which indicates the distance of said device tip to said tag,B) a medical device indicator which corresponds to the location of said medical device with respect to said tag,C) a tag-tip vector indicator which provides a representation of the two-dimensional distance, and two-dimensional location, of said device tip to said tag; andD) a depth indicator which provides an indication of how high above, or below, the device tip is with respect to said tag.","30","15/674455","2017-08-10","2018-0042517","2018-02-15","10154799","2018-12-18","ELUCENT MEDICAL, INC.","Daniel W.  van der Weide | Noah  van der Weide | Eric N.  Rudie | David  Miel | Lee G.  Wilke | Fred T.  Lee, Jr.","","","","A61B-0005/062","A61B-0005/062 | A61B-0005/0068 | A61B-0005/064 | A61B-0005/066 | A61B-0005/743 | G06K-0007/10386 | A61B-0005/6886 | A61B-0018/08 | A61B-2505/05 | H01Q-0001/2208 | H01Q-0001/2225","A61B-005/06","A61B-005/06 | A61B-005/00 | G06K-007/10 | H01Q-001/22 | A61B-018/08","","","","","","4918051000611"
"US","US","P","B2","Systems and methods for generating a treatment map","Systems and methods are described for generating a treatment map based on a microbe profile, which include receiving a two-dimensional microbe profile of a skin surface of an individual, selecting one or more treatment agents from a database of treatment agents, generating the treatment map by mapping the selected one or more treatment agents to each of one or more corresponding locations on the two-dimensional microbe profile of the skin surface of the individual, and reporting the treatment map to a user.","1. A system for generating a treatment map, comprising: a digital two-dimensional microbe profile of a skin surface of an individual'ss face the digital two-dimensional microbe profile including a two-dimensional spatial distribution, relative abundance, and identity of one or more types of microbes at each of one or more locations on the skin surface of the individual'ss face overlaid with a feature map of the skin surface of the individual'ss face;a database of treatment agents;a computing device including a processor and circuitry, the circuitry including circuitry configured to receive the digital two-dimensional microbe profile of the skin surface of the individual'ss face;circuitry configured to select one or more treatment agents from the database of treatment agents based on the two-dimensional spatial distribution, the relative abundance, and the identity of the one or more types of microbes at each of the one or more locations on the skin surface of the individual'ss face;circuitry configured to map the one or more treatment agents selected to treat at least one of the one or more types of microbes at each of the one or more locations on the skin surface of the individual'ss face to each of one or more corresponding locations on the feature map associated with the digital two-dimensional microbe profile;circuitry configured to generate a personalized treatment map including a two-dimensional spatial distribution of the one or more treatment agents selected for application at each of the one or more locations on the skin surface of the individual'ss face overlaid with the feature map of the skin surface of the individual'ss face; andcircuitry configured to report the generated personalized treatment map to a user.","24","14/192680","2014-02-27","2015-0058368","2015-02-26","10152529","2018-12-11","ELWHA LLC","Roderick A.  Hyde | Gary L.  McKnight","","","","G06F-0017/30595","G06F-0017/30595 | G06F-0017/30389 | G06F-0019/00 | G06F-0019/3462 | A61B-0005/441 | A61B-0005/443 | A61B-0005/445 | G06F-0019/321 | G06K-0009/00134 | G16H-0050/20 | Y02A-0090/26","G06F-017/30","G06F-017/30 | A61B-005/00 | G06K-009/00 | G06F-019/00 | G16H-050/20","","","","","","4918050003619"
"US","US","P","B2","Wearable electronic apparatus","A wearable electronic apparatus, a computer program and a method are disclosed. Physical activity data measured relating to a user of a wearable electronic apparatus is obtained. An exercise mode of the wearable electronic apparatus is switched on such that information related to the physical activity data is outputted to the user. While the exercise mode is on, wireless application data is received, and, only if the application data fulfills a predetermined relevance condition, the application data is outputted to the user.","1. A wearable electronic apparatus comprising: a user interface;a radio transceiver;a sensor interface;one or more processors; andone or more memories including computer program code,the one or more memories and the computer program code configured to, with the one or more processors, cause the apparatus at least to perform operations comprising:obtaining, with the sensor interface, physical activity data measured relating to a user of the wearable electronic apparatus;switching an exercise mode of the apparatus on such that information related to the physical activity data is outputted, with the user interface, to the user;while the exercise mode is on, receiving, with the radio transceiver, application data, and, only if the application data fulfills a predetermined relevance condition, outputting, with the user interface, the application data to the user, the application data comprising a message from a web service, anddetermining the predetermined relevance condition based on a tag in the application data fulfilling the predetermined relevance condition,wherein the tag refers to at least one of a hashtag of the application data, a type of label tag used on social network and microblogging services, a type of metadata tag used on social network and microblogging services, wherein, if the exercise mode is on, a suppression message is transmitted using the radio transceiver, the suppression message instructing a recipient device of the suppression message not to transmit the application data, wherein the recipient device is one or more of the following: a portable apparatus of the user, an electronic service, wherein, if the exercise mode is off, a cancel message is transmitted using the radio transceiver, the cancel message instructing the recipient device of the cancel message resume transmission of the application data.","22","14/713727","2015-05-15","2016-0337843","2016-11-17","10154129","2018-12-11","POLAR ELECTRO OY","Mikko  Repka | Mika  Erkkila","","","","H04M-0001/72569","H04M-0001/72569 | A61B-0005/02438 | A61B-0005/1118 | G06F-0001/163 | G06F-0003/014 | G06F-0003/017 | G06F-0003/0346 | G06F-0009/451 | G06F-0009/542 | H04L-0051/12 | H04L-0051/24 | H04M-0001/7253 | H04M-0001/72563 | H04M-0001/72577 | H04W-0008/22 | A61B-0005/01 | A61B-0005/02405 | A61B-0005/02416 | A61B-0005/1112 | A61B-0005/1123 | A61B-0005/681 | A61B-0005/6823 | A61B-0005/6824 | A61B-0005/6829 | A61B-2503/10 | A61B-2562/0219 | H04L-0051/32","H04M-001/725","H04M-001/725 | H04L-012/58 | H04W-008/22 | G06F-009/451 | A61B-005/024 | A61B-005/11 | G06F-001/16 | G06F-003/01 | G06F-009/54 | G06F-003/0346 | A61B-005/00 | A61B-005/01","","","","","","4918050005209"
"US","US","P","B2","Executing instructions in response to a communication","An instruction execution engine on a user device may be configured to receive an executable instruction assigned to one or more contacts or groups of contacts. A communication from the one or more contacts or groups may be detected. Upon detecting the communication, the engine may execute the executable instruction. This executing step may trigger a user reminder or data transfer to one or more third parties.","1. A computer program embodied on at least one non-transitory computer-readable medium of a first device, the computer program comprising instructions executable to cause at least one processor to: detect receipt of a communication at a first device from one or more contacts over a communication path;automatically execute a first program instruction to send the communication to one or more third parties associated with the one or more contacts over the communication path based on the detection;determine, in response to the detection, a second program instruction is assigned to at least one of the one or more contacts;automatically execute the second program instruction based, at least in part, on the determination;automatically perform a user-specified action in response to the execution of the second program instruction, wherein the user-specified action is assigned to at least one of the one or more contacts and comprises providing a reminder; andtransfer data to at least one of the one or more contacts over the communication path, the transferred data having been selected using the first device and created prior to the detected communication.","18","13/770429","2013-02-19","2014-0232815","2014-08-21","10154131","2018-12-11","APPLE INC.","Gencer  Cili | Devrim  Varoglu","","","","H04M-0001/72597","H04M-0001/72597 | H04M-0001/2745","H04M-001/725","H04M-001/725 | H04M-001/2745 | H04N-007/14 | A61B-005/00 | G06Q-010/10 | H04L-029/06 | H04L-012/18","","","","","","4918050005211"
"US","US","P","B2","Medical labeling apparatus with drug information","Provided is a labeling apparatus that generates a label for labeling a drug container at a healthcare facility. The labeling apparatus includes a code reader that reads a computer-readable code encoding a drug to be stored by the drug container and transmits a signal indicative of the identity of the drug in response to reading the computer-readable code. A non-transitory computer-readable memory stores a drug formulary comprising a plurality of drug entries. A processing component is configured to identify, from the formulary, the identity of the drug corresponding to the computer-readable code and receives a patient identity from a computer-accessible source. A printer is operable to print label content identifying the specific drug onto a label that is to be applied to the drug container. The label content includes the identity of the drug and the patient identity encoded by a label code that is computer-readable.","1. A labeling apparatus that generates a label for labeling a drug container at a healthcare facility, the labeling apparatus comprising: a code reader that reads a computer-readable code encoding a drug to be stored by the drug container and transmits a signal indicative of the identity of the drug in response to reading the computer-readable code;a non-transitory computer-readable memory that stores a drug formulary comprising a plurality of drug entries;a processing component that identifies, from the formulary, the identity of the drug corresponding to the computer-readable code and receives additional information from a computer-accessible source; anda printer for printing label content identifying the specific drug onto a label that is to be applied to the drug container, the label content comprising the identity of the drug and the additional information formatted in at least one of: a human-readable form, and encoded by a label code that is computer-readable, wherein wherein the computer-accessible source comprises a second computer-readable code encoding the additional information, and the code reader is adapted to read the second computer-readable code from a source independent of a patient and transmit an additional signal indicative of the patient identity that is received by the processing component, the source independent of the patient comprising an identification label that is not used to program a medication delivery device.","8","15/543417","2016-01-15","2018-0002056","2018-01-04","10144547","2018-12-04","CODONICS, INC.","Gary  Enos | Lawrence  Srnka","","","","B65C-0009/46","B65C-0009/46 | B65C-0001/00 | G06F-0017/40 | G06F-0019/00 | G06F-0019/3456 | G06F-0019/3462 | G06K-0007/10712 | G08B-0021/02 | G09F-0003/00 | G16H-0020/10 | A61M-0005/14546 | A61M-2205/18 | A61M-2205/6009 | A61M-2205/6072","B65C-009/46","B65C-009/46 | G06F-017/40 | A61M-005/14 | B65C-001/00 | G09F-003/00 | G06F-019/00 | G06K-007/10 | G08B-021/02 | G16H-020/10 | A61M-005/145","","","","","","4918049002058"
"US","US","P","B2","Icon-based user interfaces","Within the field of computing, many user interfaces may present a set of records. Presented herein are user interfaces that may be advantageous in some scenarios, involving the presentation of a stack of unit boxes having a stack order. A current unit box may present a record filling an entirety of the display and including at least two icons respectively depicting an item of information in the record. The device may also accept a gesture from a user along a first axis, such that a gesture in a forward direction along the first axis (e.g., tapping a right half of a touch-sensitive display) visual transitions to a next unit box in the stack order, and a gesture in a direction opposite the forward direction (e.g., tapping a left half of the display) along the first axis visually transitions to a preceding unit box in the stack order.","1. A nonvolatile computer-readable storage device comprising instructions that, when executed on a processor of a device having a display and a memory, present stack of unit boxes having a stack order, respective unit boxes comprising a first area, a second area, and at least one items, by: for a current unit box in the stack, present on the display a unit box comprising at least one icon respectively depicting an item of the unit box;upon receiving a selection of the first area, transitioning from the current unit box to a next unit box after the current unit box in the stack order, and displaying a unit box corresponding to the next unit box, the next unit box comprising at least one icon respectively depicting an item of the next unit box; andupon receiving a selection of the second area, transitioning from the current unit box to a preceding unit box before the current unit box in the stack order, and displaying a unit box corresponding to the preceding unit box, the preceding unit box comprising at least one icon respectively depicting an item of the preceding unit box.","23","13/730075","2012-12-28","2013-0145317","2013-06-06","10146400","2018-12-04","Anthony J. Vallone","Anthony J.  Vallone","","","","G06F-0003/04817","G06F-0003/04817 | A61B-0005/7435 | A61B-0005/7475 | G06Q-0010/10 | G06Q-0050/22","G06Q-010/10","G06Q-010/10 | G06F-003/0481 | A61B-005/00 | G06Q-050/22","","","","","","4918049003899"
"US","US","P","B2","Neurophysiological data analysis using spatiotemporal parcellation","A method of analyzing neurophysiological data recorded from a subject is disclosed. The method comprises identifying activity-related features in the data, and parceling the data according to the activity-related features to define a plurality of capsules, each representing a spatiotemporal activity region in the brain. The method further comprises comparing at least some of the defined capsules to at least one reference capsule, and estimating a brain function of the subject based on the comparison.","1. A method of analyzing neurophysiological data recorded from a brain of a subject, the method comprising: recording the neurophysiological data by a plurality of measuring devices respectively placed at a plurality of different locations on the scalp of the subject,operating a data processor for:identifying activity-related features in the data;parceling the data according to said activity-related features to define a plurality of capsules, each representing a spatiotemporal activity region in the brain and corresponding to an extremum of the data and a spatiotemporal neighborhood defined as a spatial region in which said extremum is located and a time-interval during which said extremum occurs, wherein a size of said neighborhood is determined based on a property of said extremum;storing said capsules in a memory;comparing at least some of said defined capsules to at least one reference capsule;estimating a brain function of the subject based on said comparison and;generating on a display an output indicative of said brain function.","30","14/442407","2013-11-13","2016-0038049","2016-02-11","10136830","2018-11-27","ELMINDA LTD.","Amir B.  Geva | Yaki  Stern | Amit  Reches","","","","A61B-0005/048","A61B-0005/048 | A61B-0005/0042 | A61B-0005/0484 | A61B-0005/165 | A61B-0005/4064 | A61B-0005/4076 | A61B-0005/4836 | A61B-0005/7246 | A61B-0005/7267 | A61N-0001/36135 | G06F-0017/30598 | G06F-0019/00 | G06T-0011/206 | G16H-0050/50 | A61B-0005/055 | A61B-0005/0515 | A61B-0005/0522 | A61B-0005/7275 | A61B-0005/7282 | G06T-2207/30016","A61B-005/048","A61B-005/048 | A61B-005/0484 | A61B-005/00 | A61B-005/16 | A61N-001/36 | G06F-017/30 | G06T-011/20 | G06F-019/00 | G16H-050/50 | A61B-005/055 | A61B-005/05","","","","","","4918048000820"
"US","US","P","B2","Mobile terminal","The present invention discloses a mobile terminal, including a touch screen, the touch screen including a touch cover plate. The touch screen further includes a sensing identification module, the touch cover plate covering the sensing identification module. In the embodiments of the present invention, the sensing identification module is integrated into a touch screen, and a full touch panel is used. In this way, the problem of sense of difference which is brought by the independently assembled sensing identification module is solved from the visual and tactile perspectives, the manufacturing procedure is simplified, production and utilization efficiencies are improved, and user's satisfaction is enhanced.","1. A mobile terminal, comprising: a touch screen, the touch screen comprising a touch cover plate,wherein the touch screen further comprises a sensing identification module, the touch cover plate covers the sensing identification module;wherein the touch sensor is placed in a side-by-side manner with the sensing identification module, and beneath the touch cover plate;wherein the touch cover plate comprises a first part and a second part, a thickness of the second part is less than that of the first part, and the second part entirely or partially covers the sensing identification module; andwherein the sensing identification module comprises at least one of a fingerprint identification module, a heartbeat identification module and a blood oxygen identification module.","14","15/249997","2016-08-29","2016-0364036","2016-12-15","10139938","2018-11-27","SHENZHEN GOODIX TECHNOLOGY CO., LTD.","Gengchun  Deng | Wei  Long","2014-10268589","CN","2014-06-16","G06F-0003/041","G06F-0003/041 | A61B-0005/02438 | A61B-0005/117 | A61B-0005/1172 | A61B-0005/14542 | A61B-0005/6898 | G06F-0001/1643 | G06F-0001/1684 | G06K-0009/00013 | G06K-0009/00053 | G06F-2203/04103","G06F-003/041","G06F-003/041 | H04B-001/38 | H04M-001/23 | A61B-005/024 | A61B-005/1172 | A61B-005/145 | A61B-005/00 | G06K-009/00 | G06F-001/16 | A61B-005/117","","","","","","4918048003908"
"US","US","P","B2","Method and system for managing multimedia accessiblity","A system that incorporates the subject disclosure may include, for example, determine a first impairment associated with a first user of a first end user device, receive user input captured at a second end user device during a communication session between the first and second end user devices, store instructions for executing a group of adjustment techniques for modifying the user input where the group of adjustment techniques includes amplifying selective frequencies and translating the user input into sign language images, select an adjustment technique from among the group of adjustment techniques, adjust the user input according to the adjustment technique to generate adjusted user input, and provide the adjusted user input to the first end user device during the communication session. Other embodiments are disclosed.","1. A method, comprising: storing, by a processing system including a processor, instructions for executing adjustment techniques for modifying user input, wherein first adjustment techniques include amplifying selective frequencies for a first degree of impairment and translating user input into first sign language images for a second degree of impairment, wherein second adjustment techniques include translating user input from sign language images into synthesized audio speech, wherein the second degree of impairment is more severe than the first degree of impairment, and wherein the first adjustment techniques includes one of modifying one of a size, color or font of text or replacing a word with another word based on a determined cognitive impairment;detecting, by the processing system, a communication session between a first end user device and a second end user device;determining, by the processing system, a first impairment associated with a first user of the first end user device and a second impairment associated with a second user of the second end user device;determining, by the processing system, a degree of impairment for the second impairment;receiving, by the processing system, a first user input captured at the first end user device and a second user input captured at the second end user device during the communication session;selecting, by the processing system, a selected adjustment technique from among the first adjustment techniques according to the degree of impairment for the second impairment;accessing, by the processing system, an impairment profile for the first user, wherein the impairment profile includes an audiogram for the first user, and wherein the selective frequencies that are amplified are selected based on the audiogram;adjusting, by the processing system, the second user input according to the impairment profile to generate adjusted second user output;adjusting, by the processing system, the first user input according to the impairment profile and then applying the selected adjustment technique to generate adjusted synthesized audio speech as adjusted first user output; andproviding, by the processing system, the adjusted first user output to the second end user device and the adjusted second user output to the first end user device during the communication session.","20","15/358959","2016-11-22","2017-0078478","2017-03-16","10142459","2018-11-27","AT&T INTELLECTUAL PROPERTY I, L.P.","Randolph  Wohlert | Aaron  Bangor | Mark  Stockert","","","","H04M-0001/72591","H04M-0001/72591 | A61B-0003/0025 | A61B-0005/121 | G06F-0003/0484 | G06F-0003/167 | G06F-0009/453 | G06F-0017/2836 | G10L-0013/033 | G10L-0013/08","H04M-001/725","H04M-001/725 | G06F-003/0484 | G06F-017/28 | A61B-005/12 | G06F-009/451 | A61B-003/00 | G06F-003/16 | G10L-013/033 | G10L-013/08","","","","","","4918048006418"
"US","US","P","B2","Method and system for prediction of post-stenting hemodynamic metrics for treatment planning of arterial stenosis","A method and system for prediction of post-stenting hemodynamic metrics for treatment planning of arterial stenosis is disclosed. A pre-stenting patient-specific anatomical model of the coronary arteries is extracted from medical image data of a patient Blood flow is simulated in the pre-stenting patient-specific anatomical model of the coronary arteries with a modified pressure-drop model that simulates an effect of stenting on a target stenosis region used to compute a pressure drop over the target stenosis region. Parameter values for the modified pressure-drop model are set without modifying the pre-stenting patient-specific anatomical model of the coronary arteries. A predicted post-stenting hemodynamic metric for the target stenosis region, such as fractional flow reserve (FFR), is calculated based on the pressure-drop over the target stenosis region computed using the modified pressure-drop model.","1. A method for predicting a post-stenting hemodynamic metric for a coronary artery stenosis from pre-stenting medical image data, comprising: extracting a pre-stenting patient-specific anatomical model of the coronary arteries from medical image data of a patient;directly modifying one or more parameters of a pressure-drop model that computes a pressure-drop over a target stenosis region in the pre-stenting anatomical model of the coronary arteries without modifying the pre-stenting patient-specific anatomical model of the coronary arteries, resulting in a modified pressure-drop model that simulates an effect of stenting on the target stenosis region;simulating blood flow in the pre-stenting patient-specific anatomical model of the coronary arteries with the modified pressure-drop model used for computing the pressure-drop over the target stenosis region in the pre-stenting patient-specific anatomical model of the coronary arteries, wherein the modified pressure-drop model simulates the effect of stenting on the target stenosis region; andcalculating a predicted post-stenting hemodynamic metric for the target stenosis region based on the pressure-drop over the target stenosis region computed using the modified pressure-drop model.","50","14/704233","2015-05-05","2015-0374243","2015-12-31","10130266","2018-11-20","SIEMENS HEALTHCARE GMBH","Lucian Mihai  Itu | Puneet  Sharma | Frank  Sauer","","","","A61B-0005/02007","A61B-0005/02007 | A61B-0005/026 | A61B-0005/02028 | A61B-0005/7275 | G06F-0017/10 | G06F-0019/00 | G16H-0050/50 | A61B-0005/055 | A61B-0006/03 | A61B-0006/481 | A61B-0006/504 | A61F-0002/82","A61B-005/02","A61B-005/02 | A61B-005/026 | A61B-005/00 | G06F-017/10 | G16H-050/50 | G06F-019/00 | A61B-006/03 | A61B-005/055 | A61F-002/82 | A61B-006/00","","","","","","4918047000860"
"US","US","P","B2","Verification that a patient with an implantable medical system can undergo a magnetic resonance imaging scan","Verification that an implantable medical system within a patient is MRI safe is provided. Several verifications may be performed such as verifying that the device and leads are of an MRI safe type, that the leads have adequate electrical integrity, that the device has entered an MRI safe mode, that the lead routing and device placement are MRI safe, and that the MRI settings of the MRI machine are safe for the implantable medical system. The result of these verifications may lead to a conclusion that the implantable medical system of interest is or is not MRI safe for a given MRI scan. An indication of this result may be output such as via a display so that an MRI technician can have some assurance as to whether to conduct the MRI scan.","1. A method of checking whether a magnetic resonance (MRI) image scan can be performed for a patient who has an implantable medical system, the method comprising: establishing by an external device a telemetry communication session with the implantable medical system;verifying by the external device that an implantable medical device of the implantable medical system is of a type that is acceptable for the MRI scan by sending a query to the implantable medical device via the telemetry communication session;verifying by the external device that an implantable medical lead of the implantable medical system is of a type that is acceptable for the MRI scan;providing by the external device an indication of whether the implantable medical system is acceptable for the MRI scan based on the verifying of the implantable medical device and the implantable medical lead;analyzing by the external device MRI scan settings of an MRI machine by the external device taking measurements within the MM machine during an MRI scan by the MRI machine; andproviding by the external device an indication of whether the implantable medical system is acceptable for the MRI scan based on the analyzing of the MRI scan settings.","43","13/265160","2010-04-28","2012-0035951","2012-02-09","10130282","2018-11-20","MEDTRONIC, INC.","Steven M.  Goetz | Shahram  Malekkhosravi | Todd V.  Smith | Kristin J.  Malekkhosravi | Jeffrey R.  Dixon","","","","A61B-0005/055","A61B-0005/055 | A61B-0005/0031 | A61N-0001/37247 | G06F-0019/00 | G06Q-0050/22 | G16H-0040/63 | A61B-2560/0271 | A61N-0001/086 | A61N-0001/3718","G06Q-050/22","G06Q-050/22 | A61B-005/055 | A61B-005/00 | A61N-001/372 | G16H-040/63 | G06F-019/00 | A61N-001/37 | A61N-001/08","","","","","","4918047000876"
"US","US","P","B2","Robotic system display method for displaying auxiliary information","A Robotic control system has a wand, which emits multiple narrow beams of light, which fall on a light sensor array, or with a camera, a surface, defining the wand's changing position and attitude which a computer uses to direct relative motion of robotic tools or remote processes, such as those that are controlled by a mouse, but in three dimensions and motion compensation means and means for reducing latency.","1. A method for displaying information on a robotic system viewer, the method comprising: receiving a first image of at least a portion of a remote worksite;causing the first image to be displayed on the robotic system viewer; andcausing an overlay of a first icon representing a first set of available tools to be displayed at a first region of the robotic system viewer.","15","15/490098","2017-04-18","2017-0333140","2017-11-23","10130434","2018-11-20","TITAN MEDICAL INC.","John  Unsworth","","","","A61B-0034/30","A61B-0034/30 | A61B-0034/10 | A61B-0034/20 | A61B-0034/25 | A61B-0034/37 | A61B-0034/70 | A61B-0034/74 | A61B-0034/76 | A61B-0090/06 | A61B-0090/361 | G01D-0005/262 | G06F-0003/016 | G06F-0003/0308 | G06F-0003/0325 | G06T-0011/00 | H05K-0999/99 | A61B-0090/36 | A61B-2017/00207 | A61B-2017/00703 | A61B-2034/107 | A61B-2034/2051 | A61B-2034/2055 | A61B-2034/2068 | A61B-2090/062 | A61B-2090/365","G06K-009/00","G06K-009/00 | A61B-034/30 | G01D-005/26 | G06F-003/01 | G06F-003/03 | G06T-011/00 | A61B-034/00 | A61B-034/37 | A61B-034/10 | A61B-017/00 | A61B-090/00 | A61B-034/20","","","","","","4918047001028"
"US","US","P","B2","Transcutaneous electrical nerve stimulator with user gesture detector and electrode-skin contact detector, with transient motion detector for increasing the accuracy of the same","Apparatus for transcutaneous electrical nerve stimulation in a user, the apparatus comprising: a housing; stimulation means carried by the housing for electrically stimulating at least one nerve; a pair of electrodes releasably mounted to the housing and connectable to the stimulation means for electrical stimulation of the at least one nerve; monitoring means for monitoring user gesture, electrode-skin contact integrity and transient motion; analysis means for analyzing the output of the monitoring means for determining user gesture, electrode-skin contact integrity and transient motion; and control means for controlling the output of the stimulation means in response to the determined user gesture, electrode-skin contact integrity and transient motion.","1. A method for controlling transcutaneous electrical nerve stimulation based on user gesture, electrode-skin contact integrity and transient motion of the user, the method comprising the steps of: applying a transcutaneous electrical nerve stimulation unit to the user'ss body;monitoring at least one selected from the group consisting of user gesture, electrode-skin contact integrity and transient motion of the user;analyzing at least one of (i) the user gesture and the transient motion to determine whether an intentional user gesture has occurred, and (ii) theelectrode-skin contact integrity and the transient motion to determine whether a non-transient degradation of the electrode-skin contact integrity has occurred; andmodifying operation of the stimulation unit in response to at least one of the determination of an intentional user gesture and a non-transient degradation of the electrode-skin contact integrity.","28","15/824351","2017-11-28","2018-0140834","2018-05-24","10130810","2018-11-20","Neurometrix, Inc.","Thomas  Ferree | Xuan  Kong | Andres  Aguirre | Michael  Williams | Shai N.  Gozani","","","","A61N-0001/36021","A61N-0001/36021 | A61N-0001/08 | G06F-0003/015 | G06F-0003/017 | A61B-0005/11 | A61B-2560/0276 | A61B-2562/0219 | A61N-0001/0456 | A61N-0001/0492 | A61N-2001/083","A61N-001/00","A61N-001/00 | A61N-001/36 | A61N-001/08 | G06F-003/01 | A61B-005/11 | A61N-001/04","","","","","","4918047001403"
"US","US","P","B2","Dropout detection in continuous analyte monitoring data during data excursions","Methods, devices, and systems are provided for identifying dropouts in analyte monitoring system sensor data including segmenting sensor data into a plurality of time series wherein each time series is associated with a different instance of a repeating event, selecting a first time series to analyze for dropouts from the plurality of time series; comparing the selected first time series to a second time series among the plurality of time series, determining whether the selected first time series includes a portion that is more than a predefined threshold lower than a corresponding portion of the second time series, and displaying, on a computer system display, an indication that the selected first time series includes a dropout if the selected first time series includes a portion that is more than the predefined threshold lower than the corresponding portion of the second time series.","1. A method of identifying a signal dropout in analyte sensor data, comprising: segmenting sensor data into a plurality of time series;generating a plurality of plots for each time series of the plurality of time series;generating a visual depiction of an analyte concentration over a period of time by at least overlaying each plot of the plurality of plots on each other to form a graph associating the analyte concentration with one or more user behaviors over the period of time;determining an appropriate smoothing window from a plurality of smoothing windows, by at least determining that smoothing the graph using the appropriate smoothing window would not change an overall shape of the graph more than an acceptability threshold;smoothing the graph using the appropriate smoothing window to obtain a smoothed graph;displaying the visual depiction, including the smoothed graph, on a computer system display;selecting a first time series to analyze for dropouts from the plurality of time series;comparing the selected first time series to a second time series among the plurality of time series, based on the smoothed graph;determining that the selected first time series includes a portion that is more than a predefined threshold lower than a corresponding portion of the second time series, based on the smoothed graph;identifying a location on the smoothed graph corresponding to the portion that is more than the predefined threshold lower than the corresponding portion of the second time series; anddisplaying, on the computer system display, an indication that the identified location on the smoothed graph includes a dropout.","20","14/424026","2013-08-20","2015-0241407","2015-08-27","10132793","2018-11-20","ABBOTT DIABETES CARE INC.","Junli  Ou | Erwin Satrya  Budiman","","","","G01N-0033/49","G01N-0033/49 | A61B-0005/14532 | G06F-0017/30958 | G06K-0009/0055 | G16H-0010/60 | A61B-2560/0276","G01N-033/49","G01N-033/49 | A61B-005/145 | G06F-017/30 | G06K-009/00 | G16H-010/60","","","","","","4918047003375"
"US","US","P","B2","Similar case retrieval apparatus, similar case retrieval method, non-transitory computer-readable storage medium, similar case retrieval system, and case database","A similar case retrieval apparatus includes: a lesion portion acquirer that acquires partial images including lesion portion images, an image feature extractor that extracts image features of each of the plurality of partial images; a location information acquirer that acquires location information of each of the partial images; a lateral position determiner that determines the right organ or the left organ in which each of the lesion portions exists based on the location information; a unilateral distribution identifier that determines whether or not a distribution of the lesion portions is a unilateral distribution; and a similar case retriever that retrieves case data from a case database including both case data for the unilateral distribution in the right organ and case data for the unilateral distribution in the left organ when the unilateral distribution identifier identifies that the distribution of the lesion portions is the unilateral distribution.","1. A similar case retrieval method for a similar case retrieval apparatus, the similar case retrieval apparatus including a display and a hardware processor that executes a program and causes the similar case retrieval apparatus to perform the similar case retrieval method comprising: receiving, using the hardware processor, image features of partial images including lesion portions;receiving, using the hardware processor, information indicating a distribution of the lesion portions is a unilateral distribution in which the lesion portions are distributed unilaterally in either a right organ or a left organ;searching, using the hardware processor, similar case data by searching through image features of images contained in first case data for the unilateral distribution of lesion portions in the right organ and second case data for the unilateral distribution of lesion portions in the left organ, and determining similar case data based on similarities between the image features of images contained in the both the first case data and the second case data, and the partial images including the lesion portion,displaying, using the display, an image feature of an image contained in each of the first and second similar case data when the image feature of the image is determined to be similar to at least one of the image features of the partial images including the lesion portion,wherein the both the first case data and the second case data are included in a case database in communication with the similar retrieval apparatus,the first case data only includes images of lesion portions included in the first case data and the second case data only includes images of lesion portions included in the second case data, andthe determining of similar case data includes determining a cosine distance between an image feature vector which is a vector representation of an image feature of the partial image containing the lesion portion of the interpretation target image and an image feature vector of the partial image containing a lesion portion contained in the case data, and calculating a sum of the calculated cosine distances as a similarity.","2","15/420375","2017-01-31","2017-0140536","2017-05-18","10133846","2018-11-20","PANASONIC CORPORATION","Kazutoyo  Takata | Kazuki  Kozuka | Kenji  Kondo | Hirohiko  Kimura | Toyohiko  Sakai","2013-160367","JP","2013-08-01","G06F-0019/321","G06F-0019/321 | G06F-0017/30256 | G06F-0019/00 | G06K-0009/4604 | G06T-0007/0012 | G06T-0007/0014 | G06T-0007/73 | G16H-0010/60 | G16H-0050/70 | A61B-0005/08 | A61B-0005/107 | A61B-0006/5217 | A61B-2576/02 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/10132 | G06T-2207/30061 | G06T-2207/30068 | G06T-2207/30096","G06K-009/00","G06K-009/00 | G06F-019/00 | G16H-050/70 | G16H-010/60 | G06K-009/46 | G06T-007/00 | G06T-007/73 | G06F-017/30 | A61B-005/08 | A61B-005/107 | A61B-006/00","","","","","","4918047004421"
"US","US","P","B2","Method and system for hemodynamic computation in coronary arteries","A method and system for computing blood flow in coronary arteries from medical image data disclosed. Patient-specific anatomical measurements of a coronary artery tree are extracted from medical image data of a patient. A reference radius is estimated for each of a plurality of branches in the coronary artery tree from the patient-specific anatomical measurements of the coronary artery tree. A flow rate is calculated based on the reference radius for each of the plurality of branches of the coronary artery tree. A plurality of total flow rate estimates for the coronary artery tree are calculated. Each total flow rate estimate is calculated from the flow rates of branches of particular generation in the coronary artery tree. A total flow rate of the coronary artery tree is calculated based on the plurality of total flow rate estimates. The total flow rate of the coronary artery tree can be used to derive boundary conditions for simulating blood flow in the coronary artery tree.","1. A method for computing blood flow in coronary arteries from medical image data, comprising: extracting patient-specific anatomical measurements of a coronary artery tree from medical image data of a patient;estimating a reference radius for each of a plurality of branches in the coronary artery tree from the patient-specific anatomical measurements of the coronary artery tree;calculating a flow rate based on the reference radius for each of the plurality of branches of the coronary artery tree;calculating a plurality of total flow rate estimates for the coronary artery tree, wherein each of the plurality of total flow rate estimates is calculated from the flow rates of branches from a respective one of a plurality of generations of branches; andcalculating a total flow rate of the coronary artery tree based on the plurality of total flow rate estimates.","47","15/304145","2015-04-09","2017-0046834","2017-02-16","10134129","2018-11-20","SIEMENS HEALTHCARE GMBH","Lucian  Itu | Puneet  Sharma","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/0263 | A61B-0006/507 | A61B-0008/06 | G06F-0017/11 | G06F-0019/00 | G06T-0007/20 | G06T-0007/60 | G16H-0050/50 | A61B-2034/105 | G06T-2207/30104","G06K-009/00","G06K-009/00 | G06T-007/00 | G16H-050/50 | A61B-005/026 | A61B-006/00 | A61B-008/06 | G06F-017/11 | G06T-007/20 | G06T-007/60 | G06F-019/00 | A61B-034/10","","","","","","4918047004702"
"US","US","P","B2","Systems and methods for using imagined directions to define an action, function or execution for non-tactile devices","A system and method for controlling a non-tactile device including a receiving device configured to receive signals corresponding to a user's brain waves or movements, the brain waves or movements corresponding to a series of directional intentions, the intentions defining at least one line pattern, a processor configured to process the at least one line pattern, each of said at least one line patterns associated with an action of the device, and output a control signal to the non-tactile device related to the action.","1. A system for controlling a device, the system comprising: a receiving device configured to receive signals corresponding to a series of directional thoughts generated in a brain of a user, the directional thoughts comprising rhythms of mu and beta rhythms, each series of directional thoughts corresponding to a series of imagined directions including at least three directional dimensions, the directions defining a line pattern, wherein the line pattern comprises one or more parts, each part comprising a plurality of steps, each step corresponding to an imagined direction, the length of each step corresponding to the duration of a corresponding thought; anda processor configured to: process the line pattern to match a pre-defined line pattern with a pre-defined action of the device; andoutput a control signal to the device related to the pre-defined action.","23","15/186910","2016-06-20","2016-0299568","2016-10-13","10126816","2018-11-13","NAQI LOGICS LLC","David Lee  Segal","","","","G06F-0003/015","G06F-0003/015 | A61B-0005/04008 | A61B-0005/04012 | A61B-0005/0476 | A61B-0005/1128 | A61B-2562/028 | A61B-2562/0219 | G06F-2203/011","G06F-003/01","G06F-003/01 | G06F-017/30 | A61B-005/04 | A61B-005/0476 | A61B-005/11","","","","","","4918046003962"
"US","US","P","B2","Motion-activated display of messages on an activity monitoring device","Methods, systems and devices are provided for motion-activated display of messages on an activity monitoring device. In one embodiment, method for presenting a message on an activity monitoring device is provided, including the following method operations: storing a plurality of messages to the device; detecting a stationary state of the device; detecting a movement of the device from the stationary state; in response to detecting the movement from the stationary state, selecting one of a plurality of messages, and displaying the selected message on the device.","1. A wearable device, comprising: one or more first sensors configured to generate motion sensor data;one or more second sensors configured to generate environmental sensor data;a storage device configured to store a plurality of messages;a display configured to display the plurality of messages; andone or more processors in communication with the storage device and configured to: determine, based at least on the motion sensor data generated during a first time period, that the wearable device has been inactive for at least a threshold amount of time;subsequent to the determination that the wearable device has been inactive for at least the threshold amount of time, cause the display to be turned off;subsequent to causing the display to be turned off, determine, based at least on the motion sensor data generated during a second time period subsequent to the first time period, that the wearable device is no longer inactive;based at least on the determination that the wearable device is no longer inactive, select, based at least on one or both of the environmental sensor data or an orientation of the wearable device, a message from the plurality of messages stored in the storage device and cause the selected message to be displayed on the display;wherein the environmental sensor data comprises at least one sensed environmental condition including one or more of ambient light, temperature, ambient pressure, altitude, humidity, or ambient sound; andwherein the message comprises information relating to one or more of the at least one sensed environmental condition, fitness activity, or social network activity.","20","15/583959","2017-05-01","2017-0249115","2017-08-31","10126998","2018-11-13","FITBIT, INC.","Shelten  Yuen | Timothy  Roberts","","","","G06F-0003/14","G06F-0003/14 | A61B-0005/0022 | A61B-0005/1118 | A61B-0005/222 | A61B-0005/6838 | A61B-0005/743 | A63B-0024/0062 | G06F-0001/163 | G06F-0001/1694 | G06F-0003/011 | G06F-0003/017 | G06F-0017/21 | G06F-0019/00 | G06F-0019/3481 | H04L-0041/22 | H04L-0067/1095 | H04L-0067/22 | H04L-0067/306 | H04L-0067/42 | H04W-0004/02 | H04W-0004/21 | A61B-0005/021 | A61B-0005/024 | A61B-0005/02055 | A61B-0005/1112 | A61B-0005/4809 | A61B-0005/4812 | A61B-0005/4815 | A61B-2560/0214 | A61B-2560/0242 | A61B-2562/0219 | G01C-0022/006 | G16H-0040/63","G06F-003/00","G06F-003/00 | A61B-005/00 | G01C-022/00 | A63B-023/00 | G06F-003/14 | G06F-003/01 | G06F-017/21 | H04L-029/08 | A63B-024/00 | H04W-004/21 | A61B-005/22 | G06F-019/00 | H04L-012/24 | G06F-001/16 | H04L-029/06 | H04W-004/02 | G16H-040/63 | A61B-005/0205 | A61B-005/024 | A61B-005/11 | A61B-005/021","","","","","","4918046004142"
"US","US","P","B2","Identifying contributors that explain differences between a data set and a subset of the data set","Methods for analyzing and rendering business intelligence data allow for efficient scalability as datasets grow in size. Human intervention is minimized by augmented decision making ability in selecting what aspects of large datasets should be focused on to drive key business outcomes. Variable value combinations that are predominant drivers of key observations are automatically determined from several competing variable value combinations. The identified variable value combinations can then be then used to predict future trends underlying the business intelligence data. In another embodiment, an observed outcome is decomposed into multiple contributing drivers and the impact of each of the contributing drivers can be analyzed and numerically quantified?as a static snapshot or as a time-varying evolution. Similarly, differences in observations between two groups can be decomposed into multiple contributing sub-groups for each of the groups and pairwise differences among sub-groups can be quantified and analyzed.","1. A method for analyzing differences in an outcome between a data set for a process and a subset of the data set, the method comprising a computer system automatically performing the following: processing a data set containing observations of the process, the observations expressed as values for a plurality of variables and for the outcome, wherein processing the data set determines behaviors for different variable combinations with respect to the outcome, the variable combinations defined by values for one or more of the variables, the subset defined as those observations for which one or more test variables take trial values;for pairs of a first variable combination and a second variable combination, wherein the test variables take the trial values in the second variable combination and the first variable combination is the same as the second variable combination except that the test variables are not specified as part of the first variable combination, estimating contributions of the pair to differences in the outcome between the data set and the subset, based on differences in the behaviors of the pair and also based on differences in populations of the pair; andreporting differences in the outcome between the data set and the subset based on the estimated contributions for the variable combinations.","20","14/672026","2015-03-27","2015-0205695","2015-07-23","10127130","2018-11-13","BEYONDCORE HOLDINGS, LLC","Arijit  Sengupta | Brad A.  Stronger | Griffin  Chronis","","","","G06F-0011/3409","G06F-0011/3409 | G06F-0011/324 | G06F-0017/30371 | G06Q-0010/06 | G06Q-0010/067 | G06Q-0010/0637 | G06Q-0010/0639","A61B-005/00","A61B-005/00 | G06F-011/34 | G06F-017/30 | G06F-011/32 | G06Q-010/06 | G06F-017/10","","","","","","4918046004274"
"US","US","P","B2","Visual field calculation apparatus and method for calculating visual field","A visual field calculation apparatus capable of accurately calculating a visual field range of a user without using a complex configuration is provided. The visual field calculation apparatus includes a saccade detector that detects a saccade on the basis of a first gaze direction detected at a first timing and a second gaze direction detected at a second timing, a saccade speed calculator that calculates speed of the saccade on the basis of a time difference between the first timing and the second timing, the first gaze direction, and the second gaze direction, and a visual field range calculator that calculates a displacement vector of a saccade whose speed exceeds a first threshold, and calculates an area including a final point of the displacement vector as the visual field range of the user.","1. A visual field calculation apparatus comprising: a saccade detector that obtains gaze direction information including gaze directions of a user in a saccade detection period, and detects a first plurality of saccades on a basis of a moving amount of each of the gaze directions in unit time;a saccade speed calculator that calculates a speed of each of the plurality of first saccades in the unit time; anda visual field range calculator that extracts a second plurality of saccades whose speeds exceed a first threshold from among the first plurality of saccades, calculates displacement vectors of the second plurality of saccades, and calculates an area including an initial point and a final point of each of the displacement vectors as the visual field range of the user,wherein the first threshold is a value which separates exogenous saccades and endogenous saccades, andthe visual field range of the user is calculated in a range of a surface, and information is displayed on the surface relative to the visual field range.","13","14/996057","2016-01-14","2016-0120403","2016-05-05","10117577","2018-11-06","PANASONIC INTELLECTUAL PROPERTY MANAGEMENT CO., LTD.","Makoto  Mochizuki | Koichi  Emura | Tetsuo  Matsuse | Hayashi  Ito","2013-164963","JP","2013-08-08","A61B-0003/113","A61B-0003/113 | A61B-0003/0025 | A61B-0003/0041 | A61B-0003/024 | A61B-0005/6893 | G02B-0027/01 | G02B-0027/0101 | G06K-0009/00604 | G08G-0001/162 | G08G-0001/166 | A61B-0005/0496 | G02B-2027/0123 | G02B-2027/0187 | G06F-0003/01","A61B-003/113","A61B-003/113 | A61B-005/00 | G02B-027/01 | A61B-003/024 | G06K-009/00 | G08G-001/16 | A61B-003/00 | A61B-005/0496 | G06F-003/01","","","","","","4918045000802"
"US","US","P","B2","Analysis and detection for arrhythmia drivers","Systems and methods are provided to detect and analyze arrhythmia drivers. In one example, a system can include a wave front analyzer programmed to compute wave front lines extending over a surface for each of the plurality of time samples based on phase information computed from electrical data at nodes distributed across the surface. A trajectory detector can be programmed to compute wave break points for each of the wave front lines and to determine a trajectory of at least one rotor core across the surface. A stability detector can be programmed to identify at least one stable rotor portion corresponding to subtrajectories of the determined trajectory.","1. One or more non-transitory computer-readable media having instructions executable by a processor to perform a method of analyzing cardiac electrophysiological signals on a cardiac envelope, the method comprising: determining wave break points for each identified cardiac wave front line at a given time sample of a plurality of time samples of the cardiac electrophysiological signals;for each other of the plurality of time samples: evaluating a spatial distance for a given wave break point relative to each active trajectory in a previous time sample to identify a closest active trajectory;appending the given wave break point to update the closest active trajectory based on the evaluating; andrepeating the evaluating and the appending for each wave break point over the plurality of time samples to generate a set of at least one rotor trajectory;computing a stability value for each of the least one rotor trajectory based on at least one of a temporal, angular and spatial characteristic for each respective rotor trajectory;identifying at least one stable subtrajectory of each of the least one rotor trajectory based on the stability value relative to a stability threshold value, wherein the stability threshold value is one of a temporal stability threshold value indicative of a minimum subtrajectory lasting time, an angular stability threshold value indicative of a minimum angular characteristic that is determined for a respective rotor subtrajectory based on rotation angles along the respective rotor subtrajectory, or a spatial stability threshold value indicative of a maximum subtrajectory component distance from a centroid of a respective subtrajectory;generating and displaying on a display a graphical map that includes a visualization of the at least one stable subtrajectory on a graphical representation of the cardiac envelope.","18","15/240636","2016-08-18","2016-0354004","2016-12-08","10117594","2018-11-06","CARDIOINSIGHT TECHNOLOGIES, INC.","Qingguo  Zeng | Ping  Jia | Ryan  Bokan | Brian P.  George | Charulatha  Ramanathan | Venkatesh  Vasudevan | Maria  Strom","","","","A61B-0005/0452","A61B-0005/0452 | A61B-0018/02 | A61B-0018/04 | A61B-0018/1492 | A61B-0034/10 | A61N-0001/056 | A61N-0001/3622 | A61N-0007/00 | G06F-0017/50 | G06F-0019/00 | G16H-0050/50 | A61B-2018/00839 | A61B-2018/0212 | A61B-2034/105 | A61N-2007/0043","A61B-005/0452","A61B-005/0452 | A61B-018/02 | A61B-018/14 | A61B-034/10 | A61N-001/05 | A61N-001/362 | A61N-007/00 | G06F-019/00 | G06F-017/50 | A61B-018/04 | G16H-050/50 | A61B-018/00","","","","","","4918045000819"
"US","US","P","B2","Biometric authentication device and biometric authentication method","A biometric authentication device collates pre-registered biometric data for authentication with biometric data acquired during authentication. An imaging section images biometric data acquired by penetration through the finger by near-infrared light from a near-infrared light irradiating section. A control section acquires the biometric data acquired by the imaging section. A visible light irradiating section irradiates a finger inserting section where the finger is inserted with visible light. The visible light irradiating section starts irradiation of the visible light before the imaging section acquires the biometric data. The control section sets irradiation luminosity from the visible light irradiating section to be lower in a case where luminosity of an imaging screen of the biometric data acquired by the imaging section is higher than luminosity appropriate for authentication, and collates the biometric data in the case where the irradiation luminosity is set to be lower with the pre-registered biometric data for authentication.","1. A biometric authentication device for carrying out biometric authentication using biometric information by collating pre-registered biometric data for authentication with biometric data acquired during authentication, the device comprising: a housing that defines a finger inserting section;a near-infrared light source configured to irradiate a finger in the finger inserting section with near-infrared light;a visible light source configured to irradiate the finger inserting section with visible light;a camera configured to capture a first image of the finger in the finger inserting section with the near-infrared light which penetrates through the finger while the visible light source irradiates the finger inserting section with the visible light;a memory configured to store the pre-registered biometric data and a predetermined luminosity; anda processor programmed by executable instructions to acquire biometric data from the first image,wherein the visible light source is configured to start irradiation of the visible light before the camera captures the image, andwhen a luminosity of the acquired biometric data from the first image is higher than the predetermined luminosity, the processor is further programmed by the executable instructions to:lower an irradiation luminosity from the visible light sourcecause the camera to capture a second image of the finger in the finger inserting section with the near-infrared light which penetrates through the finger while the visible light source irradiates the finger inserting section with the lowered visible light from the visible light source,acquire biometric data from the second image, andcollate the acquired biometric data from the second image with the pre-registered biometric data for authentication.","8","15/036957","2014-09-08","2016-0256079","2016-09-08","10117623","2018-11-06","HITACHI INDUSTRY & CONTROL SOLUTIONS, LTD.","Kazuki  Shimano | Yasuhiro  Shimizu","2014-016339","JP","2014-01-31","A61B-0005/7271","A61B-0005/7271 | A61B-0005/0059 | A61B-0005/0082 | A61B-0005/1171 | A61B-0005/489 | A61B-0005/6826 | G06F-0021/32 | G06K-0009/00013 | A61B-0005/7246 | G06K-2009/00932","A61B-005/00","A61B-005/00 | G06F-021/32 | G06K-009/00 | A61B-005/1171","","","","","","4918045000847"
"US","US","P","B2","Microwave ablation system with user-controlled ablation size and method of use","Disclosed is a system and method for enabling user preview and control of the size and shape of an electromagnetic energy field used in a surgical procedure. The disclosed system includes a selectively activatable source of microwave surgical energy in the range of about 900 mHz to about 5 gHz in operable communication with a graphical user interface and a database. The database is populated with data corresponding to the various surgical probes, such as microwave ablation antenna probes, that may include a probe identifier, the probe diameter, operational frequency of the probe, ablation length of the probe, ablation diameter of the probe, a temporal coefficient, a shape metric, and the like. The probe data is graphically presented on the graphical user interface where the surgeon may interactively view and select an appropriate surgical probe. Three-dimensional views of the probe(s) may be presented allowing the surgeon to interactively rotate the displayed image.","1. A system for planning an ablation procedure, the system comprising: a plurality of ablation probes; anda generator configured to couple to at least one of the plurality of ablation probes, the generator including: a generator module configured to generate energy suitable for ablating tissue;a display configured to display a user interface, the user interface configured to receive a user-selectable ablation shape and at least one probe parameter; anda processor configured to select at least one of the plurality of ablation probes suitable for forming an ablation volume corresponding to the user-selectable ablation shape based on the at least one probe parameter, the processor being further configured to signal the display to preview the at least one selected ablation probe.","16","15/055009","2016-02-26","2016-0175046","2016-06-23","10111718","2018-10-30","COVIDIEN LP","Joseph D.  Brannan | Kyle R.  Rick","","","","A61B-0034/25","A61B-0034/25 | A61B-0018/18 | A61B-0018/1815 | A61B-0034/10 | G06F-0003/04815 | G06F-0003/04842 | G06F-0003/04845 | G06F-0017/3028 | G06T-0013/20 | G06T-0015/00 | G06T-0019/003 | A61B-0090/90 | A61B-2034/101 | A61B-2034/104 | A61B-2034/105 | A61B-2034/107","A61B-018/18","A61B-018/18 | A61B-034/00 | A61B-034/10 | G06F-003/0481 | G06F-003/0484 | G06F-017/30 | G06T-013/20 | G06T-015/00 | G06T-019/00 | A61B-090/90","","","","","","4918044000998"
"US","US","P","B2","Risk indication for surgical procedures","The invention relates to a system (100) for computing a risk, the risk relating to injuring an anatomical structure by a medical device during a medical procedure, the system comprising: a structure unit (110) for obtaining a position of the anatomical structure; a device unit (120) for obtaining a position of the medical device; and a risk unit (130) for computing the risk relating to injuring the anatomical structure, based on the position of the medical device and the position of the anatomical structure. The system (100) may be used for planning a path of a medical device, which path minimizes said risk, or for monitoring said risk during the medical procedure.","1. A system for computing a risk, the risk relating to injuring an anatomical structure of a patient, by a medical device comprising a needle object, during a medical procedure, the system comprising: an image acquisition unit which acquires image data of the anatomical structure;a memory, including computer readable instructions; anda computer processor, wherein the computer processor executes the computer readable instructions, which causes the computer processor to: obtain, during the medical procedure, a position of the anatomical structure based on the acquired image data, wherein the anatomical structure comprises at least one blood vessel;obtain, during the medical procedure, a current actual position of the medical device used in the medical procedure with respect to the anatomical structure;obtain risk data associated with the anatomical structure; andcompute the risk relating to injuring the anatomical structure for the current actual position of the medical device, based on the current actual position of the medical device which is determined from coordinates and directional cosines, the position of the anatomical structure, and the risk data which is determined from coordinates and directional cosines,wherein the risk is defined as a ratio calculated by summing a first distance and a second distance and dividing the sum by a third distance,wherein the first distance is defined from an axis of the needle object to a nearest point on the at least one blood vessel, wherein the second distance is defined as a predefined distance, and wherein the third distance is defined as a distance from the end of the needle object to a second nearest point on the blood vessel, andwherein the computed risk is used to navigate the medical device with respect to the anatomical structure during the medical procedure.","19","12/597361","2008-04-23","2010-0121316","2010-05-13","10111726","2018-10-30","KONINKLIJKE PHILIPS ELECTRONICS N. V.","Juergen  Weese | Alexandra  Groth | Joerg  Bredno","2007-106973","EP","2007-04-26","A61B-0090/36","A61B-0090/36 | G06T-0007/75 | A61B-2034/101 | G06T-2207/30101","G06Q-010/00","G06Q-010/00 | G06Q-050/00 | A61B-017/00 | G06K-009/62 | A61B-090/00 | G06T-007/73 | A61B-034/10","","","","","","4918044001006"
"US","US","P","B2","Medication related task notification system","A task management system for informing a clinician of medication administration related tasks to be performed, includes a repository of information. The repository of information associates data identifying multiple different medications with corresponding multiple post-administration alert messages. An individual alert message notifies a clinician of a particular post-administration task to be performed concerning a particular medication following administration of the particular medication to a patient. An input processor receives data indicating the particular medication has been administered to the patient. A workflow processor, in response to received data indicating the particular medication has been administered to the patient, uses the repository for identifying a post-administration task associated with the particular medication and automatically adds data indicating the post-administration task to be performed to a task list of a clinician. A reproduction device presents the post-administration task and task list of the clinician for viewing by a user.","1. A task management system for informing a clinician of medication administration related tasks to be performed, comprising: a repository of information associating data identifying a plurality of different medications with a corresponding plurality of post-administration alert messages, an individual alert message being for notifying a clinician of a particular post-administration task to be performed concerning a particular medication following administration of said particular medication to a patient;a pharmacy information system including a configuration processor device enabling a pharmacist to initiate incorporating data in said repository associating a post-administration alert message with a particular medication as well as with times for a post-administration alert message to be generated and provided to a clinician and enabling a pharmacist to dynamically associate a post-administration alert message that is not in a medication database with a particular medication and configured to automatically generate the post-administration alert message for an order for the particular medication for presentation on a mobile point-of-care medication administration system;a communication interface presenting the post-administration alert message as a pop-up display window on a graphic user interface of a mobile point-of-care medication device, the post-administration alert message being automatically presented on the graphic user interface upon one of the following: an order for the particular administration is entered for the patient, the particular medication is selected for administration for the patient, or a medication profile for the particular medication is opened;an input processor device receiving data indicating said particular medication has been administered to said patient;a workflow processor device processing data to determine tasks to add to or remove from a task list or to modify tasks incorporated on, or for incorporation on, a task list and for, in response to received data indicating said particular medication has been administered to said patient, using information in said repository to identify a post-administration task associated with said particular medication and automatically adding data indicating an identified post-administration task to be performed to a task list of a clinician; andthe mobile point-of-care medication device presenting said identified post-administration task and task list of said clinician and a post-administration alert message to said clinician for viewing by a user.","14","12/165736","2008-07-01","2009-0048868","2009-02-19","10115171","2018-10-30","CERNER INNOVATION, INC.","Alan M.  Portnoy | Deborah  Saeger","","","","G06Q-0050/22","G06Q-0050/22 | G06F-0017/30663 | G06F-0019/00 | G06Q-0010/06316 | G06Q-0010/10","G06Q-050/00","G06Q-050/00 | G06Q-010/00 | G06F-019/00 | A61B-005/00 | G06Q-050/22 | G06Q-010/06 | G06Q-010/10 | G06F-017/30","","","","","","4918044004433"
"US","US","P","B2","Color analysis and control using an electronic mobile device transparent display screen","A mobile electronic device includes a transparent display screen for comparing and accurately determining the color of a predetermined object, for various applications, including augmented reality. Color data for a perceived color stores in a memory and displays images as perceived through the transparent display screen. Image difference values are determined between a first set of optical processing data and a second set of optical processing data. The transparent display screen indicates image difference values from including differences in color, texture, transparency, lighting, etc., especially for augmented reality applications. A memory stores optical processing data and optical processing instructions and algorithms. A computer processor executes optical processing instructions and algorithms and in response to optical processing data generated. An optical lens captures an image of an object for display on the transparent display screen. A transparent portion of the transparent display screen of the mobile electronic device displays the object.","1. A method for comparing the image data of a predetermined object using an electronic mobile device, comprising the steps of: using at least one transparent display screen associated with the electronic mobile device for generating optical processing data;storing said optical processing data, and optical processing instructions, and computer processor algorithms in a memory associated with the electronic mobile device;operating a computer processor associated with the electronic mobile device and said memory for executing said optical processing instructions and computer processor algorithms in response to said optical processing data;directing an optical lens of the electronic mobile device to capture an object image of an object for display on said at least one transparent display screen;collecting a first set of optical processing data using data deriving from the capture of the object image, said first set of optical processing data comprising a first set of color image data;displaying the object for display through a transparent portion of the said at least one transparent display screen and generating there from a second set of optical processing data comprising a second set of image data;receiving and storing in said the memory a said second set of image data associated with perceiving the object through the at least one transparent display screen;executing instructions on the computer processor for determining image difference values between said first set of image data and said second set of image data; anddisplaying on the at least one transparent display screen image difference values from the group consisting of color differences, texture differences, transparency differences, lighting differences, motion differences, focus differences and the like.","20","15/477301","2017-04-03","2018-0130235","2018-05-10","10116924","2018-10-30","SK COMMERCIAL CONSTRUCTION, INC.","Suk K.  Kim-Whitty","","","","H04N-0013/225","H04N-0013/225 | A61B-0005/0035 | A61B-0005/0059 | A61B-0005/055 | A61B-0005/4504 | A61B-0006/4417 | A61B-0006/463 | A61B-0006/467 | A61B-0090/36 | A63F-0013/2145 | A63F-0013/25 | G06Q-0030/0267 | G06T-0007/40 | G06T-0007/90 | H04N-0007/185 | H04N-0013/128 | H04N-0013/207 | H04N-0013/243 | H04N-0013/31 | H04N-0013/324 | H04N-0013/388 | H04N-0013/398 | H05K-0999/99 | A61B-0034/25 | A61B-0090/361 | A61B-2034/2048 | A61B-2090/365 | A61B-2090/373 | A61B-2090/374 | A61B-2090/376 | A61B-2090/392 | A61B-2090/3937 | A61B-2090/3945 | A61B-2090/3958 | A61B-2090/3966 | A61B-2090/3975 | A61B-2090/3995 | A63F-2300/66 | G06F-0003/03547 | G06F-0003/0414 | G06F-2203/04108","G06K-009/00","G06K-009/00 | H04N-013/225 | A63F-013/25 | A63F-013/2145 | G06Q-030/02 | H04N-013/128 | H04N-013/207 | H04N-013/31 | H04N-013/324 | H04N-013/398 | H04N-013/243 | H04N-013/388 | A61B-090/00 | A61B-005/00 | A61B-005/055 | A61B-006/00 | G06T-007/90 | G06T-007/40 | H04N-007/18 | G06F-003/0354 | G06F-003/041 | A61B-034/00 | A61B-034/20","","","","","","4918044006171"
"US","US","P","B2","Medical system having combined and synergized data output from multiple independent inputs","The present disclosure relates generally to medical systems and methods for combining and synergizing information in an expedient format for viewing on a display screen. In one embodiment, a method for combining and synergizing data from different medical systems comprises obtaining from a first medical system an image disposed relative to a first coordinate system, obtaining from a second medical system supplemental data; synchronizing first and second clocks of the first and second medical systems, respectively, and displaying in synchronicity the supplemental data combined with the image. In other embodiments, coordinate systems of the first and second medical systems can be co-registered. In another embodiment, sensor integration time and spatial accuracy of the first and second medical systems can be used with an algorithm to produce synergized information.","1. A method for combining and synergizing data from different medical systems, the method comprising the following: Obtaining, by an electronic control unit (ECU) comprising a processor, from a first medical system an image disposed relative to a first coordinate system;Obtaining, by the ECU, from a second medical system supplemental data;synchronizing, by the ECU, first and second clocks of the first and second medical systems, respectively;interpolating, by the ECU, an image accuracy value of the first medical system with a three dimensional accuracy value of a sensor of the second medical system;receiving, by the ECU, the image and supplemental data by a third medical system that displays in synchronicity the supplemental data combined with the image in real-time, the third medical system including a magnetic position sensor to generate magnetic-based location data relative to a third coordinate system; anddisplaying in synchronicity, by the ECU, the supplemental data combined with the image.","16","14/983529","2015-12-29","2016-0203608","2016-07-14","10105107","2018-10-23","ST. JUDE MEDICAL INTERNATIONAL HOLDING S.? R.L.","Alon  Izmirli | Jeffrey A.  Schweitzer | Uzi  Eichler","","","","A61B-0005/743","A61B-0005/743 | A61B-0005/02154 | A61B-0005/0402 | A61B-0005/1036 | G06F-0017/30557 | G06F-0019/321 | G16H-0010/60 | A61B-0005/0422 | A61B-0005/062 | A61B-0005/6852 | A61B-0005/6885 | A61B-0018/1492 | H04L-0067/2838 | H04L-0067/2895","G06K-009/00","G06K-009/00 | A61B-005/00 | A61B-005/0402 | A61B-005/103 | A61B-005/0215 | G06F-017/30 | G06F-019/00 | G16H-010/60 | H04L-029/08 | A61B-005/042 | A61B-005/06 | A61B-018/14","","","","","","4918043000935"
"US","US","P","B2","User physical attribute based device and content management system","Systems and methods for device and content management include determining a user is viewing virtual reality content from a user device, and receiving, through a network from the user device, body information associated with the user while the user is viewing the virtual reality content. A user device management configuration associated with the body information is determined. A user device management action is retrieved using the user device management configuration. A notification associated with the user device management action that causes the user device to perform the user device management action and modify the virtual reality content being viewed by the user is sent through the network to the user device.","1. A system, comprising: a non-transitory memory; andone or more hardware processors coupled to the non-transitory memory and configured to read instructions from the non-transitory memory to cause the system to perform operations comprising: determining a user is performing a first task using a user device;receiving, by a system provider device through a network, medical history information associated with the user;determining, by the system provider device, a user device management configuration based on the medical history information;receiving, by the system provider device through the network from the user device, user device usage information associated with the user;determining, by the system provider device, a user device management action based on the user device usage information and the user device management configuration, andsending, through the network to the user device, a notification associated with the user device management action that causes the user device to perform the user device management action.","20","15/790859","2017-10-23","2018-0107272","2018-04-19","10108262","2018-10-23","PAYPAL, INC.","Ananya  Das | Shaun  Warman | Bryant  Luk | Jason  Ziaja | Christopher Diebold  O'Toole","","","","G06F-0003/013","G06F-0003/013 | A61B-0003/101 | A61B-0003/113 | A61B-0003/14 | A61B-0005/1103 | A61B-0005/486 | A61B-0005/4824 | G02B-0027/0172 | G06K-0009/00362 | G06T-0019/006 | H04L-0067/06 | G02B-2027/0138","G09G-005/00","G09G-005/00 | G06F-003/01 | A61B-005/00 | A61B-003/10 | A61B-005/11 | G02B-027/01 | G06K-009/00 | G06T-019/00 | H04L-029/08 | A61B-003/113 | A61B-003/14","","","","","","4918043004059"
"US","US","P","B2","Cognitive load assessment for digital documents","An embodiment of the invention includes a system that tracks a user's pupillary response to content located on a web page. The system then determines a cognitive load for the user that is based on the measured response. Cognitive load refers to the total amount of mental activity imposed on working memory in any one instant. Further, the system may aggregate the cognitive load data for one user over time, for many different users, and/or for many different users over time. The cognitive load may be determined for different portions of a displayed page, such as a document object model (DOM) included on the page. The cognitive load may be specified for different elements that make up the DOM. Also, cognitive load may be apportioned over several different DOM elements at one moment in time or over a period of time. Other embodiments are described herein.","1. At least one storage medium having instructions stored thereon for causing a system to perform a method comprising: storing a first user'ss pupil activity data in the at least one storage medium, the first user'ss pupil activity data being derived from digital images that were captured by gaze tracker hardware;processing the first user'ss pupil activity data, using at least one processor, to determine a first attribution of the first user'ss pupil activity data to first and second elements of a hierarchical user interface (UI) model included on a previously displayed digital first page that displays the first and second elements in a first spatial orientation to one another;processing the first user'ss pupil activity data, using the at least one processor, to determine a second attribution of the first user'ss pupil activity data to the first and second elements included on a previously displayed digital second page that displays the first and second elements in a second spatial orientation to one another that is unequal to the first orientation;determining a single aggregate attribution of pupil activity data for one of the first and second elements, but not an additional one of the first and second elements, based on both of the first and second attributions of the first user'ss pupil activity data;determining an additional single aggregate attribution of pupil activity data for the additional one of the first and second elements based on both of the first and second attributions of the first user'ss pupil activity data; andattributing first and second portions of the first attribution of the first user'ss pupil activity data respectively to the first and second elements included on the first page,wherein (a) the first UI model includes a first document object model (DOM) and both of the first and second elements are included in a single hierarchal level of the first DOM, (b) each of the first and second elements has a parent node and a child node; and (c) the first and second portions correspond to a first instance of time.","11","13/995514","2011-12-30","2014-0208226","2014-07-24","10108316","2018-10-23","INTEL CORPORATION","Kenton M.  Lyons","","","","G06F-0003/0484","G06F-0003/0484 | A61B-0005/16 | G06F-0003/013 | G06F-0017/30905 | G06K-0009/00442 | G06Q-0030/0201 | A61B-0003/112 | A61B-0003/113 | A61B-2503/24","G06F-003/0481","G06F-003/0481 | G06F-003/0482 | G06F-003/0483 | G06Q-010/10 | G06F-003/0484 | G06Q-030/02 | G06K-009/00 | A61B-005/16 | G06F-003/01 | G06F-017/30 | A61B-003/11 | A61B-003/113","","","","","","4918043004112"
"US","US","P","B2","Vascular hole closure delivery device","A surgical delivery instrument for delivering a vascular hole closure device having first and second flexible members and a first and second engagement members extending from the respective flexible member. The delivery instrument includes a housing having first and second longitudinally extending openings and first and second projecting surfaces, the first projecting surface extending into the first opening for engagement by the first engagement member and the second projecting surface extending into the second opening for engagement by the second engagement member. The first engagement member is held by the first projecting surface until a predetermined force is applied to the first engagement member during placement of the closure device at a target site.","1. A surgical delivery instrument for delivering a vascular hole closure device having an intravascular component, an extravascular component and a first flexible member extending between the intravascular component and extravascular component, the delivery instrument comprising a housing having a first channel to slidingly receive the first flexible member and the first flexible member severable upon proximal movement of the delivery instrument, the first flexible member extending within the first channel from a distal end to a proximal end, and a cutting member enclosed within the housing to sever the first flexible member.","8","14/929201","2015-10-30","2016-0051249","2016-02-25","10108646","2018-10-23","REX MEDICAL, L.P.","James S.  Tarmin | Thanu  Anidharan","","","","G06F-0017/30303","G06F-0017/30303 | A61B-0017/0057 | A61B-0017/0401 | G06F-0003/0482 | G06F-0003/04847 | G06F-0011/0751 | G06F-0017/30371 | G06F-0017/30489 | A61B-2017/00004 | A61B-2017/00623 | A61B-2017/00659 | A61B-2017/0409 | A61B-2017/0456 | A61B-2017/0459","A61B-017/00","A61B-017/00 | G06F-017/30 | G06F-011/07 | A61B-017/04 | G06F-003/0482 | G06F-003/0484","","","","","","4918043004439"
"US","US","P","B2","Methods, systems, and products for tracking surgical items","Methods, systems, and products track equipment used during surgical procedures. An allowable zone associated with a surgical procedure is identified. The allowable zone determines where surgical items may be used during the procedure. A location of a surgical item is determined. When the location is outside the allowable zone, an alarm is triggered to indicate the surgical item is moving outside the allowable zone towards an area in which the surgical item may not be used.","1. A method comprising: identifying, via a computing device, a type of surgical procedure in which a non-disposable surgical equipment is to be used, the non-disposable surgical equipment having a tag, wherein the tag comprises a radio frequency identification tag;determining, via the computing device, whether an alert is entered for the non-disposable surgical equipment, the alert relates to a need to remove the non-disposable surgical equipment from service;associating, via the computing device, the type of surgical procedure to a patient, when the alert is not entered;determining, via the computing device, a location of the non-disposable surgical equipment, wherein the determining comprises communicating with a surgical table having a sensor that communicates with the tag;determining, via the computing device, a time of usage of the non-disposable surgical equipment based on the location of the non-disposable surgical equipment while the surgical procedure is being performed;storing, via the computing device, an identification of the patient, the type of surgical procedure and a date of use of the non-disposable surgical equipment; andcreating, via the computing device, a bill for the time of usage of the non-disposable surgical equipment for the type of surgical procedure.","20","14/754194","2015-06-29","2015-0302492","2015-10-22","10108992","2018-10-23","AT&T INTELLECTUAL PROPERTY I, L.P.","Barrett M.  Kreiner | Jonathan L.  Reeves","","","","G06Q-0030/04","G06Q-0030/04 | A61B-0090/90 | A61B-0090/98 | G06Q-0010/087 | G06Q-0050/22 | G08B-0021/02 | G08B-0021/18 | G16H-0010/65 | H04W-0004/02 | G06F-0019/324","A61B-005/05","A61B-005/05 | G06Q-030/04 | G06Q-010/08 | G06Q-050/22 | G08B-021/02 | G08B-021/18 | H04W-004/02 | A61B-090/90 | A61B-090/98 | G16H-010/65 | G06F-019/00","","","","","","4918043004784"
"US","US","P","B2","Method and apparatus for detection of heartbeat characteristics","Aspects of the present disclosure are directed to detecting Atrial Fibrillation (AF). As may be implemented in accordance with one or more embodiments, a time series of inter-beat intervals is computed from a recording of activity of a beating heart. The time series is decomposed into subcomponents, and an envelope of at least one of the subcomponents is computed. The presence of atrial fibrillation (AF) is detected based upon characteristics of the envelope that are indicative of AF.","1. A method comprising: computing a time series of inter-beat intervals from a recording of activity of a beating heart;decomposing the time series of inter-beat intervals into subcomponents;computing the energy of at least two of the subcomponents; anddetermining that atrial fibrillation is absent based upon relative energy of the at least two subcomponents.","20","15/656799","2017-07-21","2017-0319090","2017-11-09","10098561","2018-10-16","VIVAQUANT, INC.","Marina  Brockway | Brian  Brockway","","","","A61B-0005/0468","A61B-0005/0468 | A61B-0005/0006 | A61B-0005/021 | A61B-0005/026 | A61B-0005/02028 | A61B-0005/0245 | A61B-0005/02416 | A61B-0005/046 | A61B-0005/0408 | A61B-0005/04014 | A61B-0005/04017 | A61B-0005/0452 | A61B-0005/0456 | A61B-0005/0464 | A61B-0005/0472 | A61B-0005/04087 | A61B-0005/1102 | A61B-0005/7203 | A61B-0007/00 | A61B-0007/02 | G06F-0017/14 | G06K-0009/0051 | G06K-0009/0053 | A61B-0005/7253 | G16H-0050/30","A61B-005/00","A61B-005/00 | A61B-005/04 | A61B-005/0452 | A61B-005/0468 | A61B-005/046 | A61B-005/024 | A61B-005/021 | A61B-005/11 | A61B-005/026 | A61B-007/02 | A61B-007/00 | A61B-005/0245 | A61B-005/0408 | G06F-017/14 | G06K-009/00 | A61B-005/02 | A61B-005/0456 | A61B-005/0464 | A61B-005/0472 | G16H-050/30","","","","","","4918042000947"
"US","US","P","B2","Pseudo-CT generation from MR data using tissue parameter estimation","Systems and methods are provided for generating a pseudo-CT prediction model using multi-channel MR images. An exemplary system may include a processor configured to retrieve training data including multiple MR images and at least one CT image for each of a plurality of training subjects. For each training subject, the processor may determine at least one tissue parameter map based on the multiple MR images and obtain CT values based on the at least one CT image. The processor may also generate the pseudo-CT prediction model based on the tissue parameter maps and the CT values of the plurality of training subjects.","1. A system for generating a pseudo-CT prediction model, comprising: a database configured to store training data comprising multi-channel Magnetic Resonance (MR) data and Computerized Tomography (CT) data of a plurality of training subjects, the training data including a plurality of MR images and a CT image, the MR images being associated with different MR imaging protocols;a processor communicatively coupled to the database for accessing information stored in the database;a memory communicatively coupled to the processor, the memory storing instructions that, when executed by the processor, configure the processor to perform operations comprising: accessing the database to retrieve the training data;for the training subjects: obtaining MR imaging protocol parameters associated with the MR images;determining a plurality of intrinsic tissue parameters based on the MR imaging protocol parameters;generating tissue parameter maps for the intrinsic tissue parameters; andcalculating, from the CT image, CT values corresponding to the tissue parameter maps; andgenerating a pseudo-CT prediction model based on the tissue parameter maps and the calculated CT values of the training subjects.","26","14/881939","2015-10-13","2017-0103287","2017-04-13","10102451","2018-10-16","ELEKTA, INC.","Xiao  Han","","","","G06K-0009/6256","G06K-0009/6256 | A61N-0005/1039 | G06F-0017/3028 | G06K-0009/46 | G06K-0009/66 | G06N-0005/04 | G06N-0099/005 | G06T-0005/00 | G06T-0007/0012 | A61B-0005/055 | A61B-0006/032 | A61B-0006/5205 | G01R-0033/4812 | G06T-0007/00 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/20081 | G06T-2207/30096","G06K-009/00","G06K-009/00 | G06K-009/62 | G06F-017/30 | G06K-009/46 | G06K-009/66 | G06N-005/04 | G06N-099/00 | G06T-007/00 | A61N-005/10 | G06T-005/00 | A61B-005/055 | G01R-033/48 | A61B-006/03 | A61B-006/00","","","","","","4918042004811"
"US","US","P","B1","Systems and methods to locate and operate a portable device on smart clothing","Systems and methods locating and operating a portable device mounted to a garment. One method includes receiving, with an electronic processor, a signal from a communication line of a plurality of communication lines integrated within the garment. The method also includes determining, with the electronic processor, a location, on the garment, of the portable device based on the signal. The method also includes determining, with the electronic processor, an operational mode for the portable device based on the location. The method also includes adjusting, with the electronic processor, operation of the portable device based on the operational mode.","1. A method for locating and operating a portable device mounted to a garment, the method comprising: receiving, with an electronic processor, a signal from a communication line of a plurality of communication lines integrated within the garment;determining, with the electronic processor, a location, on the garment, of the portable device based on the signal;determining, with the electronic processor, an operational mode for the portable device based on the location; andadjusting, with the electronic processor, operation of the portable device based on the operational mode.","20","15/588513","2017-05-05","2018-0324551","2018-11-08","10104507","2018-10-16","MOTOROLA SOLUTIONS, INC.","Ellis A.  Pinder","","","","H04W-0004/026","H04W-0004/026 | H03G-0003/02 | H04B-0001/401 | H04R-0001/028 | H04R-0001/406 | H04R-0003/005 | H04R-0003/04 | H04W-0004/023 | H04R-2201/023 | H04R-2201/403 | H04W-0088/06","H03G-003/02","H03G-003/02 | H04B-001/401 | A61N-001/00 | A61B-005/04 | G06K-019/07 | G06K-007/10 | H04W-004/02 | H04R-001/40 | H04R-003/00 | H04R-001/02 | H04R-003/04 | H04W-088/06","","","","","","4918042006849"
"US","US","P","B2","Fingerprint identification circuit, touch apparatus and fingerprint identification method","A fingerprint identification circuit comprises multiple reading sub-circuits, and multiple fingerprint identification sub-circuits each column of fingerprint identification sub-circuits are connected with one reading sub-circuit, each fingerprint identification sub-circuit comprises a writing sub-circuit, a sensing sub-circuit and a output sub-circuit, the writing sub-circuit is connected with a scan signal input terminal; the sensing sub-circuit senses a fingerprint and transmits a sensing signal to the output sub-circuit; the output sub-circuit outputs the sensing signal upon the writing sub-circuit is turned off each fingerprint identification sub-circuit further comprises: a converting and amplifying sub-circuit provided between the sensing sub-circuit and the output sub-circuit, for converting the sensing signal into a current signal, amplifying the current signal and outputting it to the output sub-circuit, the reading sub-circuit is connected with the output sub-circuit for reading the sensing signal and converting the current signal into a voltage signal to output.","1. A fingerprint identification circuit, comprising a plurality of reading sub-circuits, and a plurality of fingerprint identification sub-circuits arranged in rows and columns, wherein each column of fingerprint identification sub-circuits are connected with one of the reading sub-circuits, each of the fingerprint identification sub-circuits comprises a writing sub-circuit, a sensing sub-circuit and a output sub-circuit connected in sequence, a control terminal of the writing sub-circuit is connected with a scan signal input terminal and is turned on upon an active signal is input to the scan signal input terminal so as to write a detection signal to the sensing sub-circuit; the sensing sub-circuit senses a fingerprint and transmits an obtained sensing signal to the output sub-circuit, the output sub-circuit is turned on and outputs the sensing signal upon the writing sub-circuit is turned off, and is turned off upon the writing sub-circuit is turned on, and wherein each of the fingerprint identification sub-circuits further comprising: a converting and amplifying sub-circuit, which is provided between the sensing sub-circuit and the output sub-circuit, for converting the sensing signal output from the sensing sub-circuit into a current signal, amplifying the current signal by a preset multiple and then outputting it to the output sub-circuit, whereinthe reading sub-circuit is connected with an output terminal of the output sub-circuit, and is configured to read the sensing signal output from the output sub-circuit and convert the current signal into a voltage signal to output.","20","15/562570","2017-02-23","2018-0211080","2018-07-26","10095910","2018-10-09","BOE TECHNOLOGY GROUP CO., LTD. | CHENGDU BOE OPTOELECTRONICS TECHNOLOGY CO., LTD.","Xiaoxiang  He | Xiaojing  Qi","2016-10342252","CN","2016-05-20","G06K-0009/0002","G06K-0009/0002 | A61B-0005/1172 | G06F-0003/044 | G06K-0009/0004 | G06K-0009/00013 | G06K-0009/00087 | G06K-0019/0718","G06K-009/00","G06K-009/00 | G06F-003/044 | G06K-019/07 | A61B-005/1172","","","","","","4918041004618"
"US","US","P","B1","Vehicle fatigue monitoring system","Embodiments can provide a real-time fatigue monitoring system for detecting and/or monitoring a fatigue condition of a driver of a driving apparatus. In some embodiments, the fatigue monitoring system can include a set of one or more sensors for detecting a physiological condition of the driver, a head movement detection device, one or more processing devices, and/or any other components. In some embodiments, the fatigue condition detection system may include a processing device configured to determine occurrence of a fatigue condition in response to the detection of a physiological condition of the driver is below a threshold while the driver's head movement is tilting downwards.","1. A method for detecting occurrence a fatigue condition of an operator of a driving apparatus, the method being implemented in a processor configured to execute machine-readable instructions, the method comprising: receiving a signal indicating a physiological condition of the operator;determining the physiological condition of the operator is below a threshold;in response to determining the physiological condition of the operator is below the threshold, obtaining head movement information regarding a movement of the operator'ss head within a time window, wherein the time window specifies an amount of seconds immediately prior to the determination that the operator'ss physiological condition is below the threshold;determining the head movement information indicates that operator'ss head is moving downwards within the time window; andin response to the head movement information indicating the operator'ss head is moving downwards within the time window and further to the physiological condition of the operator is below the threshold, generating a signal indicating a fatigue condition is detected for the operator.","16","15/675142","2017-08-11","","","10085683","2018-10-02","Wellen Sham","Wellen  Sham","","","","A61B-0005/18","A61B-0005/18 | B60K-0028/06 | B60W-0040/08 | G02B-0027/0093 | G06K-0009/00228 | G06Q-0050/30 | G08G-0001/0112 | B60W-2040/0818","G08B-023/00","G08B-023/00 | A61B-005/18 | G02B-027/00 | B60K-028/06 | G06Q-050/30 | G08G-001/01 | G06K-009/00 | B60W-040/08","","","","","","4918040000958"
"US","US","P","B2","Medical image information system, medical image information processing method, and program","The present invention correlates information, to be processed, about an organ and/or a disease, etc., obtained from a medical image and anatomical/functional medical knowledge information, and enables the information obtained from the medial image to be effectively utilized in medical examination and treatment processes. In a medical image information system (101), an image processing unit (103) processes an image, a graph model creation unit (104) creates a graph data model from the information obtained from the image, a graph data model processing unit (106) acquires a graph data model based on anatomical/functional medical knowledge, compares with each other and integrates the graph data models and stores an integrated graph data model, and a display processing unit (110) displays the integrated graph data model, whereby the effective use of information obtained from the image is made possible.","1. A medical image information system comprising: a medical knowledge database in which predetermined anatomic compartments or predetermined functional compartments with respect to one or more organ models are stored;a storage medium storing instructions;a display device; anda processor connected to the storage medium, the display device and the medical knowledge database,wherein the processor, when executing the instructions stored in the storage medium, is configured to:extract an organ region and a tract region in the organ region from an image to be processed which contains an imaged organ,divide the extracted tract region into a plurality of tract nodes linked by a plurality of tract edges to create a tract graph data model,divide the extracted organ region according to the extracted tract region and the tract graph data model into a plurality of organ region compartment nodes linked by a plurality of organ region compartment edges to create an organ region compartment graph data model,acquire an anatomical/functional graph data model which includes a plurality of functional compartment nodes linked by a plurality of functional compartment edges based on the anatomic compartments or the functional compartments of the one of the organ models stored in the medical knowledge database corresponding to the imaged organ,correlate at least one of the tract graph data model and the organ region compartment graph data model with the anatomical/functional graph data model to create an integrated graph data model, anddisplay at least one of the tract graph data model, the organ region compartment data model, and the anatomical/functional data model with the integrated graph data model on the display device.","16","15/305458","2015-03-30","2017-0042495","2017-02-16","10085707","2018-10-02","HITACHI, LTD.","Kazuki  Matsuzaki | Yuuichi  Morimoto | Wataru  Takeuchi | Kikuo  Umegaki | Tohru  Shiga | Koichi  Yasuda","2014-090139","JP","2014-04-24","A61B-0006/5217","A61B-0006/5217 | A61B-0005/00 | A61B-0005/055 | A61B-0006/032 | A61B-0006/037 | A61B-0006/501 | A61B-0006/503 | A61B-0006/504 | G06F-0017/3028 | G06F-0017/30256 | G06F-0019/321 | G06F-0019/325 | G06F-0019/3437 | G06K-0009/469 | G06K-0009/6256 | G06K-0009/6892 | G06Q-0050/24 | G06T-0007/0012 | G06T-0007/11 | G06T-0007/162 | G06T-0011/206 | G16H-0050/50 | G06T-2207/10072 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/10104 | G06T-2207/10108 | G06T-2207/20072 | G06T-2207/20161 | G06T-2207/30016 | G06T-2207/30048 | G06T-2207/30056 | G06T-2207/30096 | G06T-2207/30101","G06K-009/00","G06K-009/00 | A61B-006/00 | G16H-050/50 | A61B-005/00 | G06Q-050/24 | A61B-005/055 | A61B-006/03 | G06F-017/30 | G06F-019/00 | G06K-009/62 | G06T-007/00 | G06T-011/20 | G06T-007/11 | G06K-009/46 | G06K-009/68 | G06T-007/162","","","","","","4918040000982"
"US","US","P","B2","Electrocardiogram (ECG)-based authentication apparatus and method thereof, and training apparatus and method thereof for ECG-based authentication","Provided are electrocardiogram (ECG)-based authentication and training. An authentication method includes generating a feature vector of an ECG obtained from an entity or a person based on a dictionary, classifying the ECG through a classifier based on the feature vector, and performing authentication based on a classification result.","1. A method, comprising: generating a feature vector from an electrocardiogram (ECG) based on a pre-trained dictionary;generating a classification result of the ECG based on the feature vector and a pre-trained classifier;obtaining a classification result of a reference ECG comprising a reference signal segment; andperforming authentication of the ECG based on a voting mechanism for the classification result of the ECG and the classification result of the reference ECG,wherein the performing of the authentication based on the voting mechanism comprises generating a first distribution comprising a number of signal segments belonging to each of a plurality of categories based on a label of the ECG,obtaining a second distribution comprising a number of reference signal segments belonging to each of the categories,calculating a similarity between the first distribution and the second distribution, andperforming the authentication by comparing the similarity to a threshold.","27","15/041477","2016-02-11","2016-0232340","2016-08-11","10089451","2018-10-02","SAMSUNG ELECTRONICS CO., LTD.","Xuetao  Feng | Chao  Zhang | Chisung  Bae | Jongae  Park | Sang-joon  Kim | Yang  Liu","2015-10071283 | 10-2015-0180291","CN | KR","2015-02-11 | 2015-12-16","G06F-0021/32","G06F-0021/32 | A61B-0005/04525 | A61B-0005/117 | A61B-0005/7267 | G06K-0009/0055 | G06K-0009/6249 | G06K-0009/6255 | H04L-0009/3231 | H04L-0063/0861 | G06K-2009/00939 | G16H-0050/20 | H04L-2209/88","G06F-021/00","G06F-021/00 | G06F-021/32 | A61B-005/0452 | H04L-009/32 | A61B-005/00 | A61B-005/117 | H04L-029/06 | G06K-009/00 | G06K-009/62 | G16H-050/20","","","","","","4918040004701"
"US","US","P","B2","User authentication method and apparatus","A user authentication apparatus includes: a motion sensor configured to receive motion data associated with a motion of a body of the user authentication apparatus; a biometric sensor configured to receive biometric data associated with a user of the user authentication apparatus; and a processor configured to identify a signature of the user based on the motion data, and authenticate the user based on the identified signature and the biometric data.","1. A user authentication apparatus, comprising: a motion sensor configured to receive motion data associated with a motion of a body of the user authentication apparatus;a biometric sensor configured to obtain, when a biosignal is measured by the biometric sensor, biometric data from the biosignal, associated with a user of the user authentication apparatus; anda processor configured to: identify a signature of the user based on the motion data; andauthenticate the user based on the identified signature when the biosignal is determined to not be measured, and authenticate the user based on the identified signature and the biometric data when the biosignal is determined to be measured.","25","15/241903","2016-08-19","2017-0180988","2017-06-22","10091654","2018-10-02","SAMSUNG ELECTRONICS CO., LTD.","Sang Joon  Kim | Chang Soon  Park | Jong Wook  Lee | Seungchul  Jung","10-2015-0182728","KR","2015-12-21","H04W-0012/06","H04W-0012/06 | A61B-0005/04 | G06F-0003/03545 | G06K-0009/00006 | G06K-0009/00167 | G06K-0009/222 | H04L-0063/0861 | H04M-0001/7253","H04W-012/06","H04W-012/06 | A61B-005/04 | G06F-003/0354 | G06K-009/00 | H04M-001/725 | H04L-029/06 | G06K-009/22","","","","","","4918040006886"
"US","US","P","B2","Personal items network, and associated methods","A personal items network, comprising a plurality of items, each item having a wireless communications port for coupling in network with every other item, each item having a processor for determining if any other item in the network is no longer linked to the item, each item having an indicator for informing a user that an item has left the network, wherein a user may locate lost items. A method for locating lost personal items, comprising: linking at least two personal items together on a network; and depositing one or both of time and location information in an unlost item when one of the items is lost out of network.","1. A method for operating a virtual competition on a computerized gaming system, the method comprising: receiving, with the computerized gaming system, real performance data indicative of real performance metrics sensed during a real-life performance of a physical activity;associating, with the computerized gaming system, an identification code to the received real performance data, wherein the identification code is associated with a particular participant; andadjusting, with the computerized gaming system, the virtual competition associated with the particular participant based on the received real performance data associated with the identification code associated with the particular participant.","20","14/736218","2015-06-10","2015-0306505","2015-10-29","10080971","2018-09-25","APPLE INC.","Curtis A.  Vock | Burl W.  Amsbury | Paul  Jonjak | Adrian F.  Larkin | Perry  Youngs","","","","A63F-0013/798","A63F-0013/798 | A43B-0003/0005 | A61B-0005/0002 | A61B-0005/0022 | A61B-0005/02438 | A61B-0005/0816 | A61B-0005/1112 | A61B-0005/1113 | A61B-0005/1117 | A61B-0005/1118 | A61B-0005/14532 | A61B-0005/14542 | A61B-0005/22 | A61B-0005/4866 | A61B-0005/681 | A61B-0005/6807 | A61B-0005/721 | A63B-0024/00 | G01B-0021/16 | G01C-0021/16 | G01G-0019/44 | G01G-0023/00 | G01G-0023/3728 | G01L-0001/04 | G01L-0001/16 | G01L-0001/22 | G01P-0001/127 | G01P-0003/00 | G01P-0003/50 | G01P-0015/00 | G01P-0015/0891 | G01P-0015/18 | G01S-0001/08 | G01S-0019/00 | G06F-0011/3089 | G06Q-0010/08 | G07C-0001/10 | G07C-0001/24 | G08B-0005/36 | G08G-0001/20 | G08G-0009/00 | H04L-0043/00 | H04L-0043/04 | H04M-0001/7253 | H04Q-0009/00 | H04W-0004/02 | H04W-0004/027 | H04W-0076/14 | H05K-0005/0247 | A61B-0005/112 | A61B-0005/1114 | A61B-0005/1122 | A61B-0005/6833 | A61B-0005/7242 | A61B-2503/04 | A61B-2503/10 | A61B-2560/0214 | A61B-2560/0242 | A61B-2560/0285 | A61B-2560/0412 | A61B-2560/0456 | A61B-2562/166 | A63B-0069/004 | A63B-0069/0028 | A63B-0069/16 | A63B-0069/26 | A63B-2208/12 | A63B-2220/30 | A63B-2220/40 | A63B-2220/50 | H04Q-2209/40 | H04W-0004/043","G06F-017/00","G06F-017/00 | A63F-013/798 | A43B-003/00 | A61B-005/00 | A61B-005/11 | A63B-024/00 | G01C-021/16 | G01G-019/44 | G01G-023/00 | G01G-023/37 | G01P-001/12 | G01P-003/50 | G01P-015/08 | G01P-015/18 | G06Q-010/08 | G07C-001/10 | G07C-001/24 | G08G-001/00 | G08G-009/00 | H04W-004/02 | H04L-012/26 | G01L-001/04 | G01L-001/16 | G01L-001/22 | G01S-001/08 | H05K-005/02 | A61B-005/024 | A61B-005/22 | G01B-021/16 | G01P-003/00 | G01P-015/00 | G01S-019/00 | A61B-005/08 | A61B-005/145 | H04M-001/725 | H04Q-009/00 | G06F-011/30 | G08B-005/36 | H04W-076/14 | A63B-069/00 | A63B-069/16 | A63B-069/26 | H04W-004/04","","","","","","4918039001104"
"US","US","P","B2","Method and system of simulating a pulse generator on a clinician programmer","An electronic device having a display is provided. Interactive user engagements with the electronic device are made through the display. A simulation mode is entered. The simulation mode simulates a real pulse generator configured to generate electrical stimulation pulses. The simulation mode is entered without establishing a wireless connection with the real pulse generator. Via the display, one or more features of a virtual pulse generator are demoed after entering the simulation mode. The one or more features of the virtual pulse generator simulate corresponding features of the real pulse generator. The virtual pulse generator is a software program that resides on the electronic device. The demoing comprises mimicking a plurality of user interface screens that allow a user to interact with the real pulse generator.","1. An electronic device, comprising: a display configured to display an output;a radio component configured to conduct wireless communications with external devices;electronic circuitry that causes the electronic device to perform operations comprising: entering a simulation mode that simulates a real pulse generator configured to generate electrical stimulation pulses, wherein the entering the simulation mode is performed without establishing a wireless connection with the real pulse generator;demoing, via the display, one or more features of a virtual pulse generator after entering the simulation mode, wherein the one or more features of the virtual pulse generator simulate corresponding features of the real pulse generator, and wherein the virtual pulse generator is a software program that resides on the electronic device, and wherein the demoing comprises programming the virtual pulse generator at least in part by mimicking a plurality of user interface screens that allow a user to interact with the real pulse generator;establishing a wireless connection with the real pulse generator; andprogramming the real pulse generator based on programming data compiled as a result of the programming of the virtual pulse generator.","19","15/358295","2016-11-22","2017-0076025","2017-03-16","10083261","2018-09-25","NUVECTRA CORPORATION","Norbert  Kaula | Yohannes  Iyassu","","","","G06F-0017/5009","G06F-0017/5009 | A61N-0001/37247 | G06F-0019/34 | G06F-0021/31 | G16H-0040/63 | G06F-2221/2149","G06F-021/00","G06F-021/00 | G06F-017/50 | G06F-019/00 | G06F-021/31 | A61N-001/372 | G16H-040/63","","","","","","4918039003377"
"US","US","P","B2","Interactive avatar for social network services","An embodiment is an avatar or avatar environment to visualize data within an athletic performance system or service and/or a social network system or service, for example as part of the Internet. The avatar may further evolve or alter its appearance, animation, or other visual or audio characteristics in response to the data or other input. In particular, the avatar of an embodiment may respond to and provide visualization of athletic or sport performance data. According to one or more aspects, an avatar may be placed on other network sites and updated based on athletic performance data. The avatar may be awarded for goals achieved by a user. The awards or gifts may further include non-avatar related items such as apparel, gift cards and the like.","1. A method comprising: receiving, by a computing system through an electronic avatar widget executing on a first network site, athletic performance information of a user from a second network site different from the first network site;generating an avatar associated with the user on the first network site by executing portable code included in the electronic avatar widget, wherein the first network site and the second network site each host a different website on which the avatar is displayed;displaying, in the electronic avatar widget, the athletic performance information of the user received from the second network site;detecting that the avatar corresponding to the user has been set to private on the second network site; andin response to detecting that the avatar has been set to private on the second network site, modifying the electronic avatar widget on the first network site to hide the athletic performance information from a selected subset of users on the first network site and generating an alternate avatar associated with the user and a private mode, and generating a message to the user on the first network site indicating that the avatar has been set to private from the second network site.","17","14/521678","2014-10-23","2015-0046847","2015-02-12","10083393","2018-09-25","NIKE, INC.","Jason  Nims | Roberto  Tagliabue | Danielle  Quatrochi","","","","G06N-0003/006","G06N-0003/006 | A61B-0005/0022 | A61B-0005/1118 | A61B-0005/744 | A63B-0024/0059 | G06F-0017/3089 | G06F-0021/6245 | G06Q-0010/10 | G06Q-0050/01 | H04L-0065/403 | H04L-0067/38 | A61B-0005/4866 | A63B-0024/0075 | A63B-0069/0028 | A63B-2024/0068 | A63B-2024/0096 | A63B-2071/0638 | A63B-2220/20 | A63B-2220/40 | A63B-2225/50 | A63B-2230/06 | A63B-2230/75 | A63F-2300/407 | A63F-2300/5553 | A63F-2300/572 | A63F-2300/609 | A63F-2300/69 | A63F-2300/8005","G06N-003/00","G06N-003/00 | G06Q-050/00 | G06F-017/30 | A63B-024/00 | G06Q-010/10 | A61B-005/00 | A61B-005/11 | G06F-021/62 | H04L-029/06 | A63B-069/00 | A63B-071/06","","","","","","4918039003509"
"US","US","P","B1","Minimally invasive networked surgical system and method","A system for performing non-invasive networked medical procedures including a number of in vivo medical devices, a communication path between at least two of the devices, an ex vivo control unit to control the behavior of the devices, and a wireless communication path between the control unit and at least one of the devices. An associated method for performing non-invasive networked medical procedures is also provided. Further included is a simulation method that utilizes accurate electromagnetic field simulations, using a software based test bench, to determine the maximum allowable transmitted power levels from in vivo devices to achieve a required bit error rates (BER) at an in vivo or ex vivo node (receiver) while maintaining the specific absorption rate (SAR) under a required threshold.","1. A system for performing networked medical procedures on a subject, comprising: a plurality of in vivo medical devices including an in vivo transmitter;a network providing a communication path between at least two of said plurality of in vivo medical devices, said network permitting receipt and transmission of control signals between said at least two in vivo medical devices over said communication path, said network including a Layer 3 data network; andan ex vivo control unit to control a behavior of said plurality of in vivo medical devices, said behavior including spatial parameters of said plurality of in vivo medical devices;said network providing an additional communication path between said ex vivo control unit and at least one of said plurality of in vivo medical devices.","20","15/783568","2017-10-13","","","10076228","2018-09-18","UNIVERSITY OF SOUTH FLORIDA","Richard D.  Gitlin | Gabriel E.  Arrobo | Thomas P.  Ketterl","","","","A61B-0001/00016","A61B-0001/00016 | A61B-0001/00006 | A61B-0005/0022 | A61B-0005/0024 | A61B-0005/07 | A61B-0017/00234 | A61B-0017/32 | H04L-0067/125 | H04W-0008/22 | H04W-0040/00 | H04W-0076/10 | A61B-2017/00212 | H04W-0084/12","H04B-007/00","H04B-007/00 | A61B-001/00 | A61B-005/00 | H04W-040/00 | H04W-008/22 | H04L-029/08 | A61B-005/07 | A61B-017/32 | H04W-076/10 | H04W-084/12 | A61B-017/00","","","","","","4918038000499"
"US","US","P","B2","Card with integrated fingerprint authentication","A card, such as a credit or identification card, including an authenticating element for authenticating the card with a service provider, a fingerprint reader integral with the card for reading a fingerprint provided by a user of the card, and a processing element for comparing the fingerprint provided by the user to a fingerprint of an owner of the card to confirm that the user is the owner. In one variation, there is also provided a means for determining whether an object presented to the fingerprint reader is a finger of the user presenting the card.","1. A card comprising: an authentication element for authenticating the card with a service provider via a terminal, the card having a front surface;a photoplethysmogram device for determining whether a fingerprint provided by a finger of a user is from a live person, the photoplethysmogram device including a light emitting diode for illuminating the skin of the user and a photo diode for measuring changes in light absorption in the finger of the user;a fingerprint reader integral with the card for reading the fingerprint of the user;the fingerprint reader including an array of conductive elements that form capacitors when in contact with the finger of the user to generate an array of capacitances;a processing element for comparing the changes in light absorption with predetermined reference values stored on the card indicative of cardiovascular activity in a finger and for comparing the fingerprint of the user to a fingerprint of an owner of the card to confirm the user is the owner,wherein the processing element is configured to activate the fingerprint reader to read the fingerprint of the user after confirming, based on the comparison of the changes in light absorption with the predetermined reference values, cardiovascular activity in the finger of the user; andwherein the photo diode, the light emitting diode, and the fingerprint reader are co-planar with the front surface of the card.","4","14/237236","2012-08-03","2014-0232525","2014-08-21","10076920","2018-09-18","Saeid Mohmedi","Saeid  Mohmedi","","","","B42D-0025/313","B42D-0025/313 | A61B-0005/02427 | G06K-0009/00087 | G06K-0019/07354 | G06Q-0020/341 | G06Q-0020/40145 | G07C-0009/00087 | G07F-0007/0826 | G07F-0007/0833 | B42D-0025/00 | G07C-2009/00095 | G07F-0007/1008","G06K-009/00","G06K-009/00 | B42D-025/313 | A61B-005/024 | G06Q-020/34 | G06Q-020/40 | G06K-019/073 | G07C-009/00 | G07F-007/08 | G07F-007/10 | B42D-025/00","","","","","","4918038001187"
"US","US","P","B2","Systems, devices and methods for managing glucose levels","Systems, devices and methods for the management of glucose levels in the body of patient featuring user interface input mechanisms configured to provide haptic feedback to the user are provided.","1. A glucose management device, comprising: a processor;a user interface controllable by the processor, the user interface configured for tactile contact by a user for entering a value of one or more parameters of the glucose management device; anda feedback mechanism, wherein the processor controls the feedback mechanism to provide a haptic feedback response to the user as the entered value of a selected parameter approaches or moves away from at least one set value of the selected parameter.","20","15/093010","2016-04-07","2017-0003766","2017-01-05","10078380","2018-09-18","ABBOTT DIABETES CARE INC.","Erwin S.  Budiman","","","","G06F-0003/0362","G06F-0003/0362 | A61B-0005/14532 | A61M-0005/1723 | G06F-0003/016 | A61B-0005/746 | A61B-0005/7455 | A61B-2560/0276 | A61M-2205/18 | A61M-2205/3584 | A61M-2205/505 | A61M-2205/582 | A61M-2230/201 | H01H-2003/008","A61B-005/00","A61B-005/00 | G06F-003/0362 | A61B-005/145 | G06F-003/01 | A61M-005/172 | H01H-003/00","","","","","","4918038002633"
"US","US","P","B2","Gaze time indicator for a vehicle","A system for tracking a gaze of a driver of a vehicle includes a tracking device, a processor, a memory, and a display. The tracking device is configured to track a gaze of a driver of a vehicle. The processor is in electronic communication with the tracking device. The memory is in electronic communication with the processor. The memory includes programming code configured to be executed by the processor. The programming code is configured to determine in real-time a duration of the gaze of the driver of the vehicle tracked by the tracking device. The display is in electronic communication with the processor. The display is configured to display a symbol showing the determined duration, or a portion of the determined duration, of the gaze of the driver of the vehicle as determined by the processor.","1. A system for tracking a gaze of a driver of a vehicle comprising: a tracking device configured to track a gaze of a driver of a vehicle;a processor in electronic communication with the tracking device;a memory in electronic communication with the processor, the memory comprising programming code configured to be executed by the processor, the programming code configured to determine in real-time a duration of the gaze of the driver of the vehicle away from a path in which the vehicle is moving, and further configured to determine an object that the driver of the vehicle is viewing outside the vehicle and to passively alert the driver of his improper viewing of the object other than the path; anda display in electronic communication with the processor, the display configured to, as controlled by the processor, display an indicator which in real-time fills up, while the vehicle is moving and the driver of the vehicle is gazing away from the path in which the vehicle is moving, to track and display the real-time determined duration of the gaze of the driver as determined by the processor.","24","15/443594","2017-02-27","2017-0190252","2017-07-06","10078779","2018-09-18","VISTEON GLOBAL TECHNOLOGIES, INC.","Michael Dean  Tschirhart | Dale O.  Cramer | Anthony Joseph  Ciatti","","","","G06K-0009/00248","G06K-0009/00248 | B60K-0028/066 | G08B-0021/06 | A61B-0003/113 | A61B-0005/18 | A61B-0005/6893 | A61B-0005/746 | B60W-0040/08 | B60W-0050/14 | G06F-0003/013 | G06K-0009/00597 | G06K-0009/00845 | G06Q-0040/08 | G08B-0021/0476","B60K-028/06","B60K-028/06 | G06K-009/00 | G08B-021/06 | A61B-005/00 | G06F-003/01 | A61B-003/113 | B60W-050/14 | B60W-040/08 | G08B-021/04 | G06Q-040/08 | A61B-005/18","","","","","","4918038003031"
"US","US","P","B2","System and method for real time viewing of critical patient data on mobile devices","A data-processing tool for displaying real-time patient data on remote and/or mobile devices. The tool renders graphical data on the screen of the remote device in a manner that makes it practical for the health care provider to review the data. Charting components provide landscape support, an ability to overlay patient data and patient images, zoom in/zoom out, custom variable speed scrolling, split screen support, and formatting control. The methodology operates as an asynchronous application, allowing patient data to be streamed in real-time to the handheld device while conserving enough CPU power to simultaneously allow the end user to interact at will with the responsive display application. Finally, the methodology implements an IT management console that allows system managers to monitor the exchange of data between hospital systems and the primary database, including all patient data packets, notifications and alerts, connected remote devices, etc.","1. A method for remote monitoring of patient physiological data, the method comprising: receiving, by one or more processors, patient physiological data, the patient physiological data having been collected from a patient using at least one patient physiological sensor;establishing, by one or more processors, a customized charting control to provide display characteristics associated to a remote-handheld data processing device, the display characteristics comprising a screen size and display memory capacities of a display of a remote-handheld data processing device;conditioning, by one or more processors, the patient physiological data by adjusting the patient physiological data based on the screen size and the display memory capacities of the display of the remote-handheld data processing device to reduce a transmission time over a wide area digital network and to reduce a volume of the patient physiological data to provide conditioned patient physiological data, the conditioned patient physiological data comprising a format and an amount of data extracted from the patient physiological data that depend on the screen size and the display memory capacities of the display of the remote-handheld data processing device, the format defining sizes of displayable components of the patient physiological data, such that a presentation of the conditioned patient physiological is compressed for display in a discernable manner on the display of the remote-handheld data processing device relative to the screen size;transmitting, by one or more processors, the conditioned patient physiological data in real-time over the wide area digital network;receiving the conditioned patient physiological data in real-time at the remote-handheld data processing device, the remote-handheld data processing device executing a computer-executable application for displaying the patient physiological data on the display of the remote-handheld data processing device;reconditioning, by the remote-handheld data processing device, the conditioned patient physiological data to display the patient physiological data on the remote-handheld data processing device by formatting the conditioned patient physiological data for display on the remote-handheld data processing device; andproviding, for display on the display of the remote-handheld data processing device, by the computer-executable application, the patient physiological data comprising a trend view of the patient physiological data stored in a buffer.","34","13/588539","2012-08-17","2013-0030831","2013-01-31","10078875","2018-09-18","AIRSTRIP IP HOLDINGS, LLC","William Cameron  Powell | Trey  Moore","","","","G06Q-0050/22","G06Q-0050/22 | A61B-0005/0022 | G01D-0021/00 | G06F-0019/00 | G06F-0019/3418 | G06Q-0010/10 | G16H-0040/63 | H04L-0067/12 | A61B-0005/7232 | H04W-0004/00 | H04W-0024/00 | H04W-0088/02","G06Q-050/00","G06Q-050/00 | G06Q-050/22 | G01D-021/00 | G06F-019/00 | G06Q-010/10 | H04L-029/08 | A61B-005/00 | G16H-040/63 | G06Q-010/00 | H04W-004/00 | H04W-024/00 | H04W-088/02","","","","","","4918038003127"
"US","US","P","B1","Reading tracking system","A reading tracking system specifically designed for children including a wrist-worn arm motion and heart rate sensor coupled to a parental monitoring system, a game-style application for the child's use, and a group application useful in a classroom setting. The user's heart rate and arm movements are monitored to detect reading-related behavior states, such as reading, fallen asleep, distracted, and awoke after haven falling asleep states, independent from precise eye gaze tracking. Heart rate monitoring detects a high heart rate that is inconsistent with reading, a moderate heart rate indicative of a sedentary awake state consistent with reading, and a low hart rate indicating that the user has fallen asleep. Arm movement monitoring detects a high arm activity state that is inconsistent with reading, a moderate arm movement state or gestures consistent with page turning while reading, and a low arm activity rate indicating that the user has fallen asleep.","1. A reading tracking system, comprising: a wrist-worn device comprising a timer and sensors configured to measure inputs for a person wearing the wrist-worn device, the sensors including at least a heart rate monitor and an arm movement monitor;a reading-related state detector configured to determine reading-related behavior states of the person wearing the wrist-worn device based on the measured inputs from the heart rate monitor and the arm movement monitor, the reading-related behavior states including at least a reading state and a fallen asleep state;the timer configured to determine durations of the reading-related behavior states;a notification generator configured to communicate reading-related notifications based on the reading-related behavior states, the reading-related notifications including at least a reading state notification and a fallen asleep notification;a reading monitoring station separate from the wrist-worn device and in a different location from the location of the person wearing the wrist-worn device configured to receive or generate and display the reading-related notifications for monitoring the reading-related behavior states of the person wearing the wrist-worn device from the different location.","20","15/920851","2018-03-14","","","10078954","2018-09-18","Culin Tate","Culin  Tate","","","","G08B-0021/18","G08B-0021/18 | G06F-0003/013 | G06F-0003/014 | G06K-0009/00335 | A61B-0005/021 | A61B-0005/681 | G06F-0003/011 | G06K-0009/00671","G06F-003/01","G06F-003/01 | G08B-021/18 | G06K-009/00 | A61B-005/00 | A61B-005/021","","","","","","4918038003206"
"US","US","P","B2","Associative object tracking systems and methods","Systems and methods track a first object when continuous tracking information for the first object is not available. The systems and methods detect when the tracking information for the first object is not available. A last time of a last determined location of the first object is determined and a second object closest to the last determined location at the last time is determined. The location of the first object is associated with a location of the second object if tracking information for the first object is not available.","1. A method for annotating a delayed feed of a sporting activity with tracking information determined within a tracking apparatus for a plurality of objects, comprising: determining when continuous location tracking information for a primary one of the plurality of objects is not available;when, for a period when the continuous location tracking information for the primary object is not available and based upon a highest probability defined within one or more predetermined scenarios of the sporting activity, speculatively associating the primary object with a first one of two secondary ones of the plurality of objects that are proximate a last location of the primary object;when the continuous location tracking information for the primary object becomes available after the period, receiving an updated location for the primary object and evaluating correctness of the speculative association of the primary object with the first secondary object based upon the updated location, to produce a non-speculative association of the primary object with one of the secondary objects; andoutputting the delayed feed with the tracking information for the first object based upon tracking information of the non-speculatively associated one of the secondary objects during the period when the continuous location tracking information is not available.","14","15/789880","2017-10-20","2018-0036590","2018-02-08","10071282","2018-09-11","ISOLYNX, LLC","Douglas J.  DeAngelis | Edward G.  Evansen | Gerard M.  Reilly","","","","A63B-0024/0021","A63B-0024/0021 | A61B-0005/02438 | A61B-0005/0816 | A61B-0005/14542 | A63B-0024/0062 | A63B-0071/0619 | A63B-0071/0622 | G06K-0009/00751 | G06Q-0010/0833 | G06Q-0050/28 | G06T-0007/20 | A61B-2503/10 | A63B-2024/0025 | A63B-2024/0028 | A63B-2071/0625 | A63B-2102/22 | A63B-2220/14 | A63B-2220/836 | A63B-2225/15 | A63B-2225/20 | A63B-2243/0037 | G01S-0013/726 | G01S-0013/751 | G06T-2207/10016 | G06T-2207/30221","A63B-024/00","A63B-024/00 | A61B-005/145 | A61B-005/08 | A63B-071/06 | A61B-005/024 | G06T-007/20 | G06K-009/00 | G06Q-050/28 | G06Q-010/08 | A63B-102/22 | G01S-013/75 | G01S-013/72","","","","","","4918037001437"
"US","US","P","B2","Intra-oral image acquisition alignment","Systems and methods are presented for assisting in providing consistent alignment of a handheld intra-oral imaging device for a series of images. Live image data of the patient is received from the intra-oral image capture device and displayed on the display. A previously stored intra-oral image of the patient is accessed from the non-transitory memory and an alignment mask is generated based on the accessed previously stored intra-oral image. The alignment mask is displayed on the display overlaid onto the live image data. The system captures a new intra-oral image of the patient from the live image data and stores the new intra-oral image to the non-transitory memory.","1. An intra-oral imaging system comprising: a manually positionable intra-oral image capture device;a display;a processor coupled to the intra-oral image captured device and the display; anda non-transitory memory coupled to the processor and storing instructions that, when executed by the processor, cause the system to receive live image data of a patient from the intra-oral image capture device,display the live image data on the display,access a previously stored intra-oral image of the patient from the non-transitory memory,generate an alignment mask based on the accessed previously stored intra-oral image,display the alignment mask on the display overlaid on the live image data,capture a new intra-oral image of the patient from the live image data, andstore the new intra-oral image to the non-transitory memory, display the new intra-oral image on the display, or both.","34","14/610184","2015-01-30","2016-0225151","2016-08-04","10074178","2018-09-11","DENTAL IMAGING TECHNOLOGIES CORPORATION","George John  Cocco | Adam T.  Palermo","","","","G06T-0007/0028","G06T-0007/0028 | A61B-0005/0088 | A61B-0006/145 | A61B-0006/463 | A61B-0006/5235 | G06F-0017/3028 | G06K-0009/4604 | G06K-0009/4652 | G06K-0009/6201 | G06T-0007/0012 | G06T-0007/13 | G06T-0007/33 | G06T-0007/90 | H04N-0005/23293 | H04N-0005/33 | H04N-0007/18 | G06K-2009/4666 | G06T-2207/30036","G06T-007/00","G06T-007/00 | A61B-006/14 | A61B-006/00 | A61B-005/00 | G06F-017/30 | G06K-009/46 | G06K-009/62 | H04N-005/232 | H04N-005/33 | H04N-007/18 | G06T-007/33 | G06T-007/13 | G06T-007/90","","","","","","4918037004305"
"US","US","P","B2","Identifying hand gestures based on muscle movement in the arm","Embodiments described herein include an arm band that captures sensor data used to identify hand gestures. When worn on the arm, the arm band permits a computing device to identify different gestures made by the hand. In one embodiment, the band measures a change in position of the tendons that control the positions of the fingers on the hand which can then be correlated to a particular hand gesture. For example, the thickness of the user's arm increases in a direction perpendicular to the palm of the hand when the fingers are extended relative to the thickness of the arm when the fingers are curled into the palm of the hand. By detecting this change in thickness, the computing device can distinguish between different gestures.","1. An arm band, comprising: a first portion;a second portion;a pivoting element coupled to respective first ends of the first and second portions, wherein the pivoting element permits respective second ends of the first and second portions opposite of the first ends to separate relative to each other; anda sensor configured to, when the arm band is worn on the arm, generate an output signal indicative of a thickness of the arm in a direction substantially perpendicular to a palm of a hand.","14","14/823685","2015-08-11","2017-0045946","2017-02-16","10067564","2018-09-04","DISNEY ENTERPRISES, INC.","Lanny S.  Smoot | Michael P.  Goslin | Daniel James  Reetz | Joseph L.  Olson","","","","G06F-0003/014","G06F-0003/014 | A61B-0005/6824 | G06F-0001/163 | G06F-0003/011 | G06F-0003/017 | G06F-0003/03 | G06T-0007/0022 | G06T-0011/206 | A44C-0005/00","G06F-003/01","G06F-003/01 | G06F-003/03 | G06T-011/20 | G06T-007/00 | A61B-005/00 | G06F-001/16 | A44C-005/00","","","","","","4918036003984"
"US","US","P","B2","Methods and apparatus for identifying potentially seizure-inducing virtual reality content","Methods and apparatus for identifying potentially seizure-inducing virtual reality content are disclosed herein. An example apparatus includes a virtual reality presentation device to display virtual reality content for exposure to a user and a neurological data collector to access first neurological response data collected from the user during exposure to the virtual reality content. The example apparatus includes a predictor to generate a prediction on a likelihood that a portion of the virtual reality content will trigger a seizure based on a first vector characterizing the portion and the first neurological response data. The example apparatus includes a content modifier to modify the portion of the virtual reality content into modified virtual reality content in response to the prediction. The content modifier is to transmit the modified virtual reality content to the virtual reality presentation device.","1. An apparatus for analyzing virtual reality content, the apparatus comprising: a virtual reality presentation device to display the virtual reality content for exposure to a user;a neurological data collector to access first neurological response data collected from the user during exposure to the virtual reality content;a predictor to generate a prediction on a likelihood that a portion of the virtual reality content will trigger a seizure based on a first vector characterizing the portion and the first neurological response data; anda content modifier to modify the portion of the virtual reality content into modified virtual reality content in response to the prediction, the content modifier to transmit the modified virtual reality content to the virtual reality presentation device.","20","15/279820","2016-09-29","2018-0088669","2018-03-29","10067565","2018-09-04","INTEL CORPORTATION","Nishanth  Ramaprakash | Sreenidhi Koti Ananda  Rao","","","","G06F-0003/015","G06F-0003/015 | A61B-0005/4094 | G06K-0009/00744 | G06T-0005/009 | G06T-0011/60 | G06T-2207/20208","G06F-003/01","G06F-003/01 | A61B-005/00 | G06T-011/60 | G06K-009/00 | G06T-005/00","","","","","","4918036003985"
"US","US","P","B2","Systems and methods for determining orientation of an implanted lead","A method and system for identifying a rotational orientation of an implanted electrical stimulation lead utilize radiological images of the lead. The lead has an asymmetric marker with a longitudinal band extending around a portion of the circumference of the lead. The method and system includes obtaining radiological images of the lead; generating an isosurface image from the radiological images and displaying the isosurface image on a display device, where the isosurface image comprises an image of the longitudinal band of the marker; identifying a bulge in the isosurface image corresponding the longitudinal band of the marker; and determining a rotational orientation of the lead based on the rotational orientation of the bulge in the isosurface image.","1. A method for identifying a rotational orientation of an implanted electrical stimulation lead, the method comprising: obtaining a plurality of radiological images of the lead, the lead comprising a lead body, a plurality of segmented electrodes disposed along a distal portion of the lead body, and an asymmetric marker disposed along the distal portion of the lead body and comprising a longitudinal band that extends around a portion of a circumference of the lead body and defines a marker window extending around a remainder of the circumference of the lead body and opposite the longitudinal band, wherein the asymmetric marker and lead body are formed of different materials that are distinguishable from each other in the radiological images, wherein each segmented electrode extends around no more than 50% of a circumference of the lead body;generating an isosurface image from the plurality of radiological images and displaying the isosurface image on a display device, wherein the isosurface image comprises an image of the longitudinal band of the marker;identifying a bulge in the isosurface image corresponding the longitudinal band of the marker; anddetermining a rotational orientation of the lead based on a rotational orientation of the bulge in the isosurface image.","20","15/244977","2016-08-23","2017-0061627","2017-03-02","10067659","2018-09-04","BOSTON SCIENTIFIC NEUROMODULATION CORPORATION","Hemant  Bokil","","","","G06F-0003/04845","G06F-0003/04845 | A61B-0006/12 | A61B-0090/39 | A61N-0001/0534 | A61N-0001/0551 | A61N-0001/372 | G06F-0003/04842 | G06T-0007/73 | A61B-2090/3966 | G06T-2200/24 | G06T-2207/10004 | G16H-0040/63","G06K-009/00","G06K-009/00 | A61B-005/00 | G06F-003/0484 | A61B-006/12 | A61N-001/05 | A61N-001/372 | A61B-090/00 | G06T-007/73 | G16H-040/63","","","","","","4918036004079"
"US","US","P","B2","Compatibility checking for user interface customization","Example embodiments of compatibility checking for user interface customization are described. In an example embodiment, a first user interface view including first data items is accessed, each of the first data items referencing a corresponding data item of a data source. Whether the first user interface view is referenced by a second user interface view is determined. Based on the first user interface view not being referenced by a second user interface view, changes to any of the first data items of the first user interface view are allowed during a design time of the first user interface view. Based on the first user interface view being referenced by the second user interface view, one or more of the first data items of the first user interface view being referenced by the second user interface view are identified, and changes to the identified data items are prevented.","1. A system comprising: one or more hardware processors; anda memory storing instructions that, when executed by at least one of the one or more hardware processors, cause the system to perform operations comprising: accessing a first user interface view comprising a first plurality of data items, each of the first plurality of data items referencing a corresponding data item of a data source;determining whether the first user interface view is referenced by a second user interface view;based on the first user interface view not being referenced by a second user interface view, allowing changes to any of the first plurality of data items of the first user interface view during a design time of the first user interface view;based on the first user interface view being referenced by a second user interface view, identifying one or more of the first plurality of data items of the first user interface view being referenced by the second user interface view; andpreventing changes to at least the one or more of the first plurality of data items of the first user interface view during the design time of the first user interface view.","20","15/248177","2016-08-26","2018-0059892","2018-03-01","10067773","2018-09-04","SAP SE","Andreas  Riehl | Sonja  Barnet | Gibo Thomas  Pulipara","","","","G06F-0009/451","G06F-0009/451 | A61B-0005/7435 | G06F-0003/0481 | G06F-0003/0484","A61B-005/00","A61B-005/00 | G06F-009/451 | G06F-003/0484 | G06F-003/0481","","","","","","4918036004193"
"US","US","P","B2","Medical diagnosis support system","This invention provides a mechanism for making a doctor surely follow correct procedures in which the doctor confirms diagnosis information obtained by computer processing after he or she has completed interpretation. A medical diagnosis support apparatus executes diagnosis processing for acquiring medical diagnosis information from an image to be interpreted by computer processing. The medical diagnosis support apparatus accepts interpretation information as an interpretation result of the image to be interpreted, which information is input by, for example, a doctor. The medical diagnosis support apparatus calculates a degree of matching between the diagnosis information and interpretation information, and permits to present the diagnosis information acquired by the diagnosis processing when the calculated degree of matching exceeds a predetermined threshold.","1. A medical diagnosis support apparatus comprising: at least one processor; andat least one memory storing instructions which, when executed by the at least one processor, cause the apparatus to: acquire medical diagnosis information from an image to be interpreted by computer processing;receive from a user interpretation information as an interpretation result of the image to be interpreted;calculate a degree of matching between the acquired diagnosis information and the interpretation information; andpermit, when the calculated degree of matching exceeds a predetermined threshold, presentation of the acquired diagnosis information,wherein presentation of the acquired diagnosis information is inhibited when the calculated degree of matching does not exceed the predetermined threshold.","12","12/748324","2010-03-26","2010-0256459","2010-10-07","10068056","2018-09-04","CANON KABUSHIKI KAISHA","Kazuhiro  Miyasa | Yoshio  Iizuka | Akihiro  Katayama | Ryo  Ishikawa","2007-256009","JP","2007-09-28","G06F-0019/321","G06F-0019/321 | G06Q-0050/22","A61B-005/00","A61B-005/00 | G06F-019/00 | G06Q-050/22","","","","","","4918036004476"
"US","US","P","B2","Information processing device, recording medium, and information processing method","A non-transitory computer readable storage device includes a storage medium having a downloaded application stored therein. The downloaded application has instructions that when executed by processing circuitry configure the processing circuitry to receive sensor data from a sensor. The sensor is attached to a person or attached to an item used by the person. The processing circuitry also analyzes a motion pattern in the sensor data to identify a predetermined event in the motion pattern, the predetermined event captured in an image or series of images by an image capture device.","1. A non-transitory computer readable storage device having computer-readable instructions of an application thereon which when executed by processing circuitry cause the processing circuitry to perform a method comprising: receiving sensor data from a sensor, the sensor being attached to a person or attached to an item used by the person;analyzing a motion pattern in the sensor data to identify a predetermined event in the motion pattern, the predetermined event being captured in an image or series of images by an image capture device;generating a control signal to control an image capture process in the image capture device to select the image or series of images;generating the control signal with information that specifies a time that serves as an image selection reference; andselecting a portion of a series of consecutive images captured before and after the predetermined event by skipping, at unequal intervals with reference to the predetermined event, some images of the series of consecutive images before and after the predetermined event.","19","14/917201","2014-09-29","2016-0205317","2016-07-14","10070046","2018-09-04","SONY CORPORATION","Takaomi  Kimura | Hideyuki  Matsunaga | Kosei  Yamashita | Naofumi  Fukasawa","2013-221287","JP","2013-10-24","H04N-0005/23219","H04N-0005/23219 | G06K-0009/00342 | G09B-0019/0038 | H04N-0005/23245 | A61B-0005/11 | A61B-2503/10 | A61B-2562/0219 | G06F-0003/017 | G06F-0003/0488 | H04N-0021/84 | H04N-0021/8456","H04N-005/232","H04N-005/232 | G09B-019/00 | G06K-009/00 | G06F-003/01 | G06F-003/0488 | A61B-005/11 | H04N-021/84 | H04N-021/845","","","","","","4918036006454"
"US","US","P","B2","Neural monitor-based dynamic boundaries","A computer-assisted surgery system may have a robotic arm including a surgical tool and a processor communicatively connected to the robotic aim. The processor may be configured to receive, from a neural monitor, a signal indicative of a distance between the surgical tool and a portion of a patient's anatomy including nervous tissue. The processor may be further configured to generate a command for altering a degree to which the robotic aim resists movement based on the signal received from the neural monitor; and send the command to the robotic arm.","1. A computer-implemented method for controlling a surgical system, the method comprising: receiving, from a neural monitor, a signal indicative of a distance between a surgical tool connected to a robotic device and a portion of a patient'ss anatomy;receiving a joint angular velocity of one or more joints of the robotic device;determining a neural monitor gain based on the signal received from the neural monitor;generating a first force value based on the neural monitor gain and the joint angular velocity of the one or more joints of the robotic device;generating a second force value based on a relationship of a surgical tool and a virtual boundary associated with the patient'ss anatomy; andgenerating a robotic control to control the surgical system by altering movement of the robotic device based upon the first force value and the second force value.","7","15/796282","2017-10-27","2018-0064492","2018-03-08","10058392","2018-08-28","MAKO SURGICAL CORP.","Chris Alan  Lightcap | Hyosig  Kang | Arthur E.  Quaid, III | Rony  Abovitz","","","","A61B-0034/10","A61B-0034/10 | A61B-0005/04001 | A61B-0005/0488 | A61B-0005/4836 | A61B-0017/1671 | A61B-0017/1757 | A61B-0017/7092 | A61B-0017/86 | A61B-0034/30 | A61B-0034/70 | A61F-0002/30942 | G06F-0003/016 | A61B-0005/1127 | A61B-0005/745 | A61B-0017/7032 | A61B-0034/74 | A61B-2017/0003 | A61B-2017/00119 | A61B-2017/00725 | A61B-2034/107 | A61B-2034/108 | A61B-2034/305 | A61B-2034/306 | A61F-0002/38 | A61F-2002/4632 | A61F-2002/4633 | G05B-2219/36432 | G05B-2219/39196 | G05B-2219/40478 | G05B-2219/45117 | G05B-2219/45171 | Y10S-0901/08 | Y10S-0901/09","G05B-015/00","G05B-015/00 | G05B-019/00 | A61B-034/10 | A61B-034/00 | G06F-003/01 | A61F-002/30 | A61B-017/86 | A61B-017/70 | A61B-017/17 | A61B-017/16 | A61B-005/00 | A61B-005/0488 | A61B-005/04 | A61B-034/30 | A61F-002/46 | A61F-002/38 | A61B-017/00 | A61B-005/11","","","","","","4918035001126"
"US","US","P","B2","Global standard template creation, storage, and modification","Methods and systems for a complete vehicle ecosystem are provided. Specifically, systems that when taken alone, or together, provide an individual or group of individuals with an intuitive and comfortable vehicular environment. The present disclosure includes a system to create, modify, and maintain profiles associated with users. The user profiles are generated based on selectively collecting data associated with the users. Although each user profile may include settings, preferences, habits, and content associated with an individual user and/or vehicle, some user profiles may represent multiple users. These user profiles can change a configuration of a vehicle to match settings for a user, such as a driver and/or passenger. The configurations may also include the recognition of a unique set of gestures for a user. Further, the user profiles can be transferred from vehicle-to-vehicle and/or user-to-user.","1. A method, comprising: with a computer processor, retrieving a global standard vehicle template from a memory, the global standard vehicle template having information corresponding to at least one of a state and an arrangement of a feature associated with a vehicle;with a computer processor, adjusting, based at least partially on the information in the global standard vehicle template, the at least one of the state and the arrangement of the feature associated with the vehicle;with a computer processor, storing at least some of the information of the global standard vehicle template in a user profile memory associated with a user of the vehicle;with a computer processor, transferring the at least some of the information of the global standard vehicle template from the user profile memory to a different vehicle;with a computer processor, determining if the global standard vehicle template is compatible with the different vehicle and, if not, determining that conversion will be necessary;if conversion is determined to be necessary, with a computer processor, converting the at least some of the information of the global standard vehicle template to match characteristics associated with the different vehicle, wherein the conversion includes determining a template conversion factor; andif conversion is determined to be necessary, with a computer processor, adjusting, based at least partially on the conversion, at least one of a state and an arrangement of a feature associated with the different vehicle;further, in cases where the template conversion factor does not allow all of the information of the global standard vehicle template to match characteristics associated with the different vehicle, receiving settings made by the user in configuring the second vehicle and storing the settings along with the converted information.","9","15/400939","2017-01-06","2017-0249095","2017-08-31","10059342","2018-08-28","AUTOCONNECT HOLDINGS LLC","Christopher P.  Ricci","","","","B60W-0040/08","B60W-0040/08 | A61B-0005/0077 | A61B-0005/4809 | A61B-0005/6808 | A61B-0005/742 | A61B-0005/7405 | A61B-0007/04 | B60C-0001/00 | B60H-0001/00742 | B60K-0035/00 | B60N-0002/0244 | B60Q-0001/00 | B60Q-0009/00 | B60R-0016/037 | B60R-0016/0373 | B60R-0025/00 | B60R-0025/01 | B60R-0025/102 | B60R-0025/1004 | B60R-0025/20 | B60R-0025/25 | B60W-0040/09 | B60W-0050/08 | B60W-0050/10 | G01C-0021/206 | G01C-0021/26 | G01C-0021/28 | G01C-0021/3415 | G01C-0021/3446 | G01C-0021/3476 | G01C-0021/3484 | G01C-0021/36 | G01C-0021/365 | G01C-0021/3617 | G01C-0021/3629 | G01C-0021/3641 | G01C-0021/3647 | G01C-0021/3667 | G01C-0021/3691 | G01C-0021/3697 | G01S-0019/42 | G05D-0001/0016 | G05D-0001/0022 | G05D-0001/0027 | G05D-0001/0212 | G05D-0001/0276 | G05D-0023/1917 | G06F-0003/013 | G06F-0003/016 | G06F-0003/017 | G06F-0003/0481 | G06F-0003/0482 | G06F-0003/04842 | G06F-0003/04886 | G06F-0003/0622 | G06F-0003/0637 | G06F-0003/0673 | G06F-0003/167 | G06F-0008/65 | G06F-0009/451 | G06F-0017/28 | G06F-0017/3056 | G06F-0017/30203 | G06F-0017/30247 | G06F-0017/30528 | G06F-0017/30557 | G06F-0017/30864 | G06F-0021/00 | G06F-0021/31 | G06F-0021/32 | G06K-0009/00255 | G06K-0009/00268 | G06K-0009/00288 | G06K-0009/00335 | G06K-0009/00355 | G06K-0009/00832 | G06K-0009/00838 | G06Q-0010/00 | G06Q-0010/02 | G06Q-0010/20 | G06Q-0020/145 | G06Q-0030/00 | G06Q-0030/012 | G06Q-0030/0265 | G06Q-0030/0266 | G06Q-0030/0633 | G06Q-0030/0639 | G06Q-0030/0641 | G06Q-0030/0645 | G06Q-0050/30 | G07C-0005/00 | G07C-0005/006 | G07C-0005/008 | G07C-0005/02 | G07C-0005/085 | G07C-0005/0808 | G07C-0009/00126 | G07C-0009/00158 | G08B-0013/19647 | G08B-0021/0205 | G08B-0021/06 | G08B-0021/18 | G08B-0025/016 | G08B-0029/188 | G08G-0001/01 | G08G-0001/07 | G08G-0001/0965 | G08G-0001/0968 | G08G-0001/096725 | G08G-0001/096741 | G08G-0001/096775 | G08G-0001/096805 | G08G-0001/096811 | G08G-0001/096844 | G08G-0001/164 | G08G-0001/166 | G08G-0001/207 | G09G-0005/37 | H04L-0051/02 | H04L-0063/0236 | H04L-0063/0428 | H04L-0063/08 | H04L-0063/102 | H04L-0067/10 | H04L-0067/12 | H04L-0067/26 | H04L-0067/306 | H04N-0021/214 | H04N-0021/2181 | H04N-0021/2225 | H04N-0021/2265 | H04N-0021/2393 | H04N-0021/25816 | H04N-0021/25841 | H04N-0021/41422 | H04N-0021/43615 | H04N-0021/43637 | H04N-0021/454 | H04N-0021/4542 | H04N-0021/4751 | H04N-0021/6408 | H04N-0021/64322 | H04W-0004/021 | H04W-0004/04 | H04W-0004/046 | H04W-0004/12 | H04W-0004/21 | H04W-0004/40 | H04W-0004/60 | H04W-0004/70 | H04W-0004/80 | H04W-0012/08 | H04W-0036/0005 | H04W-0036/32 | H04W-0036/34 | H04W-0048/02 | H04W-0048/04 | H04W-0076/11 | H04W-0076/19 | H04W-0084/18 | H05K-0999/00 | A61B-2503/04 | B60K-2350/1004 | B60K-2350/1052 | B60K-2350/1056 | B60K-2350/352 | B60K-2350/965 | B60Q-0001/52 | B60R-0011/04 | B60R-0025/2081 | B60R-0025/257 | B60W-0050/085 | B60W-2040/0809 | B60W-2040/0881 | B60W-2050/146 | B60W-2540/00 | B60W-2540/12 | B60W-2540/18 | B60W-2540/30 | G01C-0021/362 | G02B-0027/0093 | G05D-0001/021 | G06F-0003/0488 | G06F-2203/04803 | G06K-0009/00221 | G06K-2009/00939 | G09G-2354/00 | G09G-2380/10 | H04L-0067/34 | H04N-0007/181 | H04W-0012/06 | H04W-0084/005","B60W-040/08","B60W-040/08 | G07C-009/00 | H04W-048/04 | H04W-036/34 | G06F-003/0488 | H04W-036/00 | H04N-021/2225 | H04N-021/226 | H04N-021/239 | H04N-021/258 | H04N-021/436 | H04N-021/4363 | H04N-021/454 | H04N-021/6408 | H04N-021/643 | H04W-084/18 | H04W-004/21 | H04W-004/60 | H04W-076/11 | G08B-025/01 | G08G-001/0965 | H04W-048/02 | H04W-004/12 | G05D-023/19 | G05D-001/00 | G05D-001/02 | B60W-040/09 | B60W-050/08 | G06F-003/01 | H04W-004/04 | H04W-036/32 | G08G-001/16 | G01C-021/36 | G01C-021/26 | H04N-021/414 | G08G-001/0967 | H04W-012/08 | G08B-013/196 | G08B-021/06 | G08B-029/18 | B60R-025/10 | G06F-021/31 | G06F-021/32 | H04L-029/08 | B60Q-001/00 | B60R-016/037 | G06F-003/0481 | G06F-003/0484 | G06F-008/65 | G06F-017/28 | G06F-017/30 | G06F-021/00 | G06K-009/00 | G06Q-010/02 | G06Q-010/00 | G06Q-020/14 | G06Q-030/00 | G06Q-030/02 | G06Q-030/06 | G06Q-050/30 | G07C-005/00 | G07C-005/08 | G08B-021/02 | H04L-029/06 | H04N-021/214 | H04N-021/218 | H04N-021/475 | B60R-025/00 | G07C-005/02 | B60W-050/10 | B60R-025/01 | B60K-035/00 | G08G-001/01 | B60C-001/00 | G06F-003/06 | A61B-005/00 | A61B-007/04 | B60Q-009/00 | H04W-076/19 | G06F-003/16 | G08G-001/07 | G08G-001/0968 | H04W-004/70 | H04W-004/80 | B60R-025/20 | G01C-021/20 | G01S-019/42 | B60H-001/00 | B60N-002/02 | G01C-021/34 | B60R-025/102 | B60R-025/25 | G06F-009/451 | G09G-005/37 | H04L-012/58 | H04W-004/021 | G01C-021/28 | G06F-003/0482 | G08G-001/00 | G08B-021/18 | H04W-004/40 | H04W-084/00 | H04N-007/18 | H04W-012/06 | B60Q-001/52 | B60R-011/04 | G02B-027/00 | B60W-050/14","","","","","","4918035002073"
"US","US","P","B2","Method and apparatus for configurable systems","The invention relates to methods and devices to define and control the design of a configurable chip module, instrument or systems, for example, for measurement, control and communication systems or any portion thereof. The module may include one or more chip elements. This can be achieved using, for example, a Graphical User interface (GUI), that transforms selections made by the user to a hardware and/or software configuration for the system in a process transparent to the user. This enables implementation of a plurality of devices and larger subsystems on a chip or chip module without specific semiconductor design knowledge from the user. This transformation process is thus accomplished transparently to the user, who operates the GUI to define the measurement or action which needs to be performed thereby resulting in an automatic combination of hardware and/or software elements available to create a specific configuration.","1. A user configurable instrument comprising: a plurality of analog elements;a plurality of digital elements;a plurality of connection elements connecting the plurality of analog elements and the plurality of digital elements; anda configurable user interface system, using at least one of a processor and a programmable logic device, that: provides a user interface that allows a user to enter a plurality of design inputs such that the user configurable instrument performs a particular action;receives, via the user interface, the plurality of design inputs to generate the user configurable instrument that performs the particular action;determines, based on the plurality of design inputs, which of the plurality of analog elements and the plurality of digital elements to connect using at least one of the plurality of connection elements such that the user configurable instrument is configured to perform the particular action; andautomatically causes, based on the determination, at least one of the plurality of connection elements to connect at least a first element selected from the plurality of analog elements and the plurality of digital elements to at least a second element selected from the plurality of analog elements and the plurality of digital elements.","22","14/068792","2013-10-31","2015-0277680","2015-10-01","10061483","2018-08-28","INNOVATIONS HOLDINGS, L.L.C.","Ewa  Herbst","","","","G06F-0003/0484","G06F-0003/0484 | A61N-0001/08 | A61N-0001/32 | G06F-0003/0481 | H01L-0027/0207 | A61N-0001/36014 | A61N-0001/37247","G06F-017/50","G06F-017/50 | G06F-003/0484 | A61N-001/08 | A61N-001/32 | H01L-027/02 | G06F-003/0481 | A61N-001/36 | A61N-001/372","","","","","","4918035004205"
"US","US","P","B2","Systems and methods for emulating RFID transponders of a plurality of medical devices","A radio frequency identification (RFID) network is presented including a plurality of medical devices each including an RFID transponder and a single RFID transponder emulator configured to emulate functionality of each of the RFID transponders of the plurality of medical devices. The RFID network further includes a plurality of RFID interrogation devices configured to operatively communicate with the single RFID transponder emulator. The single RFID transponder emulator is used for development, testing, evaluation, and validation of each of the plurality of RFID interrogation devices.","1. A system comprising: a plurality of medical devices each including a radio frequency identification (RFID) transponder storing a data set; andan RFID transponder emulator storing a plurality of data sets, each of the plurality of data sets corresponding to the data set stored in each of the RFID transponders of the plurality of medical devices, the RFID transponder emulator configured to emulate, using the stored plurality of data sets, functionality of each of the RFID transponders of the plurality of medical devices, the RFID transponder emulator including a user interface for selecting a mode from a plurality of modes of operation and which of the RFID transponders to emulate.","18","14/806339","2015-07-22","2016-0055359","2016-02-25","10061948","2018-08-28","COVIDIEN LP","Jeffrey L.  Jensen | William Gary  Paterson | Erich M.  Velandia | Paul E.  Ourada","","","","G06K-0007/10366","G06K-0007/10366 | A61B-0090/00 | A61B-0090/98 | G06K-0007/0095 | G06K-0019/0725 | G06Q-0050/22 | A61B-2018/00988 | G06K-2017/009 | G06Q-0010/08","G06K-007/10","G06K-007/10 | A61B-090/00 | G06K-007/00 | G06K-019/07 | A61B-090/98 | G06Q-050/22 | G06Q-010/08 | G06K-017/00 | A61B-018/00","","","","","","4918035004668"
"US","US","P","B1","Smart mirror","A mirror system includes a visual display disposed to convey information and images during an active period; and the visual display disposed to provide a reflected image during an inactive period; a multi-spectral 3D camera including a high definition video camera and an infrared camera; and a processor coupled to the visual display and the multi-spectral 3D camera.","1. A system, comprising: a mirror;an augmented reality display disposed as part of the mirror to convey digital information and images during an active period;a multi-spectral module in the mirror including a video camera and an infrared camera to determine a body shape or dimension for a user;a high definition video camera in the mirror, the high definition video camera capturing images of the user and one or more items worn or in contact with the user;a wearable heart rate sensor and a temperature sensor worn by the user; anda processor coupled to the augmented reality display; anda genetic sequencer or mass spectrometer.","18","15/451321","2017-03-06","","","10052026","2018-08-21","Bao Tran","Bao  Tran","","","","A61B-0005/0075","A61B-0005/0075 | A61B-0005/0077 | A61B-0005/02055 | A61B-0005/165 | A61B-0005/4815 | A61B-0005/742 | C12Q-0001/6883 | C12Q-0001/6886 | G01N-0030/724 | G01N-0033/6848 | G06F-0017/3087 | G06F-0017/30973 | G06F-0017/30979 | G06F-0019/3418 | G06F-0019/3431 | G06K-0009/00369 | G06T-0007/0012 | G06T-0011/60 | G06T-0019/006 | G06T-0019/20 | H04N-0005/33 | H04N-0013/025 | G01N-2570/00 | G06T-2207/10028 | G06T-2207/30201","A61B-005/0245","A61B-005/0245 | A61B-005/15 | A61B-005/103 | A61B-005/00 | G06T-019/20 | G06K-009/00 | H04N-005/33 | G06T-011/60 | G06T-019/00 | H04N-013/02 | G06T-007/00 | A61B-005/16 | A61B-005/0205 | G01N-030/72 | C12Q-001/6886 | C12Q-001/6883 | G01N-033/68 | G06F-019/00 | G06F-017/30","","","","","","4918034000907"
"US","US","P","B2","Data output device and method, and non-transitory computer readable medium","A data output device capable of simply performing both of recognition of an entire image at an important point in time regarding medical care and recognition of a detailed change in time series data at the point in time is provided. A data display screen includes first and second display areas. In the first display area, time-series data indicating a state transition of a patient or content related to medical care performed on the patient is displayed in a graph. First indicators can be assigned to the graph. Second indicators are displayed at corresponding positions in the second display area that temporally correspond to designated positions in the first display area to which the first indicators are assigned. A second time axis in the second display area has a time scale which is longer than that of a first time axis in the first display area.","1. A data output device for displaying time-series data indicating at least one of a state transition of a patient or content of medical care performed on the patient, the data output device comprising: a processor configured to perform the functions of:generating screen data of a data display screen including a first display area for displaying the time-series data, and a second display area for displaying a time axis in a time scale relatively longer than that of the first display area;receiving an indicator assignment instruction to assign a first indicator to a designated position designated on the time-series data; andassigning the first indicator at the designated position in the first display area on the basis of the indicator assignment instruction, and assigns a second indicator indicating that there is the first indicator to a corresponding position that temporally corresponds to the designated position in the second display area,wherein the data display screen includes a list display area for displaying content of a plurality of first indicators as a list, in addition to the first display area and the second display area,wherein the first indicator is associated with an attribute of the time-series data to which the first indicator is assigned, andwherein in the list display area, the first indicators to be displayed are narrowed down from among the plurality of first indicators according to the attribute.","14","15/279534","2016-09-29","2017-0014090","2017-01-19","10052072","2018-08-21","FUJIFILM CORPORATION","Akinari  Tsugo","2014-074276","JP","2014-03-31","A61B-0005/7425","A61B-0005/7425 | A61B-0005/00 | A61B-0005/02055 | A61B-0005/4836 | G06F-0003/048 | G06F-0003/0485 | G06F-0019/3456 | G06Q-0010/10 | G06Q-0050/24 | G09G-0005/006 | G09G-0005/18 | G16H-0015/00 | G16H-0040/63 | A61B-0005/021 | A61B-0005/024 | A61B-0005/0816 | G06F-0003/0482 | G06F-2203/04803 | G06T-0011/206 | G09G-2380/08","G06F-019/00","G06F-019/00 | G09G-005/00 | G09G-005/18 | A61B-005/00 | A61B-005/0205 | G06F-003/048 | G06F-003/0485 | G06Q-050/24 | G06Q-010/10 | G16H-040/63 | G16H-015/00 | A61B-005/021 | A61B-005/024 | A61B-005/08 | G06F-003/0482 | G06T-011/20","","","","","","4918034000953"
"US","US","P","B2","Scheduling device for customizable electronic notifications","An adjustable alarm indicator of an alarm application is described. The adjustable alarm indicator may be presented in connection with an alarm setting sequence. The adjustable alarm indicator may include a variable element having a variable annular shape, a first element associated with a first end of the variable element, and a second element associated with a second end of the variable element. The first element may be independently moveable to adjust the size of the variable element. The second element also may be independently moveable to adjust the size of the variable element.","1. A system, comprising: a memory configured to store computer-executable instructions;an input component;a processor in communication with the memory configured to execute the computer-executable instructions; anda display for presenting; a sleep alarm view of a graphical user interface during a scheduling phase of an alarm setting sequence in response to a first input received at the input component, the sleep alarm view presenting: an adjustable alarm indicator located in a first region of the sleep alarm view, the adjustable alarm indicator comprising a variable element having a variable annular shape comprising a first independently adjustable element associated with a suggested bedtime and a second independently adjustable element associated with an alarm time, the variable element moveable to cause the first independently adjustable element and the second independently adjustable element to move dependently; anda sleep graph located in a second region of the sleep alarm view, the sleep graph comprising one or more linear indicators, each corresponding to an interval, and indicating an amount of time slept during the interval and a sleep range corresponding to a period and comprising an earliest bedtime and a latest wake time.","20","15/838035","2017-12-11","2018-0101138","2018-04-12","10054909","2018-08-21","Apple Inc.","Roy J. E. M.  Raymann | Jay Kriz  Blahnik | Stephanie M.  Greer | Aroon  Pahwa | Jonathan T.  Varbel","","","","G04F-0003/06","G04F-0003/06 | A61B-0005/4812 | A61B-0005/4815 | A61B-0005/742 | G04G-0009/0064 | G04G-0013/02 | G04G-0021/025 | G06F-0003/04847 | G06F-0009/4443 | G06F-0009/451 | G06Q-0010/109","G04G-009/00","G04G-009/00 | G04G-013/02 | G04G-021/02 | G04F-003/06 | G06F-003/0484 | A61B-005/00 | G06Q-010/10 | G06F-009/44 | G06F-009/451","","","","","","4918034003782"
"US","US","P","B2","Method and apparatus for user-transparent system control using bio-input","A wearable sensor vehicle with a bio-input sensor and a processor. When the vehicle is worn, the sensor is arranged so as to sense bio-input from the user. The sensor senses bio-input, the processor compares the bio-input to a standard, and if the standard is met the processor indicates a response. The user may be uniquely identified from the bio-input. One or more systems on or communicating with the vehicle may be controlled transparently, without requiring direct action by the user. Control actions may include security identification of the user, logging in to accounts or programs, setting preferences, etc. The sensor collects bio-input substantially without instruction or dedicated action from the user; the processor compares bio-input against the standard substantially without instruction or dedicated action from the user; and the processor generates and/or implements a response based on the bio-input substantially without instruction or dedicated action from the user.","1. An apparatus, comprising: a vehicle adapted to be worn by an individual without restricting activity of the individual;a first sensor disposed on the vehicle, the first sensor to sense a cardiac wave of the individual with substantially no dedicated sensing action required from the individual and with sufficient sensitivity to identify the individual using a characteristic heart function of the body of the individual;a second sensor disposed on the vehicle, the second sensor to measure a variable input with substantially no dedicated sensing action required from the individual;a processor coupled to the first sensor, wherein the processor is to: identify a standard cardiac wave associated with the individual;receive the variable input from the second sensor;adjust the standard cardiac wave associated with the individual in view of the variable input to obtain an adjusted standard cardiac wave;compare data representative of the cardiac wave with data representative of the adjusted standard cardiac wave associated with the individual; andin response to data representative of the cardiac wave matching the data representative of the adjusted standard cardiac wave, perform a first subject service associated with the cardiac wave and the individual without any direct interaction by the individual with the apparatus.","45","14/087452","2013-11-22","2014-0159862","2014-06-12","10045718","2018-08-14","ATHEER, INC.","Allen Yang  Yang | Mohamed Nabil Hajj  Chehade | Sina  Fateh | Sleiman  Itani","","","","A61B-0005/1171","A61B-0005/1171 | A61B-0005/117 | A61B-0005/6803 | G06F-0001/163 | G06F-0003/015 | G06F-0021/10 | G06K-0009/00885 | G07C-0009/00158 | A61B-0005/7445 | G06K-2009/00939","G06F-001/16","G06F-001/16 | A61B-005/1171 | A61B-005/117 | G07C-009/00 | G06F-021/10 | G06F-003/01 | G06K-009/00 | A61B-005/00","","","","","","4918033001026"
"US","US","P","B2","Partial facial recognition and gaze detection for a medical system","A medical system automatically identifies a user based on matching a partial facial image of the user with a database of authorized users. The medical system automatically configures based on the user identification and received patient data. The medical system further automatically identifies a patient based on matching a facial image of the patient with an image of the patient to confirm the correct patient is in the operating room. The medical system still further provides for gaze detection and gesture control by a user such that the user in the sterile environment can directly control devices outside the sterile environment.","1. A medical system comprising: a computer;a storage device coupled to said computer, said storage device having system image data stored thereon related to at least one system user, the stored system image data including data points related to at least a portion of the at least one system user'ss face;at least one input device generating user image data, wherein the generated user image data includes data points related to a partial face of the at least one system user, said at least one input device coupled to said computer and transmitting the generated user image data to said computer;a partial facial recognition module executing on said computer, said partial facial recognition module receiving the generated user image data and comparing the data points of the generated user image data to the data points of the stored system image data;said partial facial recognition module matching the data points of the generated user image data with the data points of the stored system image data to identify the at least one system user and to authorize the identified at least one system user to control the functionality of said medical system, said functionality including control of a plurality of devices selected from medical tools, instruments, and equipment;a preferences module executing on said computer, said preferences module receiving preference settings associated with the identified at least one system user; anda configuration module executing on said computer, said configuration module configuring the medical system based at least in part on the received preference settings; the data points related to the partial face of the at least one system user are selected from data points corresponding to the at least one system user'ss bridge of the nose, forehead, or eyebrows.","29","14/865769","2015-09-25","2017-0086926","2017-03-30","10045825","2018-08-14","KARL STORZ IMAGING, INC.","Marc R.  Amling","","","","A61B-0034/25","A61B-0034/25 | G06F-0003/005 | G06F-0003/013 | G06F-0003/017 | G06F-0019/3406 | G06K-0009/00248 | G06K-0009/00288 | G06K-0009/00335 | G06T-0007/0012 | G16H-0040/63 | A61B-2017/00207 | A61B-2017/00216 | A61B-2034/258 | G06T-2207/30201","G06K-009/00","G06K-009/00 | A61B-034/00 | G16H-040/63 | G06F-003/00 | G06F-003/01 | G06T-007/00 | G06F-019/00 | A61B-017/00","","","","","","4918033001133"
"US","US","P","B2","Authentication system controlled by eye open and eye closed state, handheld control apparatus thereof and computer readable recording media","An authentication system controlled by eye open and eye closed state and a handheld control apparatus thereof are provided. The handheld control apparatus includes a housing case, an image capturing unit and a processing unit. The housing case has a window and is suitable for a user to hold. The image capturing unit is disposed in the housing case and captures an eye area of the user through the window to obtain an image sequence. The processing unit is coupled to the image capturing unit and analyzes the image sequence to obtain eye image information of the eye area of the user. The processing unit detects an eye-open state and an eye-closed state of the user based on the eye image information, converts a plurality of the eye-open states and the eye-closed states into a blink code, and accordingly generates a control command to control a security equipment.","1. A handheld control apparatus coupled to a security equipment and performing an authentication for a user, the apparatus comprising: a housing case having a window;an image capturing unit disposed within the housing case to capture a plurality of images of an eye area of the user through the window to obtain an image sequence, wherein the images of the image sequence are captured within a preset time period, the preset time period comprises a plurality of unit time periods sequentially connected in an order, and each of parts of the images are captured within each of the unit time periods; anda processing unit coupled to the image capturing unit and configured to analyze the image sequence to obtain eye image information of the eye area in the image sequence,wherein the processing unit sequentially detects whether a state of each of the images of the image sequences is an eye-open state or an eye-closed state based on the eye image information,wherein the processing unit sequentially generates a plurality of codes of a code sequence through the detected states of the images of the image sequences, wherein the codes comprises one or more first codes and one or more second codes, and,after the operation of generating the codes of the code sequence is complete, the processing unit generates a control command to control the security equipment according to the entire code sequence,wherein in the operation of the processing unit sequentially generates the plurality of codes of the code sequence through the detected statuses of the images of the image sequences:based on the order of the unit time periods, the processing unit sequentially generates one of the codes corresponding one of the unit time periods according to the states of images within the one of the unit time periods,wherein when the states of images within one of the unit time periods are detected as the eye-open states, the processing unit generates one first code as one code corresponding to the one of the unit time periods, wherein the first code is a bit value,wherein when the states of images within one of the unit time periods are detected as the eye-closed states, the processing unit generates one second code as one code corresponding to the one of the unit time periods, wherein the second code is another bit value different from the bit value of the first code,wherein the generated first codes and the second codes are arranged in the order of the unit time periods to form the code sequence.","19","14/510131","2014-10-09","2015-0186720","2015-07-02","10049271","2018-08-14","UTECHZONE CO., LTD.","Chia-Chun  Tsou | Chia-We  Hsu","102148804 A | 103106219 A","TW | TW","2013-12-27 | 2014-02-25","G06K-0009/00597","G06K-0009/00597 | A61B-0005/117 | A61B-0005/1171 | A61B-0005/6821 | G06F-0003/00 | G06F-0021/30 | G06F-0021/32 | G07C-0009/00142 | A61B-0005/6898 | A61B-2576/02 | G07C-0009/00158","G06K-009/00","G06K-009/00 | A61B-005/117 | A61B-005/1171 | G06F-003/00 | G06F-021/30 | G06F-021/32 | A61B-005/00 | G07C-009/00","","","","","","4918033004563"
"US","US","P","B1","Mobile law enforcement communication system and method","A communication system (200) provides a self-driving vehicle (122) having a plurality of processor controlled interface devices (230) that acquire input pertaining to a detainee and an infraction associated with the detainee located within the vehicle. The processor controlled interface devices (230) provide mobile law enforcement processing and proceedings of the detainee within the self-driving vehicle (122). The self-driving vehicle (122) automatically delivers the detainee to an approved location determined by the mobile law enforcement processes and proceedings.","1. A communication system, comprising: a self-driving vehicle within which to detain a detainee by a law enforcement officer;a plurality of interface devices located within the self-driving vehicle, the plurality of interface devices configured to acquire input pertaining to the detainee within the self-driving vehicle and an infraction associated with the detainee while the law enforcement officer remains in the field; andan electronic processor located within the self-driving vehicle, the electronic processor programmed to receive the acquired input pertaining to the detainee and the infraction, and the electronic processor enabling mobile law enforcement processes and proceedings via the plurality of interface devices located within the self-driving vehicle, the mobile law enforcement processes and proceedings providing both a virtual assistant to the detainee along with an interface to an on-call, remote judge and attorney for real-time mobile adjudication of the detainee within the self-driving vehicle and further providing delivery of the detainee to an approved location determined by the mobile law enforcement processes and proceedings.","22","15/696827","2017-09-06","","","10049419","2018-08-14","MOTOROLA SOLUTIONS, INC.","Alex  Marron | Anthony J.  Suppelsa | Barbara R.  Doutre","","","","G06Q-0050/26","G06Q-0050/26 | A61B-0005/082 | A61B-0005/1172 | G06F-0009/453 | H04L-0065/1069 | H04L-0065/403 | H04N-0007/142 | H04N-0007/147 | A61B-0005/1176 | A61B-0005/167 | G06F-0017/30424 | G06K-0009/00013 | G06K-0009/00288 | G06K-0009/00335 | G06Q-0020/14 | G06Q-0050/18","H04N-007/14","H04N-007/14 | G06Q-050/26 | H04L-029/06 | A61B-005/08 | A61B-005/1172 | G06F-009/451 | A61B-005/1171 | G06K-009/00 | G06Q-050/18 | G06Q-020/14 | G06F-017/30 | A61B-005/16","","","","","","4918033004710"
"US","US","P","B2","Control device and method for optimizing a presentation style of specific content for a specific user","The present invention relates to a control device (10) and method for controlling a display that reliably and efficiently enhances a person's compliance, e.g., a patient's compliance with his care plan. The control device comprises a presentation style selector (14) for selecting a presentation style to be used for visually presenting the received information on the display in text form, wherein the presentation style is selected based on an importance indicator indicating the importance of the information with respect to a task or plan of the person and obtained boundary conditions for the presentation style to be selected for presenting the information in text form such that more important information is displayed using a presentation style that is more difficult to read than a presentation style used for displaying less important information. A controller (15) controls the display (20) to visually present the received information on the display in text form using the selected presentation style.","1. A system for facilitating user-task/plan-based content presentation to affect user remembrance of content, the system comprising: one or more sensors configured to detect, during presentation of a first content portion, sympathetic autonomic activity data indicating a user'ss sympathetic autonomic activity related to a task or plan of the user; andone or more processors configured by machine-readable instructions to: receive content to be presented to the user, the content comprising the first content portion;obtain a first importance indicator indicating an importance of the first content portion with respect to the task or plan of the user;obtain, based on user data related to the user, presentation style boundary conditions, the presentation style boundary conditions indicating a presentation style set from which one or more presentation styles are to be selected for presenting the content to the user, the presentation style set comprising (i) a first presentation style associated with a first difficulty level and (ii) a second presentation style associated with a second difficulty level, the second difficulty level being indicative of requiring less effort from the user to read the content than the first difficulty level;select, based on the first importance indicator, from the presentation style set, the first presentation style to be used over at least the second presentation style for presenting the first content portion to the user;cause, via a display, presentation of the content based on the selected first presentation style such that the first presentation style is used to present the first content portion on the display;determine, during the presentation of the first content portion, based on the sympathetic autonomic activity data, whether the user'ss sympathetic autonomic activity corresponds to a baseline sympathetic autonomic activity level; andadjust, via the display, the presentation of the first content portion based on a determination that the user'ss sympathetic autonomic activity corresponds to the baseline sympathetic autonomic activity level such that a presentation style that is easier to read than the first presentation style is used to present the first content portion on the display.","13","15/105040","2014-12-12","2016-0322028","2016-11-03","10049645","2018-08-14","KONINKLIJKE PHILIPS N.V.","Melanie Jane  Windridge | Julian Charles  Nolan | Joyca Petra Wilma  Lacroix | Joris Hendrik  Janssen","2013-198796","EP","2013-12-20","G09G-0005/30","G09G-0005/30 | A61B-0005/044 | A61B-0005/4833 | A61B-0005/742 | A61B-0005/743 | G06F-0003/011 | G06F-0008/34 | G06F-0017/214 | G16H-0040/63 | A61B-0005/7435 | A61B-0005/7445","G06F-003/01","G06F-003/01 | G06F-003/048 | G06F-017/21 | A61B-005/00 | G09G-005/30 | G06F-019/00 | G06F-008/34 | A61B-005/044 | G16H-040/63","","","","","","4918033004934"
"US","US","P","B2","Medical monitoring with location and activity tracking","A method, system, and/or apparatus for automatically monitoring for possible mental or physical health concerns. The method or implementing software application uses or relies upon location information available on the mobile device from any source, such as cell phone usage and/or other device applications. The method and system automatically learns user activity patterns and detects significant deviations therefrom. The deviations are automatically analyzed for known correlations to mental or physical concerns, which can then be automatically communicated to a relevant friend, family member, and/or medical professional.","1. A method of determining medical conditions of users participating in a social networking service, the method executed by a computer system and comprising: automatically monitoring destinations and user activities performed at the destinations of a first user via a first electronic device of the first user;automatically determining positional locations of the first user, wherein automatically determining positional locations of a user comprises: providing a location module on the first electronic device configured to receive location transmissions;placing the location module into a sleep mode;awakening the location module upon receipt of a first location transmission;determining a first location with the location moduleincrementing a timer count configured to monitor a duration of time, wherein whenever a time exceeds a predetermined time allocation, the location module is placed into the sleep mode;incrementing a stationary counter configured to monitor a duration of time since a previous detected movement of the mobile user;receiving a second location transmission of a second location;comparing the second location to the first location;calculating a rate of travel when the second location differs from the first location, wherein if the rate of travel exceeds a predetermined threshold the location module is placed into the sleep mode;receiving a third location transmission of a third location;comparing the third location to at least one of the first location or the second location;further incrementing the stationary counter when the second or third location is the same as the first location;determining an arrival event upon reaching a predetermined arrival threshold of the stationary counter;storing data of all locations; andplacing the location module into the sleep mode;automatically awakening the location module at each of the destinations upon receipt of a corresponding location transmission;automatically determining as user information a location type and user activity at each of the destinations;automatically learning activity patterns from the user information at the destinations for the first user;automatically determining a deviation in the learned activity patterns;automatically analyzing the deviation to identify a significance of the deviation;automatically correlating the significance of the deviation to a possible medical condition; andautomatically alerting the first user via the first electronic device or a second user via a second electronic device of the possible medical condition upon the deviation significance meeting at least one predetermined threshold, wherein the alerting includes a visual communication of the deviation significance.","14","15/291819","2016-10-12","2017-0027529","2017-02-02","10039504","2018-08-07","PUSHD, INC.","Ophir  Frieder | Eric  Jensen | Abdur  Chowdhury | Ben  Cherry | Matt  Sanford","","","","A61B-0005/746","A61B-0005/746 | A61B-0005/1112 | A61B-0005/1118 | A61B-0005/1123 | A61B-0005/4866 | A61B-0005/6898 | A61B-0005/7246 | A61B-0005/7267 | A61B-0005/7282 | A61B-0005/7465 | G06F-0017/30867 | G06F-0021/552 | G16H-0040/63 | H04L-0051/20 | H04L-0051/32 | H04L-0051/38 | H04W-0004/02 | H04W-0004/023 | H04W-0004/029 | H04W-0004/043 | H04W-0004/12 | H04W-0004/21 | H04W-0052/0229 | H04W-0052/0254 | G06F-2221/2111 | H04L-0051/08 | H04M-0001/72569 | H04W-0064/006 | Y02D-0070/00 | Y02D-0070/142 | Y02D-0070/144 | Y02D-0070/164 | Y02D-0070/26","G06F-015/16","G06F-015/16 | A61B-005/00 | A61B-005/11 | H04L-012/58 | H04W-004/02 | H04W-004/12 | H04W-052/02 | H04W-004/04 | G06F-021/55 | G06F-017/30 | G16H-040/63 | H04W-004/21 | H04W-004/029 | H04W-064/00 | H04M-001/725","","","","","","4918032000809"
"US","US","P","B2","Providing assistance related to health","In one aspect, a method related to health-related data management. In addition to the foregoing, other method and system and program product aspects are described in the claims, drawings, and text forming a part of the present application.","1. A method for a computer processor related to health-related data management, the method comprising: controlling at least one network health regimen information database at least partially using one or more processing components including at least: providing health regimen information in the at least one network health regimen information database including one or more data structures linked by associative information;enabling a plurality of users of the at least one network health regimen information database at least to access, add, and modify information in the at least one network health regimen information database including at least enabling the plurality of users to modify one or more linkages between health regimen entities;accepting input information from at least one user of the plurality of users of the at least one network health regimen information database, the input information including at least information indicating at least one of patterns or correlations between health regimen entities in the health regimen information linked by associative information;automatically correlating one or more health regimen entities including adding associative information to the one or more data structures including at least one of pointers or identifiers indicating at least one or more linkages between two or more health regimen data entities based at least partly on the information indicating at least one of patterns or correlations between health regimen entities in the health regimen information linked by associative information and user modification of the one or more linkages between health regimen entities; andstoring the associative information to the one or more data structures including at least one of pointers or identifiers indicating at least one or more linkages between the two or more health regimen data entities, wherein accessibility to the health regimen entities in the at least one network health regimen information database is modified in response to the input information received from the at least one user.","38","11/283548","2005-11-17","2007-0112587","2007-05-17","10042980","2018-08-07","GEARBOX, LLC","Edward K. Y.  Jung | Royce A.  Levien | Robert W.  Lord | Mark A.  Malamud | John D.  Rinaldo, Jr. | Lowell L.  Wood, Jr.","","","","G06F-0019/324","G06F-0019/324 | G06F-0019/325 | G06F-0019/326 | G06Q-0010/087 | G06Q-0010/10 | G06Q-0030/0601 | G06Q-0050/22","A61B-005/00","A61B-005/00 | A61N-001/39 | G06F-019/00 | G06Q-010/08 | G06Q-010/10 | G06Q-030/06 | G06Q-050/22","","","","","","4918032004258"
"US","US","P","B2","Apparatus and method for fabricating a customized patient-specific orthopaedic instrument","A number of orthopedic surgical instruments are also disclosed. A method, apparatus, and system for fabricating such instruments are also disclosed.","1. A method for a vendor to create a customized patient-specific orthopaedic surgical instrument for a patient of a healthcare facility that is external to the vendor, comprising: receiving at the vendor, from the healthcare facility external to the vendor, an instrument request for a customized patient-specific orthopaedic surgical instrument that includes data relevant to the patient,creating at the vendor, in response to receiving the instrument request, a design plan that has been customized for the patient per data of the instrument request, the design plan including a plurality of instructions usable on a fabrication machine located at the healthcare facility to fabricate the customized patient-specific orthopaedic surgical instrument,sending the design plan from the vendor to the healthcare facility,loading the plurality of instructions onto a processor of the fabrication machine located at the healthcare facility, andoperating a the fabrication machine located at the healthcare facility to execute the plurality of instructions loaded on the fabrication machine to fabricate the customized patient-specific orthopaedic surgical instrument including a cutting slot sized to receive a cutting saw blade and a customized patient-specific negative contour shaped to receive a predetermined portion of the patient'ss bone per data of the design plan.","14","12/241001","2008-09-29","2009-0087276","2009-04-02","10028750","2018-07-24","DEPUY SYNTHES PRODUCTS, INC.","Bryan  Rose","","","","A61B-0017/155","A61B-0017/155 | A61B-0017/157 | A61B-0017/1764 | A61B-2017/00526 | A61B-2017/568 | A61B-2034/108 | Y10T-0409/30084","G06Q-010/00","G06Q-010/00 | G06Q-050/00 | A61B-017/15 | A61B-017/17 | A61B-017/00 | A61B-017/56 | A61B-034/10","","","","","","4918030000920"
"US","US","P","B2","Controlling audio tempo based on a target heart rate","A method for controlling an audio output comprises playing a first audio file having a first tempo, measuring a first heart rate of a user, determining whether the first heart rate of the user is greater than a target heart rate, and playing a second audio file having a second tempo, the second tempo is slower than the first tempo, responsive to determining that the first heart rate of the user is greater than the target heart rate.","1. A method for controlling an audio output, the method comprising: receiving a target heart rate for a user;calculating a warmup heart rate for the user based at least in part on the target heart rate;starting a warmup timer;playing a first audio file having a first tempo, wherein the first tempo corresponds to the warmup heart rate, wherein the first audio file includes music having the first tempo;determining whether the warmup timer has expired;responsive to determining that the warmup timer has not expired, measuring a first heart rate of the user,determining whether the first heart rate of the user is greater than the warmup heart rate, andresponsive to determining that the first heart rate of the user is greater than the warmup heart rate, playing a second audio file having a second tempo, the second tempo being slower than the first tempo; andresponsive to determining that the warmup timer has expired, playing a third audio file having a third tempo, wherein the third tempo corresponds to the target heart rate,measuring a second heart rate of a user,determining whether the second heart rate of the user is greater than the target heart rate,determining a time remaining in the third audio file,responsive to determining that the second heart rate of the user is greater than the target heart rate, playing a fourth audio file having a fourth tempo, the fourth tempo being slower than the third tempo,responsive to the time remaining in the third audio file being greater than a threshold, completing the playing the third audio file before playing the fourth audio file;determining whether an acceleration of the user is below an acceleration threshold,responsive to determining that the acceleration of the user is below the acceleration threshold, pausing the playing the third audio file or pausing the playing the fourth audio file, andplaying a fifth audio file having a fifth tempo, the fifth tempo being faster than the third tempo, responsive to determining that the second heart rate of the user is not greater than the target heart rate.","1","15/797543","2017-10-30","2018-0039476","2018-02-08","10031720","2018-07-24","INTERNATIONAL BUSINESS MACHINES CORPORATION","Adam T.  Bishop | Matthew R.  Catalfamo | Al  Chakra | Indrajit  Viswanath","","","","G06F-0003/165","G06F-0003/165 | A61B-0005/11 | G05B-0015/02 | G10H-2210/391 | G10H-2220/201","G06F-017/00","G06F-017/00 | G06F-003/16 | A61B-005/11 | G05B-015/02","","","","","","4918030003875"
"US","US","P","B2","Method, apparatus, and system for pushing network content","A method, an apparatus, and a system for pushing network content includes receiving an identity of a user and a current status parameter of the user, acquiring user information associated with the identity including personal information of the user and a browsing history of the user, selecting network content according to the status parameter and the user information, and pushing the network content to a terminal device configured to display the network content.","1. A method for pushing network content, comprising: receiving an identity of a user and a current status parameter of the user, wherein the current status parameter comprises a current motion status and a current heart rate detected by a wearable device associated with the user;acquiring user information associated with the identity, the user information comprising personal information of the user and a browsing history of the user;determining whether the current heart rate reaches a preset threshold;in response to determining that the current heart rate reaches the preset threshold, determining whether the current motion status is associated with a first activity predetermined to cause the current heart rate to reach the preset threshold;in response to determining that the current heart rate does not reach the preset threshold, selecting, based on the user information, network content associated with a second activity predetermined not to cause the current heart rate of the user to reach the preset threshold;based on a determination that the current heart rate reaches the preset threshold and the current motion status is associated with the first activity, selecting, based on the user information, network content associated with the first activity;based on a determination that the current heart rate reaches the preset threshold and the current motion status is not associated with the first activity, selecting, based on the user information, network content associated with an emotion of the user predetermined to cause the current heart rate to reach the preset threshold, wherein the emotion of the user is indicative of at least one of an emotional fluctuation and an emotional stress; andpushing the network content to a terminal device configured to display the network content.","20","14/737714","2015-06-12","2016-0105520","2016-04-14","10033821","2018-07-24","ANHUI HUAMI INFORMATION TECHNOLOGY CO., LTD.","Hui  Wang | Wang  Huang","2014-10531591","CN","2014-10-10","H04L-0067/26","H04L-0067/26 | A61B-0005/02438 | A61B-0005/1118 | A61B-0005/165 | G06F-0017/30867 | H04L-0067/22 | A61B-0005/1116","G06F-015/16","G06F-015/16 | H04L-029/08 | G06F-017/30 | A61B-005/024 | A61B-005/16 | A61B-005/11","","","","","","4918030005961"
"US","US","P","B2","Mobile self-management compliance and notification method, system and computer program product","A computerized interactive method, system and computer program product is provided for managing a person's health and lifestyle through self-managing controlled notifications, feedback, and alerts are disclosed. Embodiments provide computerized self-management and compliance scheme that does not require third party intervention or treatment options typical with immediate-response or alert-based systems. Monitoring, notification, and alert parameters can be partially or wholly self-managed using a graphical user interface or computerized device interface to enable two-way communication between the person and at least one computer server.","1. A computerized method of monitoring patient health using a patient-managed monitoring scheme, the method being performed by a server configured to manage a patient account associated with a patient and an administrator account associated with an administrator of the patient, the method comprising: receiving, from the patient via a device associated with the patient account, a proposed monitoring scheme for the patient, the proposed monitoring scheme comprising monitoring scheme settings configured by the patient, the monitoring scheme settings including: a query schedule for scheduling the transmission of a query to the device associated with the patient account, the query requesting response data; andan alert criterion and an alert procedure for at least one attribute associated with the query or the response data;activating the proposed monitoring scheme based on an approval information received from a device associated with the administrator account;generating the query based on the query schedule of the activated monitoring scheme;sending the generated query to the patient, via the device associated with the patient account, based on the query schedule; andreceiving the response data corresponding to the query from the device associated with the patient account.","22","15/012329","2016-02-01","2016-0147970","2016-05-26","10025906","2018-07-17","LIFEWIRE CORPORATION","Howard  Rosen | William  Harms | Chaitanya  Marvici","","","","G06F-0019/3418","G06F-0019/3418 | A61B-0005/0002 | G06F-0017/3051 | G06F-0017/30389 | G06Q-0010/1097 | G16H-0050/20 | A61B-0005/02 | A61B-0005/14532 | G16H-0010/20 | G16H-0010/60 | G16H-0015/00","A61B-005/00","A61B-005/00 | G06F-019/00 | G06F-017/30 | G06Q-010/10 | G16H-050/20 | A61B-005/02 | A61B-005/145 | G16H-010/20 | G16H-010/60 | G16H-015/00","","","","","","4918029004731"
"US","US","P","B2","Peak selection for self correlation analysis of cardiac rate in an implantable medical device","Self-correlation enhancements and implementations are described. In particular, certain examples demonstrate the use of a peak selector to identify peaks of a self-correlation function which serve as candidate cardiac rates for an implantable medical device. The approach may enable an alternative calculation of cardiac rate in an implantable medical device as a stand-alone rate detector or as a double-check of other rate calculations.","1. A method of analyzing cardiac signals in a medical device having a plurality of electrodes for sensing cardiac signals coupled to operational circuitry for at least performing analysis of sensed cardiac signals, the method comprising: generating a self-correlation function from the sensed cardiac signals, the self-correlation function having amplitudes as a function of lag depth; andidentifying amplitude peaks in the self-correlation function and finding a first estimate of cardiac rate by: identifying one or more candidate amplitude peaks each having lag depths;selecting a candidate peak having the least lag depth of the identified candidate amplitude peaks as a first candidate peak; andapplying a picket test to the first candidate peak by determining whether at least one additional peak appears at a second lag depth that is a multiple of the lag depth of the first candidate peak and, if so, finding that the picket test is passed for the first candidate peak;wherein the first estimate of cardiac rate is generated by converting the first lag depth to a time interval and converting the time interval into a rate in response to finding that the picket test was passed by the first candidate peak.","20","15/482004","2017-04-07","2017-0209063","2017-07-27","10016143","2018-07-10","Cameron Health, Inc.","Krzysztof Z.  Siejko","","","","A61B-0005/04012","A61B-0005/04012 | A61B-0005/0245 | A61B-0005/0422 | A61B-0005/0456 | A61B-0005/0464 | A61B-0005/04525 | A61B-0005/4836 | A61B-0005/686 | A61N-0001/3925 | A61N-0001/3956 | A61N-0001/3987 | G06F-0017/11 | G06F-0019/322 | G06F-0019/3418 | G16H-0010/60","A61B-005/04","A61B-005/04 | A61B-005/0456 | A61B-005/042 | A61B-005/00 | A61N-001/39 | A61B-005/0245 | A61B-005/0452 | A61B-005/0464 | G06F-017/11 | G06F-019/00 | G16H-010/60","","","","","","4918028000900"
"US","US","P","B2","Information processing apparatus, information processing method, and program","An information processing apparatus may include a processor to acquire information associated with behavior of a user and information associated with satisfaction degree of the user, and to analyze an association between the information associated with behavior and the information associated with satisfaction degree.","1. An information processing apparatus comprising: a processor configured to: acquire information associated with behavior of a user and information associated with a subjective satisfaction degree of the user in a period including the behavior input by selection by the user of an indication for inputting the subjective satisfaction degree;analyze an association between the information associated with the behavior and the information associated with the subjective satisfaction degree; andgenerate a behavior model of the user for display on a screen and indicating a body activity behavior pattern in relationship to subjective satisfaction over a predetermined time interval, based on integrated behavior information combining the information associated with the behavior and the information associated with the subjective satisfaction degree, in which the body activity behavior pattern includes a plurality of user body activity behaviors having different respective activity amounts set by the user as respective goals which is displayed on the screen with respective times set within the predetermined time interval for performing the goals, each of the plurality of user body activity behaviors being displayed with a total number of times the user achieved the goal of the user body activity behavior at the corresponding time and a numerical goal behavior score indicating how much the goal, when achieved, contributes to a higher satisfaction degree of the user.","19","13/488694","2012-06-05","2012-0317064","2012-12-13","10016165","2018-07-10","SONY CORPORATION","Takehiro  Hagiwara | Naoki  Kamimaeda | Masanori  Miyahara | Yasutaka  Fukumoto | Masatomo  Kurata","2011-131073","JP","2011-06-13","A61B-0005/6898","A61B-0005/6898 | A61B-0005/1118 | A61B-0005/165 | G06F-0019/3481 | G06Q-0030/0201 | A61B-0005/1112 | A61B-0005/1123 | A61B-0005/222 | A61B-2562/0219","G06F-017/00","G06F-017/00 | A61B-005/00 | A61B-005/11 | A61B-005/16 | G06Q-030/02 | G06F-019/00 | A61B-005/22","","","","","","4918028000922"
"US","US","P","B2","Systems and methods for remote patient monitoring and storage and forwarding of patient information","A method according to one aspect of the present invention includes receiving patient information, analyzing the patient information to identify a condition for the patient, formatting a report based on the patient information and the patient condition, and storing at least one of the patient information, the patient condition, and the formatted report as part of a medical record for the patient. The stored information can be processed and analyzed to perform a risk assessment for the patient, as well as compared to other data. Embodiments of the present invention may be used to monitor any appropriate medical device from essentially any location from which a communications signal can be sent and received. This enables patients to enjoy an active lifestyle by not being tied to medical device monitoring equipment that is difficult or impossible to transport or having to routinely visit health care facilities. The present invention can be used to monitor, process, and transport any amount and type of data from any medical device to any suitable user, such as a healthcare provider.","1. A method comprising: receiving wirelessly, by a computer, patient information from each of a plurality of medical devices wherein each medical device operates on a different communications protocol, the patient information from each of the plurality of medical devices including data related to the medical device;determining, by the computer, based upon the patient information and the data related to the medical device received by the computer, a data collection frequency for the data related to the medical device for each of the plurality of medical devices;determining, by the computer, whether the data collection frequency for each of the plurality of medical devices is within an expected frequency threshold;analyzing, by the computer, the patient information received from each of the plurality of medical devices to identify a condition for the patient;determining, by the computer, whether the data related to the medical device for each of the plurality of medical devices is within a predetermined range;in response to determining whether the data related to the medical device for each of the plurality of medical devices is within the predetermined range, determining, by the computer, whether one or more patients is taking one or more medications in compliance with a prescribed medical treatment;creating, by the computer, a report based on the patient information, the frequency threshold and the patient condition;storing, by the computer, at least one of the patient information, the patient condition, and the created report as part of a medical record,determining if the patient has used at least a predetermined amount of a previously prescribed dose of one or more medications, andautomatically reordering the one or more medications if the patient has used at least the predetermined amount of the previously prescribed dose of one or more medicines.","13","11/877966","2007-10-24","2009-0234672","2009-09-17","10019552","2018-07-10","MEDAPPS, INC.","Kent  Dicks | Ralph  Kent | Thomas  Crosley | Terry  Bartlett","","","","G06F-0019/3418","G06F-0019/3418 | A61M-0005/003 | G06Q-0050/22 | G06Q-0050/24 | G16H-0015/00 | G16H-0010/60 | G16H-0050/20","G06Q-050/00","G06Q-050/00 | A61B-005/00 | G06F-017/30 | G06F-019/00 | G06Q-050/22 | G06Q-050/24 | A61M-005/00 | G16H-015/00 | G16H-010/60 | G16H-050/20","","","","","","4918028004286"
"US","US","P","B1","Augmented reality viewing and tagging for medical procedures","Technology is described for augmenting medical imaging for use in a medical procedure. The method can include the operation of receiving an image of patient anatomy captured by a visual image camera during the medical procedure. An acquired medical image associated with the patient anatomy can then be retrieved. Another operation can be associating the acquired medical image to the patient anatomy. An augmentation tag associated with a location in one layer of the acquired medical image can be retrieved. A further operation can be projecting the acquired medical image and the augmentation tag using an augmented reality headset to form a single graphical view as an overlay to the patient anatomy in either 2D, 3D or holographic form.","1. A method for augmenting medical imaging of a patient during a medical procedure, the medical imaging displayed using an augmented reality headset worn by a medical professional during the medical procedure, the method comprising: receiving a visual image of patient anatomy captured by a visual image camera during the medical procedure, the visual image comprising a viewable portion of the patient anatomy obtained during the medical procedure;retrieving an acquired medical image associated with the patient anatomy from data storage, the acquired medical image comprising imaging acquired of one or more anatomical structures at a plurality of anatomical layers of the patient anatomy;associating the acquired medical image to align with the viewable portion of the patient anatomy captured by the visual image camera, wherein the one or more anatomical structures of the medical imaging at the plurality of layers are aligned with the visual image of the patient anatomy;retrieving an augmentation tag from data storage, the augmentation tag associated with a location in one layer of the acquired medical image, the augmentation tag identifying at least one anatomical structure of the acquired medical image found at the location, the augmentation tag further comprising a shape of the anatomical structure; andprojecting, during the medical procedure, the acquired medical image and the augmentation tag using the augmented reality headset to form a single graphical view as an overlay to the patient anatomy viewable through a lens of the augmented reality headset.","20","15/438715","2017-02-21","","","10010379","2018-07-03","NOVARAD CORPORATION","Wendell Arlen  Gibby | Steven Todd  Cvetko","","","","A61B-0090/36","A61B-0090/36 | A61B-0001/04 | A61B-0005/066 | A61B-0005/1072 | A61B-0005/1075 | A61B-0090/361 | A61B-0090/96 | A61B-0090/98 | G02B-0027/017 | G06F-0019/321 | G06T-0007/74 | G06T-0019/006 | A61B-2090/363 | A61B-2090/365 | A61B-2090/372 | A61B-2090/373 | A61B-2090/374 | A61B-2090/378 | A61B-2090/3762 | A61B-2090/502 | G06F-0003/011 | G06F-0003/012 | G06T-0019/00 | G06T-2207/10016 | G06T-2207/10068 | G06T-2207/30204 | G06T-2210/41","G09G-005/00","G09G-005/00 | A61B-090/00 | A61B-090/96 | A61B-001/04 | A61B-005/06 | A61B-005/107 | A61B-090/98 | G06T-019/00 | G06F-019/00 | G02B-027/01 | G06T-007/73 | A61B-090/50 | G06F-003/01","","","","","","4918027001032"
"US","US","P","B2","Operating system with haptic interface for minimally invasive, hand-held surgical instrument","A haptic system for a minimally invasive, hand-held surgical instrument and the system's various parts including a graphical user haptic interface, one or more haptic interfaces associated with a hand-held handle used to control a sensorized end-effector of the surgical instrument or inserted catheters, associated hardware, and an operating system. The system enables users to acquire, read, modify, store, write, and download sensor-acquired data in real time. The system can provide: an open, universally compatible platform capable of sensing or acquiring physiological signals/data in any format; processing of the sensor acquired data within an operating system; and outputting the processed signals to hardware which generates tangible sensations via one or more haptic interfaces. These tangible sensations can be modified by the user in real time as the system ensures the temporal relationship of sensed fiducial events are not altered or shifted relative to the generated and displayed haptic signals.","1. An operating system providing user customization of a haptic apparatus, comprising: a computer processor operatively coupled to a non-transitory data storage medium containing instructions that when executed cause the computer processor to: receive a series of continuous real time sensor acquired data from a catheter or surgical instrument, the data having a temporal relationship with sensed physiological, and physical events related to moving biological organ, muscle, cardiac valve, vasculature tissue, or flowing blood; process the sensor acquired data to create a plurality of processed signals; output the plurality of processed signals to;hardware, configured to recreate tangible palpable sensations representative of three dimensional motion via at least one haptic apparatus; anda graphical user haptic interface configured in response to user customized programming; andmodify the processed signals in real time based on the user customized programming received from the graphical user haptic interface without altering the temporal relationship of the real time sensor acquired data and the sensed physiological and physical events while enabling adjustments to the tangible palpable sensations recreated by the haptic apparatus that replicates sensed physiological, and physical events.","20","13/837132","2013-03-15","2013-0321262","2013-12-05","10013082","2018-07-03","STUART SCHECTER, LLC D/B/A CARDIATOUCH CONTROL SYSTEMS","Stuart O.  Schecter","","","","G06F-0003/041","G06F-0003/041 | A61B-0005/7455 | A61B-0034/76 | G06F-0003/016 | A61B-0018/1492 | A61B-0034/20 | A61B-2017/00871 | A61B-2018/00297 | A61B-2018/00357 | A61B-2018/00577 | A61B-2034/301 | A61B-2090/064","G06F-003/041","G06F-003/041 | G06F-003/01 | A61B-005/00 | A61B-034/00 | A61B-017/00 | A61B-018/00 | A61B-018/14 | A61B-034/20 | A61B-090/00 | A61B-034/30","","","","","","4918027003720"
"US","US","P","B2","Face detection, augmentation, spatial cueing and clutter reduction for the visually impaired","An apparatus for improving performance of a retinal implant may include processing circuitry. The processing circuitry may be configured to receive image data corresponding to a camera field of view, determine whether a particular object is detected within the camera field of view, perform image data processing to enable a representation of a portion of the image data corresponding to an implant field of view to be provided on a retinal implant where the implant field of view is smaller than the camera field of view, and, responsive to the particular object being located outside the implant field of view, provide a directional indicator in the implant field of view to indicate a location of the particular object relative to the implant field of view.","1. An apparatus comprising: a video processing unit operably coupled to a camera defining a camera field of view, the video processing unit including processing circuitry, the processing circuitry being configured to: receive image data corresponding to the camera field of view;determine whether a particular object is detected within the camera field of view, wherein the particular object comprises a face;perform image data processing to enable a representation of a portion of the image data corresponding to an implant field of view to be provided on a retinal implant, the implant field of view being smaller than the camera field of view; andresponsive to the particular object being located outside the implant field of view, provide a directional indicator in the implant field of view to indicate a location of the particular object relative to the implant field of view, wherein the video processing unit is configured to transition between a face detection mode and a background clutter reduction mode based on detection of the face in the camera field of view.","18","15/206453","2016-07-11","2017-0017831","2017-01-19","10013599","2018-07-03","THE JOHNS HOPKINS UNIVERSITY","Derek M.  Rollend | Kapil D.  Katyal | Kevin C.  Wolfe | Dean M.  Kleissas | Matthew P.  Para | Paul E.  Rosendall | John B.  Helder | Philippe M.  Burlina | Duane C.  Cornish | Ryan J.  Murphy | Matthew S.  Johannes | Arup  Roy | Seth D.  Billings | Jonathan M.  Oben | Robert J.  Greenberg","","","","G06K-0009/00228","G06K-0009/00228 | A61N-0001/36046 | G06F-0001/163 | G06F-0003/011 | G06F-0003/013 | G06F-0003/0304 | G06K-0009/00624 | G06T-0005/40 | G06T-0007/11 | G06T-2207/10004 | G06T-2207/30201","G06K-009/00","G06K-009/00 | G06T-005/40 | G06F-001/16 | G06T-007/11 | G06F-003/01 | G06F-003/03 | A61N-001/36","","","","","","4918027004235"
"US","US","P","B2","Methods and systems for measuring use of an assistive device for ambulation","The disclosed technology relates generally to systems for measuring the frequency and duration of an individual's use of an assistive device for mobility, such as a cane, in day-to-day life at home. In certain embodiments, the system is a stand-alone unit that does not require the monitored individual to wear any special sensors or use any special assistive devices. Further, in certain embodiments, the system does not require the use of visual-light images or video. The systems and methods, in certain embodiments, gather day-to-day metrics of frequency and duration of assistive-device use and may be used to monitor changes over time of the use of an assistive device by an individual for ambulation.","1. A method of detecting an individual'ss use of an assistive device for mobility such that a severity of a disease and/or an individual'ss response to a treatment can be tracked/assessed over time, the method comprising: capturing, by a depth sensor, a time sequence of frames of depth data for a space, wherein the time sequence of frames comprises a plurality of frames;determining, by a processor of a computing device, spatial coordinates of a hand of the individual in each frame in the sequence of frames;determining, by the processor, volumetric data beneath the hand of the individual in each frame of the sequence of frames; anddetermining, by the processor, a plurality of probabilities of whether the individual is holding the assistive device, wherein each probability of the plurality of probabilities is a probability, for a frame of the sequence of frames, that the hand of the individual is holding an object in space consistent with the shape, size, and orientation of an assistive device for ambulation based at least in part on the volumetric data beneath the hand of the individual in the frame.","20","15/058943","2016-03-02","2016-0267652","2016-09-15","10013756","2018-07-03","ATLAS5D, INC.","Zebadiah M.  Kimmel | Jonathan S.  Varsanik","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/1114 | A61B-0005/1128 | A61B-0005/6887 | G06F-0019/3418 | G06K-0009/62 | G06N-0007/005 | G06T-0007/77 | A61B-0005/0002 | A61B-0005/1124 | A61B-2503/08 | A61B-2505/07 | G06F-0017/30259 | G06T-2207/10021 | G06T-2207/10028 | G06T-2207/10048 | G06T-2207/20076 | G06T-2207/30196","G06K-009/00","G06K-009/00 | G06T-007/00 | A61B-005/00 | A61B-005/11 | G06F-019/00 | G06K-009/62 | G06N-007/00 | G06T-007/77 | G06F-017/30","","","","","","4918027004389"
"US","US","P","B2","Method and system for signal processing","Aspects of the disclosure provide a system for signal processing. The system includes a selection circuitry and a coordination detection circuitry. The selection circuitry is configured to receive data sets sampled at different time for a subject and select a plurality of data units from each data set that corresponds to regions of interests in the data set. The coordination detection circuitry is configured to receive the selected data units corresponding to the regions of interests over time, and detect a coordination of the regions of interests over time.","1. A system for signal processing, comprising: a selection circuitry that receives data sets sampled at different time from voxels recorded from magnetic resonance imaging (MRI) of a subject and selects a plurality of data units from each data set that corresponds to regions of interests in the data set; anda coordination detection circuitry including (i) a plurality of channels and (ii) a spiking neural network comprising a plurality of neurons, each channel coupled to a corresponding neuron of the spiking neural network, the coordination detection circuitry receives, via the channels and spiking neural network, the selected data units corresponding to the regions of interests over time, each neuron of the spiking neural network generating a train of spikes based on the received data units over time, the coordination detection circuitry detects a coordination of the regions of interests including the neurons over time, classifies an activity of the subject based on activities of the neurons including at least trains of spikes that are fed back to the spiking neural network for recursively driving the neurons in the spiking neural network, and detects a brain injury of the subject based on the classified activity.","16","14/725833","2015-05-29","2015-0346302","2015-12-03","10006978","2018-06-26","LEIDOS INNOVATIONS TECHNOLOGY, INC. | ABACUS INNOVATIONS TECHNOLOGY, INC.","Corey Brendan  Hart | William J.  Rose","","","","G01R-0033/54","G01R-0033/54 | A61B-0005/055 | G06F-0019/24 | G06N-0003/049 | G06N-0003/0454 | G06T-0007/0016 | G06T-2207/10088 | G06T-2207/20084 | G06T-2207/30016","G01N-033/48","G01N-033/48 | G01R-033/54 | A61B-005/055 | G06F-019/24 | G06T-007/00 | G06N-003/04 | G06G-007/58","","","","","","4918026003447"
"US","US","P","B2","Multi-parametric analysis of snore sounds for the community screening of sleep apnea with non-Gaussianity index","A parameter quantifying deviation from Gaussianity distribution of a patient's sounds, in the form of a non-Gaussianity distribution index, may be used to assist in diagnosis of sleep dysfunction such as OSAHS. A method for diagnosing a sleeping disorder of a subject includes processing a digitized audio signal from the subject with at least one electronic processor. The processing includes estimating a parameter quantifying deviation from Gaussianity distribution of the audio signal. in the form of a non-Gaussianity Index (NGI). The NGI value is then applied to a diagnostic model. The presence of a sleeping disorder is then indicated based on the output of the diagnostic model.","1. A method for diagnosing a sleeping disorder of a subject including: processing a digitized audio signal from the subject with at least one electronic processor, said processing including:estimating values for one or more parameters of said audio signal;applying the values to a predetermined diagnostic model; andindicating the presence of a sleeping disorder based on the output of said model;wherein the one or more parameters includes a non-Gaussianity index quantifying deviation from Gaussianity distribution of said audio signal, and wherein the method further includes:dividing the digitized audio signal into a number of segments;calculating non-Gaussianity scores for each of the segments; andcomputing the non-Gaussianity index based on said scores.","20","14/518869","2014-10-20","2015-0039110","2015-02-05","10007480","2018-06-26","THE UNIVERSITY OF QUEENSLAND","Udantha  Abeyratne | Asela Samantha  Karunajeewa | Houman  Ghaemmaghami","2008-906383 | 2009-901558","AU | AU","2008-12-10 | 2009-04-09","G06F-0003/165","G06F-0003/165 | A61B-0007/003 | G06N-0007/005 | G10L-0025/90 | A61B-0005/4818 | A61B-0005/7267","G06F-017/00","G06F-017/00 | G06F-003/16 | A61B-007/00 | G10L-025/90 | G06N-007/00 | A61B-005/00","","","","","","4918026003944"
"US","US","P","B2","Infusion devices and methods","Medical devices having restrictive access, and methods thereof are provided.","1. A method of controlling access to a medical system comprising at least one medical device and a data communication unit operable by each of a plurality of individuals including a healthcare professional, a caregiver and a user, the method comprising: configuring a medical device with an access level hierarchy that enables the plurality of individuals to have different access level rights to set or modify parameters of the medical device, the access level hierarchy including at least a first, a second, and a third access level, wherein first access level rights enable a first individual having first access level rights to set, modify or lock prescriptive parameters and non-prescriptive parameters of the medical device, wherein second access level rights enable a second individual having second access level rights to set, modify or lock non-prescriptive parameters of the medical device that have not been locked by the first individual, wherein the second access level rights preclude the second individual from setting, modifying or locking prescriptive parameters of the medical device, wherein third access level rights enable a third individual having third access level rights to set, modify or lock non-prescriptive parameters of the medical device that have not been locked by the first or second individual, and wherein the third access level rights preclude the third individual from setting, modifying or locking prescriptive parameters of the medical device.","7","14/730047","2015-06-03","2015-0269340","2015-09-24","10007759","2018-06-26","ABBOTT DIABETES CARE, INC.","Christopher V.  Reggiardo | Namvar  Kiaie | James  Thomson","","","","G06F-0019/3406","G06F-0019/3406 | A61M-0005/14244 | A61M-0005/14276 | A61M-0005/1723 | G06F-0019/3468 | G06F-0021/30 | G06F-0021/44 | G16H-0040/63 | A61B-0005/14532 | A61M-0005/31525 | A61M-0005/31546 | A61M-2205/276 | A61M-2205/3561 | A61M-2205/3569","A61M-005/14","A61M-005/14 | G06F-019/00 | A61M-005/142 | G06F-021/44 | A61M-005/172 | G06F-021/30 | G16H-040/63 | A61B-005/145 | A61M-005/315","","","","","","4918026004222"
"US","US","P","B2","Method and apparatus for sharing medical information","An apparatus and method is provided for treating a healthcare patient. The method includes the steps of establishing a audio/visual teleconference between a processor of the patient at a first location and a processor of a physician located at a second, remote location different from the first location and displaying a set of biometric parameters of the patient in real time to the physician at the remote location.","1. A computer-implemented method, in a plug computer and wireless medical peripherals that are remote from the plug computer over a computer network, for monitoring and treating a healthcare patient by healthcare consultants over the computer network, the method comprising the steps of: receiving a selection of healthcare consultants, over the computer network, from a plurality of available healthcare consultants;receiving biometric identification data of the patient from a biometric sensor;authenticating, the patient to a computer of the at least one accepting healthcare consultants based on the biometric identification data from the patient;searching for, and wirelessly connecting to, enabled medical peripherals of the patient and storing in a data table MAC (media access control) addresses of each medical peripheral along with a name of each medical peripheral and a serial number;wirelessly collecting biometric parameters of the patient from the enabled medical peripherals across the computer network and remote from the plug computer, using the stored MAC addresses;determining, with a CPU (central processing unit), whether a vital sign of the patient exceeds a limit of a biometric parameter from the collected biometric parameters; andresponsive to the vital sign exceeding the limit of a biometric parameter: automatically generating an alert for transmission across the computer network to the computer of the at least one of the selected healthcare consultants;initiating a conference network connection between the plug computer and the at least one computer for health consultants for an audio/video teleconference between the at least one computer of the patient at a first location and one or more healthcare consultants located at a second remote location, the second remote location distinct from the first location; anddisplaying the patient along with biometric parameters of the patient in real time with the conference network connection to the at least one computer for healthcare consultants.","12","13/421454","2012-03-15","2015-0019231","2015-01-15","10007761","2018-06-26","3 NET WISE, INC.","Errick  Sadler | Melanie  Mencer-Parks | William  Langford | Randy  Sessler | Joseph  Boucree | Sherrod  Woods","","","","G06F-0019/3418","G06F-0019/3418 | A61B-0005/411 | G06Q-0020/14 | G06Q-0050/22 | G16H-0010/60 | A61B-0005/0013 | A61B-0005/021 | A61B-0005/024 | A61B-0005/1172 | A61B-0005/145 | A61B-0005/14532 | A61B-0005/7465 | A61B-0007/04","G06Q-010/00","G06Q-010/00 | G06Q-050/00 | G06F-019/00 | G06Q-020/14 | A61B-005/00 | G06Q-050/22 | G16H-010/60 | A61B-007/04 | A61B-005/021 | A61B-005/024 | A61B-005/1172 | A61B-005/145","","","","","","4918026004224"
"US","US","P","B2","Methods and systems for providing online monitoring of released criminals by law enforcement","The methods and systems are designed to utilize an integrated combination of just in time, just in place, and just on device actions connected to an image recognition process for monitoring criminals who are probation, offenders who are on parole, sex offenders, and witnesses under protection by law enforcement.","1. A system for monitoring and verifying a criminal offender over a network, the system comprising: an verification app downloadable to a device comprising a camera, a GPS locator, a network interface, and a user interface, the app comprises: a process to initiate a user to take and capture a picture of an offender'ss face with the camera;a process to capture a first set of GPS coordinates, a first time, and a date of the picture of the offender'ss face;a process to initiate the user to take and capture a picture of an identification card with the camera;a process to capture a second set of GPS coordinates, a second time, and a date of the picture of the identification card;a process to capture identification data of the device;a process to send data comprising at least one of the picture of the offender'ss face, the picture of the identification card, the first set of GPS coordinates, the second set of GPS coordinates, the time and date of the picture of the user'ss face, the time and date of the picture of the identification card, and the identification data to a location on the network; anda process to receive and communicate information;a verification engine on a server at the location on the network, the verification engine comprising: an input configured to receive the data from the verification app;an image comparison algorithm configured to compare the picture of the offender'ss face, the picture of the identification card, then determine the likelihood that the user and a person in the picture of the identification card are substantially the same; anda time comparison algorithm configured to determine if the time and date of the picture of the user'ss face, the time and date of the picture of the identification card are substantially the same; anda verification to be send to the verification app if the offender and a person in the picture of the identification card are substantially the same, and if the time and date of the picture of the offender'ss face, the time and date of the picture of the identification card are substantially the same.","12","15/239797","2016-08-17","2017-0162031","2017-06-08","10008099","2018-06-26","OPTIMUM ID, LLC","James  Drolshagen | Hemanshu  Nigam","","","","G08B-0025/001","G08B-0025/001 | A61B-0005/117 | G06F-0017/3028 | G06F-0017/30256 | G06F-0017/30268 | G06K-0009/00228 | G06K-0009/00288 | H04W-0004/02 | G06Q-0050/26","G08B-023/00","G08B-023/00 | G08B-025/00 | H04W-004/02 | G06K-009/00 | G06F-017/30 | A61B-005/117 | G06Q-050/26","","","","","","4918026004561"
"US","US","P","B2","Communication systems","An integrated home health system includes a television-based patient station, a first provider station for providing telemedicine or other healthcare services to a patient located at the patient station, a second provider station for providing caregiver services to the patient, a third provider station for providing emergency response services to the patient and a system management station coupled together by a data network. In addition to various management operations performed on behalf of the integrated home health system, the system management station is further configured to provide various home health services to the patient located at the patient station, either alone, or in conjunction with one or more of the first, second and/or third provider stations.","1. A communication system comprising: a first interface configured to receive first content from a first service provider via radio frequency;a second interface configured to receive second content from a second service provider via a broadband data network; anda third interface configured to transmit the first content to a user device, to transmit the second content to the user device based upon a determination to interrupt the first content, and to transmit at least the second content to the user device independent of a request from the user device,wherein one or more of the first interface, the second interface, and the third interface, facilitates two-way communication between the user device and one or more of the first service provider and the second service provider.","33","13/618919","2012-09-14","2013-0070044","2013-03-21","10009577","2018-06-26","Comcast Cable Communications, LLC","Surendra N.  Naidoo | Michael G.  McCown","","","","H04N-0007/14","H04N-0007/14 | G06F-0019/3418 | G06Q-0010/10 | G06Q-0050/22 | H04W-0004/06 | H04W-0004/90 | A61B-0005/0022 | A61B-0005/747 | H04L-0067/12 | H04L-0067/26 | H04M-0003/5116 | H04M-2201/50 | H04M-2242/04 | H04N-0007/147 | H04N-0021/4788 | H04N-0021/4882","H04N-007/14","H04N-007/14 | H04W-004/06 | G06F-019/00 | G06Q-050/22 | G06Q-010/10 | H04L-029/08 | H04N-021/4788 | H04N-021/488 | H04M-003/51 | H04W-004/90 | A61B-005/00","","","","","","4918026006026"
"US","US","P","B2","Device and method for evaluating analgesic neurostimulation devices","In order to assist in evaluating/monitoring pain, and in treating same, a touch-sensitive graphics tool is provided with a local application (TGapps) for displaying a graphical representation of a patient's body, on which the patient can delimit a zone. A control application cooperates with the local application in order to record each delimited zone together with the corresponding surface data. The control application has a first mode in which the local application (TGapps) can be used by the patient to delimit zones of pain and a second mode in which the local application can be used by the patient to delimit treated zones. The tool is configured to activate graphical and/or numerical comparisons between the surface areas of the pain zones and the surface areas of the treated zones. In this way, it is possible to evaluate pain and the effects of treatment.","1. A tool assisting in the evaluation/monitoring of pain and of a treatment, comprising: a graphics tool (TG) equipped with a screen (102);a local application (TGapps) installed in the graphics tool for the purpose of displaying on the screen (102) a graphical representation (100) of a patient'ss body which includes target points located on the patient'ss body, while allowing a user to delimit a zone (104) on the graphical representation (100) displayed on the screen (102); anda control application (TGappmain) cooperating with the local application (TGapps) in order to record (CCSapps) the delimited zone (104) together with corresponding surface data,the control application (TGappmain) having a first mode (S5) in which the local application (TGapps) allows the patient to delimit pain zones,the control application having a second mode (S6) in which the local application (TGapps) allows the patient to delimit treated zones,the control application (TGappmain) being configured to activate graphical and/or numerical comparisons between surface areas of the pain zones and surface areas of the treated zones,which makes it possible to evaluate the pain and the effects of the treatment,wherein each graphical delimitation is realized by filling zones with selective graphical attributes, in particular of color, at least some of the zones being partially transparent.","22","15/021390","2014-08-14","2016-0220178","2016-08-04","9999387","2018-06-19","CENTRE HOSPITALIER UNIVERSITAIRE DE POITIERS","Philippe  Rigoard | Farid  Guetarni","2013-058850","FR","2013-09-13","A61B-0005/4848","A61B-0005/4848 | A61B-0005/1072 | A61B-0005/4824 | A61B-0005/4827 | A61B-0005/7435 | A61B-0007/04 | A61N-0001/36071 | G06F-0003/0481 | G06F-0003/0482 | G06F-0003/04842 | G06F-0003/04845 | G06F-0003/04883 | G06T-0011/001 | G06T-0011/206 | G06T-0011/40 | G06T-0011/60 | G09G-0005/14 | G16H-0040/63 | G06F-2203/04803 | G06T-2207/30004 | G06T-2207/30196 | G06T-2210/62 | G06T-2215/16 | G09G-2320/0693 | G09G-2380/08 | G16H-0010/20","G09G-005/14","G09G-005/14 | G06F-003/048 | G06T-011/00 | G06T-011/20 | G06T-011/40 | G06T-011/60 | A61B-005/107 | A61B-007/04 | A61N-001/36 | A61B-005/00 | G06F-003/0482 | G06F-003/0484 | G06F-003/0488 | G06F-003/0481","","","","","","4918025000752"
"US","US","P","B2","System and method for fabricating a body part model using multi-material additive manufacturing","A method for physically reconstructing a body part using multi-material additive manufacturing includes receiving image data of the body part in the form of arrays of voxels, each array of voxels representing image data pertaining to cross-section of the body part, translating the image data in the arrays of voxels to printable bitmap images representing combinations of modeling materials for reconstructing the body part, and dispensing the combinations of modeling materials responsive to the bitmap images in a layerwise manner.","1. A method for physically reconstructing an object using multi-material additive manufacturing, the method comprising: receiving tomography data of the object from one or more of a CT scanner, MRI and ultrasound device, wherein the tomography data is in the form of arrays of tomography voxels, each array pertaining to a cross-section of the object and each tomography voxel having a value;defining a relationship between tomography voxel values and target physical properties for reconstructing the object;defining a relationship between combinations of modeling materials and their physical properties; anddefining a relationship between tomography voxel values and the material combination responsive to the relationship defined between the voxel values and the target physical properties and the relationship defined between the combinations of modeling materials and their physical properties;translating tomography data to printable bitmap images representing combinations of modeling materials for reconstructing the object; anddispensing the combinations of modeling materials responsive to the bitmap images in a layerwise manner, wherein the combinations of modeling materials in each layer are dispensed in a dropwise manner with an additive manufacturing device;wherein the translating of the tomography data to the printable bitmap images is by raster-raster translation.","19","14/358092","2012-11-15","2014-0312535","2014-10-23","9999509","2018-06-19","STRATASYS LTD.","Daniel  Dikovsky | Stanislav  Shtilerman","","","","A61F-0002/30942","A61F-0002/30942 | A61C-0013/0019 | B29C-0067/0059 | B33Y-0050/00 | G06F-0017/50 | A61B-0005/055 | A61F-2002/30948 | A61F-2002/30962 | A61F-2002/30985 | B29L-2031/7532 | B33Y-0070/00","A61B-017/56","A61B-017/56 | A61F-002/30 | B33Y-050/00 | A61C-013/00 | B29C-067/00 | G06F-017/50 | B33Y-070/00 | B29L-031/00 | A61B-005/055","","","","","","4918025000873"
"US","US","P","B2","Medical device management and theft inhibitor techniques","A healthcare enterprise has an associated management resource that manages operation of one or more medical devices in the healthcare enterprise. To determine what functionality to enable in a respective medical device, the respective medical device establishes a communication link to communicate in a network environment. Subsequent to establishing the communication link, the medical device initiates communications over the communication link from the medical device to the remotely located management resource. The communications include a unique identifier value assigned to the medical device. Depending upon feedback (such as granting or denial of authorization) from the management resource with respect to the unique identifier value, the medical device operates in one of multiple different operational modes such as a fully functional mode or a reduced functionality mode.","1. A method comprising: in a medical device: accessing configuration information assigned to the medical device;initiating communications over a communication link from the medical device to a remotely located management resource over a network to register the medical device for use in a private medical network environment to which the medical device is assigned for use, the communications initiated over the communication link in response to detecting that the configuration information indicates that the medical device is assigned a lock mode in which the medical device requires confirmation by the remotely located management resource to execute a first modal operation of the medical device;receiving authorization from the remotely located management resource, the authorization indicating that the medical device has been verified for execution of the first modal operation in the private medical network environment;providing continued first modal operation of the medical device while the medical device moves outside of a wireless communication range of the private medical network environment; andswitching from the first modal operation to second modal operation of the medical device in response to detecting subsequent denial of authorization of further use of the medical device, the denial of authorization occurring in response to an attempt to authorize use of the first modal operation of the medical device in a foreign environment outside the wireless communication range of the private medical network environment.","27","14/794256","2015-07-08","2016-0045661","2016-02-18","10002235","2018-06-19","IVENIX, INC.","George W.  Gray | William C.  McQuaid","","","","G06F-0019/3468","G06F-0019/3468 | A61B-0090/90 | G06F-0019/3418 | A61M-0005/14 | A61M-2205/3584 | A61M-2205/3592 | A61M-2205/52 | A61M-2205/6018","G06F-007/04","G06F-007/04 | G06F-015/16 | G06F-017/30 | H04L-029/06 | G06F-019/00 | A61B-090/90 | A61M-005/14","","","","","","4918025003575"
"US","US","P","B2","System, method and device for confirmation of an operator's health condition and alive status","An apparatus comprising a system with an array of sensors, sound and light emitting and receiving devices having at least one object control from a monitored object comprised of an operator, a patient, an animal, or machine, control of at least one performance parameter of the system; at least one iris/retina biometric sensor; at least one physiological iris/pupil sensor; at least one infinite random light emitter; said at least one iris/pupil biometric sensor; said at least one physiological pupil sensor and said one infinite random light emitter operatively connected and synchronized communication with each other utilizing at least one central processing unit; said at least one biometric sensor and said at least one physiological sensor delivering a parallel array of sensory readings to said central processing unit; said central processing unit capable of detecting a normal or an abnormal sensory reading; said at least one central processing unit capable of effecting said at least one performance parameter in response to said sensory reading; and said central processing unit recording said sensory reading on a storage medium to be used for identifying and detection of said alive status and health condition of the monitored object in real time.","1. An apparatus comprising a system with an array of sensors, sound and light emitting and receiving devices having at least one object control from a monitored object comprised of an operator, a patient, an animal, or machine, control of at least one performance parameter of the system; at least one iris/retina biometric sensor; at least one physiological iris/pupil sensor; at least one infinite random light emitter; said at least one iris/pupil biometric sensor; said at least one physiological pupil sensor and said one infinite random light emitter operatively connected and synchronized communication with each other utilizing at least one central processing unit; said at least one biometric sensor and said at least one physiological sensor delivering a parallel array of sensory readings to said central processing unit; said central processing unit capable of detecting a normal or an abnormal sensory reading; said at least one central processing unit capable of effecting said at least one performance parameter in response to said sensory reading; and said central processing unit recording said sensory reading on a storage medium to be used for identifying and detection of said alive status and health condition of the monitored object in real time.","20","15/424886","2017-02-05","2017-0143241","2017-05-25","9993183","2018-06-12","Theodore Dean McBain","Theodore Dean  McBain","","","","A61B-0005/1171","A61B-0005/1171 | A61B-0003/0008 | B64D-0045/0015 | G06F-0021/32 | G06K-0009/00201 | G06K-0009/00604 | G06K-0009/00617 | G06K-0009/00892 | G06K-0009/00906 | B64D-2045/004 | B64D-2045/0055 | G06K-2009/00939","A61B-005/1171","A61B-005/1171 | G06K-009/00 | A61B-003/00 | B64D-045/00 | G06F-021/32","","","","","","4918024000933"
"US","US","P","B2","System for characterizing brain condition","A sensitive measure of brain condition simultaneously evaluates multiple measurements of water diffusion in brain tissue combined so as to correct for covariance between the different data types of the multipoint measurements and compares the multipoint measurements to a corresponding multipoint measure representing normal brain tissue to provide a distance indicating a likelihood of atypical brain conditions.","1. A system for assessing brain condition comprising: a magnetic resonance imaging system providing at least two quantitative image data sets generated by the magnetic resonance imaging system and providing different types of data each based on different imaging protocols, each quantitative image data set providing data values at different locations within a brain; anda processor executing a stored program to receive the at least two different quantitative image data sets from the magnetic resonance imaging system and:(a) combining data values of different types of data of the at least two quantitative image data sets at given locations corrected by correlation among the different types of data of the data values; and(b) comparing the corrected data values of the given locations to corresponding data values representing a normal brain to provide a difference revealing a brain condition;wherein the combining creates a multidimensional vector and the comparing determines a value related to a Euclidean distance between a point represented by the multidimensional vector and a point represented by a multidimensional vector of the corresponding data values representing a normal brain.","10","15/342391","2016-11-03","2018-0116603","2018-05-03","9993206","2018-06-12","WISCONSIN ALUMNI RESEARCH FOUNDATION","Andrew Lafayette  Alexander | Douglas Carl  Dean, III | Gregory Russel  Kirk | Brittany Gail  Travers","","","","A61B-0005/7275","A61B-0005/7275 | A61B-0005/0042 | A61B-0005/055 | A61B-0005/4064 | G01R-0033/4828 | G01R-0033/5602 | G01R-0033/56341 | G06F-0017/11 | G06K-0009/6202 | G06T-0007/0012 | G06T-0007/0081 | G06T-2207/10088 | G06T-2207/30016","G06K-009/00","G06K-009/00 | A61B-005/00 | G06F-017/11 | G06T-007/00 | G06K-009/62 | A61B-005/055 | G01R-033/563 | G01R-033/56 | G01R-033/48 | A61B-005/05","","","","","","4918024000956"
"US","US","P","B1","Dynamically monitoring environmental and physiological characteristics to generate a medicine ingestion alarm","According to an embodiment of the present invention, a system dynamically monitors a patient's physiological condition and location information to generate an alarm signal to enable the patient to timely administer a health substance. Initially, the system monitors location information of a health substance and the patient and physiological information of the patient. A processor in the system determines a predicted time when the patient may attain a physiological condition for receiving the health substance and may further determine a transit time for the patient to travel to a location of the health substance. Based on the predicted and transit times, the system issues an alarm signal to the patient prior to the predicted time. Embodiments of the present invention further include a method and computer program product for monitoring a patient's physiological condition and location information to generate an alarm signal in substantially the same manner described above.","1. A method of monitoring physiological conditions to generate an alarm signal comprising: monitoring location information of a health substance;monitoring location information and physiological information of a user;determining a predicted time for the user to attain a physiological condition for receiving the health substance based on the physiological information of the user;determining a transit time for the user to travel to a location of the health substance based on the predicted time and the location information of the user and the health substance; andgenerating an alarm signal at a time derived from the predicted and transit times to enable administration of the health substance prior to the predicted time.","20","15/494813","2017-04-24","","","9993209","2018-06-12","INTERNATIONAL BUSINESS MACHINES CORPORATION","Kanako  Fujitani | Mariko  Ishige | Yusuke  Nishitani | Yutaka  Oishi | Tatsuya  Sobue | Masayuki  Yamana","","","","A61B-0005/746","A61B-0005/746 | A61B-0005/0002 | A61B-0005/1112 | A61B-0005/14546 | A61B-0005/4848 | A61B-0005/7275 | G06F-0019/3406 | G06N-0005/04 | G06Q-0030/0623 | G08B-0021/0453 | A61B-2560/0242","A61B-005/00","A61B-005/00 | A61B-005/11 | A61B-005/145 | G08B-021/04 | G06N-005/04 | G06F-019/00 | G06Q-030/06","","","","","","4918024000959"
"US","US","P","B2","Systems and methods for utilizing geographic positioning data for operation of an electrically motorized vehicle","A system, method, and device for operations of an electrically motorized vehicle. The vehicle can utilize an electrically motorized wheel to convert a non-motorized wheeled vehicle to an electrically motorized wheeled vehicle. One system includes a server in communication with the device of each of a plurality of electrically motorized wheels, the server operable to track a position of each of the electrically motorized wheels and communicate the position thereof to a transportation network.","1. A system, comprising: a motorized human-powered vehicle;a server in communication with the motorized human-powered vehicle or a mobile device associated with a user of the motorized human-powered vehicle;a sensor system on the motorized human-powered vehicle to detect physical effort of the user that propels the motorized human-powered vehicle; anda display module operable to display collected data as an overlay on a map providing an overview of environmental conditions, wherein: the collected data includes (A) data from the sensor system of an indication of the user'ss physical effort exerted to propel the motorized human-powered vehicle-, and (B) sensor data related to (i) user inputs to the motorized human-powered vehicle, (ii) user physical condition, (iii) operation of the motorized human-powered vehicle, or (iv) an environment through which the motorized human-powered vehicle travels,wherein the sensor data related to (i) user inputs to the motorized human-powered vehicle, (ii) operation of the motorized human-powered vehicle, and (iii) the environment through which the motorized human-powered vehicle travels is received from the motorized human-powered vehicle.","24","14/680210","2015-04-07","2016-0012723","2016-01-14","9994099","2018-06-12","SUPERPEDESTRIAN, INC.","Assaf  Biderman | Ruben  Cagnie","","","","B60K-0007/0007","B60K-0007/0007 | A61B-0005/0002 | A61B-0005/11 | A61B-0005/6893 | A61B-0005/7275 | A61B-0005/7282 | A61G-0005/04 | A61G-0005/048 | A63B-0021/0058 | A63B-0021/22 | A63B-0022/0605 | A63B-0024/0062 | A63B-0024/0084 | A63B-0024/0087 | B60C-0005/005 | B60C-0009/00 | B60K-0007/00 | B60L-0003/0046 | B60L-0003/0061 | B60L-0003/12 | B60L-0007/00 | B60L-0007/12 | B60L-0011/007 | B60L-0011/1805 | B60L-0011/1809 | B60L-0011/1851 | B60L-0011/1861 | B60L-0011/1864 | B60L-0015/20 | B60L-0015/2009 | B60L-0015/2036 | B60Q-0005/005 | B60Q-0009/00 | B60R-0016/02 | B60R-0025/04 | B60R-0025/1003 | B60R-0025/20 | B60W-0050/085 | B61L-0025/02 | B62B-0003/00 | B62B-0005/004 | B62M-0006/45 | B62M-0006/80 | B62M-0025/08 | E05B-0049/006 | E05B-0081/54 | G01C-0021/3632 | G01C-0021/3664 | G05D-0001/021 | G05D-0001/0285 | G05D-0001/0287 | G05D-0001/0291 | G06F-0008/65 | G07C-0005/006 | G07C-0005/008 | G07C-0005/02 | G07C-0005/0808 | G07C-0009/00007 | G07C-0009/00309 | G08G-0001/0129 | G08G-0001/052 | G08G-0001/123 | G08G-0001/127 | G08G-0001/13 | G08G-0001/20 | G08G-0001/202 | H02P-0003/06 | H02P-0006/08 | H02P-0029/20 | H04L-0067/12 | H04M-0001/7253 | H04W-0004/003 | H04W-0004/008 | B60K-2007/0092 | B60L-2200/12 | B60L-2200/34 | B60L-2200/36 | B60L-2200/40 | B60L-2220/44 | B60L-2220/50 | B60L-2240/12 | B60L-2240/36 | B60L-2240/421 | B60L-2240/423 | B60L-2240/425 | B60L-2240/461 | B60L-2240/463 | B60L-2240/545 | B60L-2240/547 | B60L-2240/549 | B60L-2240/622 | B60L-2240/68 | B60L-2240/70 | B60L-2260/44 | B60W-2050/0014 | B60W-2050/0089 | B60Y-2300/18 | B60Y-2300/1884 | E05B-2047/0088 | G01C-0021/36 | G07C-2009/00769 | G08G-0001/16 | Y02P-0090/60 | Y02T-0010/641 | Y02T-0010/645 | Y02T-0010/7005 | Y02T-0010/7044 | Y02T-0010/7061 | Y02T-0010/7275 | Y02T-0010/7291 | Y02T-0090/16 | Y02T-0090/162","G08G-001/123","G08G-001/123 | B60K-007/00 | B60L-015/20 | B60L-003/00 | B60L-003/12 | B60L-007/12 | B60L-011/00 | B60L-011/18 | A61G-005/04 | B62B-003/00 | B62B-005/00 | G06F-009/445 | G07C-005/00 | G07C-005/08 | H04L-029/08 | H04W-004/00 | B60Q-005/00 | B60Q-009/00 | A61B-005/00 | A61B-005/11 | B60W-050/08 | A63B-024/00 | B62M-006/45 | B62M-025/08 | H02P-003/06 | B60L-007/00 | H02P-006/08 | B62M-006/80 | A63B-021/005 | A63B-021/22 | A63B-022/06 | B60R-016/02 | G05D-001/02 | G07C-005/02 | G08G-001/127 | B60R-025/04 | B60R-025/10 | B60R-025/20 | E05B-049/00 | E05B-081/54 | G07C-009/00 | G08G-001/01 | G08G-001/052 | G08G-001/00 | B61L-025/02 | G08G-001/13 | H04M-001/725 | H02P-029/20 | B60C-005/00 | B60C-009/00 | G01C-021/36 | B60W-050/00 | E05B-047/00 | G08G-001/16","","","","","","4918024001843"
"US","US","P","B2","Detecting eye movement based on a wearable detection apparatus","A contact lens type line-of-sight detection apparatus has a shape such that it is wearable on an eyeball of a user. Furthermore, in the line-of-sight detection apparatus, a plurality of light-emitting sections that output light and a plurality of light-receiving elements that receive light reflected by an eyeball surface. The light-receiving elements receive light that has been output from the light-emitting sections and reflected by the eyeball surface and output light-receiving signals according to amounts of light received. The signal processing unit detects a line of sight of the user based on the light-receiving signals of the light-receiving elements. The present technology can be applied to a contact lens type line-of-sight detection apparatus or a display apparatus.","1. A detection apparatus, comprising: a display region;a light-emitting element configured to output light, wherein the light-emitting element includes a plurality of light-emitting sections; anda plurality of light-receiving elements configured to receive light that enters from a first eyeball of a user,wherein the plurality of light-receiving elements and the plurality of light-emitting sections are at alternate positions on an entire surface of the display region, andwherein the detection apparatus is wearable on the first eyeball of the user.","19","14/902953","2014-07-08","2016-0147301","2016-05-26","9996151","2018-06-12","SONY CORPORATION","Masanori  Iwasaki | Yoichiro  Sako","2013-150433","JP","2013-07-19","G06F-0003/013","G06F-0003/013 | A61B-0003/113 | G06F-0001/163 | G06F-0003/0325 | G06K-0009/00604 | A61B-0005/02416 | A61B-0005/6821 | G02B-2027/0187","A61B-005/00","A61B-005/00 | G06F-003/01 | A61B-003/113 | G06F-001/16 | G06F-003/03 | G06K-009/00 | G02B-027/01 | A61B-005/024","","","","","","4918024003886"
"US","US","P","B2","Dynamic memory access management","A system, a method and a computer program product for managing memory access of an avionics control system having at least one control computer having at least one memory control device. The method includes assigning a memory access of at least one unique memory region of at least one memory unit to each of at least one application task or task set. A memory access of at least one application data update task is assigned to at least one subregion of one or more of the at least one unique memory region. At least one data parameter is written to the at least one subregion and the assigned memory access of the at least one application data update task de-activated.","1. A method for managing memory access of an avionics control system having at least one control computer, at least one memory unit having a partitioning operating system and at least one application task or task set stored thereon, at least one processor arranged to orchestrate the partitioning operating system and the at least one application task or task set, at least one memory control device arranged to control memory access of the at least one processing device to the at least one memory unit, the method comprising: assigning each of said at least one application task or task set memory access to at least one unique memory region of said at least one memory unit,assigning at least one application data update task memory access to at least one subregion of one or more of the at least one unique memory region, wherein the at least one subregion is arranged to store one or more data parameter of constant data type used to initialize data of the at least one application task or task set during an initialization procedure of said at least one application task or task set,orchestrating said at least one application data update task in order to write at least one data parameter to the one or more of the at least one subregion, andre-configuring the at least one memory control device in order to de-activate memory access of said at least one application data update task so as to protect said at least one subregion and thereby prevent any data parameter of the one or more of the at least one subregion to be overwritten, wherein the step of re-configuring the at least one memory control device is performed prior to completion of the initialization procedure of the at least one application task or task set.","13","14/409691","2012-06-21","2015-0378936","2015-12-31","9996481","2018-06-12","SAAB AB","Torkel  Danielsson | Jan  Hakegard | Anders  Gripsborn | Bjorn  Hasselqvist","","","","G06F-0012/1458","G06F-0012/1458 | G06F-0009/5016 | G06F-2212/1052 | H04L-0067/12","A61B-005/00","A61B-005/00 | A61K-031/785 | A61K-038/16 | A61K-038/22 | C07K-014/475 | C12Q-001/68 | G01N-033/68 | G06F-012/14 | G06F-009/50 | H04L-029/08","","","","","","4918024004214"
"US","US","P","B2","Systems and methods for controlling sensor-based data acquisition and signal processing in vehicles","Systems and methods are provided for dynamically controlling sensor-based data acquisition in vehicles. The disclosed embodiments may receive signals associated with sensors in a vehicle, wherein the signals are associated with sampling rates, and apply bandwidth filters to the signals to create filtered signals. The disclosed embodiments may also detect an occurrence of an event by comparing the filtered signals to one or more event thresholds and transmit event data to a control system when the event thresholds are exceeded. The disclosed embodiments also may dynamically adjust signals, sampling rates, bandwidth filters, a generated event score, and the event thresholds based on changes to a set of control variables. The control variables may depend on signals associated with a set of sensors in a vehicle or on boundary conditions and signals associated to an external system.","1. A system for dynamically controlling sensor-based data acquisition in vehicles, comprising: a memory storing a set of instructions; andone or more processors configured to execute the set instructions to perform one or more operations, the operations comprising: receiving a set of signals associated with a set of sensors in a vehicle, wherein the set of signals is associated with a set of sampling rates,applying a set of bandwidth filters to the set of signals to create a set of filtered signals, anddetecting an occurrence of an event by comparing an event score based on the set of filtered signals with an event threshold, wherein: at least one of the set of signals, the set of sampling rates, the set of bandwidth filters, the event score, or the event threshold is dynamically adjusted based on a change to a set of control variables, wherein the set of control variables is changed in response to detecting occurrences of subsequent events, wherein each change to the set of control variables causes a modification to at least one of the set of signals, the set of sampling rates, the set of bandwidth filters, the event score, or the event threshold; wherein the set of control signals comprises:a set of local control variables based on the set of signals; anda set of external control variables based on a hazard index received from the control system,the event threshold is inversely proportional to the hazard index,the hazard index is based on the event data and a set of boundary conditions reflecting conditions external to the vehicle, andthe set of boundary conditions includes at least two of a weather condition, a traffic condition, a road type condition, or an average speed map condition.","18","14/969100","2015-12-15","2017-0166217","2017-06-15","9988056","2018-06-05","OCTO TELEMATICS, SPA","Fabio  Sbianchi | Gianfranco  Giannella","","","","B60W-0040/09","B60W-0040/09 | A61B-0005/18 | B60W-0040/02 | B60W-0040/105 | B60W-0040/107 | B60W-0040/109 | G06F-0011/3089 | H04B-0001/10 | H04L-0067/12","G05D-001/00","G05D-001/00 | G05D-003/00 | G06F-007/00 | G06F-017/00 | B60W-040/09 | A61B-005/18 | B60W-040/02 | B60W-040/105 | B60W-040/107 | B60W-040/109 | G06F-011/30 | H04B-001/10 | H04L-029/08 | B60R-021/16","","","","","","4918023002021"
"US","US","P","B2","Wearable electronic device","A wearable electronic device (100) comprises a sensor (1) providing a sensor signal (s1), which sensor (1) is one of a temperature sensor and a humidity sensor. A control unit (3) determines, subject to at least the sensor signal (s1), if the wearable electronic device (100) is worn by a user, and provides an output signal (t1) indicative of a result of the determination.","1. A wearable electronic device, comprising a first sensor providing a first sensor signal, which first sensor is a temperature sensor or a humidity sensor,a second sensor providing a second sensor signal, which second sensor is a temperature sensor or a humidity sensor,wherein the first sensor and the second sensor are of the same type,a control unit configured to determine based on the first sensor signal and the second sensor signal if the device is worn by a user, and configured to provide an output signal indicative of a result of the determination,a common channel including at least one opening, the at least one opening facing a body part of the user when the device is worn by a user, andwherein the first sensor is arranged in the common channel at a first distance from the at least one opening and the second sensor is arranged in the common channel in spatial series with the first sensor, at a second distance from the at least one opening, the first distance being less than the second distance, the first and second sensors and the common channel being so configured and arranged that the first and second sensors sense an air volume propagated in the common channel and measure a heat flux or humidity flux determined as a difference between the first sensor signal and the second sensor signal.","20","14/943489","2015-11-17","2016-0162256","2016-06-09","9990172","2018-06-05","SENSIRION AG","Heiko  Komaromi | Marcel  Koller","2014-196042","EP","2014-12-03","G06F-0003/165","G06F-0003/165 | A61B-0005/01 | A61B-0005/14517 | A61B-0005/681 | A61B-0005/6817 | H04M-0001/72569 | H04Q-0009/00 | H04R-0001/1041 | H04R-0025/305 | A61B-0005/12 | A61B-0005/4266 | A61B-2560/029 | A61B-2560/0252 | A61B-2560/0462 | A61B-2562/029 | A61B-2562/043 | A61B-2562/063 | H04R-0001/1016 | H04R-2225/61","G06F-017/00","G06F-017/00 | G06F-003/16 | A61B-005/01 | A61B-005/145 | H04R-025/00 | H04M-001/725 | H04Q-009/00 | A61B-005/12 | A61B-005/00 | H04R-001/10","","","","","","4918023004132"
"US","US","P","B2","Monitoring of a time period relating to a product","A label includes a timer to monitor a predetermined time period relating to a medical device, such as an indwelling cannula, or other product. The label includes a signalling apparatus that provides an alert signal on expiry of the predetermined time period and a fixing portion to fix the label to a support surface such as medical records of a patient. The label can have a first portion and a second portion and the first portion can be separable from the second portion. The fixing portion can be provided in the second portion and all or part of the signalling apparatus provided in the first portion. Also disclosed is a monitoring system for a medical device, including a base station and a label receivable by the base station. The monitoring system monitors a predetermined time period based on receipt of the label by the base station.","1. A label comprising: a first portion and a second portion, the first and second portions being connected together;wherein the first portion comprises a timer to monitor a predetermined time period, a signalling apparatus that provides an alert signal on expiry of the predetermined time period, and a power source to supply power to the timer and signalling apparatus;wherein an adhesive is provided on a rear surface of the second portion to fix the label to a support surface during monitoring of the predetermined time period; andwherein at least one of a frangible element, a tear line, a tear notch, perforations and a region of weakness is located between the first portion and the second portion to enable disconnection of the first portion from the second portion when the second portion is fixed to the support surface by the adhesive and after monitoring of the predetermined time period.","20","15/363417","2016-11-29","2017-0076641","2017-03-16","9990864","2018-06-05","SENVER PTY LTD","Sanjaya Naresh  Senanayake | Gary Martin  Verdickt | Dilukshi Tarindu  Senanayake | Kushlani Kumari  Verdickt | Luke Thomas  Dawson | Stuart Richard  May","2014-902045 | 2014-903936","AU | AU","2014-05-29 | 2014-10-02","G09F-0003/0288","G09F-0003/0288 | A61B-0005/00 | A61B-0090/90 | A61M-0025/002 | A61M-0025/0017 | G04C-0021/00 | G04F-0001/005 | G04F-0003/06 | G06F-0019/323 | G06Q-0050/24 | G07C-0001/00 | G08B-0021/18 | G09F-0001/00 | G09F-0003/10 | G09F-0027/004 | A61B-2560/028 | A61M-2205/82 | G09F-2003/0272","G08B-013/02","G08B-013/02 | G09F-003/00 | A61B-005/00 | G06Q-050/24 | G07C-001/00 | G09F-001/00 | G06F-019/00 | A61B-090/90 | G04C-021/00 | G04F-001/00 | G04F-003/06 | A61M-025/00 | G08B-021/18 | G09F-003/10 | G09F-027/00 | G09F-003/02","","","","","","4918023004824"
"US","US","P","B2","Systems and methods for management of medical condition","Embodiments of the invention relate to a self-contained kit for medical condition monitoring and maintenance, such as the monitoring and maintenance of blood sugar levels. The kit is compact and includes components structurally retained therein for use without removal, wherein these components are normally separate and loose. Such components could include a glucose meter, an insulin pen and a lancing apparatus. Other embodiments of the invention relate to a computer system and method for monitoring a medical condition, monitoring a medical condition over time, correlating recorded results with environmental factors such as location, time and meals consumed. A method may also enable individual users to share information to provide support to one another.","1. A method performed by a computer program operating on a computer device that is a smartphone, the method comprising: (a) displaying, by the computer device, on a display screen in communication with the computer device, a plurality of icons related to managing a medical condition, wherein one of the plurality of icons comprises a community tracker window which, upon selection by the user, shows the activity of other people in a community of which the user is a member, including a leaderboard showing points earned and lost by the user and other people in the user'ss community, the point associated with blood glucose levels of the user and other people in the user'ss community, and wherein one of the plurality of icons comprises an activity challenge window which, upon selection by the user, displays a periodically updated activity to challenge the user;(b) receiving, by the computer device, information relating to the medical condition;(c) in response to receiving the information, automatically populating, by the computer device, one or more of the plurality of icons with the received information;(d) displaying, by the computer device, the one or more newly populated icons;(e) displaying, by the computer device, a color coded display for a plurality of pairings of meal data and a blood glucose level for a plurality of geographic locations;(f) acquiring, by a digital camera of the computer device, a digital image of a street at the current physical location of the smartphone, the digital image of the street having a first restaurant and a second restaurant visible in the digital image;(g) calculating, by the computer device, an average blood sugar level of the user at the first restaurant and an average blood sugar level of the user at the second restaurant;(h) modifying, by the computer device, the digital image of the street a first time by inserting the average blood sugar of the user at the first restaurant onto a portion of the digital image of the street occupied by the first restaurant;(i) modifying, by the computer device, the digital image of the street a second time by inserting the average blood sugar of the user at the second restaurant onto a portion of the digital image of the street occupied by the second restaurant; and(j) displaying, on the display screen, the modified digital image of the street to allow the user to view the users average blood sugar results at the first restaurant and the second restaurant.","19","14/217385","2014-03-17","2014-0380218","2014-12-25","9980671","2018-05-29","Johnnie J. Refvik","Johnnie J.  Refvik","","","","A61B-0005/150305","A61B-0005/150305 | A61B-0005/0022 | A61B-0005/14532 | A61B-0005/151 | A61B-0005/157 | A61B-0005/150022 | A61B-0005/15146 | A61B-0005/15186 | A61B-0005/150267 | A61B-0005/150358 | A61B-0005/6898 | A61B-0005/7445 | A61M-0005/3155 | G01N-0033/66 | G06F-0003/0488 | G06F-0003/04817 | G06F-0003/04842 | G06F-0003/04847 | G16H-0010/60 | G16H-0040/63 | A61B-0005/0205 | A61M-2005/3126","G06F-003/048","G06F-003/048 | A61B-005/15 | A61B-005/157 | A61B-005/00 | A61B-005/145 | A61B-005/151 | G01N-033/66 | G06F-003/0481 | G06F-003/0484 | G06F-003/0488 | A61M-005/315 | A61B-005/0205 | A61M-005/31","","","","","","4918022000930"
"US","US","P","B2","System and method for interactive annotation of an image using marker placement command with algorithm determining match degrees","A system 100 for enabling interactive annotation of an image 102, comprising a user input 160 for receiving a placement command 162 from a user, the placement command being indicative of a first placement location of a marker 140 in the image 102, and a processor 180 arranged for (i) applying an image processing algorithm to a region 130 in the image, the region being based on the first placement location, and the image processing algorithm being responsive to image portions which visually correspond to the marker 140 for establishing a plurality of match degrees between, on the one hand, the marker, and, on the other hand, a plurality of image portions within the region, (ii) establishing a second placement location in dependence on the plurality of match degrees and the respective plurality of image portions for matching the marker 140 to the region in the image, and (iii) placing the marker 140 at the second placement location in the image 102.","1. A system for interactive annotation of an image, comprising: a user input that receives a placement command from a user, the placement command being indicative of a first placement location of a marker in the image, the placement command being obtained by the user using a user interface device to move the marker over the image; anda processor that: applies an image processing algorithm to a region in the image, the region being based on the first placement location, the image processing algorithm determining a plurality of match degrees between the marker and a plurality of image portions within the region, wherein the match degrees are determined based on the image processing algorithm providing a distinct output for image portions that visually correspond to the marker,determines a second placement location in dependence on the plurality of match degrees and the respective plurality of image portions for matching the marker to the region in the image, andplaces the marker at the second placement location in the image.","20","14/356394","2012-10-30","2014-0289605","2014-09-25","9980692","2018-05-29","KONINKLIJKE PHILIPS N.V.","Thomas  Buelow | Kirsten Regina  Meetz | Martin  Bergtholdt","","","","A61B-0006/468","A61B-0006/468 | A61B-0005/7475 | A61B-0008/468 | G03F-0009/7069 | G06F-0003/011 | G06F-0003/04845 | G06F-0017/241 | G06F-0019/24 | G06T-0007/74 | G03F-0009/7088 | G06F-0017/2247 | G06F-0017/242 | G06F-0017/243 | G06T-2207/10116 | G06T-2207/20012 | G06T-2207/20096 | G06T-2207/20101 | G06T-2207/30068 | G06T-2207/30204","A61B-006/00","A61B-006/00 | G06F-019/24 | G06F-003/01 | G03F-009/00 | A61B-005/00 | A61B-008/00 | G06F-003/0484 | G06F-017/24 | G06T-007/73 | G06F-017/22","","","","","","4918022000951"
"US","US","P","B2","Systems and methods for determining spinal cord stimulation parameters based on patient feedback","The present disclosure provides a grip sensor for quantifying pain experienced by a patient during spinal cord stimulation (SCS). The grip sensor includes an electronics enclosure, an annular outer shell substantially surrounding the electronics enclosure and sized to be held by the patient, a pressure sensor embedded in the outer shell and communicatively coupled to the electronics enclosure, the pressure sensor configured to measure a grip strength of the patient as SCS is applied to the patient, and a plurality of galvanic skin response sensors communicatively coupled to the electronics enclosure and configured to measure an electrical impedance of the skin of the patient as SCS is applied to the patient.","1. A grip sensor for quantifying pain experienced by a patient during spinal cord stimulation (SCS), the grip sensor comprising: an electronics enclosure;an annular outer shell substantially surrounding the electronics enclosure and sized to be held by the patient;a pressure sensor embedded in the outer shell and extending along the outer shell, the pressure sensor configured to measure a grip strength of the patient as SCS is applied to the patient; anda plurality of galvanic skin response (GSR) sensors configured to measure an electrical impedance of the skin of the patient as SCS is applied to the patient;wherein the electronics enclosure is configured to calculate a weighted change in SCS pain-related pressure and GSR impedance measurements from the pressure and galvanic skin response sensors, respectively, to obtain chances SCS-related pain levels in connection with changes in SCS parameters, the SCS-related levels to be provided to a display device for display.","11","14/946538","2015-11-19","2017-0143971","2017-05-25","9981131","2018-05-29","PACESETTER, INC.","Alexander  Kent | Edward  Karst | Gene A.  Bornzin","","","","A61N-0001/36132","A61N-0001/36132 | A61B-0005/0533 | A61B-0005/225 | A61B-0005/4824 | A61N-0001/36062 | A61B-0005/4836 | A61B-2562/046 | A61N-0001/0551 | A61N-0001/36021 | A61N-0001/36071 | A61N-0001/36135 | A61N-0001/37247 | A63B-0021/4035 | G06F-0003/015","A61B-005/103","A61B-005/103 | A61B-005/117 | A61N-001/36 | A61B-005/00 | A61B-005/053 | A61B-005/22 | A61N-001/05 | G06F-003/01 | A61N-001/372 | A63B-021/00","","","","","","4918022001389"
"US","US","P","B2","Performance monitoring systems and methods","We have disclosed systems and methods for portable performance monitoring of an individual during a physical activity. The systems and methods may include a portable sensor component configured to be carried by the individual during the physical activity and configured to obtain movement data for the athlete individual during the physical activity. The systems and methods may also include a portable output component configured to be carried by the individual during the physical activity and configured to provide an output to the individual during the physical activity. The systems and methods may further include a portable processing component in communication with the portable sensor component and the portable output component, where the portable processing component is configured to be carried by the individual during the physical activity. The portable processing component may be configured to identify movement of the individual during the physical activity.","1. A method of providing fitness information to a user, the method comprising: collecting electronic position data on a portable electronic device during a first fitness activity along a route, the portable electronic device comprising a microprocessor, a microphone, a display screen, a user input, a satellite positioning system receiver, a digital camera, and a wireless communication transceiver, the electronic position data being determined via the satellite positioning system receiver;inputting supplemental electronic data into the portable electronic device, the supplemental electronic data being related to the electronic position data,wherein the supplemental electronic data comprises one of an audio signal recorded with the microphone, a digital image captured with the digital camera, a digital video segment captured with the digital camera, or a text entered using the user input; anddisplaying the supplemental electronic data on the display screen during a second fitness activity along the route.","20","15/171570","2016-06-02","2016-0275814","2016-09-22","9983007","2018-05-29","ADIDAS AG","Michael  Ellis | Caron  Schwartz","","","","G01C-0021/00","G01C-0021/00 | A61B-0005/0022 | A61B-0005/0024 | A61B-0005/01 | A61B-0005/021 | A61B-0005/024 | A61B-0005/0205 | A61B-0005/0833 | A61B-0005/1038 | A61B-0005/112 | A61B-0005/1112 | A61B-0005/1118 | A61B-0005/14532 | A61B-0005/14542 | A61B-0005/224 | A61B-0005/411 | A61B-0005/486 | A61B-0005/4836 | A61B-0005/4866 | A61B-0005/742 | A61B-0005/7405 | A61B-0005/7475 | A63B-0024/0021 | A63B-0024/0062 | A63B-0024/0075 | A63B-0024/0084 | A63B-0024/0087 | A63B-0069/16 | A63B-0071/06 | A63B-0071/0686 | G01C-0021/20 | G01C-0021/34 | G01C-0021/3676 | G01S-0019/19 | G01S-0019/42 | G06F-0003/16 | G06F-0011/328 | G06F-0017/40 | G06F-0019/3481 | G06F-0019/36 | G09B-0005/02 | G09B-0005/06 | G09B-0019/00 | G09B-0019/003 | G09B-0019/0038 | G09B-0019/0092 | H04L-0063/0236 | H04L-0063/08 | H04L-0063/1408 | H04L-0067/10 | H04W-0004/02 | H04W-0012/06 | A45F-2005/008 | A61B-2562/0219 | A63B-0022/0076 | A63B-0022/02 | A63B-0069/0028 | A63B-2024/0012 | A63B-2024/0025 | A63B-2024/0065 | A63B-2024/0068 | A63B-2024/0071 | A63B-2024/0093 | A63B-2071/063 | A63B-2071/0625 | A63B-2071/0627 | A63B-2071/0658 | A63B-2071/0661 | A63B-2071/0663 | A63B-2220/12 | A63B-2220/14 | A63B-2220/17 | A63B-2220/18 | A63B-2220/20 | A63B-2220/22 | A63B-2220/30 | A63B-2220/62 | A63B-2220/836 | A63B-2225/15 | A63B-2225/20 | A63B-2225/50 | A63B-2225/60 | A63B-2225/685 | A63B-2230/04 | A63B-2230/06 | A63B-2230/067 | A63B-2230/202 | A63B-2230/207 | A63B-2230/30 | A63B-2230/42 | A63B-2230/50 | A63B-2230/65 | A63B-2230/70 | A63B-2230/75 | A63B-2244/20 | G06F-0019/3475 | H04B-0001/385 | H04L-0063/0428 | H04M-0001/6041 | H04M-2250/02 | H04W-0012/02 | H04W-0084/18 | Y10S-0482/901","A63B-024/00","A63B-024/00 | G01C-021/00 | A61B-005/103 | A61B-005/00 | A63B-069/16 | A63B-071/06 | H04L-029/06 | H04W-012/06 | G06F-003/16 | G06F-017/40 | G01C-021/34 | G01C-021/36 | A61B-005/024 | A61B-005/11 | H04L-029/08 | G06F-011/32 | G09B-005/06 | G09B-019/00 | H04W-004/02 | G09B-005/02 | A61B-005/01 | A61B-005/021 | A61B-005/145 | A61B-005/22 | A61B-005/083 | G01S-019/42 | G01C-021/20 | G01S-019/19 | A61B-005/0205 | A45F-005/00 | A63B-022/00 | A63B-022/02 | A63B-069/00 | G06F-019/00 | H04B-001/3827 | H04M-001/60 | H04W-012/02 | H04W-084/18","","","","","","4918022003253"
"US","US","P","B2","Finger controlled medical device interface","A wearable remote control worn on a finger of a user is provided. The wearable remote control is for use with a medical equipment component. The wearable remote control has a housing, a switch located on the housing, the switch configured to provide a control signal to a control module, and an interface connector attached to the housing and the switch. The interface convector connects the wearable remote control to the control module. The housing of the wearable remote control may include a collar worn around the finger.","1. A wearable remote control system for use with a medical navigation system to control a medical equipment component including a robotic arm supporting an imaging system, the wearable remote control system comprising: a wearable remote control module configured to be worn adjacent to a wrist of a user and configured to be wearable underneath a surgical glove;a wearable remote control configured to be worn on a finger of a user, and configured to be wearable underneath the surgical glove, the wearable remote control comprising: a thin and flexible housing;a plurality of thin and flexible switches located on the housing, the switches configured to provide a control signal receivable by the wearable control module of the wearable remote control system via a plurality of signal lines, the switches being flat or two-dimensional;a thin board located underneath the switches; andan interface connector coupled with the housing and the switches, the interface connector enabling communication between the wearable remote control and the wearable control module; andthe wearable control module being configured to: receive the control signal from the wearable remote control; and send the control signal to the medical navigation system for controlling at least one of the robotic arm and a zoom level of the imaging system,wherein the wearable remote control system is configured to be worn by the user while the user is holding surgical tools in a bimanual procedural position.","22","15/326217","2015-07-13","2017-0239010","2017-08-24","9974622","2018-05-22","SYNAPTIVE MEDICAL (BARBADOS) INC.","Kresimir  Franjic | Kai  Hynna | Victor  Jagga","","","","A61B-0034/74","A61B-0034/74 | A61B-0018/1445 | A61B-0034/20 | A61B-0034/37 | A61B-0034/76 | A61B-0042/10 | A61B-0090/37 | G08C-0017/02 | A61B-0017/34 | A61B-2017/00973 | A61B-2018/00595 | A61B-2034/2055 | A61B-2034/2063 | A61B-2034/741 | A61B-2090/373 | A61B-2090/3735 | G08C-2201/32 | G08C-2201/50","H04L-017/02","H04L-017/02 | G06F-003/01 | H04N-005/44 | A61B-005/107 | A61B-018/12 | A61B-019/04 | G06F-003/038 | H04N-021/442 | A61B-034/00 | A61B-042/10 | A61B-034/37 | A61B-090/00 | A61B-018/14 | G08C-017/02 | A61B-017/34 | A61B-017/00 | A61B-034/20 | A61B-018/00","","","","","","4918021000858"
"US","US","P","B2","Synchronized exercising and singing","A computer-implemented method and system facilitating a karaoke performance while exercising during an individual exercise session or group exercise class are disclosed. An indication of a song to be performed during the session or exercise class is received. At least one computer-readable karaoke file corresponding to the song is retrieved. The at least one computer-readable karaoke file may comprise common data elements, at least two independent karaoke data streams and exercise-related data elements. From a first class participant a selection of a first data stream of the at least two independent karaoke data streams is received. From a second class participant a selection of a second data stream of the at least two independent karaoke data streams is received. The presentation of the common data elements and the exercise-related data elements on a display common to the first and the second class participants is directed. The presentation of the first karaoke data stream on a display unique to the first class participant is directed. The presentation of the second karaoke data stream on a display unique to the second class participant is directed. The presentation of the common data elements, the exercise-related data elements, the first data stream and the second data stream may be synchronized.","1. A computer-implemented method for facilitating a karaoke performance while exercising during an individual exercise session or group exercise class, comprising: receiving an indication of a song to be performed during said session or exercise class;retrieving at least one computer-readable karaoke file corresponding to said song, wherein said at least one computer-readable karaoke file comprises common data elements, at least two independent karaoke data streams and exercise-related data elements;receiving from a first class participant a selection of a first karaoke data stream of said at least two independent karaoke data streams;receiving from a second class participant a selection of a second karaoke data stream of said at least two independent karaoke data streams;directing presentation of said common data elements and said exercise-related data elements on a display common to said first and said second class participants;directing presentation of said first karaoke data stream on a display unique to said first class participant; anddirecting presentation of said second karaoke data stream on a display unique to said second class participant,wherein the presentation of said common data elements, said exercise-related data elements, said first karaoke data stream and said second karaoke data stream are synchronized.","16","14/707437","2015-05-08","2016-0325145","2016-11-10","9975002","2018-05-22","Ross Philip Pinkerton","Ross Philip  Pinkerton","","","","A63B-0024/0075","A63B-0024/0075 | A63B-0024/0087 | A63B-0071/0622 | G06F-0017/3074 | G06F-0019/3481 | G09B-0019/003 | G09B-0019/0015 | G10H-0001/361 | G10H-0001/365 | A61B-0005/024 | A63B-0022/0605 | A63B-2024/009 | A63B-2024/0081 | A63B-2071/065 | A63B-2071/0625 | A63B-2220/803 | A63B-2220/806 | A63B-2225/20 | A63B-2225/50 | A63B-2230/06 | A63B-2230/75 | G06Q-0050/01 | G10H-2220/011 | G10H-2240/181","G10H-001/36","G10H-001/36 | A63B-024/00 | A63B-071/06 | G06F-019/00 | G06F-017/30 | G09B-019/00 | A63B-022/06 | A61B-005/024 | G06Q-050/00","","","","","","4918021001236"
"US","US","P","B2","Assessment of an attentional deficit","A system and method are provided for use in the assessment of an attentional deficit. During the assessment, a test image is presented to a subject on a display. A camera image is obtained from a camera which is indicative of a geometric relation between the head of the subject and the display during the assessment. The camera image is analyzed to determine a deviation in the geometric relation between the head of the subject and the display from a reference geometric relation. Deviation data is then generated and output which is indicative of the deviation. Advantageous uses of the deviation data include providing visual feedback to the user, adjusting the test image, and taking the deviation into account when processing test data of the assessment. Advantageously, the need for a trained professional to be present during the assessment is reduced or avoided.","1. A system for use in an assessment of an attentional deficit, comprising: a display;a camera configured to obtain a camera image indicative of a geometric relation between a head of a subject and the display during an assessment; andone or more processors configured by machine-readable instructions to: effectuate presentation of a test image on the display to the subject as part of the assessment;determine, based on the camera image, a deviation in the geometric relation between the head of the subject and the display from a reference geometric relation, wherein the reference geometric relation is determined based on a marker included in the test image;determine, based on the camera image, gaze points of the subject with respect to the display; anddetermine attentional deficit of the subject based on the determined deviation and the determined gaze points.","17","14/962602","2015-12-08","2016-0171696","2016-06-16","9978145","2018-05-22","KONINKLIJKE PHILIPS N.V.","Murray Fulton  Gillies | Laura  Klaming | Daisy  Van Minde","2014-198284","EP","2014-12-16","G06T-0007/0016","G06T-0007/0016 | A61B-0005/0077 | A61B-0005/11 | A61B-0005/168 | G06F-0003/012 | G06F-0019/363 | G06K-0009/0061 | G06K-0009/00255 | G06K-0009/00268 | G06K-0009/00288 | G06K-0009/52 | G06T-0007/60 | A61B-0003/113 | G06T-2207/30041 | G06T-2207/30201","G06T-007/00","G06T-007/00 | A61B-005/00 | A61B-005/16 | G06K-009/00 | G06K-009/52 | G06T-007/60 | A61B-005/11 | G06F-003/01 | G06F-019/00 | A61B-003/113","","","","","","4918021004368"
"US","US","P","B2","Information processing apparatus, information processing method, and information processing system","An advice target location at which a user had a predetermined emotion, for example, is determined based on location information, user biological information, and user transportation means information, which have been acquired by a terminal device (20) being used by the user. Advice information containing information indicating an advice presentation region set by a server device (50) is generated based on the advice target location. This advice information is supplied from the server device (50) to the terminal device (20), so that the terminal device (20) presents advice. With this, advice as to locations pedestrians find dangerous can be presented to drivers, and advice as to locations drivers find dangerous can be presented to pedestrians. Accordingly, accidents and the like can be prevented.","1. An information processing apparatus comprising: circuitry configured to: receive location information, biological information, and mode of transportation information from a terminal device which includes a group of sensors, the group of sensors including: at least one selected from a group consisting of a gyro sensor, an acceleration sensor, a geomagnetic sensor, an atmospheric pressure sensor, and an antenna providing the location information and the mode of transportation information; andat least one selected from a group consisting of a heart rate sensor, a blood pressure sensor, a respiration sensor, and perspiration sensor, a brain wave sensor, and a myoelectric sensor providing the biological information;determine an advice target location of a plurality of advice target locations at which advice is to be presented for each mode of transportation of a plurality of modes of transportation, wherein each one of the plurality of advice target locations is determined based on associated log information including the location information, the biological information, and the mode of transportation information received from the terminal device;set an advice presentation region where advice is to be presented based on the determined advice target location;provide the advice to the information processing apparatus based on the set advice presentation region; andwherein the provided advice comprises at least one of an image and a voice, and includes information regarding each different mode of transportation identified within the mode of transportation information of the associated log information used to determine the advice target location corresponding to the advice presentation region.","20","14/414914","2013-07-02","2015-0179073","2015-06-25","9978279","2018-05-22","SONY CORPORATION","Satoshi  Suzuno","2012-175274","JP","2012-08-07","G08G-0001/166","G08G-0001/166 | A61B-0005/18 | G06K-0009/00845 | G08G-0001/005 | G08G-0001/0112 | G08G-0001/0129 | G08G-0001/0141 | G08G-0001/0962 | G08G-0001/096716 | G08G-0001/096741 | G08G-0001/096775 | A61B-0005/02438","G08G-001/16","G08G-001/16 | B60R-022/00 | E05F-015/00 | G05D-001/00 | G05D-003/00 | G06F-007/00 | G06F-017/00 | G08G-001/005 | G08G-001/01 | G08G-001/0962 | G08G-001/0967 | A61B-005/18 | G06K-009/00 | A61B-005/024","","","","","","4918021004502"
"US","US","P","B2","Risk stratification based heart failure detection algorithm","A system comprises a risk analysis module and a worsening heart failure (WHF) detection module. The risk analysis module measures at least one first physiological parameter of a subject using a physiological sensor of an ambulatory medical device, and determines a heart failure (HF) risk score for the subject according to the at least one measured first physiological parameter. The HF risk score indicates susceptibility of the subject to experiencing a HF event. The WHF detection module measures at least one second physiological parameter of the subject using the same or different physiological sensor, and generates an indication of prediction that the subject will experience a WHF event when the at least one second physiological parameter satisfies a WHF detection algorithm. The risk analysis module adjusts generation of the indication by the WHF detection algorithm according to the determined HF risk score.","1. A system comprising: one or more ambulatory medical devices, wherein a first ambulatory medical device includes a heart sound sensor configured to sense an S3 heart sound of a subject; and a processor, wherein the processor includes:a control module configured to: detect worsening heart failure (WHF) for the subject using a WHF detection scheme, wherein the WHF detection scheme includes comparing one or more measured heart failure (HF) physiological parameter parameters to a WHF detection threshold; andstore, in the memory, an alert of prediction that the subject will experience a WHF event when the one or more measured HF physiological parameter satisfies the WHF detection scheme; anda risk analysis module configured to:measure a first physiological parameter of the sensed S3 heart sound, wherein the first physiological parameter is distinct from the one or more measured HF physiological parameter parameters;determine a HF risk score for the subject according to the at least one measured first physiological parameter in response to detecting the change, and determine whether the HF risk score indicates high risk for WHF or low risk for WHF; andadjust one or more of the WHF detection scheme threshold, a weighting of the one or more measured HF physiological parameters, or a number of the one or more measured HF parameters that are compared to the WHF detection threshold according to the determined HF risk score to increase sensitivity of the WHF detection scheme when high risk for WHF is indicated and increase specificity of the WHF detection scheme when low risk for WHF is indicated;wherein the one or more measured HF physiological parameters includes at least one of heart rate (HR), respiration rate (RR), tidal volume (TV), intrathoracic impedance (ITTI), or one or more of heart sound (HS) timing or amplitude distinct from the measured first physiological parameter.","20","13/726786","2012-12-26","2013-0116578","2013-05-09","9968266","2018-05-15","CARDIAC PACEMAKERS, INC.","Qi  An | Pramodsingh Hirasingh  Thakur | Viktoria A.  Averina | Yi  Zhang | Robert J.  Sweeney","","","","A61B-0005/0205","A61B-0005/0205 | A61B-0005/4842 | A61B-0005/7275 | G06Q-0010/00 | G06Q-0050/22 | G16H-0050/30 | A61B-0005/0031 | A61B-0005/024 | A61B-0005/02007 | A61B-0005/0816 | A61N-0001/37282 | G16H-0050/20 | G16H-0050/50","A61B-005/0205","A61B-005/0205 | G06Q-050/22 | A61B-005/00 | G06Q-010/00 | A61N-001/372 | A61B-005/02 | A61B-005/024 | A61B-005/08","","","","","","4918020000923"
"US","US","P","B2","Method and apparatus to provide haptic and visual feedback of skier foot motion and forces transmitted to the ski boot","A system and method to provide haptic and visual feedback of motion of the skier foot and the forces transmitted to the skiboot insole and consequently to the ski/snow interface. This system comprises a motion and force sensors and a haptic actuator embedded in the skiboot insole in communication with a smart-phone based analysis application, configured to calculate insole motion and orientation and the distribution of pressure points inside the skiboot, then to provide haptic feedback to the skier foot instructing on timing and direction of change in the pressure points necessary to achieve optimal turn parameters. Furthermore, analyzed together with GPS coordinates are transmitted by the application to the cloud based server for further processing. Graphical and numerical representation of data is superimposed over a 3D map of a slope which may be viewed on the user smart-phone or on a remote computer terminal.","1. A system to analyze motion and balance of a skier by analyzing location of Center of Pressure (COP), and timing of the COP location change, and changes in location and distribution of Center of Force (COF) applied to ski boot insoles, and using said analysis to provide estimation of location of the skier Center of Mass (COM), and ski trajectory and to provide instructions to the skier on location the COP must be applied, wherein said system comprises: motion and force processing element embedded in a ski boot;haptic feedback actuator embedded in the ski boot; anda smart-phone based analysis application in communication with the motion and force processing element using wireless radio interface,and wherein the motion and force processing elements are configured to estimate three-dimensional motion vectors and change a of location and value of COP and the COF, and wherein said estimate of motion vectors and first information provides estimates of the skier'ss Center of Mass (COM), and wherein said estimate of motion and second information provides estimates of the ski'ss trajectory, and wherein the smart-phone based analysis application is configured to: obtain the skier'ss location GPS coordinates;store the motion vectors, location and values of the COP, COF and COM and the GPS location coordinates;integrate changes in motion vectors into a three-dimensional representation of the skis'strajectory;transmit the vectors, location and value of the COP, COF, COM and GPS location coordinates to a remote server as third information using the smart-phone cellular radio interface;receive instructions from the remote server and translate said instructions into control signals for the haptic actuators;receive 3D map of a location associated with the skier GPS coordinates from a remote server; andbased on bio-mechanics of skiing and the skis'strajectory and the second information, estimate future skis's trajectory then provide haptic instruction of time the COP location must be changed, display location numerical and graphical information of location and distribution of the COP and COF in relation to skis's pitch, roll and heading and overlay said information on the 3D map on the smart-phone screen.","17","14/747179","2015-06-23","2016-0375346","2016-12-29","9968840","2018-05-15","IPCOMM LLC","Stanislaw  Czaja | Muhammad  Afsar | Andrzej  Bachleda-Curus","","","","A63C-0011/003","A63C-0011/003 | A43B-0005/04 | A61B-0005/0022 | A61B-0005/1036 | A61B-0005/11 | A61B-0005/1112 | A61B-0005/1121 | A61B-0005/1124 | A61B-0005/6807 | G06F-0003/011 | G06F-0003/016 | A61B-2503/10 | A61B-2505/09 | A61B-2560/0223 | A61B-2562/0219 | A61B-2562/0247 | A63B-0069/18 | A63B-2071/0636 | A63B-2071/0655 | A63B-2220/12 | A63B-2220/16 | A63B-2220/36 | A63B-2220/40 | A63B-2220/44 | A63B-2220/56 | A63B-2220/74 | A63B-2225/02 | A63B-2225/20 | A63B-2225/50 | A63B-2225/54 | G06K-0009/00342 | H04M-0001/7253","A63C-005/03","A63C-005/03 | A43B-005/04 | A63C-011/00 | A61B-005/11 | G06F-003/01 | A61B-005/00 | A61B-005/103 | A63B-069/18 | G06K-009/00 | A63B-071/06 | H04M-001/725","","","","","","4918020001491"
"US","US","P","B2","Treatment planning and delivery using temperature uncertainty maps","A method and programmable computer system calculates and displays the regions where the temperature can be reliably measured in a thermal therapy procedure. The clinician or automated control system then can make an informed decision to treat these regions or plan a treatment to avoid them based on the sensitivity of surrounding structures to unintended heating.","1. A method for delivering thermal therapy to a target volume within a patient'ss body, comprising: determining a target volume for delivery of thermal therapy thereto;in a computer, storing a plurality of phase images captured using a magnetic resonance imaging (MRI) device;in said computer, creating a reference phase image of a portion of said patient'ss body using data corresponding to the plurality of phase images captured using said MRI device, wherein each phase image used in creating the reference phase image comprises a plurality of pixels, each pixel having a corresponding phase, and said reference phase image is created by calculating an average phase over several reference images for each pixel in the phase image;in said computer, creating at least one measurement image of said portion of said patient'ss body using data corresponding to one or more of said phase images captured using said MRI device;in a computer, generating at least one uncorrected temperature of the portion of said patient'ss body using said at least one measurement image and said reference phase image, wherein said at least uncorrected temperature is uncorrected for a phase drift;using said computer, correcting for said phase drift in at least one temperature map, such that said temperature map includes corrected temperatures;using said computer, calculating a temperature uncertainty map in a region of said target volume using said at least one temperature map of said corrected temperatures;using said computer, determining a treatment plan based at least in part on said temperature uncertainty map; andusing a thermal therapy applicator comprising an ultrasound transducer array, delivering a thermal therapy dose to said target volume according to said treatment plan, wherein said treatment plan avoids a region in said target volume having a temperature uncertainty above a temperature uncertainty threshold.","8","14/450805","2014-08-04","2015-0038883","2015-02-05","9971004","2018-05-15","PROFOUND MEDICAL INC.","Ron  Kurtz | Kee  Tang | Mathieu  Burtnyk","","","","G01R-0033/4804","G01R-0033/4804 | A61B-0005/015 | A61B-0005/055 | A61B-0005/4381 | A61N-0007/02 | A61N-0007/022 | G01R-0033/285 | G01R-0033/443 | G01R-0033/4814 | G06F-0003/0484 | A61B-2018/00547 | A61B-2018/00636 | A61B-2018/00702 | A61B-2018/00791 | A61B-2090/374 | A61B-2090/3784 | A61N-2007/0004 | A61N-2007/0052 | A61N-2007/0078 | G01R-0033/5608","A61H-001/00","A61H-001/00 | G01R-033/48 | A61B-005/055 | A61N-007/02 | G01R-033/28 | G01R-033/44 | G06F-003/0484 | A61B-005/01 | A61B-005/00 | A61B-018/00 | A61N-007/00 | G01R-033/56 | A61B-090/00","","","","","","4918020003646"
"US","US","P","B2","Devices, methods, and systems of functional optical coherence tomography","The present disclosure provides systems and methods for the determining a rate of change of one or more analyte concentrations in a target using non invasive non contact imaging techniques such as OCT. Generally, OCT data is acquired and optical information is extracted from OCT scans to quantitatively determine both a flow rate of fluid in the target and a concentration of one or more analytes. Both calculations can provide a means to determine a change in rate of an analyte over time. Example methods and systems of the disclosure may be used in assessing metabolism of a tissue, where oxygen is the analyte detected, or other functional states, and be generally used for the diagnosis, monitoring and treatment of disease.","1. A method for imaging a target, the method comprising: a. performing optical coherence tomography (OCT) scanning on a target with one or more beams of low coherence light, wherein the one or more beams of low coherence light comprise one or more wavelengths and the one or more beams of light are used to perform a single measurement;b. acquiring optical information from reflected signals generated by the performed OCT scanning in the single measurement;c. quantitatively three dimensional (3D) imaging the target in the single measurement using at least one of visible light or invisible light;d. concurrently determining a flow rate of a fluid in the target and a concentration of one or more analytes in the fluid from the acquired optical information and the quantitative 3D imaging in the single measurement;e. determining a rate of change of the one or more analyte concentrations in the target based on the determining of flow rate of a fluid and a concentration of one or more analytes, wherein a medical decision is made by determining the rate of change of the one or more analyte concentrations in the target.","20","15/465285","2017-03-21","2017-0188818","2017-07-06","9962075","2018-05-08","NORTHWESTERN UNIVERSITY | OPTICENT INC","Ji  Yi | Wenzhong  Liu | Vadim  Backman | Hao F.  Zhang | Kieren J.  Patel","","","","A61B-0003/102","A61B-0003/102 | A61B-0001/04 | A61B-0003/1233 | A61B-0005/0205 | A61B-0005/14507 | A61B-0005/14517 | A61B-0005/14532 | A61B-0005/14535 | A61B-0005/14542 | A61B-0005/14551 | G01B-0009/02091 | G06F-0017/13 | G06T-0007/0014 | A61B-0005/0066 | A61B-0005/0261 | G06T-2207/10028 | G06T-2207/10101","G06K-009/00","G06K-009/00 | A61B-003/10 | G06T-007/00 | G01B-009/02 | A61B-005/1455 | A61B-003/12 | A61B-005/145 | A61B-005/0205 | A61B-001/04 | G06F-017/13 | A61B-005/00 | A61B-005/026","","","","","","4918019000935"
"US","US","P","B2","Pattern recognition based motion detection for asset tracking system","An asset tracking system that optimizes the value per ping by tying the ping to a pattern of movements of the asset. The asset tracking device will send a ping to a remote host (i.e., receiver) when predetermined qualified event is detected by the device. In such a manner, the value per ping is optimized, leading to increased battery life and decreased operational cost. To satisfy these conditions, the asset tracking device is equipped with appropriate sensors, actuators, and trigger mechanism(s). A four-phase methodology or algorithm used to detect and determine when detected motions and movements warrant triggering the data ping.","1. A method of tracking an asset, the method comprising: transmitting, by a transmitter located with the asset, an initial set of data pings at an initial frequency, wherein a data ping includes data relative to the asset;detecting a series of movements of the asset, wherein detecting includes using a motion sensor coupled to the transmitter;creating one or more actions, wherein creating includes combining the series of movements;correlating the one or more actions to a qualified event, wherein the qualified event is predefined by a unique pattern in the one or more actions; andtransmitting, by the transmitter, a subsequent set of data pings at a subsequent frequency, wherein the subsequent set of data pings are transmitted based on the correlation of the one or more actions to the qualified event, and wherein the subsequent frequency is greater than the initial frequency.","20","15/439664","2017-02-22","2017-0372103","2017-12-28","9965662","2018-05-08","Chep Technology PTY Limited","Brian  Lee | Mrinmoy  Chakraborty | Jamshed  Dubash | Jahangir  Nakra","","","","G06K-0007/10366","G06K-0007/10366 | G06Q-0010/06 | G06Q-0010/08 | G06Q-0050/28 | G01S-0005/0027","G06K-007/10","G06K-007/10 | G08B-001/08 | G06Q-010/08 | G06Q-010/06 | A61B-005/103 | B60R-025/10 | G06Q-050/28 | G01S-005/00","","","","","","4918019004505"
"US","US","P","B2","Using virtual reality for behavioral analysis","Examples of the disclosure provide for calibrating a virtual reality environment based on data input in response to initial calibration prompts to provide a customized detection phase for a behavior analysis session. User interaction data are received during the customized detection phase and is dynamically pushed through a trained machine learning component to generate a dynamic behavior vector for the behavior analysis session, the dynamic behavior vector updating during the customized detection phase. The virtual reality environment is dynamically modified during the customized detection phase using the dynamic behavior vector.","1. A method for gamified behavioral analysis, the method comprising: calibrating, by a processor, a virtual reality environment based on data input in response to initial calibration prompts to provide a customized detection phase for a behavior analysis session;receiving user interaction data during the customized detection phase;dynamically pushing the received user interaction data through a trained machine learning component during the customized detection phase to generate a dynamic behavior vector for the behavior analysis session, the dynamic behavior vector updating during the customized detection phase; anddynamically modifying the virtual reality environment during the customized detection phase using the dynamic behavior vector to structure the virtual reality environment.","20","15/266583","2016-09-15","2018-0075293","2018-03-15","9965675","2018-05-08","Georgios P. Schinas | Ilias K Chrysovergis | Leontios J. Hadjileontiadis | Vasileios Baltatzis | Kyriaki-Margarita Bintsi","Georgios P.  Schinas | Ilias K  Chrysovergis | Leontios J.  Hadjileontiadis | Vasileios  Baltatzis | Kyriaki-Margarita  Bintsi","","","","G06K-0009/00335","G06K-0009/00335 | A61B-0005/16 | G06F-0003/011 | G06K-0009/42 | G06K-0009/46 | G06K-0009/6228 | G06K-0009/6269 | G06N-0099/005 | G06T-0019/006","G06K-009/00","G06K-009/00 | G06N-099/00 | G06T-019/00 | G06F-003/01 | G06K-009/42 | G06K-009/46 | G06K-009/62 | A61B-005/16","","","","","","4918019004518"
"US","US","P","B2","Notifying a user about a cause of emotional imbalance","Some aspects of this disclosure include systems, methods, and/or computer programs that may be used to notify a user about a cause of emotional imbalance. Some embodiments described herein involve determining when a user is in a state of emotional imbalance based on a measurement of affective response of the user, which is taken with a sensor. Factors characterizing an event to which the measurement corresponds are examined in order to select a certain factor that, based on a model of the user, has an effect on the user that is congruous with the measurement of affective response. The user is notified about the certain factor in order to make the user more aware of the certain factor and its effect on the user.","1. A system configured to notify a user about a cause of emotional imbalance, comprising: a sensor configured to take measurements of affective response of the user; anda computer configured to:receive from the sensor a measurement corresponding to an event, and to make a determination of whether the measurement indicates a state of emotional imbalance of the user;receive factors characterizing the event and to select a certain factor that, based on a model of the user, has an effect on the user that is congruous with the measurement of affective response of the user; wherein the model was trained based on data comprising: measurements of affective response of the user corresponding to events involving the user having various experiences, and descriptions of the events; andnotify the user about the certain factor that characterizes the event, responsive to a determination that the measurement indicates the state of emotional imbalance of the user.","21","15/193091","2016-06-26","2016-0302711","2016-10-20","9955902","2018-05-01","AFFECTOMATICS LTD.","Ari M  Frank | Gil  Thieberger","","","","A61B-0005/165","A61B-0005/165 | A61B-0005/7267 | A61B-0005/7275 | A61B-0005/7282 | A61B-0005/746 | G06F-0017/3053 | G06F-0021/6245","G08B-023/00","G08B-023/00 | A61B-005/16 | A61B-005/00 | G06F-021/62 | G06F-017/30","","","","","","4918018000952"
"US","US","P","B2","System and method for selecting an audio file using motion sensor data","The present invention relates to a system and a method for selecting an audio file using motion data from a mobile computing device connected to or held by a user, the mobile computing device comprising or coupled to motion sensors. The method comprising steps of moving the mobile computing device, obtaining motion data from the motion sensors, computing from the motion data step data based on a number of steps taken by the user in a specific period of time, computing a metronome beat based on the step data and generating a metronome beat file, selecting a stored audio file having a predefined beat parameter matching the metronome beat of the metronome beat file, and playing the audio file. The present invention provides a technology solution delivered through a mobile computing device, such as smart phone, or other computing device, such as a laptop or a PC, a wrist or smart watch, or an accelerometer, pedometer or other external computing device having computer processor means, that improves the gait of people with Parkinson's disease. In use, the user's daily mobility is assessed through application software on a mobile computing device which is operable to calculate a required individually prescribed treatment for a user. The treatment is then delivered through speakers of the mobile computing device in the form of metronome therapy which is form of auditory cueing that is used to treat people with Parkinson's disease.","1. A method of providing metronome therapy for a user who performs an activity with a cadence of movement by selecting a metronome audio file from a selection of metronome audio files accessed by a mobile computing device carried by the user during said activity, said method comprising the steps of: providing a mobile computing device that is operable to play said metronome audio files, wherein each of said audio files has corresponding audio beat parameters;providing at least one motion sensor operable to detect motion of the user at the mobile computing device, wherein said at least one motion sensor has a sensitivity setting;wherein when the user performs said activity with said cadence of movement said at least one motion sensor detects said cadence of movement;providing a sensitivity bar operable to adjust said sensitivity setting of said at least one motion sensor depending upon said cadence of movement by calibrating said at least one motion sensor to detect steps of a user according to said cadence of movement;configuring the at least one motion sensor to detect a deceleration in said cadence of movement by said user;detecting, identifying and recording changes in said cadence of movement that fall within a selected range of decelerations that are attributable to Parkinson'ss disease and generating motion data;using said motion data to generate a corresponding metronome beat;automatically selecting a specific metronome audio file from said metronome audio files on said mobile computing device by comparing said metronome beat to said audio beat parameters to find a best match; andproviding the metronome therapy to the user by playing said specific metronome audio file on said mobile computing device that corresponds to said best match.","15","15/035231","2014-11-10","2016-0270712","2016-09-22","9955906","2018-05-01","BEATS THERAPEUTICS LIMITED","Ciara Lourda  Clancy | Cianan Colm  Clancy | Wui Mei  Chew","2013-192205","EP","2013-11-08","A61B-0005/4082","A61B-0005/4082 | A61B-0005/0022 | A61B-0005/112 | A61B-0005/6898 | A61B-0005/7282 | G06F-0003/0346 | G10H-0001/0008 | G10H-0001/40 | A61B-2560/0223 | A61B-2562/0219 | G06F-0003/162 | G10H-2220/086 | G10H-2220/395 | G10H-2230/015 | G10H-2240/135","G06F-017/00","G06F-017/00 | A61B-005/00 | A61B-005/11 | G10H-001/40 | G06F-003/0346 | G10H-001/00 | G06F-003/16","","","","","","4918018000956"
"US","US","P","B2","Process for evaluation of at least one facial clinical sign","The present invention relates to a process without a therapeutic target that evaluates at least one facial clinical sign and/or evaluates make-up, in particular evaluates wrinkles or fine lines from a portion of the face, including steps consisting in: ?from a sequence of facial images of a person filmed while emitting at least one sound, extract from the sequence one or more images coinciding with the emission of at least one predefined sound, ?from the resulting image or images extracted, evaluate at least one facial clinical sign appearing on the image or images extracted and/or evaluate at least one characteristic related to make-up.","1. A method to evaluate at least one facial clinical sign, comprising: from a digitized sequence of facial images of a person filmed while emitting at least one sound, extract, with a device with a processor, one or more images coinciding with the emission of at least one predefined sound, the image extraction being performed automatically based on an analysis by the device of the sound emitted;from the resulting image or images extracted, evaluate, with the device with the processor, at least one facial clinical sign appearing on the image or images extracted, the evaluation comprising comparing automatically by the device the images extracted with reference images.","20","15/104011","2014-12-11","2017-0020436","2017-01-26","9955909","2018-05-01","L'OREAL","Frederic  Flament","2013-062468","FR","2013-12-12","A61B-0005/442","A61B-0005/442 | A61B-0005/0077 | A61B-0005/4803 | G06F-0003/167 | G06K-0009/00255 | G06K-0009/00281 | G06K-0009/00288","A61B-005/00","A61B-005/00 | G06F-003/16 | G06K-009/00","","","","","","4918018000959"
"US","US","P","B2","Imaging a body","There is disclosed a device for imaging a body. In one arrangement, the device comprises a controller, storage storing electronic program instructions for controlling the controller, a display for displaying a user interface, and an input means. In one form, the controller is operable, under control of the electronic program instructions, to receive input via the input means, where the input comprises a first representation of the body, to process the first representation, to generate a second representation of the body on the basis of processing of the first representation, and to display the generated second representation via the display.","1. A device for imaging a body of a user, the device comprising: a controller;storage storing electronic program instructions for controlling the controller;a display for displaying a user interface; andan image capturing device configured to capture visual images;wherein the controller is operable, under control of the electronic program instructions, to: receive input at least in part via the image capturing device, the input comprising a first representation of the body, and the first representation comprising one or more visual representations of the body;display the first representation via the display;generate, using (i) a model of skeleton joint positions, and (ii) at least a weight of the user, a user-specific skeleton that will appear on the display once the input is received;enable the user to align the body in the first representation with the user-specific skeleton, at least in part by (i) displaying the user-specific skeleton along with one or more real time captured images of the body and (ii) instructing the user to move in such a manner that the displayed body is aligned to the displayed user-specific skeleton;process the first representation, when the displayed body has been aligned with the displayed user-specific skeleton, by segmenting the first representation of the body to obtain a plurality of silhouettes which correspond to projected shadows of a substantially true three dimensional scan of the body;generate a second representation of the body on the basis of the plurality of silhouettes; anddisplay the generated second representation via the display.","26","15/612441","2017-06-02","2017-0273639","2017-09-28","9949697","2018-04-24","MYFIZIQ LIMITED","Katherine  Iscoe | Vlado  Bosanac | Amar  El-Sallam","2014-904940","AU","2014-12-05","A61B-0005/744","A61B-0005/744 | A61B-0005/0064 | A61B-0005/0075 | A61B-0005/0077 | A61B-0005/1072 | A61B-0005/1073 | A61B-0005/1079 | A61B-0005/1128 | A61B-0005/7475 | G06F-0003/04815 | G06F-0003/167 | G06F-0019/321 | G06F-0019/3437 | G06F-0019/3481 | G06N-0005/04 | G06N-0099/005 | G06T-0007/194 | G06T-0007/33 | G06T-0013/40 | G16H-0050/50 | A61B-2562/028 | A61B-2562/0219 | G06F-0019/3406 | G06T-0017/20 | G06T-2200/24 | G06T-2207/10028 | G06T-2207/30196 | G06T-2210/56 | G16H-0040/63","G06T-013/40","G06T-013/40 | A61B-005/00 | G06F-019/00 | G06N-099/00 | G06N-005/04 | G06F-003/16 | G06F-003/0481 | G06T-007/33 | G06T-007/194 | A61B-005/107 | A61B-005/11 | G06T-017/20","","","","","","4918017000795"
"US","US","P","B2","Portal dosimetry system","Embodiments of the invention provide systems and methods for evaluating treatment parameters for a patient undergoing radiotherapy. The method includes the step of generating a portal dosimetry image showing differences between a planning image obtained prior to a treatment session and a portal image obtained during the treatment session. A database of prior portal dosimetry results is accessed, and a processor is used to perform a similarity measurement between the portal dosimetry image and the prior portal dosimetry results. Based on the similarity measurement, the system determines whether radiation was delivered as planned during the treatment session.","1. A computer-implemented method of evaluating treatment parameters for a patient undergoing radiotherapy, wherein a portal imaging device is located under the patient such that a radiation beam passes through the patient to the portal imaging device, the method comprising: obtaining, from an initial medical imaging device, a planning image of the patient prior to radiotherapy, the planning image including an expected portal image of a target region of the patient;obtaining a portal image during radiotherapy from the portal imaging device, the portal image corresponding to an actual dose distribution delivered to the target region of the patient when a radiation beam is turned on;generating, by a processor of a portal dosimetry system, during radiotherapy, a first portal dosimetry image identifying one or more differences between the planning image and the portal image;accessing, over an electronic communications network, a database configured to store a plurality of prior portal dosimetry images identifying: differences between prior planning images and prior portal images;assessment information for the prior portal dosimetry images, the assessment information including at least one of true positive difference information and false positive difference information; andone or more corresponding decisions made regarding the prior portal dosimetry images;performing a similarity measurement, by the processor, between the first portal dosimetry image and the prior portal dosimetry images from the database;determining, by the processor, whether to interrupt radiotherapy, wherein the determination is based on an analysis of the similarity measurement, the assessment information, and the corresponding decisions made regarding the prior portal dosimetry images; andproviding, by the processor, an indication of whether to interrupt radiotherapy, the indication being displayed on a graphical user interface of the portal dosimetry system.","25","14/992117","2016-01-11","2016-0125602","2016-05-05","9953416","2018-04-24","Elekta AB (PUBL)","Colin  Winfield | Abdul  Sayeed","","","","G06T-0007/0012","G06T-0007/0012 | A61N-0005/1071 | G06F-0017/30259 | G06F-0019/321 | G06F-0019/3481 | G06K-0009/6202 | G16H-0050/20 | A61N-2005/1054 | G06T-2207/10004 | G06T-2207/10116","G06T-007/00","G06T-007/00 | G06K-009/62 | G06F-017/30 | G06F-019/00 | A61N-005/10","","","","","","4918017004500"
"US","US","P","B2","User activity tracking system","In one embodiment, sensor signals corresponding to motions of a client device are received. Activities of a user corresponding to the client device are determined, based on a first analysis algorithm that uses the sensor signals to select activity types, each activity type corresponding to a particular time period. A reference to the selected activity types is sent to the client device. User input indicating whether the reference is correct is received from the client device. Based on the indication, which reflects the accuracy of the first analysis algorithm, a priority between the first analysis algorithm and a second analysis algorithm is determined, based on determining which analysis algorithm is more accurate.","1. A method comprising: by one or more computing devices, receiving, from a client device, one or more sensor signals corresponding to one or more motions of the client device;by the one or more computing devices, determining one or more activities of a user, wherein: the user corresponds to the client device; andthe determining comprises using a first analysis algorithm of the one or more computing devices to select, based on the one or more sensor signals, one or more activity types, wherein each of the one or more activity types corresponds to a particular time period;by the one or more computing devices, sending, to the client device, a reference to the selected activity types;by the one or more computing devices, receiving user input from the client device, wherein the user input indicates whether the reference is correct; andby the one or more computing devices, in response to the user input, determining whether to prioritize a second analysis algorithm of the one or more computing devices over the first analysis algorithm, wherein the determining priority is based on determining, based on the user input, that the second analysis algorithm is more accurate than the first analysis algorithm.","20","15/343046","2016-11-03","2017-0078418","2017-03-16","9948734","2018-04-17","Facebook, Inc.","Juho  Pennanen | Aapo  Kyrola | Jukka  Partanen","","","","H04L-0067/22","H04L-0067/22 | A61B-0005/0002 | A61B-0005/0022 | A61B-0005/103 | A61B-0005/1118 | G01S-0019/19 | G06N-0099/005 | H04L-0067/12 | H04M-0001/72569 | H04M-0001/72572 | H04W-0004/005 | H04W-0004/028","H04W-024/00","H04W-024/00 | H04L-029/08 | H04W-004/00 | A61B-005/00 | A61B-005/103 | A61B-005/11 | H04W-004/02 | G06N-099/00 | G01S-019/19 | H04M-001/725","","","","","","4918016006110"
"US","US","P","B2","Automated patient-specific method for biomechanical analysis of bone","A computer-implemented method for providing FEA analysis of at least a portion of at least one bone in a patient, the method comprising steps of: providing at least one image of at least a portion of a bone; selecting at least a portion of the bone; automatically performing an FE analysis of the selected portion of the bone; and displaying at least one result of the FE analysis. Bone selection and display of the bone, the selected portion thereof, and the results of the FE analysis occur via a hand-held device, with processing and data storage performed remotely.","1. A computer-implemented method for providing finite element analysis (FEA) of at least a portion of at least one bone in a patient, said method comprising: a. providing at least one image of at least a portion of said bone;b. calculating material properties of said bone as a function of three dimensional (3D) position within said bone from density of said bone as a function of 3D position within said bone via empirically-determined material properties correlated to density, said density determined from at least one property of said image of said bone;c. generating an analyzable model using steps of: i. generating by an automatic algorithm from said image a solid model of said at least a portion of said at least one bone by steps of: identifying the boundaries of said bone in said image, said boundary identification via edge detection software; smoothing said boundaries; generating a point cloud model of said boundaries; generating spline curves through points in said point cloud; and generating a solid model through said spline curves;ii. automatically generating, from said solid model, a finite element (FE) mesh of said at least a portion of said at least one bone, said FEs being high-order finite elements (p-FE) having smooth surfaces;iii. applying a noise reduction algorithm by boundary correction and moving average for each said FE in said p-FE mesh;iv. for each said FE in said p-FE mesh, setting said material properties of said FE according to said material properties of said bone at said 3D position;v. applying boundary conditions to at least one said FE in said FE mesh;d. solving said analyzable model, thereby generating a solved model; ande. providing at least one result from said solved modelwherein said steps of providing said bone image ensure that said solved model is patient-specific;wherein said steps of generating said point cloud and generating said spline curves enable the surface of said solid model to be smooth, thereby enabling the surface of said FE model to be smooth, and further wherein said steps of generating said FE mesh of p-FE enable said FEs to have heterogeneous material properties, thereby reducing the number of FEs in said FE mesh; andfurther wherein said steps of determining material properties comprise additional steps of identifying the cortical-trabecular boundary of said bone, of identifying voxel values of Hounsfield unit (HU)>475 (bone ash density ρash>0.486 g/cm3) as said cortical bone and of identifying voxel values of HU<475 (ρash<0.486 g/cm3) as said trabecular bone.","16","15/027701","2014-10-07","2016-0242852","2016-08-25","9937011","2018-04-10","PERSIMIO LTD","Zohar  Yosibash | Nir  Trabelsi | Kent  Myers | Charles  Milgrom","","","","A61B-0034/10","A61B-0034/10 | A61B-0005/0037 | A61B-0005/055 | A61B-0005/4504 | A61B-0005/4884 | A61B-0005/7275 | A61B-0006/032 | A61B-0006/505 | A61B-0006/5217 | A61B-0006/5258 | G06F-0017/5009 | G06T-0017/20 | G06T-0019/20 | A61B-2034/102 | G06T-2200/04","G06K-009/00","G06K-009/00 | A61B-034/10 | G06T-017/20 | A61B-006/00 | A61B-005/00 | A61B-005/055 | A61B-006/03 | G06F-017/50 | G06T-019/20","","","","","","4918015001071"
"US","US","P","B2","Computer-aided multiple standard-based functional evaluation and medical reporting system","A method of performing an objective functional evaluation of a person's physical capacity comprises of a computer program particularly designed to amass and assess test data in accordance with a selected standard. A wide variety of evaluation protocols are incorporated to lead an operator in a step-by-step process. The method includes special testing tools, many of which have been modified to input data directly into the computer diagnostic program. The interface may be a wired or a wireless connection. The software program may use an algorithm to calculate a coefficient of variation for the multiple trials of a test, using the entered data, to providing a determination of validity of the trials. A second algorithm calculates an average result of the condition-specific protocol of tests, after which the software program correlates those average results to a database of normative standards to compute an impairment rating.","1. A method for displaying assessment information relating to and facilitating determining one or more functional abilities of a patient being determined in a functional evaluation using a plurality of specialized measurement devices and a computer system with displaying of measurements from three successive test trials out of a maximum of six total trials on a graphical user interface, the method comprising: dynamically displaying each measurements in a respective plurality of locations in a measurement display region, each location in the measurement display region corresponding to the measurements taken in three successive test trials for the left and right sides of the patient, the three measurements representing strength or range of motion measurements associated with at least one protocol of tests to assess the one or more current functional abilities of the patient during the functional evaluation;dynamically displaying a respective coefficient of variation in a plurality of locations in a test results display region, each location in the test results display region corresponding to a coefficient of variation for the left side of the patient and the right side of the patient, the coefficient of variation representing test validity of the three successive test trials out of the maximum of six total trials for each of the left side and right side of the patient;displaying the measurement display region and the test results display region in relation to each other, positioned below a measurement graph displaying taking of each measurement, such that when there is a deficiency between the right and left sides, a percentage of deficiency is displayed on the deficient left side or right side; and immediately stopping the functional evaluation when the coefficient of variation for the left side or the right side is above a threshold amount;displaying a test protocol selection graphical user interface comprising a pictorial image of a front side and a back side of a human body for identifying a plurality of body regions, each of said plurality of body regions being selectable for said functional evaluation; and associating a respective protocol of tests with each body region of the plurality of body regions; andin response to a selection of one or more of the body regions by a single action of a user input device, displaying of the respective protocol of tests for each of the selected one or more body regions, and providing instructions in an instructions graphical user interface for completing the respective protocol of tests for said functional evaluation.","7","12/804646","2010-07-26","2012-0022884","2012-01-26","9940437","2018-04-10","Michael Chillemi","Michael  Chillemi","","","","G06F-0019/3431","G06F-0019/3431 | A61B-0005/1121 | A61B-0005/743 | A61B-0005/7435 | G06Q-0050/22 | A61B-0005/1075 | A61B-0005/458 | A61B-0005/4566 | A61B-0005/4576 | A61B-2560/0223 | G06F-0003/048","G06Q-010/00","G06Q-010/00 | G06F-019/00 | A61B-005/11 | A61B-005/00 | G06Q-050/22 | G06Q-050/00 | G06F-003/048 | A61B-005/107","","","","","","4918015004470"
"US","US","P","B2","User control of data de-identification","A method for transmitting, storing and sharing data collected by a wearable device is provided. In one example, data related to one or more measurements obtained by the wearable device configured to be mounted to a body surface of a wearer is received in addition to an input by the wearer of the device. The input selects at least one identification rule that determines whether or how the wearer is identified in connection with the data from the wearable device. The data is stored in a database based, at least in part, on the at least one identification rule. The input from the wearer may also select at least one permission rule that determines whether third parties can access the data from the wearable device. A third party may be required to provide payment for access to or use of the data according to the at least one permission rule.","1. A method, comprising: receiving, by a server, data related to one or more measurements obtained by a wearable device, wherein the wearable device is mounted to a body surface of a wearer;receiving, by the server, a selection of at least one permission rule;determining, by the server, whether a third party can access the data from the wearable device based on the at least one permission rule;receiving, by the server, a selection of at least one identification rule;determining, by the server based on a third party use of the data, the at least one identification rule and the at least one permission rule, a type of one or more identifiers to include with the data;replacing, by the server, an express identifier received with the data with a synthetic identifier for association with at least some of the data, wherein the synthetic identifier masks an identity of the wearer from third parties; andstoring, by the server, the data with the determined type of the one or more identifiers, wherein at least some of the data is stored in association with the synthetic identifier.","14","14/325715","2014-07-08","2016-0014129","2016-01-14","9942232","2018-04-10","VERILY LIFE SCIENCES LLC | GOOGLE LLC","Brian Taewon  Park | Russell Norman  Mirov","","","","H04L-0063/10","H04L-0063/10 | A61B-0005/0022 | A61B-0005/6801 | A61B-0005/681 | A61B-2562/08","G06F-017/00","G06F-017/00 | H04L-029/06 | A61B-005/00","","","","","","4918015006254"
"US","US","P","B2","Computer-aided analysis and rendering of medical images using user-defined rules","Systems and methods that allow transfer and display rules to be defined based on one or more of several attributes, such as a particular user, site, device, and/or image/series characteristic, as well as whether individual images and/or image series are classified as thin slices and/or based on other characteristics, and applied to medical images in order to determine which images and/or image data are analyzed, downloaded, viewed, stored, rendered, processed, and/or any number of other actions that might be performed with respect to medical image data. The system and methods may include image analysis, image rendering, image transformation, image enhancement, and/or other aspects to enable efficient and customized review of medical images.","1. A computer-implemented method of automated analysis of medical images, the method comprising: by one or more processors executing program instructions: accessing a set of medical image data;automatically analyzing the set of medical image data by a CAP action to determine a value of an attribute of the set of medical image data;accessing a user-defined rule indicating an association between the value of the attribute and a desired image slice thickness;determining whether the set of medical image data is formatted according to the desired image slice thickness indicated by the user-defined rule; andin response to determining that at least a portion of the set of medical image data is not formatted according to the desired image slice thickness rendering at least the portion of the set of medical image data as a series of medical images having the desired slice thickness.","20","15/469296","2017-03-24","2017-0200270","2017-07-13","9934568","2018-04-03","D.R. SYSTEMS, INC.","Murray A.  Reicher | Michael  Trambert | Evan K.  Fram","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/7271 | A61B-0005/742 | G06F-0019/321 | G06T-0011/60 | G06T-0015/08 | H04L-0067/02 | H04L-0067/10 | H04L-0067/42 | G06F-2101/00 | G06T-0015/005 | G06T-2207/30004","G06K-009/00","G06K-009/00 | G06T-007/00 | G06T-011/60 | A61B-005/00 | H04L-029/06 | G06F-019/00 | G06T-015/08 | H04L-029/08 | G06T-015/00","","","","","","4918014004371"
"US","US","P","B2","Method of and apparatus for providing medical image","A method of providing multimodal medical images includes: loading first image data and second image data obtained by two different imaging modalities; generating object modeling data based on at least one of the first image data and the second image data; and displaying, on a display, the first image data, the second image data, and the object modeling data. The object modeling data is a virtual model of a body tissue of an object.","1. A method of providing multimodal medical images, the method comprising: loading first image data and second image data obtained by two different imaging modalities;generating object modeling data based on at least one among the first image data and the second image data;displaying, on a display, the first image data, the second image data and the object modeling data that are registered based on information about a posture of an object during imaging of at least one among the first image data and the second image data;based on receiving an input of selecting a location on the displayed object modeling data, determining locations on the displayed first image data and the displayed second image data which correspond to the selected location; anddisplaying the determined locations on the first image data and the second image data, respectively.","29","14/527326","2014-10-29","2015-0178925","2015-06-25","9934588","2018-04-03","SAMSUNG ELECTRONICS CO., LTD.","Hyun-hee  Jo","10-2013-0161783","KR","2013-12-23","G06T-0007/344","G06T-0007/344 | A61B-0005/055 | A61B-0005/7425 | A61B-0006/463 | A61B-0006/502 | A61B-0006/5235 | A61B-0006/5247 | A61B-0008/0825 | A61B-0008/463 | A61B-0008/5261 | G06F-0003/04842 | G06F-0019/321 | G06F-0019/3437 | G06T-2207/10088 | G06T-2207/10104 | G06T-2207/10116 | G06T-2207/10132 | G06T-2207/30068 | G06T-2207/30096","G06K-009/00","G06K-009/00 | G06T-007/33 | A61B-006/00 | A61B-008/00 | A61B-008/08 | A61B-005/055 | G06F-003/0484 | A61B-005/00 | G06F-019/00","","","","","","4918014004391"
"US","US","P","B2","Method for helping determine the vision parameters of a subject","The invention concerns a method for helping determine the vision parameters of a subject (100), comprising the following steps: ?taking (120) two images (11, 12) from two different angles of the face of the subject by means of a camera (10), the subject (S) being in a natural distant vision position, ?determining (130) the inclination of the camera (10) relative to the ground at the time when the images are taken, ?deducing therefrom (140) the inclination and the direction of the face of the subject (S), characterized in that the camera is arranged outside a foveal area of the subject when the images (11, 12) are taken (120).","1. A method for helping determine the vision parameters of a subject (100), including the following steps: capture (120) a first image (I1, I2) at a first angle of the subject'ss face by means of an image capturing device (10) and a second image at a second angle of the subject'ss face by means of the image capturing device, the second angle being different from the first angle and the subject (S) being in a natural distant vision posture, determine (130) the inclination of the image capturing device with respect to the ground at the time of image capture,deduce therefrom (140) the vision parameters of the face of the subject (S),characterized in that the image capturing device is positioned outside a foveal area of the subject at the time of capture (120) of the images (I1, I2).","14","14/431764","2013-09-25","2015-0339511","2015-11-26","9928421","2018-03-27","INTERACTIF VISUEL SYSTEME (I V S)","Pascal  Thomet | David  Encaoua","2012-059044","FR","2012-09-26","G06K-0009/0061","G06K-0009/0061 | A61B-0005/0077 | A61B-0005/103 | G02C-0013/003 | G02C-0013/005 | G06F-0017/3028 | G06K-0009/00268 | G06K-0009/52 | G06T-0007/0012 | G06T-0007/73 | A61B-0003/145","G06K-009/00","G06K-009/00 | G06K-009/52 | G06T-007/00 | G06F-017/30 | A61B-005/103 | G02C-013/00 | A61B-005/00 | G06T-007/73 | A61B-003/14","","","","","","4918013004458"
"US","US","P","B2","Gaze-driven augmented reality","Augmented reality (AR) systems, methods, and instrumentalities are disclosed. A user's gaze point may be estimated and may be used to search for and present information, e.g., information relating to areas on which the user is focusing. The user's gaze point may be used to facilitate or enable modes of interactivity and/or user interfaces that may be controlled by the direction of view of the user. Biometric techniques may be used to estimate an emotional state of the user. This estimated emotional state may be used to be the information that is presented to the user.","1. A method for providing augmented reality (AR) to a user, comprising: estimating a gaze point of the user to define a region of interest (ROI), wherein the ROI contains at least one physical object;adaptively adjusting a size of the ROI based upon one or more of an active command, a gaze focused for a time exceeding a threshold, a user activity, or a number of objects of interest in the first defined ROI exceeding a threshold;estimating an emotional state of the user;sending information associated with the adjusted ROI and the emotional state of the user to a server;receiving information regarding one or more objects in the ROI from the server, wherein the information about the one or more objects in the ROI is filtered based on the emotional state of the user; anddisplaying the information regarding the one or more objects in the ROI while the user is in proximity to the one or more objects in the ROI.","21","15/028233","2014-10-10","2016-0259977","2016-09-08","9922253","2018-03-20","INTERDIGITAL PATENT HOLDINGS, INC.","Eduardo  Asbun | Yuriy  Reznik | Ariela  Zeira | Gregory S.  Sternberg | Ralph  Neff","","","","G06K-0009/00671","G06K-0009/00671 | A61B-0005/0022 | A61B-0005/1112 | A61B-0005/165 | A61B-0005/742 | G02B-0027/017 | G06F-0003/013 | G06K-0009/00302 | G06K-0009/00604 | H04W-0004/04 | A61B-0005/0476 | A61B-0005/0533 | G06F-0003/015","G09G-005/00","G09G-005/00 | G02B-027/01 | G06F-003/01 | G06K-009/00 | A61B-005/16 | A61B-005/00 | A61B-005/11 | H04W-004/04 | A61B-005/0476 | A61B-005/053","","","","","","4918012004489"
"US","US","P","B2","Bluetooth service discovery","A method provides a service in a Bluetooth device. The method includes initiating, in a first Bluetooth device connection establishment with a second Bluetooth device; carrying out a service discovery procedure with the second Bluetooth device, during which at least one unique service identifier associated with a personal training data service is exchanged between the first Bluetooth device and the second Bluetooth device, wherein the personal training data service comprises at least one personal training data item processed by the first Bluetooth device and/or the second Bluetooth device during a physical exercise; and after the service discovery procedure, transferring at least one frame with the second Bluetooth device, wherein the frame comprises an information element specifying personal training data and a command information element specifying how to process the personal training data.","1. A method comprising: initiating, by a first Bluetooth device, connection establishment with a second Bluetooth device;carrying out a service discovery procedure by the first Bluetooth device with the second Bluetooth device, during which the first Bluetooth device receives from the second Bluetooth device a broadcasted radio frequency discovery frame comprising at least one unique service identifier that advertises and uniquely identifies a personal training data service, wherein the personal training data service is provided by the second Bluetooth device and processes at least one personal training data item that represents personal training data associated with a user during a physical exercise; andtransmitting, after the service discovery procedure, at least one radio frequency frame by the first Bluetooth device to the second Bluetooth device, wherein the at least one radio frequency frame comprises an information element specifying personal training data associated with the user of the discovered personal training data service and a command information element specifying how to process the personal training data specified by the information element associated with the at least one radio frequency frame.","20","15/483581","2017-04-10","2017-0214748","2017-07-27","9923973","2018-03-20","POLAR ELECTRO OY","Niclas  Granqvist | Hannu  Kinnunen","","","","H04L-0067/12","H04L-0067/12 | A61B-0005/002 | A63B-0022/02 | A63B-0022/0605 | A63B-0022/0664 | G06F-0017/30312 | H04L-0005/0055 | H04L-0067/06 | H04L-0067/16 | H04W-0004/008 | H04W-0008/005 | H04W-0048/10 | H04W-0072/04 | H04W-0076/023 | H04W-0076/06 | A63B-2220/12 | A63B-2225/15 | A63B-2225/50 | A63B-2230/06 | H04L-0067/42","H04B-007/00","H04B-007/00 | H04L-029/08 | H04W-004/00 | A63B-022/02 | A63B-022/06 | A61B-005/00 | H04W-072/04 | H04W-008/00 | G06F-017/30 | H04L-005/00 | H04W-048/10 | H04W-076/02 | H04W-076/06 | H04L-029/06","","","","","","4918012006194"
"US","US","P","B2","Systems and methods for selecting a desired quantity of follicular units","Systems and methods for selecting follicular units in a distribution of follicular units are provided. A selection parameter, such as a distance-related parameter separating the follicular units to be selected, may be used to determine a desired quantity of follicular units to be selected, such as a desired percentage of follicular units to be selected, and to help provide a substantially uniform distribution of selected follicular units. In addition, a characteristic parameter, such as a characteristic distance or characteristic density, may be determined. The characteristic parameter may be used in determining the desired quantity of follicular units to be selected and or may be used for treatment purposes.","1. A method of calculating a characteristic parameter of follicular units from follicular unit distribution data, the method comprising: for a set of selected follicular units, calculating, with a processor, an average value of a parameter between a selected follicular unit and a set of closest neighboring follicular units to establish a set of average values; andcalculating, with the processor, the characteristic parameter as the average of the set of average values.","20","14/574066","2014-12-17","2015-0112204","2015-04-23","9913610","2018-03-13","RESTORATION ROBOTICS, INC.","Mohan  Bodduluri | Gabriele  Zingaretti","","","","A61B-0005/448","A61B-0005/448 | A61B-0005/0077 | A61B-0005/1072 | A61B-0005/1079 | A61B-0005/4836 | A61B-0005/7203 | A61B-0005/7278 | A61B-0005/7425 | A61B-0005/7475 | A61B-0017/322 | A61B-0034/10 | A61B-0034/30 | A61F-0002/10 | G06F-0017/18 | G06T-0007/0012 | A61B-2017/00752 | A61B-2034/108 | A61B-2090/3612 | A61B-2090/502 | A61B-2576/02 | G06T-2207/30088 | G06T-2207/30242","A61B-017/50","A61B-017/50 | A61B-005/00 | A61F-002/10 | G06T-007/00 | A61B-005/107 | A61B-017/322 | G06F-017/18 | A61B-034/30 | A61B-034/10 | A61B-017/00 | A61B-090/50 | A61B-090/00","","","","","","4918011000726"
"US","US","P","B2","User terminal and method of providing information to a user thereof","A user terminal and a providing method thereof are provided. The method includes acquiring an iris image, determining a capturing condition of the iris image, converting the acquired iris image to an iris code and performing iris recognition by comparing the converted iris code with an iris code corresponding to a determined capturing condition among pre-registered iris codes, determining a physical condition of a user who is subject to the iris recognition on the basis of an iris recognition matching rate being within a preset range, and providing a determined physical condition result.","1. A providing method of providing information to a user of a user terminal, the method comprising: capturing, by a camera, an iris image of a user;identifying, by a processor, a capturing condition of the iris image;converting, by the processor, the iris image to an iris code;performing, by the processor, iris recognition by comparing a pre-registered iris code stored in a memory corresponding to the capturing condition of the captured iris image and the converted iris code;calculating, by the processor, an iris recognition matching rate in a process of performing the iris recognition by a processor;identifying, by the processor, a physical condition of the user who is subject to the iris recognition, in response to the iris recognition matching rate being within a preset rate; anddisplaying an identified physical condition result on a display.","20","15/019028","2016-02-09","2016-0232408","2016-08-11","9916504","2018-03-13","SAMSUNG ELECTRONICS CO., LTD.","Kang-min  Lee | Jun-ho  Koh | Byeong-hoon  Kwak | Sung-chan  Kim | Yang-wook  Kim | Chang-han  Kim | Hyun-jung  Kim | In-hak  Na | Kang-jin  Yoon | Yong-chan  Lee | Jae-ho  Jung","10-2015-0020070","KR","2015-02-10","G06K-0009/00617","G06K-0009/00617 | A61B-0005/0077 | A61B-0005/7435 | G06F-0003/048 | G06K-0009/00604","G06K-009/00","G06K-009/00 | G06F-003/048 | A61B-005/00","","","","","","4918011003600"
"US","US","P","B2","User-state mediated product selection","Systems and methods may provide purchasing suggestions to consumers based on the emotional, financial, social or physiological state of the consumer. The state of a consumer is based on data that may be collected from a variety of sources, including image data and biosensor data collected at the point of sale, as well as data accessible via smart phone or stored elsewhere. The systems and methods may be practiced in the context of a vending machine, bricks-and-mortar store, on-line store, or other venue.","1. A system to suggest items to a consumer, comprising: a processor;a suggestion logic unit, implemented by the processor, wherein the suggestion logic unit comprises: a state characterization logic module configured to characterize a state including an emotional state exclusively of a consumer based on data provided by the consumer to one or more of a reader, a sensor, a portable device, a computer, a database, a microphone or a camera, wherein the characterization of the emotional state is made independently of a history of the consumer, and wherein the state characterization logic module includes: a social network analysis logic module configured to characterize the state using data based on mining the consumer'ss social network, anda facial analysis logic module configured to characterize the state using data based on a facial analysis of the consumer; anda rule logic module configured to generate a set of vending suggestions independently of the history of the consumer based on the emotional state exclusively of the consumer as characterized by the state characterization logic module;a display presenting the set of vending suggestions to the consumer; andan electro-mechanical dispenser to providing items to the consumer in response to one or more consumer selections from the set of vending suggestions presented to the consumer on the display, and wherein the electro-mechanical dispenser provides items to the consumer that are restricted to the vending suggestions.","25","14/294428","2014-06-03","2015-0348162","2015-12-03","9916612","2018-03-13","INTEL CORPORATION","Margaret E.  Morris | Susan A.  Faulkner","","","","G06Q-0030/0631","G06Q-0030/0631 | A61B-0005/0077 | A61B-0005/165 | G06K-0009/00302 | G06Q-0030/0269 | G06Q-0030/0281 | G06Q-0030/0282 | G06Q-0050/01 | G07F-0009/00 | H04N-0007/18 | A61B-0005/024 | A61B-0005/14507 | A61B-0005/14532 | A61B-0005/14542 | G06Q-0030/02 | G06Q-0050/22","G06Q-030/00","G06Q-030/00 | G06Q-030/06 | H04N-007/18 | G06K-009/00 | G07F-009/00 | G06Q-030/02 | G06Q-050/00 | A61B-005/00 | A61B-005/16 | G06Q-050/22 | A61B-005/024 | A61B-005/145","","","","","","4918011003708"
"US","US","P","B2","Recall device","A small wearable recall device is provided to capture images triggered by a combination of a detection of a capture condition (e.g., changes in motion, temperature or light level) followed by a relatively stable period, as detected by an accelerometer. By triggering on the combination of a detected capture condition followed by a detected stability condition, a clearer image of the environment of an interesting event is expected to be captured. The small size of the recall device makes it possible to integrate it into common portable consumer products, such as MP3 players, purses, clothing, hats, backpacks, necklaces, collars, and other human-wearable products.","1. A device comprising: an optical image capture component configured to optically capture an image;one or more sensors; anda controller configured to: receive a first signal from at least one of the sensors, the first signal being indicative of movement of the device;based on the first signal, detect occurrence of a capture condition indicating a change in motion of the device;receive a second signal from at least one of the sensors, the second signal being indicative of movement of the device;based on the second signal, detect occurrence of a stable condition;determine that the stable condition and the capture condition occurred within a predefined time period of one another; andbased on the determination that the stable condition and the capture condition occurred within the predefined time period, control the device to obtain the image in a data storage component associated with the device, wherein the stable condition occurs before the capture condition,the image is captured by the image capture component before the determination, andthe controller is configured to control the device to obtain the image by controlling storage of the image in the data storage component based on the determination.","18","15/132598","2016-04-19","2016-0295175","2016-10-06","9918049","2018-03-13","MICROSOFT TECHNOLOGY LICENSING, LLC","Lyndsay  Williams | Kenneth Robert  Woodberry | Kevin Michael  Schofield","","","","H04N-0007/188","H04N-0007/188 | A61B-0005/1117 | A61B-0005/1123 | G01S-0019/34 | G06F-0011/2005 | G06F-0011/2007 | G06F-0021/6218 | G06F-0021/6245 | G06Q-0020/10 | G06Q-0020/1235 | G06Q-0020/385 | G06Q-0020/401 | G06Q-0020/425 | G06Q-0030/0277 | G06Q-0030/0609 | G06Q-0050/188 | G07F-0017/16 | G08B-0013/19621 | G08B-0013/19628 | G08B-0013/19695 | G08B-0015/004 | H01M-0016/006 | H04B-0001/0483 | H04B-0001/40 | H04B-0007/0604 | H04B-0007/084 | H04B-0007/15535 | H04J-0013/12 | H04L-0001/0041 | H04L-0001/0045 | H04L-0001/0066 | H04L-0001/0069 | H04L-0001/0071 | H04L-0001/06 | H04L-0001/08 | H04L-0001/1819 | H04L-0001/1841 | H04L-0001/1848 | H04L-0005/0023 | H04L-0005/0042 | H04L-0005/0044 | H04L-0005/0083 | H04L-0009/32 | H04L-0012/12 | H04L-0012/2803 | H04L-0012/2809 | H04L-0012/2856 | H04L-0012/2874 | H04L-0012/40078 | H04L-0012/40195 | H04L-0012/44 | H04L-0012/56 | H04L-0012/6418 | H04L-0027/2602 | H04L-0029/06027 | H04L-0029/12113 | H04L-0041/12 | H04L-0047/10 | H04L-0047/14 | H04L-0047/22 | H04L-0047/2441 | H04L-0047/28 | H04L-0047/34 | H04L-0047/50 | H04L-0047/621 | H04L-0061/1541 | H04L-0063/0428 | H04L-0063/065 | H04L-0063/08 | H04L-0063/0807 | H04L-0063/102 | H04L-0063/1441 | H04L-0065/103 | H04L-0065/104 | H04L-0065/1043 | H04L-0067/12 | H04L-0067/14 | H04L-0067/16 | H04L-0067/306 | H04L-0069/16 | H04L-0069/168 | H04L-0069/329 | H04M-0001/0214 | H04M-0001/2535 | H04M-0003/22 | H04M-0003/42 | H04M-0007/0057 | H04M-0007/0069 | H04N-0001/00127 | H04N-0001/00132 | H04N-0001/00137 | H04N-0001/00148 | H04N-0001/00342 | H04N-0001/2133 | H04N-0005/23248 | H04N-0005/772 | H04N-0007/0112 | H04N-0007/08 | H04N-0007/148 | H04N-0021/6125 | H04N-0021/64738 | H04N-0021/64784 | H04W-0024/00 | H04W-0028/14 | H04W-0052/143 | H04W-0052/24 | H04W-0052/245 | H04W-0052/46 | H04W-0052/48 | H04W-0074/02 | H04W-0076/02 | A61B-2562/0219 | G03B-2217/005 | G06F-0011/1625 | G06F-2221/2101 | G06F-2221/2141 | G06F-2221/2149 | H01M-2250/30 | H04B-0007/0894 | H04B-0007/15507 | H04L-0001/1845 | H04L-0065/80 | H04L-0069/324 | H04L-0069/326 | H04L-2001/0096 | H04L-2012/40241 | H04L-2012/40273 | H04L-2012/6462 | H04L-2209/127 | H04M-0001/0225 | H04M-0001/0235 | H04M-0003/42102 | H04N-0001/32128 | H04N-2201/0017 | H04N-2201/0084 | H04N-2201/3205 | H04N-2201/3226 | H04W-0008/005 | H04W-0008/04 | H04W-0048/16 | H04W-0052/225 | H04W-0052/241 | H04W-0052/242 | H04W-0072/08 | H04W-0080/10 | H04W-0084/12 | H04W-0088/16 | Y02B-0090/18 | Y10S-0707/99933 | Y10S-0707/99936 | Y10S-0707/99939","H04N-005/225","H04N-005/225 | H04N-007/18 | H04N-005/232 | A61B-005/11 | G01S-019/34 | G08B-013/196 | G08B-015/00 | H04L-029/08 | H04L-029/06 | H04L-029/12 | G06F-011/20 | G06F-021/62 | G07F-017/16 | G06Q-020/10 | G06Q-020/12 | G06Q-020/38 | G06Q-020/40 | G06Q-020/42 | G06Q-030/02 | H01M-016/00 | H04B-001/04 | H04B-001/40 | H04B-007/06 | H04B-007/08 | H04J-013/12 | H04L-001/00 | H04L-001/06 | H04L-001/08 | H04L-001/18 | H04L-005/00 | H04L-009/32 | H04L-012/12 | H04L-012/28 | H04L-012/40 | H04L-012/44 | H04L-012/54 | H04L-012/64 | H04L-027/26 | H04M-001/02 | H04M-001/253 | H04M-003/22 | H04M-003/42 | H04M-007/00 | H04N-001/00 | H04N-007/01 | H04N-007/08 | H04N-007/14 | H04N-021/61 | H04N-021/647 | H04W-024/00 | H04W-028/14 | H04W-052/14 | H04W-052/24 | H04W-052/46 | H04W-052/48 | H04W-074/02 | H04W-076/02 | G06Q-030/06 | H04L-012/24 | H04L-012/801 | H04L-012/815 | G06Q-050/18 | H04L-012/863 | H04L-012/851 | H04L-012/841 | H04N-005/77 | H04N-001/21 | G06F-011/16 | H04B-007/155 | H04N-001/32 | H04W-008/00 | H04W-008/04 | H04W-048/16 | H04W-052/22 | H04W-072/08 | H04W-080/10 | H04W-084/12 | H04W-088/16","","","","","","4918011005131"
"US","US","P","B2","Medical device adjusting operation when used with non-authenticated patient parameter collecting accessory","Embodiments are directed to a medical device, such as a defibrillator, for use with an accessory capable of collecting a parameter of a patient. The medical device is capable of at least performing a basic functionality, an advanced functionality, and of defibrillating the patient. The medical device includes an energy storage module within a housing for storing an electrical charge that is to be delivered to the patient for the defibrillating. The medical device includes a processor structured to determine whether a data set received from the accessory confirms or not a preset authentication criterion about the accessory. Although when the accessory is coupled to the housing the medical device is capable of the defibrillating and the basic functionality, the medical device is capable of the advanced functionality only when the accessory is coupled to the housing and it is determined that the preset authentication criterion is confirmed. Embodiments also include methods of operation and a programmed solution.","1. A medical device for an accessory capable of collecting a parameter of a patient, comprising: a housing configured to couple with a remote accessory configured to collect a parameter of a patient;an energy storage module disposed within the housing configured to store an electrical charge and configured to deliver the electrical charge to the patient for defibrillating the patient, the medical device further configured to have basic functionality and advanced functionality;a processor disposed in the housing and configured to determine whether a data set received from the remote accessory confirms preset authentication criterion about the remote accessory, wherein the data set corresponds to information stored in a memory of the remote accessory; anda memory coupled to and accessible by the processor, the memory configured to store authentication and readiness information and to authenticate the accessory.","20","15/156258","2016-05-16","2016-0256698","2016-09-08","9907971","2018-03-06","PHYSIO-CONTROL, INC.","Richard C.  Nova","","","","A61N-0001/3931","A61N-0001/3931 | A61B-0005/01 | A61B-0005/021 | A61B-0005/0215 | A61B-0005/0408 | A61B-0005/04085 | A61B-0005/082 | A61B-0005/14552 | A61N-0001/3975 | G06F-0017/30424 | G06F-0021/602 | H01M-0010/425 | A61B-2560/0214 | H01M-0002/34 | H01M-0006/5033 | H01M-0010/4221 | H01M-0016/00 | H02J-0007/0063 | H02J-0007/345","A61N-001/39","A61N-001/39 | A61B-005/01 | A61B-005/021 | A61B-005/0215 | A61B-005/0408 | A61B-005/08 | A61B-005/1455 | G06F-017/30 | G06F-021/60 | H01M-002/34 | H01M-006/50 | H01M-010/42 | H01M-016/00 | H02J-007/00 | H02J-007/34","","","","","","4918010001459"
"US","US","P","B2","Wrist device having heart activity circuitry","A method includes: receiving, by a wrist device, a notification of an event, wherein the notification is indicated to a user of the wrist device; in response to receiving the notification, initiating at least one measurement; determining, based on the at least one measurement, that a predetermined condition is met; and in response to the determining that the predetermined condition is met, performing an action having an effect on the indication of the notification.","1. A wrist device comprising: a heart activity circuitry;at least one processor; andat least one non-transitory memory including a computer program code, wherein the at least one non-transitory memory and the computer program code are configured, with the at least one processor, to cause the wrist device to perform operations comprising:measuring, using the heart activity circuitry, heart activity of a user of the wrist device, the wrist device being in a physical exercise mode during the measuring;receiving a notification of an event, wherein the notification is indicated to the user;in response to receiving the notification, initiating at least one further measurement, if the wrist device is in the physical exercise mode measuring the heart activity of the user;determining, based on the at least one further measurement, that a predetermined condition is met; andin response to the determining that the predetermined condition is met, performing an action having an effect on the indication of the notification.","25","14/713480","2015-05-15","2016-0332025","2016-11-17","9907998","2018-03-06","POLAR ELECTRO OY","Mikko  Repka","","","","A63B-0024/0062","A63B-0024/0062 | A61B-0005/02416 | A61B-0005/02438 | A61B-0005/1112 | A61B-0005/1118 | A61B-0005/681 | G06F-0001/3287 | G06F-0003/014 | G06F-0003/017 | G06F-0003/0304 | G06F-0003/0346 | G06F-0021/32 | G06F-0021/35 | G06K-0009/00228 | G06K-0009/00355 | G08B-0007/06 | H04M-0001/7253 | A61B-0005/6817 | A63B-2024/0071 | H04L-0063/0861 | H04W-0012/06","G08B-021/00","G08B-021/00 | A63B-024/00 | G08B-007/06 | G06K-009/00 | A61B-005/024 | G06F-001/32 | G06F-003/01 | G06F-003/03 | G06F-021/32 | G06F-003/0346 | G06F-021/35 | H04M-001/725 | A61B-005/11 | A61B-005/00 | H04L-029/06 | H04W-012/06","","","","","","4918010001486"
"US","US","P","B2","Obtaining metrics for a position using frames classified by an associative memory","A method for identifying a motion of interest of an individual. The method includes receiving input data from a non-invasive motion sensor measuring movements of a person. The method also includes collecting motion sensor data for an interval of time. The illustrative embodiments also provide for analyzing the motion sensor input data using an analysis application having a set of classified pre-determined motions. The analysis application classifies a movement captured during the interval of time as a motion corresponding to particular a pre-determined motion among a plurality of pre-determined motions. Classification is performed based on shared relative values among the motion sensor input data and the particular pre-determined motion. The illustrative embodiments also provide for generating an output that provides a translation of the movement for identification of a predetermined motion of interest that represents an undesirable ergonomic aspect.","1. A method for improving ergonomic movements of a person operating factory equipment at a factory, comprising: receiving input data from a non-invasive motion sensor measuring movements of the person while the person operates the factory equipment;collecting, using the non-invasive motion sensor, motion sensor data of the movements of the person for an interval of time;analyzing the motion sensor data using an analysis application having a set of classified pre-determined motions, where the analysis application classifies a movement captured during the interval of time as a motion corresponding to particular a pre-determined motion among a plurality of pre-determined motions, wherein classification is performed based on shared relative values among the motion sensor data and the particular pre-determined motion, wherein a classified motion is formed, and wherein the shared relative values comprise qualitative descriptions of the movements of the person as opposed to quantitative measurements of the movements of the personcomparing the classified motion to a set of pre-determined motions that were pre-determined to be undesirable ergonomic motions in an ergonomic analysis for a factory setting; andresponsive to the classified motion being among the pre-determined motions that were pre-determined to be undesirable ergonomic motions, monitoring an amount of time for the classified motion, and, using a display to display information to the person and issuing an alert that communicates to the person that the pre-determined motion during the interval of time represents an ergonomically incorrect or undesirable movement for a factory setting.","16","14/573591","2014-12-17","2016-0070958","2016-03-10","9911031","2018-03-06","THE BOEING COMPANY","John Desmond  Whelan | Glenn Alan  Hancock","","","","G06K-0009/00335","G06K-0009/00335 | A61B-0005/11 | A61B-0005/1123 | A61B-0005/7275 | G06F-0003/017 | G06F-0012/082 | G06K-0009/00342 | G06K-0009/6201 | G06K-0009/6267 | G06K-0009/6285 | G06T-0001/60 | G06T-0007/20 | G06T-0007/70 | A61B-0005/1116 | A61B-2503/20 | G06F-0012/0822 | G06T-2207/20081 | G06T-2207/30196","G06T-007/20","G06T-007/20 | G06K-009/62 | A61B-005/11 | G06K-009/00 | G06F-003/01 | G06T-001/60 | G06F-012/0817 | A61B-005/00 | G06T-007/70","","","","","","4918010004500"
"US","US","P","B2","Imaging control apparatus, storage system, and storage medium","There is provided an imaging control apparatus including an imaging control section configured to control an imaging section to capture a predetermined area in a body cavity, a comparison section configured to compare a captured image captured by the imaging section with a reference image, and a storage control section configured to execute a control to store the captured image in response to a comparison result by the comparison section.","1. A medical imaging apparatus, comprising: one or more processors configured to:control an imaging section to capture an image of an area in a body cavity;compare the captured image with a reference image of the area in the body cavity;store the captured image based on the comparison of the captured image with the reference image; andtransmit a notification from the medical imaging apparatus to a device based on the comparison which indicates a first difference between the captured image with the reference image, wherein the first difference is equal to or greater than a threshold value.","11","15/193606","2016-06-27","2016-0307317","2016-10-20","9911186","2018-03-06","SONY CORPORATION","Yoichiro  Sako | Akira  Tange | Takatoshi  Nakamura","2012-142619","JP","2012-06-26","G06T-0007/0012","G06T-0007/0012 | A61B-0001/0002 | A61B-0001/00009 | A61B-0001/04 | A61B-0001/041 | G06F-0017/3028 | G06K-0009/46 | G06K-0009/6201 | G06K-0009/6253 | G06T-0007/0016 | G06T-0007/254 | G06K-2009/4666 | G06K-2209/05 | G06T-2207/10068 | G06T-2207/30028 | G06T-2207/30092","G06K-009/00","G06K-009/00 | G06T-007/00 | A61B-001/00 | A61B-001/04 | G06F-017/30 | G06K-009/46 | G06K-009/62 | G06T-007/254 | A61B-005/00","","","","","","4918010004653"
"US","US","P","B2","Activating functional electrical stimulation of abdominal muscles to assist coughing","A system for assisted coughing includes a first sensor for measuring a parameter which can indicate a closed glottis and producing a first signal, a processor for receiving the first signal, determining a state indicating the closed glottis and generating an instruction for a Functional Electric Stimulation (FES) controller based, at least in part, on the determining, and a FES controller for generating an electric stimulation signal.","1. A system for assisted coughing comprising: a first air flow sensor configured for sensing a patient'ss air flow, for measuring a parameter which indicates a closed glottis and producing a first signal;a processor and associated memory for receiving the first signal, determining a state indicating the closed glottis and generating an instruction for Functional Electric Stimulation (FES) based, at least in part, on the determining; anda FES controller for generating an electric stimulation signal based on the instruction;wherein the processor determines a specific point in time associated with the indication of the closed glottis based, at least in part, on detecting a start of a plateau in the first signal.","22","15/102588","2014-12-09","2016-0310068","2016-10-27","9901299","2018-02-27","MOR RESEARCH APPLICATIONS LTD. | YEDA RESEARCH AND DEVELOPMENT CO. LTD.","Lior  Haviv | Noam  Sobel | Amiram  Catz | Itzhak  Glass | Anton  Plotkin | Aharon  Weissbrod | Sagit  Shushan","","","","A61B-0005/4836","A61B-0005/4836 | A61B-0005/0492 | A61B-0005/087 | A61B-0005/0816 | A61B-0005/0823 | A61B-0005/1103 | A61B-0005/7282 | A61N-0001/3601 | A61N-0001/36003 | A61N-0001/36014 | A61B-0005/0488 | A61B-0005/0806 | A61B-0005/7475 | A61N-0001/36017 | G06F-0003/012","A61N-001/00","A61N-001/00 | A61B-005/00 | A61B-005/087 | A61B-005/11 | A61N-001/36 | A61B-005/0492 | A61B-005/0488 | A61B-005/08 | G06F-003/01","","","","","","4918009000987"
"US","US","P","B2","Coordinating relationship wearables","In various example embodiments, devices including a wearable device may be associated to share information and coordinate data between the devices as part of a coordination between relationship wearables. For example, a first wearable device and a second device, each associated with different users, may provide data to a history analysis module. The history analysis module may analyze this data for coordinated relationship patters made up of repeated events. Coordinated relationship data may be generated by this analysis, and then used by a current data analysis module to analyze an incoming stream of current data from at least one of the devices. When a repeated status value is identified within the current data stream, a coordination communication may be initiated.","1. A system comprising: a first analysis module to:receive a first set of first device sensor data from a first wearable device of a first user, and a first set of second device data from a second device of a second user;identify a first coordinated relationship pattern comprising a plurality of events, each event of the plurality of events being associated with a first repeated status value within the first set of first device sensor data, a first coordinated status value within the first set of second device data, and a temporal association between the first repeated status value and the first coordinated status value;generate a trigger threshold associated with at least the first repeated status value;a first communication module communicatively coupled to the first analysis module, the first communication module to receive at least a portion of a first current data stream from the first wearable device;a second analysis module communicatively coupled to the first communication module, the second analysis module to analyze the first current data stream using the trigger threshold and to initiate a coordination communication to the second device communicating when the trigger threshold is met by a portion of the first current data stream; anda server computer, wherein the server computer comprises the first analysis module, and wherein the server computer is communicatively coupled to the first wearable device via a first mobile device and a wide area network.","20","14/569518","2014-12-12","2016-0173359","2016-06-16","9901301","2018-02-27","EBAY INC.","Jennifer T.  Brenner | Bryant Genepang  Luk | Robert  He | Christopher Diebold  O'Toole | Yu  Tang | Jason  Ziaja | Ananya  Das","","","","A61B-0005/6801","A61B-0005/6801 | A61B-0005/0022 | A61B-0005/0205 | A61B-0005/02438 | G06F-0019/00 | G06F-0019/3406 | G06F-0019/3418 | H04L-0067/00 | H04L-0067/12 | A61B-0005/01 | A61B-0005/021 | A61B-0005/1112 | A61B-0005/1172 | A61B-0005/681 | A61B-0005/6823 | A61B-0005/6824 | A61B-0005/7275 | A61B-0005/7282 | A61B-2562/0219","G06F-017/30","G06F-017/30 | A61B-005/00 | A61B-005/0205 | A61B-005/024 | G06F-019/00 | H04L-029/08 | A61B-005/01 | A61B-005/021 | A61B-005/11 | A61B-005/1172","","","","","","4918009000989"
"US","US","P","B2","Field update of an ambulatory infusion pump system","Portable or ambulatory infusion devices and systems capable of remotely updating an ambulatory fluid delivery device include safety protocols that verify the status of the ambulatory fluid delivery device before and after a field update of software. Methods of accomplishing the same field update of software are also described.","1. A method performed by software executable instructions on a hardware processor for remotely updating software on an ambulatory fluid delivery device comprising: from a computing system, interrogating the ambulatory fluid delivery device and obtaining data, from the ambulatory fluid delivery device, the data including a patient basal medication dosage profile and device history logs;by the computing system, verifying that the ambulatory fluid delivery device is compatible with a software update, including both verifying a memory capacity of the ambulatory fluid delivery device and confirming that a model of the ambulatory fluid delivery device is compatible with the software update;verifying that a user of the ambulatory fluid delivery device wishes to update software on the ambulatory fluid delivery device;sending the software update from the computing system to the ambulatory fluid delivery device;verifying that the ambulatory fluid delivery device is in a safe condition for the software update, including verifying an absence of error messages within a certain time period in the device history logs;performing the software update on the ambulatory fluid delivery device; andverifying that the ambulatory fluid delivery device in is a safe condition to perform as intended after the software update.","20","14/995958","2016-01-14","2016-0129185","2016-05-12","9895491","2018-02-20","TANDEM DIABETES CARE, INC.","Don  Ludolph","","","","A61M-0005/172","A61M-0005/172 | A61M-0005/142 | A61M-0005/1723 | G06F-0008/65 | G06F-0019/3406 | G06F-0019/3412 | G06F-0019/3468 | A61M-2005/14208 | A61M-2205/18 | A61M-2205/3569 | A61M-2205/3584 | A61M-2205/502 | A61M-2205/52 | A61M-2205/60 | A61M-2230/005 | A61M-2230/20 | A61M-2230/201 | A61M-2230/30 | A61M-2230/50 | A61M-2230/63","G06F-019/00","G06F-019/00 | G06F-009/44 | A61B-005/00 | H04L-029/08 | A61M-005/172 | A61M-005/142 | G06F-009/445","","","","","","4918008001353"
"US","US","P","B2","Method and system for rule based display of sets of images","The invention provides, in some aspects, a system for implementing a rule derived basis to display image sets. In various embodiments of the invention, the selection of the images to be displayed, the layout of the images, as well as the rendering parameters and styles can be determined using a rule derived basis. In an embodiment of the present invention, the user is presented with images displayed based on their preferences without having to first manually adjust parameters.","1. A method comprising: (a) receiving a primary Study of a patient selected from a plurality of studies;(b) executing on a server digital data processor a render server program which applies one or more Study Selection Rules to generate a list of a plurality of secondary studies based on two or more parameters selected from the group consisting of one or more DICOM parameters from the primary Study, one or more Abstract Tags from the primary Study, one or more DICOM parameters from the plurality of secondary studies and one or more Abstract Tags from the plurality of secondary studies, where the one or more Study Selection Rules restrict the plurality of secondary studies to studies of the patient selected from the plurality of studies;(c) executing on the server digital data processor the render server program which applies one or more Protocol Selection Rules to select a Display Protocol, where the one or more Protocol Selection Rules are based on two or more parameters selected from the group consisting of one or more DICOM parameters from the primary Study, one or more Abstract Tags from the primary Study, one or more DICOM parameters from the plurality of secondary studies and one or more Abstract Tags from the plurality of secondary studies; and(d) displaying one or more of the plurality of secondary studies selected from the list based on the Display Protocol selected in step (c).","20","15/380848","2016-12-15","2017-0098329","2017-04-06","9898855","2018-02-20","PME IP PTY LTD","Malte  Westerhoff | Detlev  Stalling","","","","G06T-0015/08","G06T-0015/08 | A61B-0005/055 | A61B-0006/032 | A61B-0006/037 | A61B-0006/465 | A61B-0006/466 | G06F-0019/321 | G06T-2200/04 | G06T-2210/41","G06T-007/00","G06T-007/00 | G06T-011/00 | G06T-005/40 | G06F-003/0481 | G06T-015/08 | G06F-019/00 | A61B-006/03 | A61B-006/00 | A61B-005/055","","","","","","4918008004699"
"US","US","P","B2","Hand-held medical-data capture-device having determination of a temperature by a microprocessor from a signal from a digital infrared sensor and having interoperation with electronic medical record systems to transmit the temperature and device information","In one implementation, an apparatus estimates body core temperature from an infrared measurement of an external source point using a cubic relationship between the body core temperature and the measurement of an external source point is described, estimates temperature from a digital infrared sensor and determines vital signs from a solid-state image transducer, or determines vital signs from a solid-state image transducer and estimates body core temperature from an infrared measurement of an external source point using a cubic relationship between the body core temperature and the measurement of an external source point; after which the estimated and/or determined information is transmitted to an external database.","1. A non-touch thermometer to measure a human vital sign, the non-touch thermometer comprising: a microprocessor;a battery operably coupled to the microprocessor;a single button operably coupled to the microprocessor;a camera operably coupled to the microprocessor and operable to capture at least two images to a memory;wherein the microprocessor includes a pixel-examination-module that is operable to examine pixel values of the at least two images in the memory, a temporal-variation module that is operable to determine temporal variation of the pixel values between the at least two images, a signal processing module that is operable to amplify the temporal variation resulting in amplified temporal variation, and a vital-sign generator that is operably coupled to the signal processing module that generates the human vital sign from the temporal variation;a wireless communication subsystem that is operably coupled to the microprocessor and that is operable to transmit a representation of the human vital sign; anda display device that is operably coupled to the microprocessor that displays the human vital sign,wherein the wireless communication subsystem further comprises a component that is operable to transmit a representation of date and time, operator identification, patient identification and manufacturer, model number and firmware revision of the non-touch thermometer.","16","14/588315","2014-12-31","2016-0116351","2016-04-28","9888852","2018-02-13","ARC DEVICES LIMITED","Irwin  Gross | Michael G.  Smith | Mark  Khachaturian | Martin  Crawley | Steven  Gerst | John  Barrett | Michael  Cronin | Derek  Turnbull | Jason  Bodnick","","","","A61B-0005/0008","A61B-0005/0008 | A61B-0005/0013 | A61B-0005/0022 | A61B-0005/0059 | A61B-0005/0075 | A61B-0005/0077 | A61B-0005/01 | A61B-0005/015 | A61B-0005/021 | A61B-0005/02055 | A61B-0005/0261 | A61B-0005/02433 | A61B-0005/03 | A61B-0005/0402 | A61B-0005/08 | A61B-0005/441 | A61B-0005/6887 | A61B-0005/6898 | A61B-0005/725 | A61B-0005/7225 | A61B-0005/7264 | A61B-0005/7271 | A61B-0005/7275 | A61B-0005/7278 | A61B-0005/746 | A61B-0005/7425 | A61B-0005/7475 | G01J-0005/0025 | G01J-0005/025 | G01J-0005/10 | G01K-0013/004 | G06F-0019/322 | G06F-0019/3406 | G06F-0019/3418 | G06K-0009/6218 | G06T-0003/40 | G06T-0007/0012 | G06T-0007/174 | G06T-0007/269 | G06T-0007/90 | G08B-0005/36 | G08B-0021/182 | G08C-0017/02 | H04B-0007/26 | H04L-0012/4633 | H04L-0067/04 | H04L-0067/10 | H04L-0067/12 | H04L-0067/16 | H04L-0067/20 | H04L-0067/22 | H04N-0005/33 | H04W-0012/06 | H04W-0048/08 | H04W-0048/16 | H04W-0076/02 | H04W-0076/022 | H04W-0080/04 | A61B-0005/024 | A61B-0005/0245 | A61B-0005/742 | A61B-2560/0214 | A61B-2560/0475 | A61B-2562/166 | A61B-2576/00 | G06T-2207/10048 | G06T-2207/20024 | G06T-2207/20132 | G06T-2207/30004 | G06T-2207/30088 | G06T-2207/30104 | G06T-2210/22 | G06T-2210/41 | H04W-0012/08","G08B-023/00","G08B-023/00 | A61B-005/00 | A61B-005/01 | G06F-019/00 | A61B-005/021 | A61B-005/026 | A61B-005/08 | A61B-005/024 | A61B-005/0205 | G06T-003/40 | G06T-007/00 | H04W-048/16 | H04W-076/02 | A61B-005/0402 | A61B-005/03 | G01J-005/00 | H04W-080/04 | G01J-005/02 | G01J-005/10 | G08C-017/02 | H04L-029/08 | H04W-012/06 | H04B-007/26 | H04L-012/46 | H04N-005/33 | H04W-048/08 | G08B-005/36 | G08B-021/18 | G01K-013/00 | G06K-009/62 | G06T-007/174 | G06T-007/269 | G06T-007/90 | A61B-005/0245 | H04W-012/08","","","","","","4918007000902"
"US","US","P","B2","System and methods for soiled garment detection and notification","Aspects of the present disclosure involve an apparatus, systems, and methods for soiled garment detection and notification. The method may include receiving a measure of odor being released from a garment from a soiled garment detection apparatus. The method may further include determining that the measure of odor exceeds an acceptable odor threshold. A message may then be sent to a user device associated with the garment (e.g. a device of the owner of the garment) in response to determining that the measure of odor exceeds the threshold. The message may include a notification that the garment is soiled, and a suggested course of action to improve the measure of odor released by the garment.","1. A system for soiled garment detection and notification, the system comprising: a controller comprising:a data repository to store a laundering status for a garment based on a measure of odor being released by the garment;a receiver configured to receive, from a soiled garment detection apparatus, sensor data comprising a measure of odor being released by a garment; andone or more processors configured to:determine that the measure of odor exceeds an acceptable threshold level of odor; andtransmit a message to a user device in response to the measure of odor exceeding the acceptable threshold of odor, the message including a notification related to the measure of odor being released by the garment.","20","15/341115","2016-11-02","2017-0053514","2017-02-23","9892615","2018-02-13","EBAY INC.","Dane  Glasgow | Corinne Elizabeth  Sherman | David  Ramadge | Timothy  Carlson | Sergio Pinzon  Gonzales, Jr.","","","","G08B-0021/182","G08B-0021/182 | A47G-0025/14 | G01N-0033/0001 | G06K-0007/10366","G08B-023/00","G08B-023/00 | G08B-021/18 | G01N-033/00 | A47G-025/14 | G06K-007/10 | A41D-027/22 | G06Q-010/00 | F26B-019/00 | A61B-005/00 | G01N-030/96","","","","","","4918007004634"
"US","US","P","B2","Device for viewing an interior of a mouth","The viewing device for the interior of a mouth of a patient includes a penetrating ray emitter adapted to take a view of an inner portion located under an outer surface of an organ arranged in the mouth. There is a pair of augmented-reality glasses having an optical glass through which a user of the pair of glasses can see the interior of the mouth and a viewing camera adapted to take an image of what the user sees through the optical glass. A central unit correlates first images corresponding to those taken by the viewing camera with second images corresponding to those taken by the penetrating-ray emitter.","1. A viewing device for an inside of a patient'ss mouth, the mouth having an organ, said viewing device comprising: a penetrating ray emitter having an anatomical view;a pair of augmented-reality glasses being comprised of: an optical glass having a direct view; anda viewing camera having an image view, according to position of said optical glass; anda central unit being in communication with said optical glass, said optical glass having a projected view, said projected view being comprised of said anatomical view, said direct view, and said image view, said anatomical view being visible through said optical glass over said direct view and said image view.","17","15/007010","2016-01-26","2016-0220105","2016-08-04","9877642","2018-01-30","Francois Duret","Francois  Duret","","","","A61B-0001/24","A61B-0001/24 | A61B-0001/00048 | A61B-0001/04 | A61B-0001/0684 | A61B-0005/0088 | A61B-0005/6803 | A61B-0005/7425 | A61B-0006/022 | A61B-0006/14 | A61B-0006/462 | A61B-0006/463 | A61B-0006/466 | A61B-0006/5229 | A61B-0008/12 | A61B-0008/462 | A61B-0034/20 | A61B-0090/37 | A61C-0001/082 | A61C-0001/084 | A61C-0001/088 | A61C-0019/00 | G02B-0027/0172 | G06F-0003/005 | G06F-0003/012 | G06F-0003/16 | G06T-0007/0012 | G06T-0007/32 | G06T-0019/006 | G10L-0015/22 | H04N-0005/2256 | A61B-0006/145 | A61B-2562/17 | G02B-2027/014 | G02B-2027/0138 | G02B-2027/0178 | G06T-2207/30036 | G06T-2219/2004","G09G-005/00","G09G-005/00 | A61B-001/24 | A61B-005/00 | A61B-008/00 | A61B-090/00 | A61B-001/00 | A61B-001/04 | A61B-001/06 | A61C-001/08 | A61C-019/00 | G02B-027/01 | G06F-003/00 | G06F-003/01 | G06F-003/16 | G06T-007/00 | G06T-019/00 | G10L-015/22 | H04N-005/225 | A61B-006/02 | A61B-006/00 | A61B-008/12 | A61B-034/20 | G06T-007/32 | A61B-006/14","","","","","","4918005000886"
"US","US","P","B2","Arrangement comprising medical treatment units and peripheral devices as well as a peripheral device and treatment unit for use in such an arrangement","An assembly includes at least two medical treatment units, each of which can be allocated to a patient and at least two peripheral devices, each of which can be allocated to a patient. The peripheral devices and the treatment units have means for allocating a peripheral device to a treatment unit and means for verifying the allocation of a peripheral device to a patient. To allocate a peripheral device to a treatment unit, the peripheral device is placed by operators in a receiving unit belonging to the treatment unit. Said receiving unit is preferably designed as a charging station for the battery of the peripheral device. In the event of a successful allocation of peripheral device and patient, confirmed by the receipt of physiological data of the patient, the operators verify the correct allocation of a peripheral device to the patient and must confirm the correct allocation by confirmation means. The peripheral device is only released if the operator has confirmed the correct allocation, preferably within a predefined time period.","1. An arrangement comprising: at least two medical treatment units; andat least two peripheral devices,wherein a first medical treatment unit of the at least two medical treatment units and a first peripheral device of the at least two peripheral devices are configured to be allocated to a patient, and the first peripheral device comprises a first connector, the first peripheral device and the first treatment unit together includinga system of at least one of tubes or lines configured for connecting the patient to the first treatment unit to thereby allocate the first medical treatment unit to the patient,an accommodation unit fixed to the first medical treatment unit, configured to receive the first peripheral device, and comprising a second connector configured to connect with the first connector,a data transmission system comprising a transmitter in the first peripheral device and a receiver in the first medical treatment unit, and being configured such that, when the first peripheral device is received in the accommodation unit the transmitter sends address information to the receiver and the first medical treatment unit identifies the first peripheral device as being allocated to the first medical treatment unit,a detector for detecting when the first peripheral device is removed from the accommodation unit,a physiological sensor for detecting patient-specific data of the patient, wherein the first peripheral device comprises the physiological sensor and the data transmission system is configured to transmit a status signal to both the first peripheral device and the first medical treatment unit, indicating that the first peripheral device has been allocated to the patient,an acknowledgement switch or button configured to, upon activation, acknowledge that the first peripheral device and the first medical treatment unit have been allocated to the same patient,a display comprising a prompt that prompts an operator to activate the acknowledgement switch or button once the receiver receives the status signal, anda processor configured to release the peripheral device such that the transmitter sends the patient-specific data to the receiver only on condition that the correct allocation of the peripheral device to the patient has been acknowledged.","18","12/596613","2008-04-17","2010-0114639","2010-05-06","9878081","2018-01-30","FRESENIUS MEDICAL CARE DEUTSCHLAND GMBH","Claus  Leiendecker | Carsten  Muller | Elke  Schulte | Wei  Zhang","10-2007-018741","DE","2007-04-20","A61M-0001/14","A61M-0001/14 | A61B-0090/90 | A61B-0090/98 | G06Q-0050/24 | A61B-0005/002 | A61B-0005/021 | A61B-0005/024 | A61B-2017/00119 | A61B-2017/00221 | A61B-2017/00482 | A61B-2562/08 | A61M-2205/3569 | A61M-2205/3576 | A61M-2205/6018 | A61M-2205/6054 | A61M-2205/8237 | A61M-2205/84","G06Q-050/22","G06Q-050/22 | A61M-001/14 | G06Q-050/24 | A61B-090/90 | A61B-090/98 | A61B-005/021 | A61B-005/024 | A61B-017/00 | A61B-005/00","","","","","","4918005001322"
"US","US","P","B2","Grasp assist device with automatic mode control logic","A system includes a glove, sensors, actuator assemblies, and controller. The sensors include load sensors which measure an actual grasping force and attitude sensors which determine a glove attitude. The actuator assembly provides a grasp assist force to the glove. Respective locations of work cells in the work environment and permitted work tasks for each work cell are programmed into the controller. The controller detects the glove location and attitude. A work task is selected by the controller for the location. The controller calculates a required grasp assist force using measured actual grasping forces from the load sensors. The required grasp assist force is applied via the glove using the actuator assembly to thereby assist the operator in performing the identified work task.","1. A system comprising: a glove;a plurality of sensors positioned with respect to the glove, including load sensors configured to measure an actual grasping force applied to an object by an operator wearing the glove, and attitude sensors configured to determine an attitude of the glove;an actuator assembly operable for providing a grasp assist force via the glove; anda controller programmed with a respective location of each of a plurality of work cells in a work environment, and also with a set of permitted work tasks for each of the work cells, wherein the controller is further programmed to: determine a location of the glove within the work environment;determine the attitude of the glove within the detected location by processing the attitude signals from the attitude sensors;select a work task from a list of permitted work tasks for the detected location using the determined location and attitude;calculate a required grasp assist force using the actual grasping force from the load sensors; andcommand an application of the required grasp assist force to the object, via the glove using the actuator assembly, to thereby assist the operator in performing the identified work task.","18","14/739428","2015-06-15","2016-0361820","2016-12-15","9878452","2018-01-30","GM GLOBAL TECHNOLOGY OPERATIONS LLC","Donald R.  Davis | Chris A.  Ihrke | Evan  Laske","","","","B25J-0013/08","B25J-0013/08 | A61B-0005/6804 | A61F-0002/68 | G01S-0019/19 | G06F-0003/014 | A41D-0019/0024 | Y10S-0901/36","B25J-013/08","B25J-013/08 | A61B-005/00 | A61F-002/68 | G01S-019/19 | G06F-003/01 | A41D-019/00","","","","","","4918005001691"
"US","US","P","B1","Mobile healthcare application for facilitating color determination","A method for assisting a health care practitioner in color evaluation includes maintaining, in a database, a plurality of images each corresponding to a particular result or condition; capturing, by a healthcare practitioner using a camera of a mobile electronic device, a subject image of a patient or an object associated with the patient; automatically comparing, utilizing one or more electronic processors, the captured subject image to images maintained in the database, such comparison including comparing one or more colors in the subject image to one or more colors in the images maintained in the database; automatically determining, based on the automatic comparison, that the captured subject image is positively matched to one or more of the plurality of images maintained in the database; and displaying an indication of the particular result or condition corresponding to each of the positively matched plurality of images.","1. A method for assisting a health care practitioner in color evaluation, the method comprising: (a) maintaining, in a database, a plurality of images each corresponding to a particular result for a healthcare test utilizing a first type of test object;(b) capturing, by a healthcare practitioner using a camera of a mobile electronic device, a subject image of a first test object associated with the patient, the first test object being the first type of test object;(c) communicating, from the mobile electronic device to a remote server, the captured image of the test object of the first type;(d) automatically comparing, at the remote server utilizing one or more electronic processors, the captured subject image to the images maintained in the database for a healthcare test utilizing the first type of test object, such comparison including comparing one or more colors in the subject image to one or more colors in the images maintained in the database;(e) automatically determining, at the remote server based on the automatic comparison, that the captured subject image is positively matched to one of the plurality of images maintained in the database;(f) communicating, from the remote server to the mobile electronic device, data based on the determination; and(g) displaying, to the healthcare practitioner via a display of the mobile electronic device, an indication of the particular result corresponding to the positively matched images.","16","14/528349","2014-10-30","","","9881024","2018-01-30","ALLSCRIPTS SOFTWARE, LLC","Mary Sumner  Johnson","","","","G06F-0017/3025","G06F-0017/3025 | A61B-0005/742 | G06F-0019/321 | G06T-0007/0014 | G06T-0007/408 | H04N-0005/23293 | G06T-2207/10024 | G06T-2207/30088","H04N-007/18","H04N-007/18 | G06F-017/30 | G06F-019/00 | H04N-005/232 | G06T-007/40 | G06T-007/00 | A61B-005/00","","","","","","4918005004250"
"US","US","P","B2","3D patient interface device selection system and method","An electronic apparatus for use in selecting a patient interface device and including a geometric fit score determining unit (42) configured to calculate a geometric fit score for each of one or more of patient interface devices, a patient criteria fit score determining unit (44) configured to calculate a patient criteria fit score for each of the one or more patient interface devices, and an overall fit score determining unit (46) configured to calculate an overall fit score for each of the one or more patient interface devices based on the calculated geometric fit score and the calculated patient criteria fit score for each of the one or more patient interface devices.","1. An electronic apparatus comprising: a geometric fit score determining unit configured to receive a 3-D model of a patient'ss face and a plurality of 3-D models of patient interface devices, to determine one or more landmarks on the 3-D model of the patient'ss face, and to calculate a geometric fit score for each of one or more of the patient interface devices by using the 3-D model of the patient'ss face and the 3-D models of the one or more patient interface devices, wherein the geometric fit score determining unit is configured to fit a respective 3-D model of one of the patient interface devices to the 3-D model of the patient'ss face by aligning the respective 3-D model of the patient interface device with the determined landmarks on the 3-D model of the patient'ss face and performing a fine adjustment on the respective 3-D model of the patient interface device, wherein the fine adjustment includes rotating and translating the 3-D model of the patient interface device to match the contour of the cushion with the contour of the 3-D model of the patient'ss face;a user interface generator configured to generate a user interface including a display area configured to display the 3-D model of the patient'ss face and a 3-D model a patient interface device selected from the plurality of 3-D models of patient interface devices, and a patient interface device selection area configured to display patient interface device identification information and an overall fit score which is calculated for each of the one or more patient interface devices based on the geometric fit score for each of the one or more patient interface devices and to allow a user to select the patient interface device to be displayed in the display area.","14","14/890044","2014-04-25","2016-0148437","2016-05-26","9881426","2018-01-30","KONINKLIJKE PHILIPS N. V.","Ruud  Vlutters | Karl Catharina  Van Bree","2013-167311 | 2013-170960","EP | EP","2013-05-10 | 2013-06-07","G06T-0019/20","G06T-0019/20 | A61B-0005/1077 | A61M-0016/06 | G06F-0003/04815 | G06F-0003/04842 | G06F-0003/04847 | G06K-0009/00281 | G06K-0009/00288 | G06T-0007/344 | G06T-0019/00 | A61B-0005/0077 | A61M-2016/0661 | G06T-2200/24 | G06T-2207/10028 | G06T-2207/30201 | G06T-2210/41 | G06T-2219/2016","G06K-009/00","G06K-009/00 | G06T-019/20 | G06T-019/00 | A61M-016/06 | A61B-005/107 | G06F-003/0481 | G06F-003/0484 | G06T-007/33 | A61B-005/00","","","","","","4918005004650"
"US","US","P","B1","Medical toilet with user authentication","A medical toilet with fingerprint reading handles is disclosed. The handles extend from a side surface of a seat on the medical toilet allowing a toilet seat user to use the fingerprint reader while sitting on the medical toilet. The handles enable authentication of a user and loading of specific medical toilet functionality associated with the authenticated user. The fingerprint readers are also used to determine cardiac functions of the user in addition to authentication of the user. The handles may be retractable and may include UV sanitation.","1. A medical toilet comprising: a handle which extends from a side of a toilet seat of the toilet allowing a toilet seat user to sit on the toilet seat and access a fingerprint reader located on or within the handle, wherein the fingerprint reader is used to identify the toilet seat user, control medical functionality of the medical toilet, and monitor a cardiac function of the toilet seat user; anda processor electrically connected to the fingerprint reader programmed to associate the medical toilet, the toilet seat user, the medical functionality of the toilet, and the cardiac function with a user account;wherein the fingerprint reader is a non-contact fingerprint reader comprising a capacitive coupled display (CCD) imager.","9","15/257014","2016-09-06","","","9867513","2018-01-16","David R. Hall | Dan Allen | Andrew Davis","David R.  Hall | Dan  Allen | Andrew  Davis","","","","A47K-0013/24","A47K-0013/24 | A47K-0017/02 | G06F-0003/16 | G06F-0019/3406 | G06K-0009/00033 | G06K-0009/00926 | A61B-0005/207 | A61B-0005/68 | A61B-0010/007 | A61B-0010/0038","A47K-013/24","A47K-013/24 | A47K-017/02 | G06K-009/00 | G06F-003/16 | G06F-019/00 | A61B-010/00 | A61B-005/00 | A61B-005/20","","","","","","4918003000715"
"US","US","P","B2","Remote flashing during infusion","A medical device controller operating in conjunction with a medical device determines one or more current versions of executable code associated with one or more processors in a medical device. Medical devices may include infusion pumps, other patient treatment devices as well as vital signs monitors. The medical device controller determines one or more current versions of executable code and configuration information associated with the one or more processors in the medical device. The medical device controller further determines which of the processors in the medical device require updated executable code, and which of the processors in the medical device require updated configuration information. The medical device controller distributes to the medical device as required at least one of the updated executable code and the updated configuration information. The medical device deploys the distributed updates, and activates the updates at a clinically appropriate time.","1. A method comprising: determining, at a medical device controller, one or more current versions of executable code associated with one or more processors in a medical device, wherein the medical device controller operates in conjunction with the medical device;determining, at the medical device controller, one or more current versions of configuration information associated with the one or more processors in the medical device, the configuration information including patient treatment information;determining, at the medical device controller, which of the one or more processors in the medical device require updated executable code, and which of the one or more processors in the medical device require updated configuration information associated with the updated executable code; anddistributing, from the medical device controller to the medical device, at least one of the updated executable code and the updated configuration information as required by the one or more processors in the medical device;activating at least one of the updated executable code and the updated configuration information at the medical device at a clinically appropriate time based on the patient treatment information.","16","15/213325","2016-07-18","2016-0381142","2016-12-29","9871866","2018-01-16","CAREFUSION 303, INC.","Gregory  Borges | Donald  Halbert | Jeffrey L.  Gaetano","","","","H04L-0067/12","H04L-0067/12 | A61B-0005/0022 | A61B-0005/02 | A61B-0005/082 | A61B-0005/145 | A61B-0005/14552 | A61M-0005/142 | A61M-0005/14216 | A61M-0005/14228 | G06F-0008/65 | G06F-0019/30 | H04L-0067/10 | H04L-0067/34 | H04W-0004/001 | A61B-2560/045 | A61M-2005/1405 | A61M-2205/3561 | A61M-2205/3569 | A61M-2205/3584 | A61M-2205/3592 | A61M-2205/50 | A61M-2205/502 | A61M-2205/52 | A61M-2205/6054 | A61M-2205/6072","G06F-009/445","G06F-009/445 | H04L-029/08 | A61M-005/142 | A61B-005/00 | H04W-004/00 | G06F-019/00 | A61B-005/02 | A61B-005/08 | A61B-005/145 | A61B-005/1455 | A61M-005/14","","","","","","4918003005040"
"US","US","P","B2","Platform for patient monitoring","A system for storing data collected by a body-worn sensor includes a central processing unit (CPU) that is configured to control operation of a gateway device; and one or more computer readable data storage media storing software instructions that, when executed by the CPU, cause the gateway device to: receive a MAC address of a new sensor and a protocol version associated with the new sensor from a server; attempt to contact the new sensor using the protocol version and the MAC address; when a response is received, send the response to the server for validation; when the response is validated by the server, establish communications with the new sensor; and forward data from the new sensor to a second server.","1. A system for storing data collected by a body-worn sensor, the system comprising: a central processing unit (CPU) that is configured to control operation of a gateway device; andone or more computer readable data storage media storing software instructions that, when executed by the CPU, cause the gateway device to: receive a MAC address of a new sensor and a protocol version associated with the new sensor from a server, the server being in communication with a manufacturer portal having access to the MAC address of the new sensor and the protocol version associated with the new sensor;attempt to contact the new sensor using the protocol version and the MAC address;when a response is received, send the response to the server for validation;when the response is validated by the server, establish communications with the new sensor; andforward data from the new sensor to a second server, the second server being different from the server, wherein the second server includes a super application associated with a user of the new sensor, with the super application being programmed to control access to the data by causing the second server to:receive a request from another application for access to the data, the request including an authentication token;validate the authentication token against a white list of acceptable tokens; andpermit access to the data by the another application upon validation of the authentication token.","5","14/488917","2014-09-17","2015-0334474","2015-11-19","9872087","2018-01-16","WELCH ALLYN, INC.","James J.  DelloStritto | Atanu  Roy Chowdhury | Harrish  Mugundhan | Adam P.  Vallee | Laleh  Rabieirad","","","","H04Q-0009/00","H04Q-0009/00 | A61B-0005/0015 | G06F-0017/30312 | G06F-0017/30864 | G06F-0017/30876 | G06F-0019/322 | G06F-0019/3406 | G06F-0019/3418 | G06F-0019/3487 | H04L-0067/12 | A61B-0005/0002 | A61B-0005/0022 | A61B-0005/0026","H04Q-009/00","H04Q-009/00 | A61B-005/00 | G06F-017/30 | G06F-019/00 | H04L-029/08","","","","","","4918003005259"
"US","US","P","B2","Gaze detector","A detector detects head postures and gaze directions from images of a person to be measured captured by an imaging unit; a generation unit generates a gaze direction distribution with respect to each of the head postures, from the head postures and the gaze directions detected by the detector; a calibration unit determines predetermined one of the head postures as a reference posture, and calculates calibration parameters to be used to calibrate the gaze direction distribution with respect to the reference posture; and a correction unit corrects the gaze direction distributions with respect to the head postures other than the reference posture by using the calibration parameters calculated by the calibration unit. This reduces the influence on the calibration which may vary due to change in the head posture.","1. A gaze detector comprising: an imaging unit configured to capture images of a person to be measured;a detector configured to detect head postures and gaze directions of the person to be measured from the images captured by the imaging unit;a generation unit configured to generate a gaze direction distribution with respect to each of the head postures from the head postures and the gaze directions detected by the detector;a calibration unit configured to select at least one reference posture from the head postures and configured to calculate calibration parameters by using the gaze direction distribution with respect to the at least one reference posture; anda correction unit configured to correct the gaze direction distributions generated with respect to the head postures other than the reference posture, by using the calibration parameters calculated by the calibration unit.","7","14/940847","2015-11-13","2016-0066782","2016-03-10","9854967","2018-01-02","PANASONIC INTELLECTUAL PROPERTY MANAGEMENT CO., LTD.","Masayuki  Kimura | Tadashi  Shibata","2014-049642","JP","2014-03-13","A61B-0003/113","A61B-0003/113 | A61B-0003/0025 | A61B-0003/145 | A61B-0005/0077 | G06F-0003/012 | G06F-0003/013 | G06K-0009/00248 | G06K-0009/00604 | A61B-2560/0223","G06K-009/00","G06K-009/00 | A61B-003/113 | G06F-003/01 | A61B-003/00 | A61B-003/14 | A61B-005/00","","","","","","4918001000903"
"US","US","P","B2","System and method for performing chemical analysis of fingerprints for providing at least one response","An electronic device includes a fingerprint module for at least receiving fingerprint information and a chemical analysis module for analyzing the fingerprint information for chemical features to derive distinguishing characteristics therefrom used for formulating at least one response. The distinguishing characteristics are identified by selecting a number of molecules and/or organic compounds from the fingerprint information analyzed for the chemical features. The distinguishing characteristics include at least age, gender, race, dietary information, and lifestyle information or a combination thereof.","1. An electronic device comprising: a fingerprint module for at least receiving fingerprint information on-the-spot, in real-time, and/or substantially instantaneously;a chemical analysis module for analyzing the fingerprint information for chemical features to derive distinguishing characteristics used for formulating at least one response and to create at least one chemical profile based on the fingerprint information analyzed for the chemical features; andan illuminating module positioned adjacent the fingerprint module to illuminate an area designated to receive the fingerprint information;wherein the distinguishing characteristics are identified by selecting a number of molecules and/or organic compounds from the fingerprint information analyzed for the chemical features; andwherein the fingerprint module conveys to a user a plurality of audible and/or non-audible messages and/or recommendations based on the fingerprint information, the messages and/or recommendations being additional information, supplemental information, educational information, and/or advertising information.","15","14/539289","2014-11-12","2015-0068329","2015-03-12","9857341","2018-01-02","Theodosios Kountotsis","Theodosios  Kountotsis","","","","G01N-0033/00","G01N-0033/00 | A61B-0005/1172 | G01N-0033/5005 | G06F-0003/03547 | G06F-0019/34 | G06K-0009/00006 | G06K-0009/00892 | A61B-0005/14517 | G06F-2203/0338 | G07C-0009/00158","G08B-021/00","G08B-021/00 | G01N-033/00 | A61B-005/1172 | G01N-033/50 | G06K-009/00 | G06F-003/0354 | G06F-019/00 | A61B-005/145 | G07C-009/00","","","","","","4918001003269"
"US","US","P","B2","Reconfigurable garment definition and production method","Computer-aided design and manufacture software and hardware automate garment and fashion definition and production. Configurable garment includes ornamental element, pattern display, and personal identifier and wireless sensor electronics.","1. Electronically reconfigurable sleeve or cuff garment comprising: an electronically personalizable sleeve or cuff garment comprising a flexible optical fiber screen woven into the sleeve or cuff, a media player, and an identifier device;a user interface appliance comprising a user device, a processor/memory, and a networking interface; anda power source;wherein the networking interface is to couple with the user interface appliance with the sleeve or cuff garment using reconfigurable software to configure operation of the media player enabling real-time user-control via the user device and the flexible optical fiber screen, the software further configuring electronically a variable color element, a variable reflectivity element, a variable electroluminescent element, or a variable optical chameleon element of the flexible optical fiber screen according to a computerized celebrity or fashion expert consultant application that automatically generates a fashion or style recommendation using a design template for personalizing the sleeve or cuff garment electronically according to a user-defined garment definition or user input via the user device, thereby allowing the sleeve or cuff garment to change color, images, projections, and patterns based on configuration commands for a unique fashion look-and-feel and for displays of texts, data, and audio and video media content.","15","14/589854","2015-01-05","2015-0120253","2015-04-30","9858361","2018-01-02","Dennis S. Fernandez","Dennis S.  Fernandez","","","","G06F-0017/50","G06F-0017/50 | A41H-0003/007 | A61B-0005/0002 | A61B-0005/6804 | G06Q-0030/0601 | A41D-0001/002 | A61B-0005/02 | A61B-0005/024 | A61B-0005/0816 | A61B-2017/00017 | A61B-2017/00084 | A61B-2017/00212 | Y02T-0010/82 | Y10S-0002/905","G06F-017/50","G06F-017/50 | A41H-003/00 | A61B-005/00 | G06Q-030/06 | A41D-001/00 | A61B-005/02 | A61B-005/024 | A61B-005/08 | A61B-017/00","","","","","","4918001004284"
"US","US","P","B2","Method and apparatus for controlling media play device","The present disclosure is related to a play control method, apparatus and terminal. The method comprises: acquiring brain wave information of a user; and controlling an electronic device based on the brain wave information. When the embodiments of this disclosure are applied, by acquiring brain wave information of a user and controlling an electronic device based on the brain wave information, the state of the user can be reflected through the brain wave information; accordingly, effective control of the user's needs can be realized through the brain wave information without any triggering operation by the user, thereby enhancing the user experience and improving the intelligence level of electronic device.","1. A method for controlling an electronic device, comprising: detecting an object being in touch with a sensor device;determining whether the object is a user;acquiring brain wave information of the user who is associated with the electronic device when the object is determined to be the user; andcontrolling the electronic device based on the brain wave information,whereinthe determining whether the object is the user comprises:receiving touch attributes of the object that is in touch with the sensor device;determining whether at least one of the touch attributes of the object meets a preset condition; anddetermining that the object that is in touch with the sensor device is the user when the at least one of the touch attributes meets the preset condition, andthe determining whether the at least one of the touch attributes of the object meets the preset condition comprises:when a pressure of the object is detected by a built-in pressure sensor, an area of the object is detected by the built-in area sensor, and a ratio of the pressure to the area matches a preset density, determining that the detected pressure and area meet the corresponding preset condition.","15","15/135245","2016-04-21","2017-0049350","2017-02-23","9848796","2017-12-26","XIAOMI INC.","Ke  Wu | Xinyu  Liu","2015-10518405","CN","2015-08-21","A61B-0005/0476","A61B-0005/0476 | G05B-0015/02 | G06F-0003/015 | G06F-0003/165 | H04N-0005/4403 | H04N-2005/4428","G06F-017/00","G06F-017/00 | A61B-005/0476 | G06F-003/01 | G05B-015/02 | G06F-003/16 | H04N-005/44","","","","","","4917052000957"
"US","US","P","B2","Systems and methods for communication between medical devices","Systems and methods for conducted communication are described. In one embodiment, a method of communicating with a medical device implanted within a patient comprises receiving, at a medical device via electrodes connected to the patient, a conducted communication signal, wherein the conducted communication signal comprises a signal component and a noise component. The method may further comprise adjusting, by the medical device, a receive threshold based at least in part on an amplitude of the received conducted communication signal so as to reduce an amplitude of the noise component of the conducted communication signal.","1. A method of communicating with a medical device implanted within a patient comprising: receiving, at a medical device via electrodes connected to the patient, a conducted communication signal, wherein the conducted communication signal comprises: a signal component that includes a plurality of communication pulses generated by a remote medical device; anda noise component;adjusting, by the medical device, a receive threshold based at least in part on an amplitude of the received conducted communication signal; andwherein adjusting the receive threshold at least partially reduces an amplitude of the noise component of the conducted communication signal.","19","15/239484","2016-08-17","2017-0054516","2017-02-23","9853743","2017-12-26","CARDIAC PACEMAKERS, INC.","Brian L.  Schmidt | Lance Eric  Juffer | Keith R.  Maile | Michael J.  Kane | Brendan Early  Koop","","","","H04B-0013/005","H04B-0013/005 | A61B-0005/0028 | A61B-0005/0031 | A61N-0001/37211 | A61N-0001/37223 | A61N-0001/37252 | H04B-0017/318 | H04L-0067/12 | H04W-0076/045 | A61N-0001/3756 | A61N-0001/37205 | A61N-0001/37217","H04B-005/00","H04B-005/00 | H04B-013/00 | H04B-017/318 | A61B-005/00 | H04L-029/08 | H04W-076/04 | A61N-001/375 | A61N-001/372","","","","","","4917052005870"
"US","US","P","B2","Implantable remote control","The present application discloses systems, methods, and articles of manufacture for controlling one or more functions of a device utilizing one or more tags. In one example, a method for controlling one or more functions of a medical device includes scanning a data interface of the medical device for signals induced wirelessly by one or more gestures made with one or more tags associated with a recipient of the medical device and controlling one or more functions of the medical device based on the wirelessly induced signals.","1. A hearing system, comprising: a first portion configured to be implanted in a recipient of the hearing system, wherein the first portion includes a data interface and a processor; anda second portion configured to be disposed on or worn by the recipient, wherein the second portion includes a passive circuit, wherein the second portion is powered by wireless signals,wherein the data interface is configured to receive a set of signals consisting of signal(s) wirelessly induced by the passive circuit while the passive circuit is within about 4 centimeters or less of the data interface, andwherein the processor is configured to perform a function of the hearing system in response to the set of wirelessly induced signals.","17","15/445534","2017-02-28","2017-0232256","2017-08-17","9854370","2017-12-26","Cochlear Limited","Werner  Meskens","","","","H04R-0025/554","H04R-0025/554 | A61N-0001/37217 | A61N-0001/37247 | A61N-0001/37252 | G06F-0003/017 | G06F-0017/218 | G06F-0019/3406 | H04R-0025/405 | H04R-0025/604 | A61N-0001/36036 | H04R-2225/51 | H04R-2225/67","A61N-001/00","A61N-001/00 | H04R-025/00 | A61N-001/372 | G06F-003/01 | G06F-019/00 | G06F-017/21 | A61N-001/36","","","","","","4917052006492"
"US","US","P","B2","System and devices for image targeting","A medical imaging system may include an imaging device; an optical head coupled to the imaging device, the optical head comprising a plurality of optical sensors; and a control unit in communication with the optical head. The control unit may be configured to: receive data from the plurality of optical sensors, determine a subset of optical sensors from the plurality of optical sensors for viewing one or more visible targets based on the received data from the plurality of optical sensors, and instruct the optical head to transmit images from the subset of optical sensors.","1. A medical imaging system comprising: an imaging device;an optical head coupled to the imaging device, the optical head comprising a plurality of optical sensors; anda control unit in communication with the optical head, the control unit configured to:receive data from the plurality of optical sensors,determine a subset of optical sensors from the plurality of optical sensors for viewing one or more visible targets based on the received data from the plurality of optical sensors, andinstruct the optical head to transmit images from the subset of optical sensors.","22","14/524468","2014-10-27","2016-0113724","2016-04-28","9844360","2017-12-19","CLEAR GUIDE MEDICAL, INC.","Philipp Jakob  Stolka | Pezhman  Foroughi | Matthew C.  Rendina | Gregory Donald  Hager","","","","A61B-0008/4444","A61B-0008/4444 | A61B-0005/0077 | A61B-0005/066 | A61B-0008/0841 | A61B-0008/4254 | A61B-0008/46 | A61B-0008/466 | A61B-0008/52 | A61B-0008/54 | A61B-0034/20 | A61B-0034/76 | G06F-0003/016 | A61B-0005/055 | A61B-0005/743 | A61B-0008/464 | A61B-2017/3413 | A61B-2034/2057 | A61B-2034/2063 | A61B-2560/0238 | A61B-2562/0233","A61B-008/00","A61B-008/00 | A61B-008/08 | A61B-034/00 | A61B-005/00 | G06F-003/01 | A61B-005/06 | A61B-034/20 | A61B-005/055 | A61B-017/34","","","","","","4917051000663"
"US","US","P","B2","System and method for managing a supply of breast milk","A system is disclosed for managing a supply of breast milk. In one form the system includes a codified container for receiving expressed breast milk. A computing device receives an image of the expressed milk in the codified container. The codification allows for software to recognize the size and type of the container, as well as scale and orientation, to translate the image into an accurate volume. The milk data is then processed and analyzed to produce feedback regarding the pumping session, such as logs, charts, or reminders. In other embodiments, nipple positioning may be analyzed as well.","1. A non-transitory computer readable medium having stored thereon instructions executable by a computing device to cause the computing device to perform functions comprising: analyzing at least one image of a milk collection device, the milk collection device being configured to receive expressed breastmilk;based on the analyzing, identifying a codification element associated with the milk collection device; andgenerating feedback associated with the expressed breastmilk based on the codification element.","13","15/149465","2016-05-09","2017-0087285","2017-03-30","9844616","2017-12-19","MEDELA HOLDING AG","Ryan  Bauer","","","","A61M-0001/062","A61M-0001/062 | A61B-0090/90 | A61B-0090/96 | A61J-0001/165 | A61M-0001/0001 | A61M-0001/06 | G06K-0009/52 | G06T-0007/0012 | G06T-0007/60 | G06T-0007/62 | G06T-0007/70 | H04N-0007/185 | A61B-2090/038 | A61M-2205/3306 | A61M-2205/3379 | A61M-2205/3553 | A61M-2205/3561 | A61M-2205/3584 | A61M-2205/3592 | A61M-2205/50 | A61M-2205/502 | A61M-2205/52 | A61M-2205/6063 | A61M-2205/6072 | A61M-2205/702 | G06T-2207/30208","G06F-017/00","G06F-017/00 | A61M-001/06 | G06K-009/52 | G06T-007/60 | H04N-007/18 | A61B-090/96 | A61B-090/90 | A61M-001/00 | G06T-007/70 | G06T-007/62 | A61J-001/16 | G06T-007/00 | A61B-090/00","","","","","","4917051000916"
"US","US","P","B2","Dispatch of automated external defibrillators","Technologies are generally described for an automated external defibrillator (AED) dispatch system. In various examples, the AED dispatch system may include a receiver, a vehicle determination unit, and a transmitter. The receiver may be configured to receive, from a first device, a request message that includes first location information that indicates a location of the first device, and also receive, from one or more of second devices, one or more report messages, each of which includes second location information that indicates a location of the corresponding one of the second devices. The vehicle determination unit may be configured to select a vehicle to be dispatched based at least in part on the first location information and the respective second location information. The transmitter may be configured to transmit an instruction message to the second device associated with the selected vehicle to be dispatched.","1. An automated external defibrillator (AED) dispatch system, comprising: a receiver configured to: receive a request message from a first device, wherein the request message includes first location information that indicates a location of the first device; andreceive one or more report messages from one or more second devices, wherein each of the one or more report messages includes second location information that indicates a location of one of the one or more second devices,wherein each of the one or more second devices is associated with a candidate vehicle from a plurality of candidate vehicles, andwherein each of the plurality of candidate vehicles has an AED;a vehicle determination unit, comprising: a memory implemented in an integrated circuit; anda processor implemented in an integrated circuit, the processor coupled to the memory, the processor configured to execute an application, which through an AED dispatch algorithm performs: select two or more candidate vehicles from the plurality of candidate vehicles to be dispatched based on: the first location information and the second location information,a subscription level of a patient, the patient associated with the first device, wherein the subscription level identifies a defibrillator dispatch service provided by the AED dispatch system, wherein the subscription level is associated with provision of the AED dispatch system at specific locations, wherein the provision of the AED dispatch system comprises provision of access to one or more users associated with the AED dispatch system, the access being provided based on one or more of an identity card, a magnetic access card, and a transponder, anddirection information associated with the plurality of candidate vehicles extracted from the received one or more report messages, wherein the direction information comprises whether the candidate vehicle is moving towards or moving away from the first device; anda transmitter configured to: transmit an instruction message to two or more second devices associated with the selected two or more candidate vehicles to be dispatched, wherein the instruction message includes the first location information and instructions to dispatch the selected two or more candidate vehicles by the two or more second devices.","21","14/917278","2013-11-13","2016-0217691","2016-07-28","9847030","2017-12-19","EMPIRE TECHNOLOGY DEVELOPMENT LLC","Rieko  Kadobayashi | Tsutomu  Miyasato | Noriaki  Kuwahara | Masataka  Ohira | Noriaki  Mitsunaga","","","","G08G-0001/202","G08G-0001/202 | A61N-0001/3993 | G01S-0019/51 | G06Q-0010/083 | G06Q-0050/22 | G08G-0001/005 | G08G-0001/13","H04W-004/02","H04W-004/02 | G08G-001/00 | G06Q-050/22 | G06Q-010/08 | A61N-001/39 | G01S-019/51 | G08G-001/005 | G08G-001/13","","","","","","4917051003320"
"US","US","P","B2","Phenotypic integrated social search database and method","A method for generating correlations between human biological phenotype and human behavioral and/or emotional phenotype, and optionally to temporal location, comprising the steps of correlating data on biological phenotype with survey-based data on behavioral and/or emotional phenotype. The data on biological phenotype is collected from a sample from an individual, and the survey-based data can be collected from answers to behavioral and emotional questions from the individual or from observations of the individual by a third party. Correlations can further be used to predict behavior, including preferences, wellness needs and desires, and/or emotions. Feedback, advice and guidance can be provided to individuals based on such correlations. Such correlations are further useful for product and service providers and industries for purposes of standardizing or rating product quality and efficacy, and/or for promotion and selling purposes. A database comprising the data on biological phenotype and survey-based data is also provided.","1. A database comprising information identifying a plurality of human subjects, data on biological phenotype of the plurality of subjects, survey-based data on behavioral and/or emotional phenotype of the plurality of subjects, and correlations between the data on biological phenotype from the plurality of subjects and the survey-based data on behavioral and/or emotional phenotype from the plurality of subjects, wherein the data on biological phenotype is collected from a plurality of samples from the plurality of subjects,the survey-based data is collected from answers to social behavioral and emotional questions from the plurality of subjects or from observations of the plurality of subjects by a third party, andthe sample and the survey-based data are collected simultaneously so that a temporal biologic condition or state is correlated with behavior and/or emotion,wherein the database is configured to evolve when additional sample and survey-based data is added to the sample and survey-based data from the plurality of subjects by correlating the updated sample and survey-based data wherein the correlations are configured for use to provide feedback or guidance to the subject, to provide information to a product provider or a service provider for use in marketing and/or selling of products and/or services, to provide a product provider or service provider with information useful in grading or rating products or services, or to provide a product provider or service provider with information useful to design new and/or better products or services.","4","14/892185","2014-05-23","2016-0110524","2016-04-21","9839380","2017-12-12","IPHENOTYPE LLC","Jay M.  Short | Steve  Briggs","","","","A61B-0005/14546","A61B-0005/14546 | A61B-0003/113 | A61B-0005/02055 | A61B-0005/0488 | A61B-0005/1459 | A61B-0005/1473 | A61B-0005/165 | A61B-0005/4875 | A61B-0005/7246 | G06F-0017/30598 | G06F-0017/30867 | G06F-0019/18 | G06F-0019/3406 | G06F-0019/3443 | G06F-0019/363 | G06Q-0030/02 | G06Q-0030/0631 | G06Q-0050/22 | G09B-0005/12 | G09B-0019/00 | A61B-0005/021 | A61B-0005/024 | A61B-0005/05 | A61B-0005/0816 | G06F-0019/24","G01N-033/53","G01N-033/53 | A61B-005/145 | G06F-019/18 | G06F-019/00 | G06Q-030/02 | G06Q-050/22 | G06F-017/30 | A61B-003/113 | A61B-005/0205 | A61B-005/0488 | A61B-005/1459 | A61B-005/1473 | A61B-005/00 | G09B-019/00 | A61B-005/16 | G06Q-030/06 | G09B-005/12 | G06F-019/24 | A61B-005/021 | A61B-005/024 | A61B-005/08 | A61B-005/05","","","","","","4917050000739"
"US","US","P","B2","User authenticating method and head mounted device supporting the same","A head mounted device (HMD) includes an imaging unit configured to capture at least one image of a partial region of an iris, an electrocardiogram (ECG) sensor configured to receive an ECG signal, and a control unit configured to acquire at least one image of the partial region of the iris and ECG signals, and authenticate a user by using the acquired image(s) of the partial region of the iris and the ECG signals.","1. A head mounted device (HMD) comprising: at least one camera configured to capture one or more partial region images of an iris;an electrocardiogram (ECG) sensor configured to receive ECG signals; andat least one processor configured to authenticate a user by acquiring at least one of the one or more partial region images, which are captured by the at least one camera, and the ECG signals, which are received through a plurality of electrodes,wherein the at least one processor is further configured to generate a normalized image to authenticate the user, by combining the one or more partial region images and by using a curvature of an inner contour line of the iris, which is included in the one or more partial region images.","19","15/014652","2016-02-03","2016-0259986","2016-09-08","9836663","2017-12-05","SAMSUNG ELECTRONICS CO., LTD.","In-kuk  Yun | Je-in  Yu | Byeong-hoon  Kwak | Hyun-jung  Kim | In-hak  Na | Bo-seok  Moon | Jae-hyun  Park | Young-eun  Lee | Ji-yeon  Han","10-2015-0031245 | 10-2015-0066244","KR | KR","2015-03-05 | 2015-05-12","G06K-0009/00892","G06K-0009/00892 | A61B-0005/04525 | A61B-0005/6803 | G02B-0027/017 | G02B-0027/0172 | G06F-0021/32 | G06K-0009/0061 | G06K-0009/00617 | G02B-2027/014 | G02B-2027/0138 | G02B-2027/0141 | G02B-2027/0178 | G02B-2027/0187 | G06K-2009/00939","G06K-009/00","G06K-009/00 | G02B-027/01 | G06F-021/32 | A61B-005/0452 | A61B-005/00","","","","","","4917049004396"
"US","US","P","B1","Biometric sensing device with discrete ultrasonic transducers","A biometric sensing system includes discrete ultrasonic transducers, a first electrode layer disposed over a first surface of the discrete ultrasonic transducers, and a second electrode layer disposed over a second surface of the discrete ultrasonic transducers. The first electrode layer may be a sheet of conductive material that is a common ground connection for the discrete ultrasonic transducers. Alternatively, the first electrode layer can be formed with discrete electrode elements, with a discrete electrode element disposed over the first surface of a discrete ultrasonic transducer. The second electrode layer may be formed with discrete electrode elements, with a discrete electrode element disposed over the second surface of one ultrasonic transducer. At least one integrated circuit can be attached and connected to one of the electrode layers. The integrated circuit includes drive circuits and sense circuits for the discrete ultrasonic transducers.","1. A biometric sensing system, comprising: a first discrete ultrasonic transducer;a second discrete ultrasonic transducer;a first electrode layer comprising a sheet of conductive material disposed over a first surface of the first and the second discrete ultrasonic transducers;a second electrode layer comprising a first discrete electrode element disposed over a second surface of the first discrete ultrasonic transducer and a second discrete electrode element disposed over the second surface of the second discrete ultrasonic transducer; andan integrated circuit attached and electrically connected to the second electrode layer, the integrated circuit comprising: a first drive circuit operably connected to the first discrete ultrasonic transducer through the first discrete electrode element in the second electrode layer;a first sense circuit operably connected to the first discrete ultrasonic transducer through the first discrete electrode element in the second electrode layer;a second drive circuit operably connected to the second discrete ultrasonic transducer through the second discrete electrode element in the second electrode layer; anda second sense circuit operably connected to the second discrete ultrasonic transducer through the second discrete electrode element in the second electrode layer.","23","14/590821","2015-01-06","","","9824254","2017-11-21","APPLE INC.","Mohammad Yeke  Yazdandoost | Giovanni  Gozzini | Jean-Marie  Bussat","","","","G06K-0009/0002","G06K-0009/0002 | A61B-0005/1172 | G06F-0003/0416 | G06F-0003/0436 | G06K-0009/00087","G06K-009/00","G06K-009/00 | A61B-005/1172 | G06F-003/043 | G06F-003/041","","","","","","4917047004481"
"US","US","P","B2","Wearable emotion detection and feedback system","A see-through, head mounted display and sensing devices cooperating with the display detect audible and visual behaviors of a subject in a field of view of the device. A processing device communicating with display and the sensors monitors audible and visual behaviors of the subject by receiving data from the sensors. Emotional states are computed based on the behaviors and feedback provided to the wearer indicating computed emotional states of the subject. During interactions, the device, recognizes emotional states in subjects by comparing detected sensor input against a database of human/primate gestures/expressions, posture, and speech. Feedback is provided to the wearer after interpretation of the sensor input.","1. A see through head mounted display apparatus, comprising: a see-through, head mounted display;a plurality of sensors cooperating with the see-through, head mounted display to detect at least one of audible and visual behaviors of a subject in a field of view of the apparatus; andone or more processing devices in communication with the see-through, head mounted display and the sensors, the one or more processing devices:monitor the at least one of audible and visual behaviors of the subject by receiving data from the sensors;receive supplemental data relating to an emotional state of the subject from a second see-through, head mounted display also monitoring at least one of audible and visual behaviors of the subject;compute an emotional state of the subject based on the at least one of audible and visual behaviors monitored by see-through, head mounted display device and the supplemental data received from the second see-through, head mounted display; andprovide at least one of audible and visible feedback to a computing device indicating computed emotional states of the subject.","24","15/364037","2016-11-29","2017-0117005","2017-04-27","9824698","2017-11-21","MICROSOFT TECHNOLOGY LICENSING, LLC","Robert  Jerauld","","","","G10L-0025/63","G10L-0025/63 | A61B-0005/165 | A61B-0005/7278 | A61B-0005/742 | G02B-0027/0172 | G06F-0001/163 | G06F-0003/0482 | G06K-0009/00335 | G02B-2027/014 | G02B-2027/0138","G06K-009/00","G06K-009/00 | G10L-025/63 | G06F-001/16 | G06F-003/0482 | G02B-027/01 | A61B-005/16 | A61B-005/00","","","","","","4917047004920"
"US","US","P","B2","System for diagnosing bloodflow characteristics, method thereof, and computer software program","This system is a computer-based system for analyzing a blood flow at a target vascular site of a subject by means of a computer simulation, having a three-dimensional shape extraction unit, by a computer, for reading a captured image at the target vascular site and generating three-dimensional data representing a shape of a lumen of the target vascular site; a fluid dynamics analysis unit, by a computer, for determining state quantities (pressure and flow velocity) of blood flow at each position of the lumen of the target vascular site by means of computation by imposing boundary conditions relating to blood flow to the three-dimensional shape data; a blood flow characteristic determination unit for determining, from the state quantities of the blood flow determined by the fluid dynamics analysis unit, a wall shear stress vector at each position of the lumen wall surface of the target vascular site, determining relative relationship between a direction of the wall shear stress vector at a specific wall surface position and directions of wall shear stress vectors at wall surface positions surrounding the specific wall surface position, and from the morphology thereof, determining characteristics of the blood flow at the specific wall surface position and outputting the same as a determined result; and a display unit, by a computer, for displaying the determined result of the blood flow characteristic which is graphically superposed onto a three-dimensional shape model.","1. A computer-based system for determining patient-specific vascular information, the system comprising at least one computer configured to: receive three dimensional data representing a shape of at least one vascular portion of the patient, the three dimensional data being suitable for simulations using computational fluid dynamics (CFD);determine information regarding blood flow properties including pressure and velocity at each computational mesh in the vascular portion of the patient using a CFD simulation on the three dimensional data;determine, based solely on the information regarding the blood flow properties, information relating to vascular wall vulnerability characteristics at each computational mesh located on an inner surface of the vascular portion of the patient,wherein the information relating to the vascular wall vulnerability characteristics includes a disturbance in blood flow exerted at each computational mesh and at surrounding computational meshes, located on the inner surface of the vascular portion of the patient;wherein the disturbance is determined based on at least a relative relationship among directions of wall shear stress vectors at each computational mesh and at surrounding computational meshes, located on the inner surface of the vascular portion of the patient; anddisplay the information relating to the vascular wall vulnerability characteristics graphically superposed on the three dimensional data.","19","14/240666","2012-08-27","2014-0316758","2014-10-23","9814531","2017-11-14","EBM CORPORATION","Takanobu  Yagi | Young-Kwang  Park","2011-184751","JP","2011-08-26","A61B-0019/50","A61B-0019/50 | A61B-0005/026 | A61B-0005/055 | A61B-0005/7275 | A61B-0006/507 | A61B-0017/083 | A61B-0017/12118 | A61B-0034/10 | A61B-0034/25 | A61B-0090/37 | A61F-0002/82 | A61F-0002/95 | G06F-0017/5009 | G06F-0019/3437 | G06T-0017/00 | G06T-0019/00 | A61B-0005/02014 | A61B-0005/7435 | A61B-0006/504 | A61B-0008/06 | A61B-2034/104 | A61B-2034/105 | A61B-2034/107 | A61B-2034/108 | A61B-2576/02 | G06F-0019/321 | G06T-2210/24 | G06T-2210/41","G06G-007/50","G06G-007/50 | A61B-019/00 | A61B-005/055 | A61B-005/026 | G06T-019/00 | G06F-017/50 | G06T-017/00 | A61B-005/00 | A61B-017/08 | A61B-017/12 | A61F-002/82 | A61F-002/95 | A61B-034/00 | A61B-090/00 | A61B-006/00 | A61B-008/06 | A61B-005/02 | G06F-019/00 | A61B-034/10","","","","","","4917046001030"
"US","US","P","B2","Head-mounted systems and methods for providing inspection, evaluation or assessment of an event or location","Systems and methods for providing assessment of a local scene to a remote location are provided herein. The systems and methods facilitate collection, storage and transmission of data from the local scene to the remote location without limiting the mobility, dexterity, adaptability and interactive capability of an on-scene technician. For example, a head-mounted device according to an implementation discussed herein can include: a head-mounted frame that is configured to hold a transparent visor; an image capturing device attachable to at least one of the head-mounted frame and the transparent visor; and a micro-optic display system attachable to at least one of the head-mounted frame and the transparent visor. The micro-optic display system can be configured to render a heads up image on the transparent visor. In addition, the heads up image can define an outline of a field of view of the image capturing device.","1. A head-mounted device, comprising: a head-mounted frame that is configured to hold a transparent visor;an image capturing device attachable to at least one of the head-mounted frame and the transparent visor;an interface configured to receive medical information, the interface having a wireless receiver configured to receive vital sign data for at least one patient from one or more medical instruments over a wireless communication link; anda micro-optic display system attachable to at least one of the head-mounted frame and the transparent visor, the micro-optic display system being configured to render a heads up image and the vital sign data on the transparent visor, wherein the heads up image comprises an outline of a field of view of the image capturing device and an outline of a field of view corresponding to an image as viewed at a remote work station, wherein the outline of the field of view corresponding to the image as viewed at the remote work station is dynamically displayed as a subset of the field of view of the image capturing device, the subset corresponding to a level of zoom on the image as viewed at the remote work station.","20","14/430005","2013-09-20","2015-0244903","2015-08-27","9819843","2017-11-14","ZERISCOPE INC. | MUSC FOUNDATION FOR RESEARCH AND DEVELOPMENT","Robert J.  Adams","","","","H04N-0005/2252","H04N-0005/2252 | G02B-0027/017 | G02B-0027/0172 | G06F-0003/012 | G06F-0003/0338 | G06F-0003/0362 | G06T-0007/0012 | G06T-0011/00 | H04N-0005/23293 | H04N-0005/23296 | A61B-0005/0002 | G02B-2027/014 | G02B-2027/0123 | G02B-2027/0127 | G02B-2027/0138 | G02B-2027/0178 | G06F-0019/3406","H04N-005/222","H04N-005/222 | G09G-005/00 | H04N-005/225 | G02B-027/01 | H04N-005/232 | G06F-003/01 | G06F-003/0338 | G06T-011/00 | G06F-003/0362 | G06T-007/00 | A61B-005/00 | G06F-019/00","","","","","","4917046006308"
"US","US","P","B2","Systems and methods for managing fault codes","Various embodiments of the present invention provide systems and methods for managing fault codes triggered by one or more vehicles during operation. In general, various embodiments of the invention involve recording and analyzing fault codes triggered during a particular time period while a vehicle is in operation. As a result of the analysis, various embodiments of the invention may set a state for each of the identified fault codes, the state indicating a level of action to address the identified fault code. In particular embodiments, the states may be one of a caution state indicating one or more components or sub-systems of the vehicle should be monitored, a critical state indicating one or more components or sub-systems of the vehicle should be repaired, or an environmental state indicating failure or potential failure of one or more components or sub-systems of the vehicle may affect one or more environmental conditions.","1. A system for managing fault codes associated with a vehicle, the system comprising: a memory storing a plurality of parameters and a plurality of fault codes, wherein each parameter is associated with a fault code and said plurality of parameters comprise: a threshold value and a consecutive value associated with the particular fault code, the threshold value defining a threshold number of times the particular fault code is generated during the predefined time period the vehicle was in operation and the consecutive value defining a number of consecutive predefined time periods during which the threshold value was met or exceeded; andone or more computer processors configured to: receive fault code information retrieved from the vehicle, the fault code information comprising one or more of said plurality of fault codes, the one or more fault codes generated during a particular time period the vehicle was in operation;retrieve parameters stored in the memory associated with the one or more fault codes; analyze the fault code information to identify each of the one or more fault codes signaling failure or potential failure of one or more components or sub-systems of the vehicle based at least in part on the parameters associated with the one or more fault codes in the fault code information; andset a state for each identified fault code, based at least in part on the parameters associated with each identified fault code, the state indicating a level of action associated with the identified fault code, wherein the state for the particular fault code is also set by the processors in response to the fault code information showing that the particular fault code was generated a number of times meeting or exceeding the threshold value during a number of consecutive time periods meeting or exceeding the consecutive value.","10","15/040486","2016-02-10","2016-0163135","2016-06-09","9811951","2017-11-07","UNITED PARCEL SERVICE OF AMERICA, INC.","John A.  Olsen, III | David L.  Bradley | Matthew S.  Hendrix","","","","G07C-0005/0808","G07C-0005/0808 | G05B-0023/0283 | G07C-0005/02 | G07C-0005/08 | G07C-0005/085 | A61B-0005/00 | B64F-0005/60 | G01M-0015/05 | G01M-0017/00 | G05B-0023/0235 | G06F-0007/00 | G06F-0015/00 | G06F-0017/10 | G06F-0019/00 | G06Q-0050/22 | G07C-0005/008","G07C-005/08","G07C-005/08 | G07C-005/02 | G01M-015/05 | G07C-005/00 | G05B-023/02 | G06Q-050/22 | A61B-005/00 | G06F-017/10 | G06F-019/00 | G01M-017/00 | G06F-007/00 | G06F-015/00 | B64F-005/60","","","","","","4917045004669"
"US","US","P","B2","Ranking device, ranking method, and program","A device, a system, a method, and a program are realized which are capable of predicting the order of the feeling and the preference of a subject to products which are the research objects, for marketing research and others. The images of a plurality of research objects are presented a plurality of times as visual stimuli in order to measure the brain wave. A brain wave data of an event related electrical potential for the research objects which the subject has selected as a target immediately after the stimulus presentation, is processed by a linear discriminant analysis to quantitatively represent with a single index, in order to rank the research objects.","1. A ranking device for ranking a plurality of research objects based on differences in a degree of a rising attention of a subject to each of the plurality of research objects, configured to: classify target and non-target for brain wave data of event related electrical potentials, wherein the brain wave data is measured by a brain wave monitor with electrodes attached on a head of the subject;calculate a weighting factor of discriminant equation based on data point of time series data and the number of a channel according to a number of measured positions where the brain wave data of the even related electrical potential is acquired when each of the plurality of research objects is the target;calculate a discriminant point for each product as the target based on the discriminant equation; andrank the research objects based on the discriminant point calculated for each product.","3","14/380955","2012-10-12","2015-0026195","2015-01-22","9798796","2017-10-24","NATIONAL INSTITUTE OF ADVANCED INDUSTRIAL SCIENCE AND TECHNOLOGY","Ryohei  Hasegawa","2012-040913","JP","2012-02-28","G06F-0017/30595","G06F-0017/30595 | A61B-0005/0476 | A61B-0005/04842 | G06F-0019/36 | G06Q-0030/02","G06F-017/30","G06F-017/30 | A61B-005/0476 | G06Q-030/02 | A61B-005/0484 | G06F-019/00","","","","","","4917043004329"
"US","US","P","B2","Protective medical device faceplate","Devices are provided that include a faceplate for a medical device. In embodiments, an identifier chip adapted to be affixed to an exterior portion of a faceplate provides a unique identifier for the faceplate. Accordingly, the identifier chip enables tracking and monitoring of an associated medical device. And, in embodiments, the faceplate includes a visual communication alert indicator to enable the faceplate to provide visual cues a user. As such, the status of the medical device and the faceplate can be easily communicated to the user. Methods to use the faceplate are also provided.","1. A wireless communication device integrated with a faceplate, the device comprising: a faceplate configured to be removably affixed to a medical device'ss housing;the faceplate having an interior surface and an exterior surface;the interior surface having affixed there to at least one processor, computer readable memory, a power supply, a wireless receiver, a wireless transmitter, and a communication port, wherein the communication port is adapted to communicate with the medical device.","25","15/394322","2016-12-29","2017-0119955","2017-05-04","9789246","2017-10-17","CERNER INNOVATION, INC.","Alan Mark  Portnoy","","","","A61M-0005/142","A61M-0005/142 | A61B-0090/96 | A61B-0090/98 | A61M-0005/1415 | G06F-0019/322 | G06F-0019/327 | G06K-0007/10297 | A61M-2005/14208 | A61M-2205/3584 | A61M-2205/6054 | A61M-2205/6072","G06F-017/00","G06F-017/00 | A61M-005/142 | G06F-019/00 | G06K-007/10 | A61M-005/14 | A61B-090/96 | A61B-090/98","","","","","","4917042001421"
"US","US","P","B2","Customized skin care and method to provide same","Methods to provide customized skin care by using specimen dispensing device to dispense specimens from removable dispensers for the purpose of treating skin of a user are presented. Methods to utilize the embedded memory and electrical interface of the dispensing device and dispensers to produce customizable skin care products that give better skin treatment results are also presented. The invention may also be applied to health care and personal care needs.","1. A method to provide customized skin care by using a specimen dispensing device to dispense specimens for treating a skin area of a user comprising the steps of: a first computing device creating user data during a skin analysis of said user, whereas said user data contains a first identification (ID) of a first skin feature with a first grade, and a second ID of a second skin feature with a second grade;said first computing device transferring said user data to a first information storage component included in a control unit enclosed in said specimen dispensing device;said user installing a first dispenser containing a first specimen and a second dispenser containing a second specimen into said specimen dispensing device;wherein said first dispenser comprising a second information storage component storing a first specimen data including said first ID and a first method of dispensing, and said second dispenser comprising said second information storage component storing a second specimen data including said second ID and a second method of dispensing;said control unit acquiring said first and said second specimen data from said second information storage components of said first and second dispensers through a first data connection between said control unit and said first and second dispensers;an information processing component included in said control unit calculating a first dispensing recipe with using said first grade, said first method of dispensing, said second grade, and said second method of dispensing;said control unit commanding the dispensing of said first and second specimens from said first and said second dispensers according to said first dispensing recipe.","20","15/193059","2016-06-26","2016-0331308","2016-11-17","9789295","2017-10-17","LA PIERRES, INC.","Yuchen  Zhou","","","","A61M-0035/003","A61M-0035/003 | A61B-0005/002 | A61B-0005/0022 | A61B-0005/0077 | A61B-0005/103 | A61B-0005/441 | A61B-0005/4836 | A61H-0007/002 | A61H-0023/00 | A61M-0037/00 | A61N-0007/00 | G06F-0019/3406 | G06F-0019/3456 | G06F-0019/3462 | G06Q-0050/01 | A61F-2007/0087 | A61H-0007/003 | A61H-0009/0007 | A61H-0023/006 | A61H-0023/0245 | A61H-2201/0153 | A61H-2201/0157 | A61H-2201/02 | A61H-2201/0207 | A61H-2201/0214 | A61H-2201/0228 | A61H-2201/0292 | A61H-2201/10 | A61H-2201/1409 | A61H-2201/5046 | A61H-2201/5048 | A61H-2201/5064 | A61H-2201/5097 | A61H-2205/022 | A61M-0037/0092 | A61M-2205/3584 | A61M-2205/50 | A61N-0001/0408 | A61N-0001/328 | A61N-0005/0616 | A61N-2005/0644 | A61N-2007/0034 | G01S-0019/19","A61M-035/00","A61M-035/00 | A61H-023/00 | A61H-023/02 | A61B-005/00 | A61H-007/00 | A61B-005/103 | A61M-037/00 | A61N-007/00 | G06F-019/00 | G06Q-050/00 | A61N-001/00 | A61N-001/04 | A61N-005/06 | A61N-001/32 | A61F-007/00 | A61H-009/00 | G01S-019/19","","","","","","4917042001468"
"US","US","P","B2","Systems and methods for VOA model generation and use","A computer implemented system and method provides a volume of activation (VOA) estimation model that receives as input two or more electric field values of a same or different data type at respective two or more positions of a neural element and determines based on such input an activation status of the neural element. A computer implemented system and method provides a machine learning system that automatically generates a computationally inexpensive VOA estimation model based on output of a computationally expensive system.","1. A computer-implemented method, comprising: obtaining, by a computer processor, electric field data corresponding to settings of a non-cylindrically symmetrical implanted leadwire that is adapted for stimulating anatomical tissue, the electric field data including for each of a plurality of neural elements a respective plurality of electric values for a same electric field parameter;determining in a first determining step, by the processor and for each of the neural elements, a respective activation status based on the respective plurality of electric values associated with the respective neural element; andthe processor determining in a second determining step, and outputting an indication of, an estimated activated tissue region corresponding to a combination of points surrounding the leadwire corresponding to those of the neural elements for which an active status is determined;wherein the determining of the second determining step is performed by executing a first module that at least one of: does not base the determining of the second determining step on input of different sets of values of an electric field at different points in time;does not use more than one differential equation; oris generated based on observed functioning of a second module that uses differential equations, wherein the first module uses only linear equations.","25","13/973113","2013-08-22","2014-0122379","2014-05-01","9792412","2017-10-17","BOSTON SCIENTIFIC NEUROMODULATION CORPORATION","Michael A.  Moffitt | G. Karl  Steinke","","","","G06F-0019/3437","G06F-0019/3437 | A61N-0001/36128 | G06F-0019/345 | G06N-0005/02 | G06N-0099/005 | A61N-0001/37247","G06F-017/00","G06F-017/00 | G06F-017/20 | G06F-019/00 | G06N-005/02 | G06N-099/00 | A61N-001/36 | A61N-001/372","","","","","","4917042004564"
"US","US","P","B2","Display control apparatus, display control method of display control apparatus, and eye gaze direction detection system","It is determined whether a driver is gazing at a gaze target object in the eye gaze direction, and the eye gaze of the driver is guided by changing a display mode of the gaze target object determined to be gazed at by the driver. Calibration of eye gaze direction detection information is accurately and promptly executed.","1. A display control apparatus to use a display object displayed by a display unit as a gaze target object, and to control calibration of an eye gaze direction detection apparatus based on the gaze target object, the display control apparatus comprising: an eye gaze state determinator to determine, based on eye gaze direction detection information detected by the eye gaze direction detection apparatus and display information of the gaze target object, whether a subject is gazing at the gaze target object existing in an eye gaze direction of the subject;an eye gaze guider to output display information of the gaze target object and screen control information relating to a display mode of the gaze target object, and to guide an eye gaze of the subject by changing the display mode of the gaze target object when the subject is determined to be gazing at the gaze target object;a display controller to output display control information for controlling the display unit, based on the screen control information output by the eye gaze guider; anda calibration controller to output a calibration control signal toward the eye gaze direction detection apparatus when the subject is determined to be gazing at the gaze target object,wherein the gaze target object is an icon or a button displayed by an intelligent panel functioning as the display unit, or by the display unit of a car navigation apparatus, or a marking displayed by a head-up display as the display unit.","18","15/114759","2014-02-19","2016-0342205","2016-11-24","9785235","2017-10-10","MITSUBISHI ELECTRIC CORPORATION","Asako  Shigeta | Takahisa  Aoyagi | Tetsuji  Haga","","","","G06F-0003/013","G06F-0003/013 | A61B-0003/0041 | A61B-0003/113 | A61B-0005/18 | G06K-0009/00617 | G06T-0007/70 | G06F-0009/4446 | G06T-2207/30201","G09G-005/00","G09G-005/00 | G06F-003/01 | A61B-003/113 | A61B-003/00 | A61B-005/18 | G06K-009/00 | G06T-007/70 | G06F-009/44","","","","","","4917041004021"
"US","US","P","B2","Radiotherapy method, computer program and computer system","A method of obtaining a 3D image of a part of a patient's body is disclosed, based on a fraction image having a limited field-of-view and complementing this with information from a planning image having a greater field-of-view. In the area outside of the fraction image field-of-view, contour and anatomical data from the planning image are used to complement the fraction image, by means of a contour-guided deformable registration between the planning image and the fraction image.","1. A method of obtaining a 3D composite image of at least a first portion of a patient'ss body, comprising the steps of: obtaining a 3D planning image corresponding to the first portion of the patient'ss body and having a first field-of-view,obtaining a 3D fraction image of the first portion of the patient'ss body, the fraction image having a second field-of-view which is limited in at least one dimension compared to the first field-of-view,creating a model outline including at least one area of the patient'ss body included in the first field-of-view but not in the second field-of-view,appending the model outline to the fraction image, to include at least one outlined portion in the fraction image which is outside the second field-of-view to obtain an intermediate image,performing a deformable registration between the outline of the planning image and the outline of the fraction image,using the result of the deformable registration to include material information from the area in the planning image inside of the outlined portion in the intermediate image, to obtain a composite image.","11","15/381382","2016-12-16","2017-0178391","2017-06-22","9786093","2017-10-10","RAYSEARCH LABORATORIES AB","Stina  Svensson","2015-201272","EP","2015-12-18","G06T-0015/20","G06T-0015/20 | A61N-0005/1039 | G06F-0019/3437 | G06T-0003/0068 | G06T-0007/344 | G06T-0011/003 | G06T-0019/20 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/30196","G06F-017/50","G06F-017/50 | G06T-015/00 | G06T-015/20 | A61N-005/10 | G06F-019/00 | G06T-011/00 | G06T-019/20 | G06T-003/00 | G06T-007/33","","","","","","4917041004874"
"US","US","P","B2","Automatic sound equalization device","A technique for determining one or more equalization parameters includes acquiring, via one or more electrodes, auditory brainstem response (ABR) data associated with a first audio sample and determining, via a processor, one or more equalization parameters based on the ABR data. The technique further includes reproducing a second audio sample based on the one or more equalization parameters, acquiring, via the one or more electrodes, complex auditory brainstem response (cABR) data associated with the second audio sample, and comparing, via the processor, the cABR data to at least one representation of the second audio sample to determine at least one measure of similarity. The technique further includes modifying the one or more equalization parameters based on the at least one measure of similarity.","1. A non-transitory computer-readable storage medium including instructions that, when executed by a processor, configure the processor to determine one or more equalization parameters, by performing the steps of: acquiring complex auditory brainstem response (cABR) data associated with an audio sample;comparing the cABR data to at least one representation of the audio sample to determine at least one measure of similarity; anddetermining the one or more equalization parameters based on the at least one measure of similarity.","20","14/918239","2015-10-20","2016-0112022","2016-04-21","9787274","2017-10-10","HARMAN INTERNATIONAL INDUSTRIES, INC.","Donald Joseph  Butts","","","","H03G-0005/165","H03G-0005/165 | A61B-0005/125 | A61N-0001/36032 | G06F-0003/015 | H04R-0001/10 | H04R-0005/04 | A61B-0005/04845 | H04R-0003/04 | H04R-0025/70","H03G-005/00","H03G-005/00 | H03G-005/16 | G06F-003/01 | A61N-001/36 | H04R-005/04 | A61B-005/12 | H04R-001/10 | H04R-003/04 | H04R-025/00 | A61B-005/0484","","","","","","4917041006045"
"US","US","P","B2","Network connectivity unit for hospital bed","A hospital bed is programmable with new firmware that is downloaded to the bed over a network. The firmware is downloaded to the bed automatically from a remote computer device. The remote computer device receives a message from the hospital bed which includes data regarding the version number of the bed's current firmware, and if the version number indicates that the firmware is an outdated version, the remote computer device downloads a new version of the firmware to the bed.","1. An interface unit for use in a healthcare facility having a computer located remotely from a patient room which has a patient bed therein, the interface unit being located in the patient room and spaced from the patient bed, the interface unit comprising: a first connector which is communicatively coupleable to the hospital bed,a second connector which is communicatively coupleable to the computer, andcircuitry comprising at least two device connectors for connection to external devices, the circuitry storing a unit identification (ID) that is associated with the patient room of the healthcare facility, the unit ID being transmitted by the circuitry through the second connector without transmitting the unit ID through the first connector and the at least two device connectors.","20","15/332428","2016-10-24","2017-0035295","2017-02-09","9775519","2017-10-03","Hill-Rom Services, Inc.","Williams F.  Collins, Jr. | James M.  Allen | Keith A.  Huster | Carl W.  Riley | Patricia A.  Glidewell | Irvin J.  Vanderpohl, III | Richard J.  Schuman | Benjamin E.  Howell | Timothy D.  Wildman","","","","A61B-0005/002","A61B-0005/002 | A61B-0005/024 | A61B-0005/1115 | A61B-0005/1117 | A61B-0005/447 | A61B-0005/746 | A61G-0007/018 | A61G-0012/00 | G06F-0008/65 | G06F-0019/327 | G06F-0019/3412 | G06F-0019/3418 | G07C-0003/00 | G08B-0005/22 | G08B-0005/222 | G08B-0021/22 | H04L-0067/10","G08B-005/22","G08B-005/22 | A61B-005/00 | A61B-005/11 | A61G-007/018 | G06F-019/00 | G07C-003/00 | G08B-021/22 | G06F-009/445 | H04L-029/08 | A61B-005/024 | A61G-012/00","","","","","","4917040000910"
"US","US","P","B2","Methods and systems for calibrating user devices","Methods and systems are described herein for a media guidance application that improves the customization and calibration of user devices to a particular user. For example, in response to erroneously detecting (or failing to detect) a user input of a first type, the media guidance application may re-calibrate the user device based on subsequent corrective inputs issued using a second input type such that future user inputs of the first type will not be erroneously detected (or fail to be detected).","1. A method of calibrating user devices, the method comprising: monitoring, with a user device, a first input type for a command;receiving a first user input comprising a first user attempt to issue the command using the first input type, wherein the first user input does not trigger the command, wherein the first user input is detected based on a detection of a first indicium of the first user input, and wherein the first user input does not trigger the command because a value corresponding to the first indicium of the first user input is below a threshold value;receiving a second user input comprising a second user attempt to issue the command using a second input type, wherein the second user attempt triggers the command; andin response to receiving the second user attempt, recalibrating the user device such that subsequent receipt of the first user input with the first input type triggers the command by reducing the threshold value based on the value corresponding to the first indicium of the first user input.","20","14/492358","2014-09-22","2016-0085295","2016-03-24","9778736","2017-10-03","UV CORP. | TV GUIDE, INC. | ROVI GUIDES, INC.","Camron  Shimy | Michael R.  Nichols","","","","G06F-0003/01","G06F-0003/01 | A61B-0005/486 | A61B-0005/7267 | G06F-0003/015 | G06F-0017/30843 | H04N-0021/44218 | A61B-0005/16 | A61B-2560/0223 | G06F-0001/163 | G06F-2203/011 | H04L-0029/08675 | H04N-0005/44543","G06F-003/00","G06F-003/00 | G06F-003/01 | A61B-005/00 | H04N-021/442 | G06F-017/30 | A61B-005/16 | G06F-001/16 | H04L-029/08 | H04N-005/445","","","","","","4917040004114"
"US","US","P","B2","Translation station","An interactive electronic translation and communications process is provided for use in a translation station that provides a mobile or stationary fixed interactive facility for interviews or interrogations to be carried out between two persons speaking in different languages. The process can be assisted by animated virtual characters (avatars) realistically created and displayed on a computer screen to represent ethnic looks from around the globe. The avatars can be lip synchronized to deliver messages to the interviewee in the interviewee's languages and can guide the users and interviewee through a series of questions and answers. Biometric conditions of the interviewee and electronic identification of the interviewee can also be readily accomplished by the novel process. The process is particularly useful for hospitals, law enforcement, military, airport security, transportation terminals, financial institutions, and government agencies.","1. An interactive electronic communications process for use in a translation station, comprising: providing a computer system with a printer and dual displays operatively connected by hard wire or wireless to a central processing unit (CPU) for interaction between a host comprising an interviewer and a person comprising an interviewee, said CPU selected from the group consisting of a computer, laptop, desktop computer, portable computer, microprocessor, computer system, iPad, tablet computer, wireless computer, wired computer, netbook, electronic communications device, portable networking device, internet communications device, mobile phone, flip phone, camera phone, clamshell device, radio telephone, cellular phone, smart phone, tablet phone, portable media player (PMP), personal digital assistant (PDA), wireless e-mail device, handheld electronic device, mobile electronic device, network communications device, cloud network communications device, electronic subscriber device, and combinations of any of the preceding;electronically recognizing a person'ss language from a person'ss conversations selected from the group consisting of voice, speech, voice message, on-line conversations, off-line conversations, verbal communications, discussions, conferences, oral responses, replies, electronic communications, and sound;electronically comparing the person'ss language to a host language in the CPU;electronically translating the person'ss language into the host language in the CPU if the person'ss language and host language are not the same;visually displaying and electronically transmitting an electronic animated avatar from the CPU on one of the dual displays with lip synchronized speech in the interviewee'ss language, the avatar being modeled from human beings from the interviewee'ss country;electronically transmitting audible communications in the person'ss language from the CPU to the person, the audible communications selected from the group consisting of inquiries, electronically synchronized speech, questions, interviews, interrogations, sounds, speech, words, dialog, discussions, menu driven communications, electronics, interactive verbal communications, and combination thereof; andproviding an audit trail by printing said electronic translations and said electronic communications in both the host language and the person'ss language on the printer.","19","15/042370","2016-02-12","2016-0170975","2016-06-16","9779088","2017-10-03","David Lynton Jephcott","David Lynton  Jephcott","","","","G06F-0017/289","G06F-0017/289 | A61B-0005/7465 | G06K-0009/00885 | G06K-0009/6201 | G06Q-0010/10 | G06T-0013/00 | G10L-0015/005 | G10L-0015/25 | G10L-0025/63","G06T-013/40","G06T-013/40 | G06F-017/28 | G10L-015/00 | G10L-015/25 | G10L-025/63 | G06K-009/00 | G06K-009/62 | G06T-013/00 | G06Q-010/10 | A61B-005/00","","","","","","4917040004464"
"US","US","P","B2","System and method for providing automatic setup of a remote patient care environment","A system and method for providing automatic setup of a remote patient care environment. Connectivity to a centralized server over a network connection is confirmed. Data reporting for a patient by one or more monitoring devices that are wirelessly connectable is induced through control provided through a user interface. Each of the devices is registered as the device attempts to establish a wireless connection and report the data conditioned on permission for access. Upon granting of the permission for access, the device is wirelessly connected and the data is subsequently received over the wireless connection.","1. A system for providing automatic setup of a remote patient care environment, comprising: a first remote interface to confirm connectivity over a network connection to a centralized server; a configuration module on a patient management device to induce data reporting to the patient management device for a patient by wirelessly connectable monitoring devices through control provided through a user interface, wherein the induced data reporting establishes an initial connection between each of the monitoring devices and the patient management device,wherein the induced data reporting causes the configuration module to execute an automated setup procedure enabling the initial connection and subsequent connections between each of the monitoring devices and the patient management device;a lookup module configured to: register each of the monitoring devices on a list of devices having permission for access as each monitoring device attempts to establish the initial wireless connection and report the data conditioned on permission for access; andlook up each of the monitoring devices on the list of devices having permission for access as each monitoring device attempts to establish subsequent wireless connections and report the data conditioned on permission for access; anda second remote interface to wirelessly connect with each of the monitoring devices upon granting of the permission for access and to subsequently receive the data over the initial wireless connection; andwherein one or more of the monitoring devices are reconfigured by specifying operational parameters to the device.","31","11/516300","2006-09-05","2008-0059239","2008-03-06","9773060","2017-09-26","CARDIAC PACEMAKERS, INC.","Kimberly S.  Gerst | Benjamin L.  Somberg | Bharat K.  Jain | Larry D.  Canady","","","","G06F-0017/30861","G06F-0017/30861 | A61B-0005/0002 | G06F-0019/3418 | G06Q-0050/24 | H04L-0067/04 | H04L-0069/40 | H04W-0012/06 | H04W-0084/18","G06F-019/10","G06F-019/10 | G06F-017/30 | A61B-005/00 | G06F-019/00 | G06Q-050/24 | H04W-012/06 | H04L-029/08 | H04L-029/14 | H04W-084/18","","","","","","4917039003611"
"US","US","P","B1","Automated, data-driven treatment management system for adaptive radiotherapy workflows","Systems and methods can include obtaining computerized physician intent data representing an initial patient care plan; creating a computerized workflow to include a course of multiple radiation therapy sessions; performing instructions on the oncology computer system to generate control parameters for a radiation therapy apparatus to provide the radiation treatment in accordance with the workflow during the course of sessions; obtaining computerized treatment data after initiating the course of sessions; processing the computerized treatment data, using the processor circuit, to determine an indication of delivery or effect of the radiation treatment during the course of sessions based on the initial patient care plan relative to the workflow; using the indication of delivery or effect of the radiation treatment to adapt the patient care plan; and managing the workflow for the patient using the adapted patient care plan as the patient proceeds through a course of sessions.","1. A computer-implemented method of facilitating radiation treatment management using a computerized oncology computer system, the method comprising: obtaining computerized physician intent data representing an initial patient care plan for a patient;creating a computerized workflow for the patient to include a course of multiple radiation therapy sessions;performing a plurality of computer-executable instructions on a processor circuit of the oncology computer system to generate a plurality of control parameters for a radiation therapy apparatus to provide the radiation treatment to a patient in accordance with the workflow during the course of the multiple radiation therapy sessions;obtaining computerized treatment data after initiating the course of the multiple radiation therapy sessions;processing the computerized treatment data, using the processor circuit, to determine an indication of effect on a patient tumor characteristic of the radiation treatment during the course of the multiple radiation therapy sessions based on the initial patient care plan relative to the workflow, including determining, based on the treatment data, an efficacy of the delivery of the radiation treatment during at least one of the multiple radiation therapy sessions, wherein the determining an efficacy of the delivery of the radiation treatment comprises: comparing the treatment data, including patient tumor characteristic data for one or more of the multiple radiation therapy sessions to data, including patient tumor characteristic data from a patient population of other patients that is stored in a database, comparing the treatment data against one or more triggers specified in the physician intent data, and generating a predictive alert and presenting it to a user based on a result of the comparison;using the indication of effect on the patient tumor characteristic of the radiation treatment to adapt the patient care plan; andmanaging the workflow for the patient using the adapted patient care plan as the patient proceeds through a course of multiple radiation therapy sessions.","23","14/524757","2014-10-27","","","9764162","2017-09-19","ELEKTA, INC.","Virgil Matthew  Willcut | Richard Henry  Stark","","","","A61N-0005/1071","A61N-0005/1071 | A61B-0005/743 | A61B-0006/5217 | A61B-0006/5294 | A61N-0005/1048 | A61N-0005/1064 | G06F-0019/30 | G06F-0019/3431 | G06T-0007/0012 | G06T-0007/0014 | G06T-0007/0016 | A61B-0005/4836 | A61N-0005/103 | A61N-0005/1075 | A61N-2005/1041 | A61N-2005/1072 | A61N-2005/1074 | G06Q-0050/24","A61N-005/10","A61N-005/10 | A61B-005/00 | A61B-006/00 | G06F-019/00 | G06Q-050/24 | G06T-007/00","","","","","","4917038001457"
"US","US","P","B2","Determining user response to notifications based on a physiological parameter","In some examples, a technique may include outputting information associated with a notification. The notification may be associated with a notification attribute. The technique may further include determining, by a computing device, that a user has perceived the information associated with the notification; and receiving, by the computing device, an indication of at least one physiological parameter representative of a reaction of the user to the information associated with the notification. In some examples, the technique also includes, responsive to receiving the indication of the at least one physiological parameter representative of the reaction of the user to the information associated with the notification, controlling, by the computing device, at least one notification configuration setting related to outputting information associated with other notifications associated with the notification attribute.","1. A method comprising: outputting, by a display device of a wearable computing device, a visual indication of information associated with a notification, wherein the notification is associated with a notification attribute;while the visual indication is being output: determining, based at least in part on motion data generated by one or more motion sensors of the wearable computing device, that the display device is within a field of view of the user; anddetermining, based at least in part on the motion data, whether the display device remains within the field of view of a user for at least a threshold duration;determining, by the wearable computing device, that the user has perceived the information associated with the notification based at least in part on determining that the display device remains within the field of view of the user for at least the threshold duration;responsive to determining that the user has perceived the information associated with the notification, detecting, by the wearable computing device, at least one physiological parameter representative of a reaction of the user to the information associated with the notification; andcontrolling, by the wearable computing device and based on the at least one physiological parameter, at least one notification configuration setting related to outputting information associated with other notifications associated with the notification attribute.","22","14/244514","2014-04-03","2015-0269009","2015-09-24","9766959","2017-09-19","GOOGLE INC.","Alexander  Faaborg | Gabriel Aaron  Cohen | Austin  Robison","","","","G06F-0009/546","G06F-0009/546 | A61B-0005/024 | A61B-0005/0205 | A61B-0005/0484 | A61B-0005/0533 | A61B-0005/165 | A61B-0005/486 | A61B-0005/6898 | G06F-0003/048 | G06F-0003/162 | H04L-0051/24 | A61M-2230/005 | A61M-2230/04 | G06F-2203/011 | G06F-2209/547","G06F-003/00","G06F-003/00 | G06F-009/44 | G06F-009/46 | G06F-013/00 | G06F-009/54 | G06F-003/16 | H04L-012/58 | A61B-005/0484 | G06F-003/048 | A61B-005/00 | A61B-005/0205 | A61B-005/053 | A61B-005/16 | A61B-005/024","","","","","","4917038004238"
"US","US","P","B2","Head-mounted display head pose and activity estimation","A system may receive head pose indications determined according to movement data from a motion sensor of an optical head-mounted display worn by a vehicle driver, determine, according to the head pose indications, driver activity characteristics indicative of a history of movement of the head of the driver, and send the driver activity characteristics to a driver-aware vehicle system configured to adjust driver notification based on the driver activity characteristics. The system may also receive raw movement data from a motion sensor of an optical head-mounted display worn on a head of a vehicle driver, compute head velocity data based on the raw movement data, compute head displacement data based on the head velocity data, and update head pose indications indicative of head positioning upon determining that the head displacement data exceeds a predetermined threshold displacement.","1. A system comprising: a processor configured to store head pose indications,receive raw movement data from a motion sensor of an optical head-mounted display worn on a head of a vehicle driver,compute head velocity data based on the raw movement data,compute head displacement data based on the head velocity data,update the stored head pose indications indicative of head positioning upon determining that the head displacement data exceeds a predetermined threshold displacement,determine, according to the head pose indications over time, driver activity characteristics indicative of a history of frequency and magnitude of movement of the head of the driver, andsend the driver activity characteristics to a driver-aware vehicle system configured to adjust driver workload notification settings based on driver-action previously observed with respect to the driver activity characteristics.","16","14/478440","2014-09-05","2016-0070966","2016-03-10","9767373","2017-09-19","FORD GLOBAL TECHNOLOGIES, LLC","Hsin-hsiang  Yang | Kwaku O.  Prakah-Asante","","","","G06K-0009/00845","G06K-0009/00845 | A61B-0005/11 | A61B-0005/1116 | B60R-0021/01542 | B60W-0040/08 | G02B-0027/0093 | G02B-0027/017 | G06F-0003/012 | G06K-0009/00335 | B60R-0021/01552 | B60W-2040/0827 | G02B-2027/014 | G02B-2027/0141 | G02B-2027/0178 | G02B-2027/0187","G06K-009/00","G06K-009/00 | G02B-027/01 | A61B-005/11 | B60W-040/08 | B60R-021/015 | G06F-003/01 | G02B-027/00","","","","","","4917038004651"
"US","US","P","B2","Deformable registration of images for image guided radiation therapy","A system and method for developing radiation therapy plans and a system and method for developing a radiation therapy plan to be used in a radiation therapy treatment is disclosed. A radiation therapy plan is developed using a registration of medical images. The registration is based on identifying landmarks located within inner body structures.","1. A radiation therapy planning procedure comprising: a) with one or more processors, segmenting organs and diseased tissue with surface meshes from 4D medical images received from a diagnostic imaging device and from a computer memory;b) identifying surface and internal landmarks located within one or more of the segmented organs and diseased tissue, the surface landmarks including vertices of the surface meshes and the internal landmarks being identified by at least one of: a template matching algorithm;an automated vessel tree extraction algorithm; andan automated marker detection algorithm;c) determining a deformation field based on the identified surface and internal landmarks;d) applying the deformation field to register the 4D medical images;e) developing a radiation therapy plan based on the registered 4D medical images; andf) on a display device, displaying at least one of the 4D medical images, the registered 4D medical images, and the developed radiation therapy plan.","19","12/300339","2007-05-01","2009-0187422","2009-07-23","9757588","2017-09-12","KONINKLIJKE PHILIPS ELECTRONICS N V","Michael  Kaus | Vladimir  Pekar | Rafael  Wiemker","","","","A61N-0005/103","A61N-0005/103 | A61B-0006/466 | G06F-0019/3481 | G06Q-0050/22 | G06T-0007/33 | G06T-0007/38 | A61B-0005/7285 | A61B-0006/03 | A61B-0006/541 | A61B-0008/543 | A61N-0005/1037 | A61N-2005/1061 | G06F-0019/321 | G06F-0019/3437 | G06T-2207/30004","G06Q-010/00","G06Q-010/00 | A61N-005/10 | A61B-006/00 | G06Q-050/22 | G06T-007/33 | G06T-007/38 | A61B-005/00 | A61B-006/03 | A61B-008/00 | G06F-019/00","","","","","","4917037001471"
"US","US","P","B1","Haptic feedback as accessibility mode in home automation systems","Systems and methods for providing haptic feedback in a home automation monitoring system are provided. A method for providing haptic feedback in a home automation system includes receiving an electronic command by a home automation controller, from a haptic feedback remote control device. The home automation controller determines whether the electronic command is associated with a user interface control condition stored in a haptic effects database. If so, the home automation controller accesses the haptic effects database to identify a first haptic feedback effect associated with the determined user interface control condition, and transmits a first haptic feedback command indicating the first haptic feedback effect to the haptic feedback remote control device. A haptic feedback element in the haptic feedback remote control device is then activated to provide the first haptic feedback effect to a user of the haptic feedback remote control device.","1. A method for providing haptic feedback in a home automation system, comprising: storing, in a haptic effects database, information representing a plurality of user interface (UI) control conditions, each of the plurality of UI control conditions being associated with a respective haptic feedback effect;activating a haptic feedback accessibility mode in a home automation controller;transmitting an electronic command from a haptic feedback remote control device to the home automation controller;receiving the electronic command by the home automation controller;determining, by the home automation controller, whether the received electronic command is associated with a UI control condition stored in the haptic effects database;if the received electronic command is determined to be associated with a UI control condition stored in the haptic effects database, then: accessing, by the home automation controller, the haptic effects database to identify a first haptic feedback effect associated with the determined UI control condition;transmitting, by the home automation controller, a first haptic feedback command indicating the first haptic feedback effect to the haptic feedback remote control device; andactivating a haptic feedback element within the haptic feedback remote control device, based on the first haptic feedback command, to provide the first haptic feedback effect to a user of the haptic feedback remote control device.","20","15/204393","2016-07-07","","","9760174","2017-09-12","ECHOSTAR TECHNOLOGIES INTERNATIONAL CORPORATION","Ellen  Letendre","","","","G06F-0003/016","G06F-0003/016 | G06F-0009/4443 | G08B-0006/00 | G09B-0021/003 | G09B-0021/009 | A61B-0005/0022 | A61B-0005/1112 | G06F-0003/013 | G07C-0009/00182","G06F-003/01","G06F-003/01 | G08B-006/00 | G09B-021/00 | G06F-009/44 | A61B-005/11 | G07C-009/00 | A61B-005/00","","","","","","4917037004045"
"US","US","P","B2","Enabling an IM user to navigate a virtual world","Systems and methods are provided for enabling communications between users of an instant messaging application and a virtual world environment. In accordance with one implementation, a method is provided that includes operations performed by one or more processors, including enabling a first user to navigate the virtual world environment by controlling an avatar representing the first user. The method also includes capturing a first paralinguistic indicator made by the first user, the first paralinguistic indicator configured for communications in the virtual world environment. In addition, the method includes translating the first paralinguistic indicator into a message configured for text-based communications in the instant messaging application, the message comprising at least one of a text description of the first paralinguistic indicator and a second paralinguistic indicator configured for communications in the instant messaging application. The method further includes providing the message to a second user.","1. A computer-implemented method for enabling communications between users of a first environment and a second environment, the method comprising the following operations performed by at least one processor: enabling a first user to navigate the first environment by controlling an avatar representing the first user;capturing a first paralinguistic indicator made by the first user, the first paralinguistic indicator representing a first emotion of a first complexity compatible with the first environment;translating the first paralinguistic indicator into a second paralinguistic indicator different from the first paralinguistic, wherein the second paralinguistic indicator is communicated to a second user of the second environment and represents a second emotion of a second complexity different from the first complexity and is compatible with the second environment;wherein at least one of the first complexity and the second complexity is defined as the co-occurrence of two or more emotions.","20","14/270744","2014-05-06","2014-0330550","2014-11-06","9760568","2017-09-12","OATH INC.","David S.  Bill","","","","G06F-0017/289","G06F-0017/289 | G06Q-0010/10 | G06T-0019/006 | H04L-0051/046 | A61B-0005/744 | A63F-2300/5553 | A63F-2300/572 | A63F-2300/575 | G06N-0003/006 | G06Q-0030/02 | G06Q-0050/01 | H04N-0005/44543 | H04N-0021/25883 | H04N-0021/25891 | H04N-0021/44222 | H04N-0021/4532 | H04N-0021/4788 | H04N-0021/6125 | H04N-0021/6175 | H04N-0021/6547 | H04N-0021/6582 | H04N-0021/84","G06F-017/28","G06F-017/28 | G06Q-010/10 | G06T-019/00 | H04L-012/58 | G06Q-050/00 | A61B-005/00 | H04N-021/4788 | H04N-021/84 | H04N-021/442 | H04N-021/61 | H04N-021/6547 | H04N-021/658 | H04N-005/445 | H04N-021/45 | H04N-021/258 | G06N-003/00 | G06Q-030/02","","","","","","4917037004437"
"US","US","P","B1","Rating applications based on emotional states","Method and apparatus for rating applications. Execution of an application on a computing device is monitored to determine usage information for a user. Embodiments capture a plurality of images and for each of the plurality of images, extract, from the respective image, a set of user facial features and determine an user emotional state corresponding to the respective set of user facial features by applying a model correlating a set of predefined emotional states with corresponding predefined facial features. A trend of user emotional states across a plurality of executions of the application on the computing device is determined. Embodiments calculate a rating for the application based on the usage information, the user emotional states, and the trend of the user emotional states. The rating is sent to a server over a network connection for use in an aggregate rating of the application.","1. A computer-implemented method to rate applications based on weighted emotional states, the computer-implemented method comprising: monitoring execution of an application on a computing device to determine usage information for a user;capturing, via a user-facing camera of the computing device, a plurality of images;for each of the plurality of images, using one or more computer processors of the computing device: extracting, from the respective image, a set of user facial features; anddetermining an user emotional state corresponding to the respective set of user facial features by applying a facial-emotional model correlating a set of predefined emotional states with corresponding predefined facial features;determining a trend of user emotional states across a plurality of executions of the application on the computing device;calculating a rating for the application based on: (i) the usage information; (ii) the trend of user emotional states; and (iii) the user emotional states weighted by at least one of: (A) a demographic factor comprising a specified age group to which the user belongs and (B) an expressiveness factor comprising a variance of emotional expression of the user; andsending, via a network connection, the rating to a server configured to determine an aggregate rating of the application.","20","15/276967","2016-09-27","","","9760767","2017-09-12","INTERNATIONAL BUSINESS MACHINES CORPORATION","Simone  Bonazzoli | Marco  Borgianni | Claudio  Falcone | Alessio  Fioravanti | Giuseppe  Longobardi | Silvano  Lutri | Luigi  Presti | Paolo  Salerno | Alessandro  Tomasi | Francesca  Ziantoni","","","","G06K-0009/00315","G06K-0009/00315 | A61B-0005/0077 | A61B-0005/165 | G06F-0017/3028 | G06K-0009/00255 | G06K-0009/00268 | G06K-0009/6212 | H04L-0067/42 | A61B-2503/12","G06K-009/00","G06K-009/00 | H04L-029/06 | G06F-017/30 | G06K-009/62 | A61B-005/00 | A61B-005/16","","","","","","4917037004636"
"US","US","P","B2","System and method for reliable and scalable health monitoring","A health-monitoring system and method are disclosed. The health-monitoring system and method comprise a sensory system and a sensory to front-end communication (SFCM) protocol coupled to the sensory system. The health-monitoring system and method include a front-end system coupled to the sensory system and a front-end to back-end communication (FBCM) protocol coupled to the front-end system. The health-monitoring system and method include a back-end system. The SFCM protocol communicates with the front-end system using a first state awareness link and the FBCM protocol communicates with the back-end system using a second state awareness link.","1. A health-monitoring system comprising: a sensory system, wherein the sensory system includes at least one sensor that includes a system on-a-chip hardware (SOC HW), a hardware abstraction layer device driver, and at least one sensory communication (SCM) task, and wherein the at least one SCM task is directly coupled to a sensory to front-end communication (SFCM) protocol;a front-end system coupled to the sensory system via the SFCM protocol, wherein the front-end system includes at least one smart relay device that includes a user interface (UI), a device driver, at least one diagnostic layer, and at least one front-end communication (FCM) task, wherein the at least one FCM task is directly coupled to both the SFCM protocol and a front-end to back-end communication (FBCM) protocol, and wherein the SFCM protocol is only coupled to the at least one SCM and FCM tasks; anda back-end system coupled to the front-end system via the FBCM protocol, wherein the back-end system includes a server that comprises a hardware (HW) platform, a communication (COMM) channel driver, an application programming interface (API), a user interface (UI), and a back-end communication (BCM) process, wherein the BCM process is directly coupled to the FBCM protocol, wherein the FBCM protocol is only coupled to the at least one FCM task and the BCM process, andwherein the diagnostic layer comprises any of simulating a device driver protocol, simulating the UI, simulating the at least one FCM task that includes communicating with the SCM task within the sensory system and communicating with the BCM process within the back-end system, and simulating error injection.","11","13/672119","2012-11-08","2013-0099937","2013-04-25","9762673","2017-09-12","Vital Connect, Inc.","Saeed  Azimi","","","","H04L-0067/12","H04L-0067/12 | A61B-0005/1113 | G06F-0017/3056 | G06F-0019/3412 | H04L-0067/142 | A61B-0005/0002 | A61B-0005/0015 | A61B-0005/0024 | A61B-0005/6833 | A61B-2560/045 | A61B-2560/0412 | G06F-0019/34 | G06F-0019/3418","H04L-029/08","H04L-029/08 | G06F-017/30 | G06F-019/00 | A61B-005/00 | A61B-005/11","","","","","","4917037006531"
"US","US","P","B2","Active acoustic pressure mapping system","Method and apparatus for determining that a pressure field is applied on a structure. A plurality of acoustic waves are generated within the structure using at least one wave generator and a plurality of measurements of the acoustic waves is taken using at least one wave sensor. A pressure field applied to a surface of the structure is determined by processing at least two of the plurality of measurements. The wave generator and the wave sensor may be piezoelectric elements, which may alternate between acting as the wave generator and the wave sensor. Processing the measurements may comprise obtaining a differential measurement value and comparing the value to a threshold. Determining that the pressure field is applied may comprise processing the measurements using a model based on acoustic wave propagation or experimental results. The processing may provide a mapping of the pressure field of an object on the structure.","1. A method for determining that a pressure field is applied on a structure, the method comprising: generating a plurality of acoustic waves within the structure using at least one wave generator;taking a plurality of measurements of the plurality of acoustic waves using at least one wave sensor;determining a model, specific to the structure, of acoustic wave propagation within the structure from the plurality of measurements by performing: a free-calibration while the structure is free of external pressure; anda loaded-calibration while an object of known characteristics is placed at a known location on the structure;subsequently to the determination of the model, determining that a pressure field is applied to a surface of the structure by processing at least two of the plurality of measurements;correlating the at least two measurements with the model of acoustic wave propagation within the structure; andproviding a two-dimensional mapping of the pressure field on the surface of the structure from the correlated measurements.","36","14/419257","2013-08-01","2015-0185898","2015-07-02","9750451","2017-09-05","SOCPRA SCIENCES ET G?NIE S.E.C.","Patrice  Masson | Nicolas  Quaegebeur | Pierre-Claude  Ostiguy | Nicolas  Beaudet | Philippe  Sarret","","","","A61B-0005/4561","A61B-0005/4561 | A61B-0005/1036 | G06F-0003/0436 | G06K-0009/00006 | A61B-2560/0223","A61B-005/00","A61B-005/00 | A61B-005/103 | G06F-003/043 | G06K-009/00","","","","","","4917036000926"
"US","US","P","B2","Terminal and control method thereof","A terminal wearable by a user and a control method thereof are provided. The terminal includes: a body configured to wrap at least one region of a wrist and detachably formed; a sensing unit disposed in one surface of the body and configured to sense a movement of at least one of tendons passing through the wrist and the wrist; and a controller configured to generate a control signal for controlling an external device to execute a function previously matched to the sensed movement of the at least one of the tendons and the wrist.","1. A terminal comprising: a body configured to detachably wrap around a user'ss wrist;a flexible display unit that is bowable and positioned on a first region of the body;a sensing unit positioned on a surface of the body and configured to sense a direction in which the user'ss wrist faces and to sense movements of tendons passing through the wrist, the movements caused by movements of the user'ss fingers;a first camera and a second camera located at different positions of the body and facing in different directions; anda controller configured to:select at least the first camera or the second camera based on the sensed direction;cause the flexible display unit to display an image received from the selected camera, the image displayed on a region of the flexible display unit based on the sensed direction;execute a first function related to the image when a shape formed by the sensed movements matches any of a plurality of predetermined shapes;determine a position where the display unit wraps around the wrist by determining an area where the sensing unit and the wrist are in contact with each other;control a size of a specific display region of the display unit based on the determined position; andadjust a sensitivity of the sensing unit based on the determined position.","12","13/950158","2013-07-24","2014-0028546","2014-01-30","9753543","2017-09-05","LG ELECTRONICS INC.","Taeyoung  Jeon | Raehoon  Kang | Inyong  Hwang | Seungbum  Hong | Seungjin  Jang | Sungwoo  Kim | Gyuseog  Hong","10-2012-0082721 | 10-2013-0028204","KR | KR","2012-07-27 | 2013-03-15","G06F-0003/017","G06F-0003/017 | A61B-0005/11 | A61B-0005/681 | A61B-0005/6824 | G06F-0001/163 | G06F-0001/1652 | G06F-0003/011 | G06F-0003/013 | G06F-0003/014 | G06F-0003/015 | G06F-0003/0304 | G06F-0003/04842 | G06F-0003/04845 | G06F-0009/4446 | A61B-0005/721 | G09G-2380/02","G06F-003/01","G06F-003/01 | A61B-005/00 | A61B-005/11 | G06F-003/03 | G06F-003/0484 | G06F-009/44 | G06F-001/16","","","","","","4917036004003"
"US","US","P","B2","Display relative motion compensation","Embodiments that relate to displaying an image via a display device worn on a head of a user are disclosed. In one example embodiment, an image is displayed at an initial registration position with respect to a user's eye. Composite motion data is received from one or more sensors, with the composite motion data comprising a head motion component and a relative motion component which is relative motion between the head and the display device. The composite motion data is filtered to remove the head motion component and yield the relative motion component. Using the relative motion component, the initial registration position of the image is adjusted to an adjusted registration position that compensates for the relative motion component. The image is then displayed at the adjusted registration position.","1. A method for displaying an image via a display device worn on a head of a user, the display device including one or more sensors, the method comprising: displaying the image at an initial registration position with respect to an eye of the user;receiving composite motion data from the one or more sensors, the composite motion data comprising a head motion component and a relative motion component which is relative motion between the head and the display device;filtering the composite motion data to remove the head motion component and yield the relative motion component;using the relative motion component, adjusting the initial registration position of the image to an adjusted registration position with respect to the eye of the user that compensates for the relative motion component;displaying the image at the adjusted registration position by projecting the image onto a cornea of the eye;at a stabilization frequency, performing subsequent adjustments of image registration positions using relative motion components;displaying the image at adjusted registration positions corresponding to the subsequent adjustments of the image registration positions;at a centering frequency that is slower than the stabilization frequency, performing centering adjustments of image registration positions that progressively locate the image closer to a reference location on the cornea; anddisplaying the image at adjusted registration positions corresponding to the centering adjustments of the image registration positions.","18","14/228147","2014-03-27","2015-0279102","2015-10-01","9754415","2017-09-05","MICROSOFT TECHNOLOGY LICENSING, LLC","Rod G.  Fleck | Marshall T.  DePue | David D.  Bohn","","","","G06T-0019/006","G06T-0019/006 | A61B-0005/1121 | A61B-0005/7445 | G02B-0027/0172 | G02B-0027/0179 | G06F-0003/011 | G06F-0003/012 | G06K-0009/00335 | G06T-0007/246 | G06T-0007/579 | G09G-0003/36 | H04N-0013/0014 | H04N-0013/0429 | G02B-2027/0154 | G02B-2027/0178 | G02B-2027/0187 | G06T-2207/20221 | G06T-2219/016 | H04N-2013/0085","G06T-019/00","G06T-019/00 | A61B-005/11 | A61B-005/00 | G02B-027/01 | G06F-003/01 | G06K-009/00 | H04N-013/00 | H04N-013/04 | G09G-003/36 | G06T-007/579 | G06T-007/246","","","","","","4917036004867"
"US","US","P","B2","Quantification of brain vulnerability","The invention relates to a medical data processing method for determining a vulnerability field of a brain of a patient, the steps of the method being constituted to be executed by a computer and comprising: a) acquiring a nerve-indicating dataset comprising information about the brain of the patient suitable for identifying neural fibers in the brain of the patient; b) determining nodes within the brain preferably being neuron-rich grey matter parts of the brain; c) determining the axonal linkage of the nodes based on the nerve-indicating dataset to obtain edges connecting the nodes, the nodes and edges constituting a connectivity graph; d) determining a weight for each of the edges depending on centrality graph theoretical statistical measure of the respective edge in the connectivity graph; e) determining, for each of the edges, which voxels in a dataset of the brain of the patient belong to the edges or are passed by the edges and assigning or adding the determined weight of the respective edges to all of the voxels belonging to the respective edge to obtain a weighted voxel-based dataset of the brain of the patient defining the vulnerability field of the brain.","1. A medical system, comprising: a medical imaging device for generating medical image data utilized for generating a nerve-indicating dataset comprising information about a brain of a patient suitable for identifying neural fibres in the brain of the patient;at least one computer operably coupled to the medical imaging device and having at least one processor and memory with instructions, the instructions, when executed on the computer, configuring the computer to determine a weight of a trajectory between a starting point and a target within the brain of the patient using a vulnerability field of the brain, by:acquiring, at the at least one processor, the medical image data and determining, by the at least one processor and based on the medical image data, the nerve-indicating dataset;determining, by the at least one processor, a plurality of nodes within the brain;determining, by the at least one processor, axonal linkage of the nodes based on the nerve-indicating dataset to obtain edges connecting the nodes, the nodes and edges constituting a connectivity graph;determining, by the at least one processor, a weight for each of the edges depending on a statistical measure of the respective edge in the connectivity graph;determining, by the at least one processor and for each of the edges, which of a plurality of voxels in a dataset of the brain of the patient belong to the edges or are passed by the edges and assigning, by the at least one processor, or adding, by the at least one processor, the determined weight of the respective edges to all of the voxels belonging to the respective edge to obtain a weighted voxel-based dataset of the brain of the patient defining the vulnerability field of the brain;acquiring, at the at least one processor, a number of potential starting points of at least one trajectory between each of the starting points and a target in the brain;determining, by the at least one processor, and for each of the starting points, the at least one trajectory connecting the respective starting point with the target, the at least one trajectory passing through a number of respective adjacent voxels of the weighted voxel-based dataset;adding, by the at least one processor, the weights of all voxels being passed by the respective trajectory to obtain a respective weighted trajectory.","16","15/034077","2013-11-05","2016-0284082","2016-09-29","9741114","2017-08-22","BRAINLAB AG","Balint  Varkuti","","","","G06T-0007/0012","G06T-0007/0012 | A61B-0005/055 | A61B-0005/4064 | A61B-0006/032 | A61B-0006/037 | A61B-0006/501 | A61B-0008/0808 | A61B-0008/488 | G06F-0017/16 | G06F-0019/3437 | G06T-0017/005 | A61B-0006/481 | G06F-0019/321 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/10092 | G06T-2207/10104 | G06T-2207/30016 | G06T-2207/30241 | G06T-2210/41","G06K-009/00","G06K-009/00 | G06T-007/00 | G06T-017/00 | A61B-006/03 | A61B-005/055 | A61B-005/00 | A61B-008/08 | G06F-017/16 | A61B-005/04 | G06F-019/00 | A61B-006/00","","","","","","4917034004776"
"US","US","P","B2","Neuropsychological spatiotemporal pattern recognition","Systems and methods for identifying and analyzing neuropsychological flow patterns, include creating a knowledge base of neuropsychological flow patterns. The knowledge base is formed by obtaining signals from multiple research groups for particular behavioral processes, localizing sources of activity participating in the particular behavioral processes, identifying sets of patterns of brain activity for the behavioral processes and neuropsychologically analyzing the localized sources and the identified patterns for each of the research groups. The neuropsychological analysis includes identifying all possible pathways for the identified sets of patterns, ranking the possible pathways based on likelihood for the particular behavioral process and reducing the number of ranked possible pathways based on additional constraints. A system for comparison of obtained signals from an individual to the created knowledge base is provided. These obtained signals are then used to further update the existing knowledge base.","1. A system for brain activity analysis, the system comprising: an input module for receiving EEG and/or MEG signals from a subject;a processor, configured for identifying brain activity patterns in said signals using a counting method or method of calculating statistical significances of pairs, for identifying a plurality of candidate pathways for said brain activity patters, for defining flow patterns among functional brain regions based on candidate pathways, for accessing a flow pattern database having previously determined flow patterns, and for comparing said flow pattern to said previously determined flow patterns of said database; andan output module for presenting results of said comparison.","18","14/703913","2015-05-05","2015-0305685","2015-10-29","9730642","2017-08-15","ELMINDA LTD.","Goded  Shahaf | Amir B.  Geva","","","","A61B-0005/7246","A61B-0005/7246 | A61B-0005/04008 | A61B-0005/04012 | A61B-0005/0476 | A61B-0005/7275 | G06F-0017/18 | G06F-0019/3437 | G06K-0009/00543 | G06K-0009/6224","A61B-005/00","A61B-005/00 | G06K-009/00 | G06K-009/62 | G06F-017/18 | G06F-019/00 | A61B-005/04 | A61B-005/0476","","","","","","4917033000940"
"US","US","P","B2","Unmanned device interaction methods and systems","Structures and protocols are presented for configuring an unmanned aerial device to participate in the performance of tasks, for using data resulting from such a configuration or performance, or for facilitating other interactions with such devices.","1. A system comprising: a wall-mountable unmanned aerial device mooring structure including at least a wall-mountable base including at least one coil; andan unmanned aerial device including at least one optical sensor configured at least for sensing optical image data from a vicinity of the wall-mountable unmanned aerial device mooring structure when the unmanned aerial device is positioned on the wall-mountable base, and at least one inductive charging coil configured to align with the at least one coil of the wall-mountable base for contactless charging of the unmanned aerial device, wherein at least one of the wall-mountable base or the unmanned aerial device include at leastcircuitry configured for controlling the unmanned aerial device to launch responsive to an application of at least one recognition criterion to the optical image data sensed from the vicinity of the wall-mountable unmanned aerial device mooring structure; andcircuitry configured for causing the unmanned aerial device to perform at least one task following launch of the unmanned aerial device.","22","13/601096","2012-08-31","2014-0025229","2014-01-23","9733644","2017-08-15","ELWHA LLC","Royce A.  Levien | Richard T.  Lord | Robert W.  Lord | Mark A.  Malamud | John D.  Rinaldo, Jr. | Lowell L.  Wood, Jr.","","","","G05D-0001/0202","G05D-0001/0202 | A63H-0027/12 | G05B-0019/00 | G05D-0001/005 | G05D-0001/0011 | G05D-0001/0027 | G05D-0001/102 | G06Q-0010/08 | A61M-0005/002 | B64C-0039/02 | G05D-2201/0207","G05D-001/00","G05D-001/00 | G05D-003/00 | G06F-007/00 | G06F-017/00 | G05D-001/02 | G05B-019/00 | A63H-027/00 | G05D-001/10 | G06Q-010/08 | B64C-039/02 | A61M-005/00","","","","","","4917033003928"
"US","US","P","B2","System and method for association of patient care devices to a patient","A system and method for collecting, communicating, displaying, and/or analyzing data from multiple medical devices is disclosed. The system includes a local data collection module and a number of medical device adapters. The medical device adapters are coupled to respective medical devices via hardwired connections to receive data from the respective medical devices. The medical device adapters wirelessly transmit the data to the local data collection module. The local data collection module communicates the data received from the medical device adapters to an Electronic Medical Records (EMR) system for automatic entry of at least some of the data in the electronic medical record of a patient associated with the medical devices.","1. A method of associating at least one patient care device in a room of a healthcare facility with a first patient in the room which also has a second patient in the room, the method comprising coupling an input port of a medical device adapter to an output port of the patient care device, the medical device adapter using a low power protocol to wirelessly transmit patient data received from the patient care device, the medical device adapter being battery powered by an onboard battery, the medical device adapter enhancing battery life by using power from the patient care device if power is available via the output port of the patient care device,receiving at an association computer wireless location data transmitted wirelessly from the patient care device via the medical device adapter and received by first and second wireless receivers located in the room and positioned near first and second hospital beds assigned to the first and second patients, respectively, the association computer being operable to determine that the patient care device should be associated with the first patient and not with the second patient based upon association rules programming executed by the association computer including rules regarding resolving ambiguities concerning whether the patient care device is to be associated with the first patient or the second patient based on proximity of the patient care device to the first wireless receiver and to the second wireless receiver,prompting a caregiver with a graphical display in the room to provide an input on the graphical display to confirm the association of the patient care device to the first patient, andreceiving the input on the graphical display from the caregiver to confirm the association of the patient care device to the first patient, wherein the patient care device comprises one or more of the following: life support equipment, a ventilator, vital signs monitoring equipment, an electrocardiograph (EKG), an electroencephalograph (EEG), a heart rate monitor, a blood pressure monitor, a blood oxygen saturation monitor, an intravenous (IV) pump, a drug infusion pump, an insulin pump, or a passive motion device.","20","14/305013","2014-06-16","2014-0297310","2014-10-02","9734293","2017-08-15","Hill-Rom Services, Inc.","Williams F.  Collins, Jr. | Michael D.  Gallup","","","","G06F-0019/3406","G06F-0019/3406 | A61B-0005/002 | G06F-0019/327 | G06F-0019/3418 | G06Q-0050/22 | G06Q-0050/24 | H04L-0067/12 | H04L-0067/125 | H04L-0069/18 | A61B-0005/021 | A61B-0005/0205 | A61B-2017/00221 | A61B-2034/256 | G06F-0019/322","G06Q-050/00","G06Q-050/00 | G06F-019/00 | G06Q-050/22 | G06Q-050/24 | H04L-029/08 | H04L-029/06 | A61B-005/00 | A61B-005/0205 | A61B-005/021 | A61B-017/00 | A61B-034/00","","","","","","4917033004573"
"US","US","P","B2","Wearable terminal","There is disclosed a wearable terminal including a main body, a main board provided in the main body, a first touch pad provided in a rear surface of the main body, a flexible board configured to connect the main body and the first touch pad to each other, a band coupled to the main body, wound around a user's wrist to secure the main body to the user's body part, a second touch pad provided in the other surface of one surface contacting with the user's body part when the user wears the band, a flexible board having one end connected to the second touch pad and the other end connected to the main board, and a controller configured to extract an electrocardiogram by measuring a difference of electric potentials of body muscles sensed from the first touch pad and the second touch pad.","1. A wearable terminal comprising: a main body;a main board in the main body;a first touch pad coupled to a rear surface of the main body;a band coupled to the main body, the band configured to secure the wearable terminal to the user;a second touch pad positioned such that a user can touch the second touch pad when the wearable terminal is secured to the user'ss body;a conductive board connected to the second touch pad and to the main board; anda controller configured to measure a difference in electric potentials between the first touch pad and the second touch pad, and based on the measured difference in electric potentials, generate an electrocardiogram,wherein the band comprises:a lower band configured to contact the user'ss body; andan upper band coupled to the lower band,wherein the conductive board is made of a flexible material and mounted between the upper band and the lower band, andwherein the second touch pad is positioned on the upper band and connected to the flexible conductive board through a hole formed in the upper band.","19","14/717720","2015-05-20","2016-0063232","2016-03-03","9734315","2017-08-15","LG ELECTRONICS INC.","Jaehyuk  Seol | Wonseok  Joo | Chisang  You | Soyeon  Lee | Seungwoo  Ryu | Hosang  Lee | Hyengcheul  Choi | Yohan  Lim | Yuntaek  Jung","10-2014-0115248 | 10-2014-0124782","KR | KR","2014-09-01 | 2014-09-19","G06F-0021/32","G06F-0021/32 | A61B-0005/0245 | A61B-0005/04525 | A61B-0005/117 | A61B-0005/681 | G04G-0009/0064 | G04G-0021/08 | G04R-0060/04 | G06F-0003/038 | G06F-0003/03547 | G06K-0009/00885 | H01Q-0001/273 | H01Q-0007/00 | H01Q-0021/28 | A61B-0005/742 | H01Q-0001/38","G06F-021/32","G06F-021/32 | G06F-003/038 | G06F-003/0354 | A61B-005/0245 | A61B-005/0452 | A61B-005/117 | G06K-009/00 | G04R-060/04 | H01Q-001/27 | H01Q-021/28 | G04G-009/00 | G04G-021/08 | H01Q-007/00 | A61B-005/00 | H01Q-001/38","","","","","","4917033004594"
"US","US","P","B2","Real-time multi-channel EEG signal processor based on on-line recursive independent component analysis","A real-time multi-channel EEG signal processor based on an on-line recursive independent component analysis is provided. A whitening unit generates covariance matrix by computing covariance according to a received sampling signal. A covariance matrix generates a whitening matrix by a computation of an inverse square root matrix calculation unit. An ORICA calculation unit computes the sampling signal and the whitening matrix to obtain a post-whitening sampling signal. The post-whitening sampling signal and an unmixing matrix implement an independent component analysis computation to obtain an independent component data. An ORICA training unit implements training of the unmixing matrix according to the independent component data to generate a new unmixing matrix. The ORICA calculation unit may use the new unmixing matrix to implement an independent component analysis computation. Hardware complexity and power consumption can be reduced by sharing registers and arithmetic calculation units.","1. A real-time multi-channel EEG signal processor based on an on-line recursive independent component analysis (ORICA), the real-time multi-channel EEG signal processor comprising: an inverse square root matrix calculation unit for providing a computation of eigen value, eigen vector and inverse square root matrix;a whitening unit coupled to the inverse square root matrix calculation unit for covariance computation of a sampling signal to generate a covariance matrix, wherein the covariance matrix generates a whitening matrix based on the computation of the inverse square root matrix calculation unit;an ORICA calculation unit coupled to the inverse square root matrix calculation unit and the whitening unit for computing the sampling signal and the whitening matrix to obtain a post-whitening sampling signal, wherein an independent component analysis computation of the post-whitening sampling signal and a predetermined unmixing matrix is performed to obtain independent component data;an ORICA training unit coupled to the inverse square root matrix calculation unit and the ORICA calculation unit for training the unmixing matrix according to the independent component data to obtain an inverse matrix of the unmixing matrix by the computation of the inverse square root matrix calculation unit, and computing the unmixing matrix and the inverse matrix of the unmixing matrix to generate a new unmixing matrix, wherein the new unmixing matrix is used for the ORICA calculation unit to perform a next independent component analysis computation of a next post-whitening sampling signal and the new unmixing matrix, so as to obtain next independent component data; anda memory unit coupled to the inverse square root matrix calculation unit, the whitening unit, the ORICA calculation unit and the ORICA training unit for storing the sampling signal, the whitening matrix and the unmixing matrix, the memory unit configured to temporarily store data generated by the inverse square root matrix calculation unit, the whitening unit, the ORICA calculation unit and the ORICA training unit so as to store the data in an ordered manner and enable memory sharing between the inverse square root matrix calculation unit, the whitening unit, the ORICA calculation unit and the ORICA training unit,wherein the ORICA training unit further comprises:a nonlinearity module for computing the independent component data to obtain a non-linear transfer function;a kurtosis estimation module for identifying the independent component data to be a super Gaussian signal or sub-Gaussian signal and generating a kurtosis value;a multiplexer coupled to the nonlinearity module and the kurtosis estimation module for obtaining a nonlinear transfer function of independent component distribution data in accordance with the Gaussian signal or the sub-Gaussian signal and the kurtosis value;a learning rate module for computing a learning rate determining convergence and steady state performance of the unmixing matrix during training; anda weight training module for implementing an iterative computation using the independent component data, the nonlinear transfer function of the independent component distribution data, the learning rate and the unmixing matrix, so as to generate the next unmixing matrix.","8","14/093330","2013-11-29","2014-0350864","2014-11-27","9724005","2017-08-08","NATIONAL CHIAO TUNG UNIVERSITY","Wai-Chi  Fang | Wei-Yeh  Shih | Jui-Chieh  Liao | Kuan-Ju  Huang | Chiu-Kuo  Chen | Gert  Cauwenberghs | Tzyy-Ping  Jung","102118193 U","TW","2013-05-23","A61B-0005/04012","A61B-0005/04012 | A61B-0005/0476 | G06F-0017/18 | G06K-0009/624","A61B-005/0476","A61B-005/0476 | G06F-017/16 | A61B-005/04 | G06F-017/18 | G06K-009/62","","","","","","4917032000890"
"US","US","P","B2","Motion information processing apparatus","A motion information processing apparatus according to an embodiment includes processing circuitry. The processing circuitry obtains pieces of motion information of a subject acquired from mutually-different positions with respect to the subject performing a predetermined motion. The processing circuitry calculates association information used for bringing the pieces of motion information obtained into association with one another. The processing circuitry exercises control so as to cause an output circuitry to output such output information in which the pieces of motion information are kept in association with one another on the basis of the association information calculated.","1. A motion information processing apparatus, comprising: processing circuitry configured to obtain first motion information of a subject performing a predetermined motion acquired by a first sensor and second motion information of the subject performing the predetermined motion acquired by a second sensor arranged at a position different from a position of the first sensor,calculate association information for synchronizing the obtained first motion information and the obtained second motion information based on information included in each of the first motion information and the second motion information, andgenerate output information by synchronizing the first motion information and the second motion information based on the calculated association information, and exercise control so as to cause output circuitry to output the output information.","23","14/804493","2015-07-21","2015-0324637","2015-11-12","9727779","2017-08-08","TOSHIBA MEDICAL SYSTEMS CORPORATION","Kazuki  Utsunomiya | Kousuke  Sakaue | Satoshi  Ikeda | Hayato  Konishi","2013-010524 | 2013-010547 | 2013-223470","JP | JP | JP","2013-01-23 | 2013-01-23 | 2013-10-28","G06K-0009/00342","G06K-0009/00342 | A61B-0005/11 | G06K-0009/00348 | G06Q-0010/06 | G06Q-0050/24 | G06T-0007/248 | G06T-0007/292 | A61B-2576/00 | G06T-2207/10024 | G06T-2207/30196","G06K-009/00","G06K-009/00 | A61B-005/11 | G06Q-050/24 | G06Q-010/06 | G06T-007/246 | G06T-007/292 | H04N-007/18","","","","","","4917032004645"
"US","US","P","B2","Secure pairing of eHealth devices and authentication of data using a gateway device having secured area","A gateway device, system, and method are presented for securely obtaining health information from a personal medical device. The system installs a gateway application in a gateway device. The gateway application executes in a secure area of the gateway device. The system establishes first secure communications with the gateway application and receives aggregated personal medical device information from the gateway application. The gateway application establishes second secure communications with a personal medical device and receives information from the personal medical device via the second secure communications. The gateway application aggregates information from the personal medical device and send the aggregated information to the system via the first secure communications.","1. A gateway device comprising: a memory;a communications interface configured to receive a gateway application from a relying system (RS): anda hardware processor coupled to the memory and the communications interface and configured to execute the gateway application in a secure area of the hardware processor and the memory, wherein the gateway application is configured to cause the hardware processor to:establish a first secure communications link with a personal medical device (PMD) by exchanging one or more security certificates with the PMD, wherein the one or more security certificates includes a self-signed certificate;establish a second secure communications with the RS;receive information from the PMD via the first secure communications link; andsend aggregated received information to the RS via the second secure communications link.","20","14/832763","2015-08-21","2017-0054563","2017-02-23","9729330","2017-08-08","SAMSUNG ELECTRONICS CO., LTD.","Sanjeev  Verma","","","","H04L-0009/3263","H04L-0009/3263 | A61B-0005/0022 | G06F-0008/65 | G06F-0019/3418 | G06F-0021/44 | G06F-0021/6245 | G06Q-0050/24 | H04L-0063/0428 | H04L-0063/08 | H04L-0063/168 | H04L-0067/06 | H04W-0012/06 | H04L-0067/12 | H04W-0012/04","H04L-029/06","H04L-029/06 | H04L-009/32 | A61B-005/00 | G06F-019/00 | G06F-021/44 | G06F-021/62 | G06Q-050/24 | H04W-012/06 | G06F-009/445 | H04W-012/04 | H04L-029/08","","","","","","4917032006189"
"US","US","P","B2","Health promotion system using wireless and ropeless jump rope apparatus","There is provided a health promotion system using a wireless and ropeless jump rope. When a plurality of users use a plurality of wireless and ropeless jump rope apparatuses, each wireless and ropeless jump rope apparatus transmits each user's weight, the number of jumps made by the user and the time of using the wireless and ropeless jump rope to an external health promotion server. The health promotion server analyzes the user's weight, the number of jumps made by the user and the time of using the wireless and ropeless jump rope as transmitted and provides an instructor with the information of the number of jumps made by the user and the analyzed health-relevant data. The instructor who receives the information of the number of jumps made by the user and the analyzed health-relevant data is able to improve the health of the user.","1. A health promotion system using a wireless and ropeless jump rope comprising: a wireless and ropeless jump rope apparatus with a handle unit and a floor mat unit, a health promotion server configured to communicate with the wireless and ropeless jump rope apparatus, and a user terminal to access the health promotion server, the handle unit comprising: a pair of handle bodies, where each handle body has a weight and a string where the string connects the handle body to the weight,an acceleration sensor and an angular velocity sensor included in the weight as a rotation sensing sensor module to sense the rotation of the weight of each handle body,an incline sensor further installed in an upper end of the handle body where the string is fixed,to detect an incline of the handle unit, anda handle communication module to transmit an output of the rotation sensing sensor module and an output of the incline sensor to the floor mat unit,the floor mat unit comprising: a weight sensing sensor module to sense a user'ss current weight when the user is positioned on the floor mat unit,a jump sensing sensor module to sense the user'ss jumps when the user jumps on the floor mat unit,a mat communication module to receive the output of the rotation sensing sensor module and the output of the incline sensor transmitted from the handle communication modulea mat controller to count a number of jumps made by the user of the wireless and ropeless jump rope, by using the outputs of the rotation sensing sensor module and incline sensor received through the mat communication module and the output of the jump sensing sensor module of the floor mat unit, andan external communication module to transmit the user'ss weight measured in the weight sensing sensor module and the number of the jumps counted in the mat controller, andthe health promotion server comprising: a user database to store information including the user'ss height and an initial weight input when the user registers in the health promotion server and the user'ss current weight, the number of jumps made by the user of the wireless and ropeless jump rope and the amount of time using the wireless and ropeless jump rope which are transmitted from the external communication module of the wireless and ropeless jump rope apparatus,a user analysis server to analyze the information stored in the user data base and to store the analyzed data in the user database,a web-service server, andan application service server to provide the data analyzed in the user analysis server through an application installed in the user terminal,wherein the user analysis server generates analysis data of the user'ss wireless and ropeless jump rope exercise, by using the height and the initial weight information stored in the user database the user'ss current weight, the number of jumps made by the user of the wireless and ropeless jump rope and the amount of time using the wireless and ropeless jump rope as transmitted from the external communication module of the wireless and ropeless jump rope apparatus, and the user analysis server provides the generated analysis data to the user terminal.","8","14/836986","2015-08-27","2016-0059073","2016-03-03","9717944","2017-08-01","FAMSPO CO. LTD.","Bong Sam  Jeon","10-2014-0113763","KR","2014-08-29","A63B-0021/4035","A63B-0021/4035 | A61B-0005/11 | A63B-0005/20 | A63B-0021/4037 | G06F-0019/3481 | G06K-0009/00342 | G06Q-0030/0241 | G06Q-0050/20 | G09B-0019/003 | A63B-0024/0075 | A63B-0071/0622 | A63B-2024/0068 | A63B-2071/063 | A63B-2071/065 | A63B-2071/0625 | A63B-2071/0627 | A63B-2220/10 | A63B-2220/16 | A63B-2220/17 | A63B-2220/18 | A63B-2220/34 | A63B-2220/44 | A63B-2220/56 | A63B-2220/801 | A63B-2220/805 | A63B-2225/20 | A63B-2225/50 | A63B-2225/54 | A63B-2230/01 | A63B-2230/75","A63B-071/00","A63B-071/00 | A63B-021/00 | A63B-005/20 | G09B-019/00 | A61B-005/11 | G06F-019/00 | G06K-009/00 | G06Q-030/02 | G06Q-050/20 | A63B-024/00 | A63B-071/06","","","","","","4917031001427"
"US","US","P","B2","Individual discrimination device and individual discrimination method","A frame storage stores an image obtained by imaging a region of at least part of the body of a user. A vital sign signal detector detects a signal sequence of a vital sign that cyclically varies from plural imaged regions of the body of the user by using captured images of a predetermined number of frames stored in the frame storage. A correlation calculator obtains the correlation between the signal sequences of the vital sign detected from the respective imaged regions of the body. An identity determining section determines whether or not the respective imaged regions of the body belong to the same user based on the correlation between the signal sequences of the vital sign detected from the respective imaged regions of the body.","1. An individual discrimination device comprising: a storage that stores an image obtained by imaging a region of at least part of a body of a user playing a video game;a vital sign signal detector that detects a signal sequence, of a detected vital sign that cyclically varies, from a plurality of imaged regions of the body of the user by using captured images of a predetermined number of frames stored in the storage;a sensor input section that receives input of a signal sequence of a sensed vital sign that cyclically varies from at least one of a sensor mounted in a controller operated by the user and a wearable sensor worn by the user;a correlation calculator that obtains a correlation between the signal sequences of the detected vital sign detected from the imaged regions of the body and obtains a correlation between the signal sequence of the sensed vital sign obtained by the sensor input section and at least one of the signal sequences of the detected vital sign detected from the imaged regions of the body;an identity determining section that determines, based on the correlation between the signal sequences of the detected vital sign detected from the imaged regions of the body, that the imaged regions of the body belong to a same user and that determines, based on the correlation between the signal sequence of the sensed vital sign obtained by the sensor input section and at least one of the signal sequences of the detected vital sign detected from the imaged regions of the body, that the imaged regions of the body belong to at least one of the operator of the controller and the wearer of the sensor; andan individual information management section that feeds back to a progression of the game at least one characteristic of the user, the characteristic being based on the detected signal sequence.","10","14/351274","2012-07-02","2014-0254902","2014-09-11","9717987","2017-08-01","SONY CORPORATION","Akihiko  Sugawara | Akio  Ohba | Toshiyuki  Hiroi","2011-235327","JP","2011-10-26","A63F-0013/213","A63F-0013/213 | A61B-0005/0077 | A61B-0005/117 | A61B-0005/7246 | A63F-0013/212 | G06F-0003/011 | G06F-0003/017 | G06F-0003/0304 | G06K-0009/00362 | G06K-0009/00496 | G06T-0007/0016 | A61B-0005/024 | A61B-0005/1102 | A61B-0005/113 | A63F-2300/1093 | A63F-2300/6045 | A63F-2300/69 | G06F-2203/011 | G06K-0009/00771 | G06K-0009/342 | G06K-0009/6212 | G06K-2009/00939","G06T-007/00","G06T-007/00 | A63F-013/213 | A63F-013/212 | A61B-005/117 | A61B-005/00 | G06K-009/00 | G06F-003/01 | G06F-003/03 | A61B-005/024 | A61B-005/11 | A61B-005/113 | G06K-009/34 | G06K-009/62","","","","","","4917031001470"
"US","US","P","B2","Wrist-worn apparatus control with fingerprint data","A wrist-worn apparatus control with fingerprint data includes a physical activity-related measurement sensor interface, a fingerprint sensor, one or more processors, and one or more memories including computer program code. The one or more memories and the computer program code are configured to, with the one or more processors, cause the apparatus at least to receive fingerprint data from a user with the fingerprint sensor, identify the fingerprint data as matching with one finger of the user on the basis of a comparison between the fingerprint data and reference data of a plurality of fingers of the user stored in the memory, and select a function of a physical activity-related measurement on the basis of the identified finger.","1. A wrist-worn apparatus comprising: a physical activity-related measurement sensor interface;a fingerprint sensor;one or more processors;a display; andone or more non-transitory memories including computer program code, the computer program code configured to, with the one or more processors, cause the apparatus to perform operations comprising: receiving fingerprint data from a user using the fingerprint sensor;identifying the fingerprint data as matching with one finger of the user on the basis of a comparison between the fingerprint data and reference data of a plurality of fingers of the user stored in the one or more non-transitory memories;selecting a function of a physical activity-related measurement on the basis of the identified finger;detecting clicking of the finger on the fingerprint sensor;selecting the function of the apparatus on the basis of the identified finger and further on the basis of the detected clicking of the finger, the selected function comprising a user interface displayed on the display comprising at least one of a control of an apparatus internal sensor measuring functioning of the body of the user, a control of an apparatus external sensor measuring functioning of the body of the user, a control of a heart rate measurement of the user, a control of an acceleration measurement related to a movement of the user, a control of a well-being measurement of the user, a control of a menu related to a sport exercised by the user, a control of a start of an exercise measuring function of the user, a control of a stop of the exercise measuring function of the user; andselecting a home button press as the function on the basis of an earlier assignment of a finger of the user to the home button press function, whereupon the apparatus navigates to a predetermined page of the user interface displayed on the display.","26","14/528632","2014-10-30","2016-0125219","2016-05-05","9721141","2017-08-01","POLAR ELECTRO OY","Pertti  Puolakanaho","","","","G06K-0009/00033","G06K-0009/00033 | A61B-0005/1118 | A61B-0005/7475 | G06F-0017/30247 | G06K-0009/6202 | A61B-0005/02438","G06K-009/00","G06K-009/00 | G06K-009/62 | G06F-017/30 | A61B-005/00 | A61B-005/11 | A61B-005/024","","","","","","4917031004604"
"US","US","P","B2","Biometrics for user identification in mobile health systems","A wearable device may include a sensor system capable of obtaining physiological from a user's body. Some wearable devices may include a substance delivery system. A sensor system of a wearable device may include at least one ""bio-assurance sensor"" capable of obtaining biometric data that may be used to identify a user. For example, the bio-assurance sensor may be used to ensure that the wearable device is not removed from the user's body and/or placed on or in another user's body. In some examples, the wearable device may be used with a second device, such as a smart phone, that includes at least one ""authentication sensor,"" such as a fingerprint sensor, that also may be used to identify a user. However, in some implementations the wearable device may include at least one authentication sensor.","1. A wearable device, comprising: apparatus for securing the wearable device to a user'ss body;a sensor system including one or more biometric sensors, the sensor system being configured for obtaining first biometric data from the user'ss body;a wireless interface system; anda control system configured for: receiving the first biometric data from the sensor system;determining first biometric authentication information based on the first biometric data, wherein the first biometric authentication information includes a representation of the first biometric data;providing, via the wireless interface system, the first biometric authentication information to a second device;receiving, via the wireless interface system, a signal from the second device; andcontrolling the wearable device according to the signal, wherein controlling the wearable device involves preventing or ceasing at least one function of the wearable device if the signal indicates that the user has not been authenticated.","17","14/268245","2014-05-02","2015-0317855","2015-11-05","9721409","2017-08-01","QUALCOMM INCORPORATED","Muhammed Ibrahim  Sezan | John Keith  Schneider | Kenneth  Kaskoun | Eugene  Dantsker","","","","G07C-0009/00158","G07C-0009/00158 | A61B-0005/117 | A61M-0005/1723 | G06F-0019/323 | G06F-0021/32 | G06F-0021/35 | G08C-0017/02 | A61M-0005/14244 | A61M-0005/14248 | A61M-0005/14276 | A61M-2205/3553 | A61M-2205/3561 | A61M-2205/3584 | A61M-2205/3592 | A61M-2205/50 | A61M-2205/609 | A61M-2230/04 | A61M-2230/06 | A61M-2230/201 | A61M-2230/205 | A61M-2230/30 | A61M-2230/42 | A61M-2230/50 | G06F-0019/3468 | H04L-0063/0853 | H04L-0063/0861","G07C-009/00","G07C-009/00 | A61B-005/117 | G08C-017/02 | G06F-021/32 | G06F-021/35 | A61M-005/172 | G06F-019/00 | H04L-029/06 | A61M-005/142","","","","","","4917031004870"
"US","US","P","B2","Method, measuring device and control unit for adaptation of vehicle convoy control","A method (400), control device (240) and measuring unit (230) for adapting a control algorithm having at least one driver-dependent parameter, which control algorithm governs the control of a vehicle convoy (200) in which at least a first vehicle 220A with a first driver (210A) and a second vehicle 220B with a second driver (210B) are included. The method includes measurement (401) of at least one physical characteristic of the first driver (210A), determination (402) of the stress level of the driver based on the performed measurement (401), and adaptation (403) of the control algorithm to the determined (402) stress level of the driver.","1. A method for governing control of a vehicle convoy, the convoy comprising at least a first vehicle with a first driver and a second vehicle with a second driver, the method for governing including: measuring at least one physical characteristic of the first driver indicative of or related to stress of the first driver;determining automatically, by a data processor circuit, a stress level of the first driver based on the measured characteristic of the first driver;adjusting automatically, by the data processor circuit, the control algorithm based on the determined stress level of the first driver, and the control algorithm for the vehicle convoy sending an indication of a stress alarm to other drivers, including the second driver, of vehicles in the vehicle convoy when the determined stress level of the first driver exceeds a respective selected limit value for the stress level; andcontrolling automatically, by the data processor circuit, the vehicle convoy according to the adjusted control algorithm.","26","14/430722","2013-09-19","2015-0243172","2015-08-27","9721474","2017-08-01","SCANIA CV AB","Anders  Eskilson","2012-51072","SE","2012-09-24","G08G-0001/22","G08G-0001/22 | A61B-0005/18 | B60W-0040/08 | H04L-0067/12 | A61B-0005/01 | A61B-0005/021 | A61B-0005/024 | A61B-0005/0533 | A61B-0005/0816 | A61B-0005/11 | A61B-0005/14546 | A61B-0005/4266 | B60W-2040/0872 | B60W-2540/22 | G08G-0001/16","G05D-001/00","G05D-001/00 | G05D-003/00 | G06F-007/00 | G06F-017/00 | G08G-001/00 | A61B-005/18 | B60W-040/08 | H04L-029/08 | G08G-001/16 | A61B-005/01 | A61B-005/021 | A61B-005/024 | A61B-005/053 | A61B-005/08 | A61B-005/11 | A61B-005/145 | A61B-005/00","","","","","","4917031004935"
"US","US","P","B2","Systems and methods for wireless communication with implantable and body worn devices","A medical monitoring and communication system for wireless communication between an implantable medical device, a mobile user device, and a remote server includes a sensor device coupled to the implantable medical device. The sensor device is configured to default to a master mode prior to pairing with the mobile user device, listen for a request to connect from the mobile user device, refrain from communicating with the mobile user device responsive to the request to connect from the mobile user device being invalid, and switch to a slave mode to allow cooperative pairing with the mobile user device responsive to the request to connect from the mobile user device being valid. The mobile user device facilitates communication between the sensor device and the remote server when the mobile user device and the sensor device are cooperatively paired.","1. A medical monitoring and communication system for wireless communication between an implantable medical device, a mobile user device, and a remote server, comprising: a sensor device communicably coupled to the implantable medical device and configured to: default to a master mode prior to pairing with the mobile user device;listen for a request to connect from the mobile user device;refrain from communicating with the mobile user device responsive to the request to connect from the mobile user device being invalid; andswitch to a slave mode to allow cooperative pairing with the mobile user device responsive to the request to connect from the mobile user device being valid;wherein the mobile user device facilitates communication between the sensor device and the remote server when the mobile user device and the sensor device are cooperatively paired; andwherein the sensor device is configured to acquire data regarding at least one of a user of the sensor device or the sensor device, wherein the sensor device is configured to encrypt at least a portion of the data with at least one layer of encryption.","18","15/148514","2016-05-06","2016-0330573","2016-11-10","9723433","2017-08-01","SORIN CRM SAS","Javaid  Masoud | David  Amaoua","2015-166692","EP","2015-05-07","H04W-0004/008","H04W-0004/008 | A61B-0005/0024 | A61N-0001/37217 | A61N-0001/37252 | G06F-0019/3418 | G06F-0021/30 | G06F-0021/44 | H04W-0004/22 | G06F-0019/322 | G06F-0019/3481 | G06F-2221/2103 | H04W-0012/04 | H04W-0012/06 | H04W-0084/20 | H04W-0088/04","H04B-007/00","H04B-007/00 | H04W-004/00 | H04W-004/22 | A61N-001/372 | A61B-005/00 | G06F-019/00 | G06F-021/30 | G06F-021/44 | H04W-012/04 | H04W-012/06 | H04W-088/04 | H04W-084/20","","","","","","4917031006875"
"US","US","P","B2","Human-digital media interaction tracking","A system for human-digital media interaction tracking. One example system includes a database that stores information regarding a user's activity history for various different cognitive tasks, and a computing device that receives user behavior information indicating usage by a user of an interactive software program, the interactive software program associated with at least one of the cognitive tasks. The computing device, in response to the receipt of user behavior information indicating usage by the user of the interactive software program, updates the database information regarding the user's activity history for the at least one of the cognitive tasks.","1. A system for cognitive training based on user-digital media interaction tracking, comprising: a plurality of computing devices having a plurality of commercially available third-party interactive digital media stored therein, said digital media including a video game and a web-browser, each of the plurality of computing devices including: a processor and a memory, the memory including: one or more of the plurality of digital media in the form of executable software programs;a user-digital media interaction monitor configured to plug-in as a monitoring extension to each of the digital media without modification of interactive content of said digital media, the user-digital media interaction monitor having executable instructions that configure the computing device to: identify a user identity for the user; andunobtrusively track the user-digital media interaction, which includes a speed and duration of active interaction of the user with each of the plurality of digital media;a computer server with a processor and a memory, the memory including: a database having a first predetermined weighted mapping between each of the plurality of digital media with one or more of a plurality of cognitive tasks, and a second predetermined weighted mapping between each of the plurality of cognitive tasks with one or more of a plurality of brain areas, wherein the plurality of cognitive tasks include at least two of memory, attention, motor function, visual search, decision making, inhibitory control, computation and speed of processing; andexecutable instructions that configure the computer server to: perform an analysis that determines a duration of exercise of each of the plurality of cognitive tasks and brain areas for the user based on the first predetermined weighted mapping, the second predetermined weighted mapping and a daily, weekly or monthly history of the user-digital media interaction across the plurality of the computing devices; anddetermine a plan of cognitive exercise of one or more of the plurality of cognitive tasks and one or more of the plurality of brain areas for the user, the plan including a schedule with a recommended duration of user-digital media interaction with each of the plurality of digital media; andserve the plan to at least one of the computing devices;wherein each of the computing devices are further configured to receive and display the plan.","7","12/343305","2008-12-23","2010-0076274","2010-03-25","9713444","2017-07-25","DIGITAL ARTEFACTS, LLC","Joan  Severson","","","","A61B-0005/165","A61B-0005/165 | A61B-0005/16 | G06F-0017/30029 | G06Q-0010/00 | G06Q-0050/24 | G09B-0019/22","A61B-005/16","A61B-005/16 | G09B-019/00 | G09B-019/22 | G06F-017/30 | G06Q-010/00 | G06Q-050/24","","","","","","4917030000515"
"US","US","P","B2","Methods and systems for ear device design using computerized tomography (CT)-collected anthropomorphic data","Methods and systems for designing an earpiece device are provided. The method includes receiving a plurality of images for a respective plurality of individuals. Each image includes at least one ear anatomy. For each image, a three-dimensional (3D) surface representing the at least one ear anatomy is extracted, to form a plurality of extracted surfaces corresponding to the plurality of images. At least one statistical measurement representative of at least a portion of the plurality of individuals is determined from among the plurality of extracted surfaces. At least one design parameter for the earpiece device is optimized based on the at least one statistical measurement, The earpiece device is formed using the optimized at least one design parameter.","1. A method of designing an earpiece device customized for a predefined group of individuals, the method comprising: receiving a plurality of images for a respective plurality of individuals, each image including at least one ear anatomy;for each image, extracting a three-dimensional (3D) surface representing the at least one ear anatomy, to form a plurality of extracted surfaces corresponding to the plurality of images;determining at least one statistical measurement representative of at least a portion of the plurality of individuals from among the plurality of extracted surfaces; andoptimizing at least one design parameter for the earpiece device based on the at least one statistical measurement for the predefined group among the plurality of individuals, the earpiece device being formed using the optimized at least one design parameter.","34","14/362603","2012-12-06","2014-0343900","2014-11-20","9715562","2017-07-25","STATON TECHIYA, LLC","Steven W.  Goldstein | Sergei  Azernikov","","","","G06F-0017/50","G06F-0017/50 | A61B-0006/032 | G02C-0013/003 | G06F-0017/18 | G06T-0003/0068 | G06T-0007/35 | G06T-0017/00 | H04R-0001/1058 | H04R-0025/658 | A61B-0005/055 | A61B-0005/12 | A61B-0006/469 | A61B-0006/5217 | A61B-0008/5223 | G06T-2200/04 | G06T-2207/10081 | G06T-2207/30052 | H04R-2201/029 | H04R-2225/77","G06F-017/50","G06F-017/50 | A61B-006/03 | G02C-013/00 | H04R-001/10 | H04R-025/00 | G06F-017/18 | G06T-003/00 | G06T-017/00 | G06T-007/35 | A61B-006/00 | A61B-008/08 | A61B-005/055 | A61B-005/12","","","","","","4917030002619"
"US","US","P","B2","Device for remote monitoring of at least one medical device","A device (9) for remotely monitoring at least one medical device (7) includes at least one portion (11) that vibrates when the medical device is used by a patient in order to receive a medical treatment. The monitoring device (9) includes: at least one sensor (15) intended to be in mechanical contact with the portion and suitable for detecting vibrations and for producing a primary electric or radio-electric signal (23) representing vibrations, and a local processing unit (13) suitable for receiving and extracting from the primary signal, at least one information item representing a duration of use of the medical device by the patient, and for producing at least one secondary signal (29) containing the information, the secondary signal being intended to be sent to at least one remote server (3) suitable for receiving and for extracting from the secondary signal, the information.","1. Device (9; 100) for remote monitoring of at least one medical device (7) comprising at least one portion (11) that vibrates when the medical device (7) is used by a patient in order to receive a medical treatment, the monitoring device (9) comprising: at least one sensor (15) intended to be in mechanical contact with the portion (11) and suitable for detecting the vibrations when the medical device (7) administers the medical treatment to the patient and for producing a primary electric or radio-electric signal (23) representing the vibrations, anda local processing unit (13) suitable for receiving the primary signal (23), for extracting from the primary signal (23) at least one information item representing a duration of use of the medical device (7) by the patient, and for producing at least one secondary signal (29) containing said information item indicating the duration of use of the medical device (7) in administering the medical treatment to the patient, the secondary signal (29) being intended to be sent to at least one remote server (3) suitable for receiving the secondary signal (29) and for extracting said information item from the secondary signal (29).","20","14/295548","2014-06-04","2014-0365615","2014-12-11","9716757","2017-07-25","L.3 MEDICAL","Philippe  Fernandes","2013-055152","FR","2013-06-05","H04L-0067/12","H04L-0067/12 | A61B-0005/0022 | A61B-0005/4818 | A61M-0016/0051 | A61B-0005/7257 | A61B-2560/028 | A61B-2560/0271 | A61M-0001/00 | A61M-0011/00 | A61M-0016/101 | A61M-2202/0208 | A61M-2205/3375 | A61M-2205/3553 | A61M-2205/3592 | A61M-2205/52","G06F-015/16","G06F-015/16 | H04L-029/08 | A61M-016/00 | A61M-001/00 | A61M-011/00 | A61B-005/00 | A61M-016/10","","","","","","4917030003806"
"US","US","P","B2","Automatic background region selection for lesion delineation in medical images","In a method and apparatus for automatic background region selection for lesion segmentation in medical images, a patient medical image dataset is loaded into a computer and an image region is delineated to obtain a segmentation containing a lesion. A background region is created from the segmentation representing the patient organ.","1. A method for automatic segmentation of a depiction of a lesion in a functional medical image data set, comprising: loading a medical image data set into a computer, said medical image data set comprising a functional medical image data set and an anatomical image data set, both obtained from a patient but with respectively different imaging modalities, said functional medical image data set and said anatomical image data set being in registration with each other in said medical image data set;in said computer, automatically identifying and delineating an image region in said anatomical image data set that contains a lesion;in said computer, using the registration of said functional image data set and said anatomical image data set to apply the delineation of said image region identified in said anatomical image data set in order to delineate said image region also in said functional medical image data set;in said computer, within the delineated image region in said functional medical image data set, automatically identifying a potential lesion region surrounding a depiction of said lesion in said functional medical image data set, and potential non-background regions depicted in said functional medical image data set;in said computer, automatically identifying a background region in said delineated image region in said functional medical image data set, by subtracting said potential lesion region and said potential non-background regions from the functional medical image data set within said delineated image region;in said computer, segmenting said lesion in said functional medical image data set by differentiating the depiction of the lesion in said functional medical image data set from said background region; andat a display in communication with said computer, depicting the segmented lesion in a display of said functional image data set.","9","14/796361","2015-07-10","2016-0012604","2016-01-14","9710915","2017-07-18","SIEMENS MEDICAL SOLUTIONS USA, INC.","Azadeh  Firouzian | Jens  Kaftan | Matthew David  Kelly | Antonios  Makropoulos","2014012394","GB","2014-07-11","G06T-0007/0081","G06T-0007/0081 | A61B-0006/032 | A61B-0006/037 | A61B-0006/12 | A61B-0006/5217 | A61B-0006/5247 | G06F-0017/30244 | G06T-0007/11 | G06T-0007/136 | G06T-0007/194 | A61B-0005/055 | A61B-0005/7425 | G06T-2207/10081 | G06T-2207/10104 | G06T-2207/30096","G06K-009/00","G06K-009/00 | G06T-007/00 | G06F-017/30 | A61B-006/03 | A61B-006/12 | A61B-006/00 | G06T-007/11 | G06T-007/194 | G06T-007/136 | A61B-005/00 | A61B-005/055","","","","","","4917029004846"
"US","US","P","B2","Motion information processing device","A motion information processing device for supporting a rehabilitation according to an embodiment includes obtaining circuitry and specification circuitry. The obtaining circuitry obtains image information of a subject carrying out a predetermined motion in the rehabilitation and surroundings of the subject. The specification circuitry specifies motion information of the subject carrying out the predetermined motion on the basis of a predetermined feature in the image information obtained by the obtaining circuitry.","1. A motion information processing device for supporting a rehabilitation, the motion information processing device comprising: obtaining circuitry configured to obtain image information of a subject carrying out a predetermined motion in the rehabilitation and surroundings of the subject, the image information including photographic image information and depth image information; andspecification circuitry configured to calculate positions of joints of the subject from the photographic image information and the depth image information included in the image information obtained by the obtaining circuitry, and to specify motion information of the subject carrying out the predetermined motion on the basis of a feature represented by the calculated positions of joints.","25","14/793396","2015-07-07","2015-0310629","2015-10-29","9710920","2017-07-18","TOSHIBA MEDICAL SYSTEMS CORPORATION","Kazuki  Utsunomiya | Masashi  Yoshida | Hayato  Konishi | Shigeyuki  Ishii | Kousuke  Sakaue | Satoshi  Ikeda","2013-007872 | 2013-167836 | 2013-171755","JP | JP | JP","2013-01-18 | 2013-08-12 | 2013-08-21","G06T-0007/2033","G06T-0007/2033 | A61B-0005/11 | A61B-0005/112 | G06K-0009/00342 | G06K-0009/00348 | G06K-0009/44 | G06Q-0010/063 | G06Q-0050/22 | G06T-0007/246 | G06T-0007/251 | G09B-0019/003 | G06K-2209/055 | G06T-2207/30196 | G06T-2207/30204","G06K-009/00","G06K-009/00 | G06T-007/20 | A61B-005/11 | G06Q-010/06 | G06Q-050/22 | G09B-019/00 | G06K-009/44 | G06T-007/246 | H04N-007/18 | A61B-005/103","","","","","","4917029004851"
"US","US","P","B2","Providing to a public-safety answering point emergency information associated with an emergency call","Users store information relevant to first responders in the event of an emergency. When a user later places an emergency call, the user's emergency information is automatically made available to the public-safety answering point operator handling the call. Hotel personal are notified of the call and may listen to and break in to the ongoing call in order to assist. A reverse 9-1-1 broadcast enables hotel personnel to quickly notify guests of an emergency situation via in-room and mobile phones. In the event that police need to conduct surveillance on a target location, the onsite PBX server reconfigures phones within the vicinity of the target location to operate in an open mode and records the audio/visual information received. An incoming call to a hotel room from the PSAP is automatically connected to the in-room phone even if other incoming calls not from the PSAP are being screened by front desk.","1. A system for providing personalized emergency information to a public-safety answering point (PSAP) regarding a guest of a hospitality establishment, the system comprising: a server configured to receive emergency information from a plurality of different users;a storage device configured to store each of the users's emergency information associated with a respective unique user identifier; anda controller configured to determine a particular user identifier, the particular user identifier corresponding to a user who is currently checked in to a guest room in the hospitality establishment at the time an emergency call is placed from the guest room;wherein the controller is further configured to send to the Public Safety Answering Point (PSAP) the emergency information associated with the particular user identifier.","13","15/152423","2016-05-11","2016-0255197","2016-09-01","9712673","2017-07-18","Innacloud Technologies LLC | Guest Tek Interactive Entertainment Ltd.","Christopher  Abnett | Russell D.  McComb | Andrew T.  MacMillan","","","","H04M-0003/5116","H04M-0003/5116 | A61B-0005/0004 | A61B-0005/0022 | A61B-0005/747 | G06F-0017/30477 | G06Q-0050/12 | H04M-0003/42068 | H04M-0003/42323 | H04M-0007/0024 | H04W-0004/16","H04M-011/00","H04M-011/00 | H04M-003/51 | G06Q-050/12 | H04W-004/16 | A61B-005/00 | G06F-017/30 | H04M-003/42 | H04M-007/00","","","","","","4917029006588"
"US","US","P","B2","Digital image processing using face detection and skin tone information","A technique for processing a digital image uses face detection to achieve one or more desired image processing parameters. A group of pixels is identified that corresponds to a face image within the digital image. A skin tone is detected for the face image by determining one or more default color or tonal values, or combinations thereof, for the group of pixels. Values of one or more parameters are adjusted for the group of pixels that correspond to the face image based on the detected skin tone.","1. A method of processing a digital image using face detection, the method comprising: identifying a first group of pixels that correspond to a first face region within a digital image;determining one or more first initial color values for pixels in the first group of pixels;based on the one or more first initial color values for the pixels in the first group of pixels, determining a first skin tone for the first face region;identifying a second group of pixels that correspond to a second face region within the digital image;determining one or more second initial color values for pixels in the second group of pixels;based on the one or more second initial color values for the pixels in the second group of pixels, determining a second skin tone for the second face region;determining whether the first skin tone is lighter than the second skin tone; andin response to determining that the first skin tone is lighter than the second skin tone: based on, at least in part, the first skin tone and the second skin tone, determining an initial fill-flash and applying the initial fill-flash to the first face region;based on, at least in part, the first skin tone and the second skin tone, increasing the fill-flash and applying the increased fill-flash to the second face region.","20","15/369698","2016-12-05","2017-0085785","2017-03-23","9712743","2017-07-18","FotoNation Limited","Peter  Corcoran | Igor  Barcovschi | Eran  Steinberg | Yury  Prilutsky | Petronel  Bigioi","","","","H04N-0005/23219","H04N-0005/23219 | A61B-0005/1176 | G06F-0017/30793 | G06K-0009/00228 | G06K-0009/00275 | G06T-0005/001 | H04N-0005/23229","H04N-005/20","H04N-005/20 | H04N-005/232 | G06K-009/00 | G06T-005/00 | G06F-017/30 | A61B-005/1171","","","","","","4917029006658"
"US","US","P","B2","Image observation apparatus and storage medium that generates a plurality of image lists","According to one embodiment, an image observation apparatus includes a condition storage, list generation circuitry, and a display. The condition storage stores a plurality of display target conditions respectively corresponding to a plurality of display areas in a display screen. The list generation circuitry generates a plurality of image lists respectively corresponding to the plurality of display areas, which concern additional items of a plurality of images respectively corresponding to the display target conditions. The display displays the plurality of image lists in the plurality of display areas, and an image corresponding to an additional item selected from the plurality of displayed image lists in the corresponding display area.","1. An image observation apparatus comprising: a condition memory configured to store a plurality of display target conditions respectively corresponding to a plurality of display areas in a display screen;processing circuitry configured toextract additional information of a plurality of images displayed to the plurality of the display areas respectively, andgenerate a plurality of image lists based on the extracted additional information, wherein each of images in the image list has corresponding additional items to the extracted additional items in response to a request to display the image lists, the image lists respectively corresponding to the plurality of display areas; anda monitor configured to display an image list of the plurality of image lists in each of the plurality of display areas, and an image corresponding to an additional item selected from the plurality of displayed image lists in the corresponding display area.","11","14/731859","2015-06-05","2015-0265233","2015-09-24","9700274","2017-07-11","TOSHIBA MEDICAL SYSTEMS CORPORATION","Kota  Aoyagi | Satoshi  Wakai | Kazumasa  Arakita","2012-266444 | 2013-251907","JP | JP","2012-12-05 | 2013-12-05","A61B-0006/463","A61B-0006/463 | A61B-0005/002 | A61B-0005/0035 | A61B-0005/743 | A61B-0005/7425 | A61B-0005/7435 | A61B-0006/5294 | A61B-0006/563 | G06F-0003/1446 | G06F-0017/30277 | G09G-0005/14 | G09G-2380/08","A61B-006/00","A61B-006/00 | G06F-017/30 | A61B-005/00 | G06F-003/14 | G09G-005/14","","","","","","4917028000991"
"US","US","P","B2","System and method for detecting interpersonal touch using electrical properties of skin","Disclosed herein is an accurate and efficient, yet non-obtrusive system and method (using same) for detecting interpersonal touch, such as a high-five, which is prevalent in people's daily lives, so as to promote everyday interactions at diverse settings. Based on ubiquitous computing technology, one embodiment of the system for detecting interpersonal touch comprises a pre-motion filter for filtering a pre-motion prior to the interpersonal touch, a sensor for sensing electrical properties of skin, an evaluator for analyzing and determining the interpersonal touch based on the pre-motion and the electrical properties of skin, and a communicator for communicating information analyzed by the evaluator. Other embodiments are described and shown.","1. A system for detecting interpersonal touch, comprising: a pre-motion filter for filtering a pre-motion prior to the interpersonal touch,a sensor for sensing electrical properties of skin,an evaluator for analyzing and determining the interpersonal touch based on the pre-motion filtered by the pre-motion filter and the electrical properties of skin sensed by the sensor, anda communicator for communicating data for the interpersonal touch analyzed by the evaluator.","19","14/666339","2015-03-24","2015-0316676","2015-11-05","9703395","2017-07-11","KOREA ADVANCED INSTITUTE OF SCIENCE AND TECHNOLOGY","Junehwa  Song | Yuhwan  Kim | Seungchul  Lee | Inseok  Hwang | Hyunho  Ro | Youngki  Lee | Miri  Moon","10-2014-0052777","KR","2014-04-30","G06F-0003/0338","G06F-0003/0338 | G01R-0029/0814 | G01V-0003/08 | G06F-0003/011 | G06F-0003/017 | G06Q-0010/10 | H04W-0004/003 | A61B-0005/0531 | A61B-0005/1116 | A61B-0005/6898","G08B-023/00","G08B-023/00 | G06F-003/0338 | G01V-003/08 | G06Q-010/10 | H04W-004/00 | G01R-029/08 | G06F-003/01 | A61B-005/00 | A61B-005/053 | A61B-005/11","","","","","","4917028004099"
"US","US","P","B2","Pairing of devices","A server computer to provide a web service including exercise data user accounts, acquire and store a unique device identifier of at least one physiological sensor device, associate each of the acquired at least one device identifier with one of the exercise data user accounts, detect that an exercise application of a user terminal successfully accesses a specific exercise data user account, and provide the user terminal with the at least one device identifier which is associated with the specific exercise data user account. There is further provided a user terminal to successfully access the specific exercise data user account in the web service, acquire the at least one device identifier from the web service, and apply the acquired at least one device identifier in determining whether or not to allow the user terminal to wirelessly pair with a physiological sensor device.","1. A system, comprising: a server computer comprising at least one processor and at least one memory including a computer program code, wherein the at least one memory and the computer program code are configured, with the at least one processor, to cause the server computer to perform operations comprising:providing a web service accessible by users via a network, wherein the web service comprises a plurality of exercise data user accounts and a database for storing the plurality of exercise data user accounts, and wherein each exercise data user account is for storing physiological exercise data associated with a specific user;acquiring and storing a unique device identifier of at least one physiological sensor device, wherein each physiological sensor device is portable and associated with a user having an exercise data user account;associating each of the acquired at least one device identifier with one of the plurality of exercise data user accounts;detecting that an exercise application of a user terminal successfully accesses a specific exercise data user account of the plurality of exercise data user accounts;providing the user terminal with the at least one device identifier previously associated with the specific exercise data user account of the plurality of exercise data user accounts in response to detecting that the exercise application of the user terminal successfully accesses the specific exercise data user account of the plurality of exercise data user accounts to enable the user terminal to determine which physiological sensor device is allowed to wirelessly pair with the user terminal;acquiring physiological exercise data of a user from the at least one physiological sensor device;storing said physiological exercise data to the exercise data user account associated with said at least one physiological sensor device, the physiological exercise data comprising at least one of the following data: heart rate zone data, speed zone data, activity zone data, cadence sample data, pedal index data, left-right balance data, running index data, training load data, and fluid balance data; anddetecting the device identifier, which has already been uploaded to a mediating device prior to the server computer being connected to the physiological sensor device, automatically while the physiological sensor device is connected to the mediating device, which is used in accessing the web service.","23","14/026519","2013-09-13","2015-0081763","2015-03-19","9705989","2017-07-11","POLAR ELECTRO OY","Matti  Sipola | Erkki  Silvola | Juha  Onkila | Petteri  Siekkinen","","","","H04L-0067/12","H04L-0067/12 | A61B-0005/00 | A61B-0005/0002 | G06Q-0010/0639 | H04W-0012/08 | H04L-0063/101","G06F-015/173","G06F-015/173 | H04L-029/08 | A61B-005/00 | H04W-012/08 | G06Q-010/06 | H04L-029/06","","","","","","4917028006671"
"US","US","P","B2","Systems and methods for managing blood donations","Methods and apparatus collecting blood from patients and managing blood donations are provided, which may include any number of features. One feature is a blood collection device configured to collect blood from a patient and periodically transmit blood collection data from the device to a control system. Another feature is a system and method for updating firmware on a plurality of blood collection devices. In one embodiment, a software interface with a blood collection control can be used to specify a blood collection protocol, and the blood collection protocol can be then transmitted to one or more blood collection devices.","1. A method of specifying a collection protocol for a blood collection device, the method comprising: specifying in a blood collection control system, a first input to be scanned, the first input being selected from the group consisting of a donation ID barcode on a blood collection bag, a donor ID, a technician ID that identifies the user at a start of the blood collection event, a blood product code, a first sample tube, a second sample tube, a biometric input, and a technician ID that identifies the user at an end of the blood collection event;specifying in the blood collection control system, a first time during a blood collection event for the blood collection device to prompt a user to scan the first input;specifying in the blood collection control system, a second input to be scanned, the second input being selected from the group consisting of a donation ID barcode on a blood collection bag, a donor ID, a technician ID that identifies the user at a start of the blood collection event, a blood product code, a first sample tube, a second sample tube, a biometric input, and a technician ID that identifies the user at an end of the blood collection event;specifying in the blood collection control system, a second time during the blood collection event for the blood collection device to prompt the user to scan the second input;compiling in the blood collection control system a customized blood collection protocol operable on a blood collection device and configured to prompt the user for the first input at the first time and the second input at the second time;transmitting the customized blood collection protocol from the blood collection control system to one or more blood collection devices;initiating a blood draw from a patient with one of the blood collection devices running the customized blood collection protocol;prompting the user for the first input at the first time during the blood draw;prompting the user for the second input at the second time during the blood draw; andcompleting the blood draw from the patient.","7","13/445274","2012-04-12","2012-0265099","2012-10-18","9697337","2017-07-04","APPLIED SCIENCE, INC.","James E.  Goodnow, II | James A.  Bancroft | Jonathan G.  Morgan","","","","G06F-0019/366","G06F-0019/366 | A61B-0005/15003 | A61B-0005/153 | A61B-0005/155 | A61B-0005/150221 | A61B-0005/150229 | A61B-0005/150366 | A61B-0005/150389 | A61B-0005/150755 | A61B-0005/150786 | A61B-0005/150862 | A61B-0005/150946 | G06F-0019/3412 | A61B-0005/157 | A61B-2560/0209 | G06F-0008/665","G06F-009/44","G06F-009/44 | A61B-005/15 | G06F-015/16 | G06F-017/40 | G06F-019/00 | A61B-005/153 | A61B-005/155 | A61B-005/157 | G06F-009/445","","","","","","4917027004477"
"US","US","P","B2","Electrocardiogram (ECG) biometric authentication","Electrocardiogram, better known as ECG or EKG, is a method used to measure and record the electrical potential generated by the heart on the skin. ECG data is unique to a user and can be used for authentication systems such as access or financial cards or for granting access to computing devices such as mobile devices. Electrode contact on a card or device are used to received ECG data which is processed to extract features of the ECG which are compared to a template for a user.","1. A method of security authentication, the method comprising: receiving electrocardiogram (ECG) signals from contact electrodes;transferring ECG signals to a processor;extracting features from ECG data of the ECG signal by the processor;verifying ECG data against stored biometric information template (BIT) associated with a user; andproviding access to the user based upon confirmed ECG data;wherein the ECG data is normalized by: dividing the ECG data into its composing heart cycles;aligning all the heart cycles by ensuring that their R peaks share a same index wherein the index at which all R peaks are aligned is referred to as Rref and there the calculated median of the indicies is referred to as TPref; andcalculating a median of indices of TP valleys from all heart cycles wherein median is an alignment point Rref that is used as a reference to align fiducial points of the ECG data and medians of TP valleys, TPref and Rref are used to modify the index of all the points belonging to a heart cyclewhere alignment is performed by: where, Inew is a re-calculated index, Icur is an index that needs to be re-calculated, and TPcur is the index of the TP valley of a current heart cycle.","17","14/748913","2015-06-24","2015-0373019","2015-12-24","9699182","2017-07-04","Abdulmotaleb El Saddik | Juan Sebastian Arteaga Falconi | Hussein Al Osman","Abdulmotaleb  El Saddik | Juan Sebastian  Arteaga Falconi | Hussein  Al Osman","","","","H04L-0063/0861","H04L-0063/0861 | A61B-0005/0452 | A61B-0005/117 | G06F-0021/00 | G06F-0021/32 | H04W-0012/06","G06F-021/00","G06F-021/00 | G06F-021/32 | G06K-009/00 | H04L-029/06 | H04W-012/08 | A61B-005/117 | H04W-012/06 | A61B-005/0452","","","","","","4917027006303"
"US","US","P","B2","Selection assisting method and selection assisting apparatus","The present invention relates to a selection assisting method including a first selection step of selecting a recommended grip from a plurality of types of grips based on information on a hand size of a testing golfer; a measurement step of measuring by using a measurement device a swing characteristic of the testing golfer in a shot by using a golf club to which the recommended grip selected in the first selection step is attached; and a second selection step of selecting a recommended grip from the plurality of types of grips based on a measurement result in the measurement step.","1. A selection assisting method comprising: a first selection step of selecting a recommended grip from a plurality of types of grips based on information on a hand size of a testing golfer;a measurement step of measuring by using a measurement device a swing characteristic of the testing golfer in a shot by using a golf club to which the recommended grip selected in the first selection step is attached;a second selection step of selecting a recommended grip from the plurality of types of grips based on a measurement result in the measurement step,a re-measurement step of measuring by using a measurement device in a shot by using a golf club to which the recommended grip selected in the second selection step is attached; anda third selection step of selecting a recommended grip from the plurality of types of grips based on a measurement result in the re-measurement step,whereinin the measurement step, a direction of a face at impact is measured as the swing characteristic,in the re-measurement step, a degree of a change in direction of a face with respect to a moving direction of a head within a moving range of the head from an impact position to a position at a predetermined distance before the impact position is measured as the swing characteristic,in the second selection step, the more open the face, the thinner a grip that is selected as the recommended grip, and the more closed the face, the thicker a grip that is selected as the recommended grip, andin the third selection step, the larger the degree of the change, the stronger taper of a grip that is selected as the recommended grip, and the smaller the degree of the change, the weaker taper of a grip that is selected as the recommended grip.","6","15/141266","2016-04-28","2016-0339313","2016-11-24","9689654","2017-06-27","BRIDGESTONE SPORTS CO., LTD.","Hirotada  Iwade | Tatsuya  Ishikawa | Shintaro  Yoshida","2015-103996","JP","2015-05-21","G01B-0005/0023","G01B-0005/0023 | G06F-0001/3206 | G06F-0003/00 | G06F-0003/014 | G06F-0019/00 | G09B-0019/0038 | A61B-0005/1072 | A61B-0005/6825 | G06Q-0010/0639","A63B-053/14","A63B-053/14 | A63B-049/08 | G01B-005/00 | G06F-003/00 | G06F-019/00 | G06F-001/32 | G06F-003/01 | G09B-019/00 | G06Q-010/06 | A61B-005/107 | A61B-005/00","","","","","","4917026003418"
"US","US","P","B2","Living object investigation and diagnosis using a database of probabilities pertaining to ranges of results","An object investigation and classification system may include an object test system, a data storage system, and a data processing system. The object test system may receive a command to perform at least one action with a test object, perform the at least one action with the test object, and return test information indicative of at least one percept resulting from the at least one action. The data storage system may contain an experience database containing data indicative of multiple classifications and, for each classification, at least one action that was performed with at least one previously-observed reference object having this classification, and at least one percept value that is based in whole or in part on the test information resulting from the at least one action.","1. A living object investigation and classification system comprising: a living object test system that includes one or more actors and sensors and that receives a command to perform at least one diagnostic test with a living test object, performs the at least one diagnostic test with the living object, and returns diagnostic test information indicative of at least one measurement from the at least one diagnostic test;a data storage system that includes one or more tangible hardware memories and that contains an experience database containing data indicative of multiple diagnoses and, for each diagnosis, at least one diagnostic test that was performed with at least one previously-observed living reference object having this diagnosis, and at least one result that is based in whole or in part on diagnostic test information indicative of at least one measurement from the at least one diagnostic test; anda data processing system that includes one or more hardware processors and that: a) for each of multiple different diagnoses, computes or receives an initial prior probability that the diagnosis is correct for a living test object;b) determines at least one diagnostic test that should be performed with the living test object to obtain at least one measurement about the living test object that is likely to enable the diagnosis of the living test object to be more accurately determined based on the initial prior probabilities and data within the experience database that is indicative of the probability that a living object with a particular diagnosis will generate a particular range of test results;c) causes the living object test system to perform the at least one diagnostic test with the living test object;d) receives test information from the living object test system indicative of at least one measurement from the at least one diagnostic test with the living test object;e) computes at least one result;f) for each of multiple different diagnoses, determines a posterior probability that the diagnosis is correct for the living test object based on the initial prior probability, the at least one result, and the data within the experience database that is indicative of the probability that a living object with a particular diagnosis will generate a particular range of test results;g) determines whether any of the posterior probabilities meets or exceeds a threshold;h) if none of the posterior probabilities meets or exceeds the threshold, repeats b) through i), substituting the posterior probabilities determined in f) for the initial prior probabilities in b); andi) when one or more of the posterior probabilities meets or exceeds the threshold, outputs information indicative of one or more of the diagnoses that correspond to the one or more posterior probabilities that meets or exceeds the threshold.","30","15/269408","2016-09-19","2017-0011198","2017-01-12","9690906","2017-06-27","SYNTOUCH, LLC","Jeremy A.  Fishel | Gerald E.  Loeb","","","","G06F-0019/3443","G06F-0019/3443 | A61B-0005/0048 | A61B-0005/0077 | A61B-0005/01 | A61B-0005/6897 | G01B-0021/30 | G06K-0009/6277","G06F-017/00","G06F-017/00 | G06F-019/00 | G01B-021/30 | G06K-009/62 | A61B-005/00 | A61B-005/01","","","","","","4917026004661"
"US","US","P","B2","Context emotion determination system","Systems, methods, and devices for determining contexts and determining associated emotion profiles using information received from multiple emotion sensor enabled electronic devices, are disclosed. Contexts can be defined by a description of spatial and/or temporal components. Such contexts can be arbitrarily defined using semantically meaningful and absolute descriptions of times and locations. Emotion sensor data is associated with or includes context data that describes the circumstances under which the data was determined. The emotion sensor data can include emotion sensor readings that are implicit indications of an emotion for the context. The sensor data can also include user reported data with explicit descriptors of an emotion for the context. The emotion sensor data can be filtered by context data according a selected context. The filtered sensor data can then be analyzed to determine an emotion profile for the context that can be output to one or more users or entities.","1. A method comprising: receiving, by a computer system, emotion sensor data for a plurality of contexts from a plurality of distributed electronic devices, wherein each of the plurality of contexts corresponds to one or more of a geographical area and a time period, wherein the emotion sensor data comprises implicit emotion indicators based on information sensed by the plurality of distributed electronic devices for the plurality of contexts, wherein the emotion sensor data further comprises explicit emotion descriptors based on user reported descriptions of emotions for the plurality of contexts;determining, by the computer system, a first context in the plurality of contexts;determining, by the computer system, a first portion of the emotion sensor data determined to be received from a first portion of the plurality of distributed electronic devices, wherein the first portion of the emotion sensor data is based on information sensed for the first context;generating, by the computer system, a first emotion profile for the first context based on the first portion of the emotion sensor data, the generating comprising weighting the implicit emotion indicators differently from the explicit emotion descriptors based at least on a reliability,tracking, using an emotion trend profile, an emotional change associated with a move from one of the plurality of contexts to another of the plurality of contexts; andpredicting, using the emotion trend profile and the first emotion profile, a predicted emotional change associated with a move from one of the plurality of contexts to the first context;wherein the first emotion profile comprises a description of a first emotion associated with the first context, and wherein the computer system comprises one or more computer processors configured to perform the steps of the method.","19","13/798367","2013-03-13","2014-0280529","2014-09-18","9692839","2017-06-27","ARRIS | ARRIS ENTERPRISES LLC","Paul C.  Davis | Mir F.  Ali | Jianguo  Li | Dale W.  Russell | Di  You","","","","H04L-0067/22","H04L-0067/22 | A61B-0005/0022 | A61B-0005/165 | G06F-0017/27 | G06F-0017/2785 | A61B-0005/6898 | G06F-0017/21 | G06F-2203/011","G06F-017/27","G06F-017/27 | H04L-029/08 | A61B-005/16 | G06F-017/21 | A61B-005/00","","","","","","4917026006571"
"US","US","P","B2","Method and apparatus for sensing touch","Aspects of the present disclosure are directed towards methods, systems, and apparatuses that include a pressure-sensor arrangement including a plate structure and a plurality or array of pressure-sensor cells. Additionally, the methods, systems, and apparatuses include integrated circuitry communicatively coupled to the pressure-sensor arrangement that senses pressure changes exhibited by changes in capacitance or vibrational characteristics.","1. An apparatus comprising: a pressure-sensor arrangement including a plate structure and a plurality or array of pressure-sensor cells, with the plate structure anchored around edges of the plurality or array of pressure-sensor cells;integrated circuitry communicatively coupled to the pressure-sensor arrangement and configured and arranged to provide capacitance and to sense pressure changes exhibited by changes in the capacitance or in vibration due to dampening, the integrated circuitry including separate signal paths for each of the plurality or array of pressure-sensor cells; andthe plurality of pressure-sensor cells and the plate structure being configured and arranged to detect changes in capacitance or in vibration in the pressure-sensor arrangement due to dampening, via the separate signal paths, in response to a touch event at or near the plate structure as caused by a single touch, wherein the pressure-sensor arrangement is configured and arranged to include the separate signal paths for each of the respective pressure-sensor cells to provide an indication of the touch event at or near the plate structure.","20","14/300033","2014-06-09","2014-0362013","2014-12-11","9678591","2017-06-13","THE BOARD OF TRUSTEES OF THE LELAND STANFORD JUNIOR UNIVERSITY","Amin  Nikoozadeh | Butrus T.  Khuri-Yakub","","","","G06F-0003/0414","G06F-0003/0414 | A61B-0005/1172 | G06F-0003/044 | G06F-0021/32 | G06K-0009/0002 | G06K-0019/07 | A61B-0005/021 | A61B-0005/024 | A61B-2562/0247 | A61B-2562/046","G06F-003/041","G06F-003/041 | G06K-009/00 | G06F-021/32 | G06K-019/07 | A61B-005/1172 | G06F-003/044 | A61B-005/021 | A61B-005/024","","","","","","4917024004240"
"US","US","P","B2","User identification system based on plethysmography","A light emitter and light sensor pair can be used to determine one or more characteristics of a user's vasculature. For example, a pulse oximeter employs a light emitter and a light sensor to measure the percentage of oxygenated blood in a subject. In examples of the present disclosure, light emitters and light sensors can be used to perform biometric identification of a user based on identifying characteristics of the user's vasculature. For example, light information can be obtained at one or more light sensors, and the information can be compared to stored information associated with a user identity. Based on the comparison, the user of the device can be identified as having the user identity.","1. A method of an electronic device including a plurality of light sensors and light emitters, the method comprising: receiving first light information at a first light sensor co-located with a first light emitter of at least a first wavelength, the first light information based on a reflection of light emitted by the first light emitter, wherein receiving the first light information includes receiving a plurality of first light information data points over a plurality of collection times;receiving second light information at a second light sensor co-located with a second light emitter of at least a second wavelength, different from the first wavelength, the second light information based on a reflection of light emitted by the second light emitter, the second light sensor and the second light emitter separate and distinct from the first light sensor and the first light emitter, respectively,wherein receiving the second light information includes receiving a plurality of second light information data points over the plurality of collection times;for each of the plurality of collection times, associating the first information with the collection time to the second information associated with the collection time;generating a scatterplot using the associations of the first information to the second information with the collection time;comparing the generated scatterplot to a stored scatterplot;determining one or more physical characteristics of a vasculature of a user based on the comparison; andidentifying the user of the electronic device based on the one or more physical characteristics of the vasculature.","20","15/038419","2013-12-30","2016-0296142","2016-10-13","9668676","2017-06-06","Apple Inc.","Daniel J.  Culbert","","","","A61B-0005/117","A61B-0005/117 | A61B-0005/0205 | A61B-0005/02416 | A61B-0005/14551 | A61B-0005/6824 | A61B-0005/6898 | A61B-0005/7246 | G06F-0003/017 | G06F-0021/32 | G06K-0009/00885 | A61B-0005/02438 | G06K-0009/00355 | G06K-2009/00939","A61B-005/117","A61B-005/117 | A61B-005/00 | A61B-005/0205 | A61B-005/024 | A61B-005/1455 | G06F-021/32 | G06F-003/01 | G06K-009/00","","","","","","4917023000934"
"US","US","P","B2","Image display device and medical image capturing device","An object of the present invention is to display measurement result with maintaining good visibility for a peripheral part of measurement area. The image display device of the present invention comprises a cursor processing part that performs control for generating an area cursor 81 that indicates a measurement area on a medical image, an identification label 83 including identification information for specifically identifying the area cursor 81, and a result label 82 including the identification information and a measurement result, and displaying them on a screen, and an operation part that receives an operation of setting the area cursor and moving the result label. When the area cursor 81 is set, the result label 82 is attached to the area cursor 81, and they are displayed. Then, an operation for moving the result label 82 is performed, the result label 82 is separated from the area cursor 81, and made movable, an identification label 83 is attached to the area cursor 81 instead of the result label 82, and they are displayed.","1. An image display device comprising: a first operation part that receives an operation of specifying a measurement area on a medical image displayed on a screen of a display device,a measurement part that measures a physical quantity of the measurement area,a cursor processing part that performs control for generating an area cursor that indicates the measurement area, an identification label including identification information for specifically identifying the area cursor, and a result label including the identification information and a measurement result obtained by the measurement part, and displaying them on the screen, anda second operation part that receives an operation of moving the result label,wherein:when the first operation part receives specification of the measurement area, the cursor processing part displays the area cursor, when the measurement performed by the measurement part is completed, the cursor processing part attaches the result label to one end point of the area cursor and displays them, and when the second operation part receives an operation of moving the result label, the cursor processing part separates the result label from the area cursor and displays it following the moving operation, and displays the identification label at the one end point of the area cursor at which the result label has been attached.","17","14/419259","2013-07-11","2015-0220240","2015-08-06","9671925","2017-06-06","HITACHI, LTD.","Kenta  Tsukijishin | Kouhei  Motoki","2012-187966","JP","2012-08-28","G06F-0003/04812","G06F-0003/04812 | A61B-0005/7445 | A61B-0090/37 | G06F-0003/0482 | G06F-0003/04847 | G06F-0019/321 | G06F-0019/3406 | G06T-0007/0012 | A61B-0008/0858 | A61B-2090/374 | A61B-2090/378 | A61B-2090/3762 | G06T-2207/10072 | G06T-2207/30004","G06F-003/0481","G06F-003/0481 | A61B-005/00 | G06F-019/00 | G06F-003/0482 | G06F-003/0484 | G06T-007/00 | A61B-090/00 | A61B-019/00 | A61B-008/08","","","","","","4917023004160"
"US","US","P","B2","Producing a three-dimensional model of an implant","Determining a shape of a medical device to be implanted into a subject produces an image including a defective portion and a non-defective portion of a surface of a tissue of interest included in the subject. The tissue of interest is segmented within the image. A template, representing a normative shape of an external anatomical surface of the tissue of interest, is superimposed to span the defective portion. An external shape of an implant, is determined as a function of respective shapes of the defective portion as seen in the template, for repairing the defective portion.","1. A computer implemented method of obtaining data for determining a three-dimensional shape of a medical device, the method comprising: rendering a computer-generated three-dimensional representation of a target tissue from computer readable image data of the target tissue wherein the target tissue comprises two portions, a portion with a defect and a portion without a defect;identifying anatomical landmarks on the computer-generated three-dimensional representation of the target tissue;superimposing onto the rendered computer-generated three-dimensional representation of the target tissue a three-dimensional template to span the defective portion;deforming the three-dimensional template to match the identified anatomical landmarks to determine the three-dimensional shape of the medical device.","9","15/075498","2016-03-21","2016-0203241","2016-07-14","9672302","2017-06-06","CASE WESTERN RESERVE UNIVERSITY | OSTEOPLASTICS, LLC","Howard David  Dean | Krishnamoorthy  Subramanyan | Alexandros T.  Moullas | Robert A.  Ratcheson","","","","G06F-0017/50","G06F-0017/50 | A61B-0005/103 | A61B-0005/1075 | A61B-0034/10 | A61F-0002/2875 | A61F-0002/30942 | G05B-0019/4099 | G06T-0015/00 | G06T-0019/00 | A61B-2034/108 | G05B-2219/49023 | G06T-2210/41 | Y10S-0128/923 | Y10S-0623/911","A61B-005/00","A61B-005/00 | G06F-017/50 | A61B-005/107 | A61B-034/10 | G05B-019/4099 | G06T-019/00 | A61B-005/103 | A61F-002/30 | G06T-015/00 | A61F-002/28","","","","","","4917023004531"
"US","US","P","B2","Method for creating a surgical resection plan for treating a pathological deformity of a bone","The invention relates to a method for creating a surgical resection plan for treating a pathological deformity of a bone.","1. Method for creating a surgical resection plan for treating a pathological deformity of a bone having a rim bounding a substantially hemispherical cavity of the bone, comprising: receiving a set of 3D medical images of said bone,defining from said 3D medical images patient anatomical landmark data comprising a center of said substantially hemispherical cavity in a patient referential, a rim axis extending from said center and generally perpendicular to the opening plane of said substantially hemispherical cavity, a circumferential coordinate system assigned to said rim and a plurality of points located along the rim,determining from said patient anatomical landmark data a 3D patient coverage curve comprising, in the circumferential coordinate system assigned to the rim, a plurality of points representing a coverage parameter of the bone with respect to the substantially hemispherical cavity at a plurality of points along the rim, wherein, for each of said plurality of rim points, said coverage parameter is computed from the coverage angle between (i) the rim axis and (ii) a radius connecting the center of the substantially hemispherical cavity and the respective rim point,receiving reference data corresponding to a reference rim morphology, said data comprising a 3D reference coverage curve,creating: a 3D surface model of at least a part of the bone including the rim from said set of 3D images, anda 3D reference rim morphology model from the 3D reference coverage curve,computing and displaying a virtual resection of the bone onto the 3D surface model tosimulate removal of over-covered bone portions.","19","14/906679","2014-07-25","2016-0253846","2016-09-01","9672662","2017-06-06","A2 SURGICAL | SMITH & NEPHEW, INC.","Sean  Scanlan | Stephane  LaVallee | Laurence  Chabanas | Asheesh  Bedi | Thomas  Byrd | Bryan  Kelly | Christopher  Larson","2013-306077","EP","2013-07-25","G06T-0019/20","G06T-0019/20 | A61B-0005/055 | A61B-0005/4504 | A61B-0005/4571 | A61B-0006/032 | A61B-0006/505 | A61B-0008/0875 | A61B-0008/483 | A61B-0034/10 | G06F-0003/04815 | G06F-0003/04845 | G06T-0007/0014 | G06T-0007/0022 | G06T-0007/0044 | G06T-0007/0051 | G06T-0007/0081 | G06T-0007/0091 | G06T-0017/00 | A61B-2034/105 | G06T-2207/10072 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/10136 | G06T-2207/30008","G06T-019/20","G06T-019/20 | G06T-007/00 | A61B-034/10 | A61B-005/055 | A61B-005/00 | A61B-006/03 | A61B-006/00 | A61B-008/08 | G06F-003/0481 | G06F-003/0484 | G06T-017/00","","","","","","4917023004890"
"US","US","P","B2","Tactile imaging system","One embodiment of the present invention provides a tactile imaging system. The tactical imaging system includes: a receptive field tactile control unit; and a connecting module configured to connect the tactile imaging system with a host system. In addition, the receptive field tactile control unit includes: a monitoring module configured to monitor a property of a human skin; and a tactile stimulation providing module configured to provide a tactile stimulation.","1. A tactile imaging system comprising: a receptive field tactile control unit; anda connecting module configured to connect the tactile imaging system with a host system,wherein the receptive field tactile control unit includes: a monitoring module configured to monitor a property of a human skin; anda tactile stimulation providing module configured to provide a tactile stimulation,wherein the connecting module includes: a processor; anda host interface,wherein the processor generates a contact event based on information received from the monitoring module, andwherein the processor controls the tactile stimulation based on an effect parameter stored in a memory thereof or based on information received from the host system through the host interface.","18","14/794264","2015-07-08","2016-0012689","2016-01-14","9672701","2017-06-06","TAMPEREEN YLIOPISTO | FUKOKU CO., LTD.","Grigori  Evreinov | Ahmed  Farooq | Roope  Raisamo | Arto  Hippula | Daisuke  Takahata","2014-141263","JP","2014-07-09","G08B-0006/00","G08B-0006/00 | A61B-0005/0531 | A61N-0001/36 | G06F-0003/016","H04B-003/36","H04B-003/36 | G08B-006/00 | A61B-005/053 | A61N-001/36 | G06F-003/01","","","","","","4917023004928"
"US","US","P","B1","Media playback after reduced wakefulness","Technology for media playback is provided. In one example, a method may include identifying playback of media. Wakefulness data may be collected during the consumption from a wakefulness detector. A determination may be made whether an asleep state exists. The determination may be based on the wakefulness data collected from the wakefulness detector and based on historical user sleep data. The method may include terminating the playback of the media when the asleep state is determined to exist and resuming playback of the media upon request.","1. A computing device that is configured to resume playback of digital media, comprising: a processor;a memory in electronic communication with the processor;instructions stored in the memory, the instructions being executable by the processor to:identify playback of the digital media for consumption;collect wakefulness data from a plurality of discrete devices, the wakefulness data being indicative of a wakefulness during the consumption of the digital media and at periodic intervals during the consumption;determine a state of reduced wakefulness at the periodic intervals by comparing the wakefulness data with historical user sleep data and by weighting wakefulness data from the plurality of discrete devices based on historical accuracy of the plurality of discrete devices for predicting the state of reduced wakefulness;wherein the state of reduced wakefulness comprises an asleep state and a state at which a user is falling asleep; andwherein the historical user sleep data comprises historical wakefulness data;reduce a volume of audio associated with the playback of the digital media during the state at which the user is falling asleep;terminate the playback of the digital media at a termination point when the asleep state is determined to exist;set a resume playback position for the digital media at a resume point in the digital media, wherein the resume point is prior to the termination point; andresume playback of the digital media at the resume playback position when consumption of the digital media resumes.","18","14/645329","2015-03-11","","","9665169","2017-05-30","AMAZON TECHNOLOGIES, INC.","Rong  Dai | Georges Raouf Georges  Bargoud | Bashar Mohd  Qudah | Shouda  Wang","","","","G06F-0003/011","G06F-0003/011 | A61B-0005/0077 | A61B-0005/02055 | A61B-0005/11 | A61B-0005/4809 | A61B-0005/7475 | A61B-0007/04 | G06F-0003/015 | A61B-0005/01 | A61B-0005/024","G06F-017/00","G06F-017/00 | G06F-003/01 | A61B-005/00 | A61B-007/04 | A61B-005/0205 | A61B-005/11 | A61B-005/024 | A61B-005/01","","","","","","4917022003997"
"US","US","P","B2","System for monitoring caregivers and equipment","A hospital monitoring system for monitoring hospital personnel, a plurality of patient locations for patients, and associated devices is configured to control the associated devices based on the presence of hospital personnel or alarms.","1. A nontransitory method of monitoring a patient room of a healthcare facility, the method comprising: monitoring a patient room for a signal indicating presence of a caregiver in the patient room,detecting an alarm of at least one piece of patient care equipment in the patient room,if the caregiver is present in the patient room when the alarm occurs, permitting the alarm to sound for a predetermined amount of time and then signaling the at least one piece of patient care equipment to silence the alarm after the predetermined amount of time has elapsed, andif the caregiver is not present in the patient room when the alarm occurs, signaling the at least one piece of patient care equipment to silence the alarm in response to the caregiver'ss presence being detected in the patient room after the alarm sounds.","20","14/976388","2015-12-21","2016-0148489","2016-05-26","9666061","2017-05-30","Hill-Rom Services, Inc.","Ryan A.  Reeder | Kenneth L.  Kramer | William L.  Jacques | Carl William  Riley | Richard J.  Schuman","","","","G08B-0025/008","G08B-0025/008 | A61B-0005/0002 | A61B-0005/1113 | A61B-0005/742 | A61B-0005/7475 | A61G-0012/00 | G06F-0019/3406 | G06F-0019/3418 | G06F-0019/3487 | G08B-0021/02 | G08B-0021/0453 | A61B-0005/02055 | A61B-2560/0242 | A61B-2560/0443 | A61B-2560/0456 | A61G-0005/10 | A61G-0007/018 | A61G-0007/05 | A61G-0011/00 | A61G-2203/12 | A61G-2203/46 | A61G-2203/80 | A61G-2205/10 | G06F-0019/322 | G06F-0019/327 | G06F-0019/3425 | G06F-0019/3456 | G06F-0019/3481","G08B-025/00","G08B-025/00 | A61B-005/00 | A61B-005/11 | A61G-012/00 | G08B-021/02 | G08B-021/04 | A61B-005/0205 | A61G-005/10 | A61G-007/018 | A61G-007/05 | A61G-011/00 | G06F-019/00","","","","","","4917022004878"
"US","US","P","B2","Inter-apparatus connection verification support system, web server apparatus and inter-apparatus connection verification method","A system includes a medical diagnostic imaging apparatus configured to generate medical images of subjects and to generate connection verification support information to be used by a connection-target apparatus to verify connection with medical diagnostic imaging apparatus; a peripheral apparatus expected to be connected with the medical diagnostic imaging apparatus via a communication network and configured to operate the medical images generated by the medical diagnostic imaging apparatus; and a web server apparatus configured to record the connection verification support information generated by the medical diagnostic imaging apparatus. The peripheral apparatus verifies connection with the medical diagnostic imaging apparatus by using the connection verification support information acquired from the web server apparatus.","1. An inter-apparatus connection verification support system comprising: a medical diagnostic imaging apparatus configured to generate a medical image of a subject and to generate connection verification support information to be used by a connection-target apparatus to verify connection with the medical diagnostic imaging apparatus;a peripheral apparatus expected to be connected with the medical diagnostic imaging apparatus via a communication network and configured to operate the medical image generated by the medical diagnostic imaging apparatus; anda web server apparatus configured to record the connection verification support information generated by the medical diagnostic imaging apparatus;wherein the peripheral apparatus verifies connection with the medical diagnostic imaging apparatus by using the connection verification support information acquired from the web server apparatus;wherein the medical diagnostic imaging apparatus includes processing circuitry configured to: collect, as request item information, specification items matched with items requested by the peripheral apparatus from the specification information; andidentify measurement data in conformance to the request item information;wherein the web server apparatus includes processing circuitry configured to: receive request items and information on specifications of the medical diagnostic imaging apparatus; andgenerate the connection verification support information to be used by the peripheral apparatus to verify the connection, on the basis of the specification information outputted from the medical diagnostic imaging apparatus and the request items outputted from the peripheral apparatus.","6","14/521938","2014-10-23","2015-0046585","2015-02-12","9667520","2017-05-30","TOSHIBA MEDICAL SYSTEMS CORPORATION","Kenshi  Nakano","2012-196234 | 2013-183647","JP | JP","2012-09-06 | 2013-09-05","H04L-0043/10","H04L-0043/10 | A61B-0005/0013 | A61B-0005/7475 | A61B-0006/563 | A61B-0008/565 | G06F-0013/10 | G06F-0019/321 | G06F-0019/3406 | G06Q-0010/10 | G06Q-0050/24 | H04L-0067/02 | H04L-0067/12 | A61B-0005/0022 | A61B-0005/0555","G06F-015/173","G06F-015/173 | H04L-012/26 | G06Q-050/24 | G06Q-010/10 | A61B-005/00 | G06F-013/10 | A61B-006/00 | A61B-008/00 | G06F-019/00 | H04L-029/08 | A61B-005/055","","","","","","4917022006319"
"US","US","P","B2","Use of machine learning for classification of magneto cardiograms","The use of machine learning for pattern recognition in magnetocardiography (MCG) that measures magnetic fields emitted by the electrophysiological activity of the heart is disclosed herein. Direct kernel methods are used to separate abnormal MCG heart patterns from normal ones. For unsupervised learning, Direct Kernel based Self-Organizing Maps are introduced. For supervised learning Direct Kernel Partial Least Squares and (Direct) Kernel Ridge Regression are used. These results are then compared with classical Support Vector Machines and Kernel Partial Least Squares. The hyper-parameters for these methods are tuned on a validation subset of the training data before testing. Also investigated is the most effective pre-processing, using local, vertical, horizontal and two-dimensional (global) Mahanalobis scaling, wavelet transforms, and variable selection by filtering.","1. A method for automating the identification of meaningful features and the formulation of expert rules for classifying magnetocardiography data, comprising: applying a wavelet transform to sensed data acquired from sensors sensing magnetic fields generated by a patient'ss heart activity, resulting in wavelet domain data; andfollowing additional transformation of said wavelet domain data, identifying said meaningful features and formulating said expert rules therefrom, using machine learning.","20","14/928833","2015-10-30","2016-0066860","2016-03-10","9655564","2017-05-23","Cardio Mag Imaging, Inc.","Karsten  Sternickel | Boleslaw  Szymanski | Mark  Embrechts","","","","A61B-0005/7267","A61B-0005/7267 | A61B-0005/04007 | A61B-0005/726 | A61B-0005/7253 | G06K-0009/00496 | G06K-0009/00523 | G06N-0003/086 | A61B-0005/7203 | A61B-2560/0475 | G06F-0019/345","A61B-005/04","A61B-005/04 | A61B-005/00 | G06K-009/00 | G06N-003/08 | G06F-019/00","","","","","","4917021000911"
"US","US","P","B2","Visualization guided ACL localization system","A computerized system provides assistance for placement of localization markers for medical operations such as ACL repair procedures. The system displays, on a graphical user interface, an image of an anatomical structure and allows identification, via an input device on the graphical user interface, of a set of landmark locations identifying respective anatomical positions within the displayed image of the anatomical structure. The system displays a graphical overlay over the image of the anatomical structure. Placement of the graphical overlay is based on the set of landmark locations. The system displays at least one localization marker within the graphical overlay. The localization marker(s) identify a location for performing a surgical operation associated with the anatomical structure, such as ACL repair surgical operations.","1. In a computerized device, a method comprising: displaying, on a graphical user interface, an image of knee joint including a graphical view of a femur and a tibia;identifying, via an input device on the graphical user interface, a set of landmark locations identifying respective anatomical positions within the displayed image of the anatomical structure, the identifying by: receiving a structure selection of a specific anatomical structure to which landmark locations are to be provided, the structure selection defining a number of landmark locations to be identified;receiving a selection, via a graphical pointer on the graphical user interface, of a first known bone location and a second known bone location associated with the at least one bone; anddisplaying a graphical overlay over the view of the at least one femur and the tibia within the image, placement of the graphical overlay based on the set of landmark locations, the displaying the graphical overlay comprising rendering the graphical overlay between the selected first known bone location and the selected second known bone location, the graphical overlay including a series of guidance indicators operable to indicate positions associated to the anatomical structure for performing the surgical operation associated with the anatomical structure, and the graphical overlay enabling ease of determination of at least one reference location to be marked by at least one localization marker for performing a surgical operation related to repair of a ligament of the human knee joint; anddisplaying at least one localization marker within the graphical overlay, the at least one localization marker identifying a location for performing a surgical operation associated with the anatomical structure;wherein displaying an image showing a view of a femur and tibia within a human knee joint comprises: displaying a lateral view of the femur within a human knee joint;wherein receiving a selection of first and second known bone locations comprises: receiving, as the first known bone location, a selection of an anterior edge of the view of the femur displayed within the image;receiving, as the second known bone location, a selection of a posterior edge of the view of the femur displayed laterally within the image, a line defined between the first know bone location and the second know bone location defining a plane that substantially aligns with a patellar surface of the femur; and wherein the method comprises:receiving a selection of a third known bone location corresponding to the laterally displayed distal condyle surface of the femur within the image; andwherein displaying a graphical overlay over the image of the anatomical structure comprises: displaying an overlay grid over the view of the distal end of the femur within the graphical user interface, the overlay grid having a width rendered between the selected first and second known bone locations, and having a height that extends to the selected third known bone location.","5","14/962667","2015-12-08","2016-0192992","2016-07-07","9655682","2017-05-23","ADVANCED CONCRETE SOLUTIONS, LLC | SMITH & NEPHEW, INC.","Paul Robert  Duhamel | Carlos  Rodriguez | Charles H.  Brown","","","","A61B-0034/10","A61B-0034/10 | A61B-0001/00045 | A61B-0001/317 | A61B-0005/7264 | A61B-0034/25 | G06F-0003/04812 | G06F-0003/04842 | G06T-0007/0012 | G06T-0007/0014 | G06T-0011/60 | A61B-0090/36 | A61B-2034/105 | A61B-2034/107 | A61B-2090/3983 | A61B-2560/0475 | A61B-2576/02 | G06T-2200/24 | G06T-2207/20101 | G06T-2207/20221 | G06T-2207/30008","G06T-011/00","G06T-011/00 | A61B-034/10 | G06T-007/00 | A61B-001/00 | A61B-001/317 | A61B-005/00 | A61B-034/00 | G06F-003/0481 | G06F-003/0484 | G06T-011/60 | A61B-090/00","","","","","","4917021001029"
"US","US","P","B2","Medical device identifier","A medical device identifier can identify an implanted medical device. In one example arrangement, the medical device identifier sends electromagnetic signals to the implanted device according to one or more stored digitized waveforms. The device then senses any returned electromagnetic signals, and identifies the implanted device based on the returned electromagnetic signals. The medical device identifier may generate the electromagnetic signals from the stored digitized waveforms using an analog-to-digital converter, and may compare the returned electromagnetic signals with one or more stored digital templates corresponding to different device manufacturers. The comparison may be performed using cross correlation. In another aspect, a portal device includes an identification subsystem for identifying the provider of a medical device, and a communication subsystem for establishing two-way communication a call center servicing medical devices from an identified provider. The portal device may relay information between the medical device and the identified provider.","1. A medical device identifier, comprising: a coil;a computer subsystem comprising a processor and memory, the memory holding instructions executable by the processor and also holding a plurality of digitized waveforms;a digital-to-analog converter coupled to the processor;drive circuitry coupled to the coil and the digital-to-analog converter; andreceiver circuitry coupled to the coil and the computer subsystem;wherein the instructions, when executed by the processor, cause the medical device identifier to:sequentially excite the coil, via the digital-to-analog converter and the drive circuitry, to generate electromagnetic waveforms corresponding to one or more of the digitized waveforms;receive and digitize, via the coil and the receiver circuitry, a returned electromagnetic waveform transmitted from a medical device in response to the electromagnetic waveforms generated by the medical device identifier; andidentify the medical device based on the digitized returned electromagnetic waveform, wherein the memory further holds a plurality of digital templates corresponding to different medical devices, and wherein the instructions, when executed by the processor, cause the medical device identifier to identify the medical device based on a comparison of the digitized returned electromagnetic waveform with the plurality of digital templates.","18","13/942465","2013-07-15","2014-0019076","2014-01-16","9649165","2017-05-16","BOARD OF REGENTS, THE UNIVERSITY OF TEXAS SYSTEM | CARDIAC INNOVATION, LLC","Rodney P.  Horton | John Anthony  Pearce | Jonathan Walker  Valvano","","","","A61B-0019/44","A61B-0019/44 | A61B-0005/74 | A61B-0090/90 | A61N-0001/3718 | A61N-0001/37235 | A61N-0001/37252 | G06F-0019/3406 | H04W-0012/00 | A61B-0001/00112 | A61B-0005/00 | A61B-2562/08 | A61N-0001/3727 | A61N-0001/37288 | G06F-0017/40 | G06F-0019/00 | G06F-0019/3481 | H03M-0003/00 | H04B-0001/401 | H04L-0013/02 | H04M-0003/00","H04W-012/00","H04W-012/00 | H04M-003/00 | H04L-013/02 | G06F-017/40 | G06F-019/00 | A61B-019/00 | A61N-001/37 | A61B-090/90 | A61B-001/00 | A61B-005/00 | H03M-003/00 | A61N-001/372 | H04B-001/401","","","","","","4917020001028"
"US","US","P","B2","Enabling continuous or instantaneous identity recognition of a large group of people based on physiological biometric signals obtained from members of a small group of people","The present invention is a biometric security system and method operable to authenticate one or more individuals using physiological signals. The method and system may comprise one of the following modes: instantaneous identity recognition (MR); or continuous identity recognition (CIR). The present invention may include a methodology and framework for biometric recognition using physiological signals and may utilize a machine learning utility. The machine learning utility may be presented and adapted to the needs of different application environments which constitute different application frameworks. The present invention may further incorporate a method and system for continuous authentication using physiological signals and a means of estimating relevant parameters.","1. A biometric security system operable to authenticate one or more individuals, said system characterized in that it comprises: a) a device operable to obtain one or more physiological signals of each of the one or more individuals, wherein the one or more individuals are initially enrolled in the biometric security system and the one or more individuals are members of a small scale frame work of individuals that were previously identified before the device is employed to currently obtain the one or more physiological signals;b) a machine learning utility connected to the device, said machine learning utility being operable to biometrically process the one or more physiological signals to determine a variability of physiological signals for a larger population of the one or more individuals based on the one or more physiological signals obtained from the individual members of the small scale frame work, and to identify or verify the identity of each of the one or more individuals, wherein the machine learning utility is trained with recordings of one or more older physiological signals that were previously obtained from the previously identified individuals that are members of the small scale frame work and the larger population of the one or more individuals; andc) one or more databases connected to the machine learning utility operable to store one or more biometrically processed physiological signals.","22","14/116058","2012-05-10","2014-0188770","2014-07-03","9646261","2017-05-09","NYMI INC.","Foteini  Agrafioti | Francis Minhthang  Bui | Dimitrios  Hatzinakos","","","","G06N-0099/005","G06N-0099/005 | A61B-0005/117 | A61B-0005/7267 | G06F-0021/316 | G06F-0021/32 | G06K-0009/00006 | G06K-0009/00885 | A61B-0005/04012 | G06K-2009/00939 | H04L-0063/0861","G06F-015/18","G06F-015/18 | G06N-099/00 | A61B-005/117 | G06F-021/31 | G06F-021/32 | G06K-009/00 | A61B-005/00 | A61B-005/04 | H04L-029/06","","","","","","4917019004603"
"US","US","P","B2","System, method and computer program product for providing a healthcare user interface and incentives","Actively engaging members in managing their own healthcare, improving their health, and reducing healthcare costs to the payer involves providing a unified interface for member engagement. The interface may be communicatively coupled with a healthcare system, may be personalized to the member, and may offer multiple possible rewards to the member to encourage member behavior to effectively reduce healthcare costs and improve the quality of healthcare plans. The interface may provide the member with a pathway guiding the member to engage in activities to achieve short-term, intermediate and long-term goals for which actions are presented. Goals or actions may be predefined and may additionally be selected by the member. When member-engagement in the actions is verified, rewards may be granted to the member's account. In connection with such member engagement, the healthcare system collects member information, applies rules to that information, and generates alerts from those rules.","1. A computer-implemented method of encouraging healthy behavior, the method comprising the steps of: receiving, at a server, health-related member information with respect to a member of a health plan;applying evidence-based medicine rules to the received member information to identify actions to improve the member'ss health or health risk, wherein the actions may be pending or completed;comparing the received member information with the identified actions to determine whether the actions are completed; andfor completed actions, granting rewards under a rewards program, the rewards program comprising a sequence of steps including at least one action that is verifiable and at least one action that is non-verifiable, each step in the sequence being associated with a reward;wherein granting rewards for the at least one verifiable action comprises verifying completion of the at least one verifiable action by obtaining biometric data from an authenticated biometric device that confirms or denies completion of the at least one verifiable action, wherein the biometric data comprises biometric data selected from the group consisting of blood pressure data, glucose level data, cholesterol data, and weight data, and wherein the authenticated biometric device reports one or more of blood pressure, glucose level, cholesterol, or weight;wherein granting rewards for the at least one non-verifiable action comprises receiving non-verifiable medical information or self-reported member data and the granted rewards for the at least one non-verifiable action are based thereon; andwherein the completed verified action is granted a first level of reward and the completed non-verifiable action is granted a second level of reward having a lesser value relative to the first.","20","14/180694","2014-02-14","2015-0235006","2015-08-20","9633174","2017-04-25","OPTUM, INC.","Matt  Nichols","","","","G06F-0019/3475","G06F-0019/3475 | A61B-0005/0002 | A61B-0005/7275 | G06F-0019/324 | G06F-0019/328 | G06F-0019/345 | G06F-0019/3418 | G06F-0019/3431 | G06F-0019/3456 | G06F-0019/3481 | G06F-0019/3487 | G06F-0019/363","G06Q-010/10","G06Q-010/10 | G06Q-030/02 | G06F-019/00 | A61B-005/00","","","","","","4917017004514"
"US","US","P","B2","Image analysis method and apparatus for assessment of peritoneal dialysis complication in peritoneal dialysis","An image analysis method and an apparatus thereof for assessment of PD (peritoneal dialysis) complications in peritoneal dialysis are provided. An analysis procedure is executed on an image under test of a dialysis bag, so as to obtain a color location in a color space corresponding to the image under test. A prompt signal is sent when the color locations obtained in a time period gradually become close to a disease warning range after executing the analysis procedure on a plurality of images under test.","1. An image analysis method for assessment of a peritoneal dialysis complication in peritoneal dialysis, comprising: capturing an image under test of a dialysis bag;executing an analysis procedure on the image under test, comprising: executing an edge detection on the image under test to obtain a region of interest;executing a color detection on a plurality of pixels included in the region of interest to obtain original color information corresponding to the region of interest;executing a color correction on the original color information to obtain corrected color information;converting the corrected color information to a color location in a color space; andcomparing the color location with a plurality of disease warning ranges recorded in a database;continuing to capture another image under test of another dialysis bag and executing the analysis procedure on the another image under test; andafter continuously executing the analysis procedure on a plurality of the images under test, sending a prompt signal when detecting that the color locations of the images under test captured in a time period gradually becomes close to one of the disease warning ranges.","10","14/957601","2015-12-03","2017-0039700","2017-02-09","9633432","2017-04-25","NATIONAL TSING HUA UNIVERSITY | NATIONAL TAIWAN UNIVERSITY | NATIONAL TAIWAN UNIVERSITY HOSPITAL","Hung-Shao  Chen | Jenq-Wen  Huang | Hsi-Pin  Ma","104125440 A","TW","2015-08-05","G06T-0007/0012","G06T-0007/0012 | A61M-0001/28 | G06T-0005/20 | G06T-0007/13 | G06T-0007/90 | H04L-0067/1097 | A61M-2205/52 | G06T-2207/10024 | G06T-2207/30084","G06T-007/00","G06T-007/00 | A61M-001/28 | G06T-005/20 | H04L-029/08 | G06T-007/90 | G06T-007/13","","","","","","4917017004770"
"US","US","P","B2","Quantification and inventory management of expressed human breast milk","Systems, methods, and devices for milk expression are provided. In one aspect, a system includes an expression apparatus having an interface configured to engage a breast and an actuation assembly operably coupled to the interface. Actuation of the actuation assembly causes the interface to apply vacuum pressure against the breast to express milk from the breast. The system also includes various sensors for quantifying characteristics of the expressed milk, and a unique identifier allows inventory management of the expressed milk.","1. A system for quantifying expressed milk from a human breast, said system comprising: a breast milk expression device configured to express milk from the breast;a reservoir fluidly coupled to the breast milk expression device and configured to collect the expressed breast milk;a sensor unit integrated with the reservoir or the breast milk expression device and configured to quantify one or more attributes of the expressed breast milk; anda peripheral device in communication with the sensor unit, wherein the peripheral device is configured to obtain a unique identifier for the expressed breast milk and associate the unique identifier with the one or more attributes of the expressed breast milk.","51","14/858924","2015-09-18","2016-0082165","2016-03-24","9623160","2017-04-18","NAYA HEALTH, INC.","Jeffery B.  Alvarez | Janica B.  Alvarez | Nathaniel  Gaskin | Polina A.  Segalova","","","","A61M-0001/062","A61M-0001/062 | A61M-0001/06 | G06Q-0010/087 | A61M-2205/071 | A61M-2205/3393 | A61M-2205/502 | A61M-2205/6072","G06F-017/00","G06F-017/00 | A61M-001/06 | G06Q-010/08","","","","","","4917016001516"
"US","US","P","B2","Pocketed concrete anchor","The invention provides for a pocketed anchor for post-tensioned concrete reinforcement. The anchor includes a body having a flange portion with a front and rear surface, a button portion extending from the rear surface, and a nose portion extending from the front surface. The anchor also includes a tapered bore that extends through the nose, flange, and button portions. The bore can receive a wedge that cams against the bore to clamp down on a tendon. The front surface of the flange has at least two planar surfaces that are parallel to the bearing surface on the rear surface of the anchor. One of the planar surfaces is recessed relative to the other such that the recessed surface is closer to the load bearing surface on the rear surface of the anchor. The two planar surfaces define a pocket on the anchor, where mounting holes may be located.","1. An anchor for post-tensioned concrete reinforcement, comprising: a body having a flange portion with a front surface, a rear surface, an edge surface extending between the front surface and the rear surface, a button portion extending from the rear surface of the flange, and a nose portion extending from the front surface of the flange, the flange extending laterally from the nose portion and from the button portion so as to have at least one bearing surface on the rear surface of the flange to one lateral side of the button portion and an opposite surface on the front surface of the flange to the one lateral side of the nose portion opposite from the bearing surface;ribs on the front surface that extend between the nose portion and the flange portion;a bore extending through the nose portion, the flange portion, and the button portion, the bore being tapered in diameter in the direction from the nose portion to the button portion to receive a wedge that cams against the bore to clamp down on a tendon that extends into the bore from where the tendon enters the bore through the button portion;wherein the opposite surface on the front of the flange includes at least two planar surfaces that define a pocket on the front surface of the flange; andwherein a hole is formed in the pocket and the hole is closer to an outer edge of the pocket than it is to an inner edge of the pocket.","27","15/130769","2016-04-15","2016-0230390","2016-08-11","9624668","2017-04-18","ACTUANT CORPORATION","Frantz  Stanford","","","","E04C-0005/12","E04C-0005/12 | E04C-0005/122 | G06F-0003/04842","A61B-019/00","A61B-019/00 | E04C-005/12 | G06F-003/0484","","","","","","4917016003012"
"US","US","P","B2","Terminal, system, display method, and recording medium storing a display program","A communication terminal for communicating with a counterpart communication terminal includes a receiver that receives image data including an eye image of a user operating the counterpart communication terminal from the counterpart communication terminal, the eye image of the user being captured at the counterpart communication terminal while the user is viewing a predetermined position on a counterpart display and circuitry that specifies a sightline position indicating a sightline position of the user operating the counterpart communication terminal based on the received image data every time the image data is received by the receiver, determines a frequency of changes in the specified sightline position for a predetermined time period, and displays information indicating the frequency of changes in the specified sightline position on a display.","1. A first communication terminal for communicating with a counterpart communication terminal, the first communication terminal comprising: a receiver configured to receive image data including an eye image of a user operating the counterpart communication terminal from the counterpart communication terminal, the eye image of the user being captured at the counterpart communication terminal and indicating which of a plurality of positions on a counterpart display the user is viewing when the eye image is captured, the counterpart display being a display of the counterpart terminal; andcircuitry configured to, display a first screen on a first display, the first display being a display of the first communication terminal,cause the counterpart terminal to display the first screen on the counterpart display by transferring shared screen data to the counterpart terminal,specify a sightline position indicating a sightline position of the user operating the counterpart communication terminal based on the received image data when the image data is received by the receiver,determine a frequency of changes in the specified sightline position for a first time period, andcause information indicating the frequency of changes in the specified sightline position to be displayed on the first and counterpart displays.","10","14/995328","2016-01-14","2016-0261826","2016-09-08","9621847","2017-04-11","RICOH COMPANY, LTD.","Takuya  Mizuhara","2015-039781","JP","2015-03-02","H04N-0007/147","H04N-0007/147 | A61B-0003/0025 | A61B-0003/0041 | A61B-0003/113 | A61B-0005/0013 | A61B-0005/165 | G06F-0003/013 | G06K-0009/00597 | H04N-0007/155","H04N-007/14","H04N-007/14 | A61B-003/113 | A61B-005/00 | A61B-005/16 | A61B-003/00 | G06F-003/01 | G06K-009/00 | H04N-007/15","","","","","","4917015007036"
"US","US","P","B2","Multi-track playback of media content during repetitive motion activities","A system for multi-track playback of media content includes: a media device; a user interface, provided at the media device, which displays a visual array of media options, a playback logic, provided within the media device, which is configured so that, while a selected point or region is determined by the user interface as being moved in response to user input, within the visual array of media options, the system determines media options that are proximate to the selected point or region, and adjusts playback parameters for corresponding media content items, by crossfading or otherwise combining playback to reflect the media options relative distances from the selected point or region; and a tempo logic, provided within the media device, which is configured to provide or receive a selected tempo and provide the one or more media content items associated with the selected tempo.","1. A system for multi-track playback of media content while a repetitive-motion activity is performed by a user, comprising: a media device, including a processor;a tempo logic, provided within the media device, configured to identify a cadence of the repetitive-motion activity performed by the user and provide a plurality of media content items associated with a tempo that corresponds to the cadence;a user interface, provided at the media device, which displays a visual array of media options, wherein each media option is associated with one of the plurality of media content items provided by the tempo logic that can be played on the media device;a playback logic, provided within the media device, which is configured so that, while a selected region is determined by the user interface as being moved in response to user input, within the visual array of media options, the system determines media options that are proximate to the selected region, and adjusts playback parameters for media content items corresponding to the determined media options to reflect the relative distances of the media options from the selected region.","20","14/883273","2015-10-14","2016-0342200","2016-11-24","9606620","2017-03-28","SPOTIFY AB","Dariusz  Dziuk | Rahul  Sen","","","","G06F-0003/011","G06F-0003/011 | A61B-0005/024 | A63B-0071/00 | G06F-0003/165 | G11B-0027/038 | G11B-0027/105 | G11B-0027/34 | A63B-2230/062","G06F-017/00","G06F-017/00 | G06F-003/01 | G11B-027/038 | G11B-027/10 | G11B-027/34 | A61B-005/024 | A63B-071/00 | G06F-003/16","","","","","","4917013003954"
"US","US","P","B2","Determining a user based on features","A signal may be emitted by an emitter or transducer. The signal may be sensed by a sensor, such as an accelerometer. Features of a body part or portion may be one of detected, extracted, or constructed from the sensed signal. It may be determined whether the body part or portion matches that of a user, such as an authorized user, based on the features.","1. A computing device, comprising: an emitter to emit an acoustic signal;a sensor to sense the acoustic signal after the acoustic signal has passed through a portion of a user'ss body;an extractor to extract multiple features of the portion of the user'ss body from the sensed acoustic signal; anda classifier to determine, based on the extracted multiple features, whether the portion of the user'ss body corresponds to a model of the portion of the user'ss body used by the classifier.","20","14/394513","2012-07-31","2015-0111537","2015-04-23","9609511","2017-03-28","HEWLETT-PACKARD DEVELOPMENT COMPANY, L.P.","Esra  Vural | Mark W  Van Order | Peter S  Nyholm | Stephanie  Schuckers","","","","H04W-0012/06","H04W-0012/06 | A61B-0005/0051 | A61B-0005/117 | A61B-0005/6898 | G06F-0021/32 | G06K-0009/00885 | H04W-0008/18 | A61B-0005/4869","H04M-001/66","H04M-001/66 | H04M-001/68 | H04M-003/16 | H04W-012/06 | A61B-005/117 | A61B-005/00 | G06K-009/00 | G06F-021/32 | H04W-008/18","","","","","","4917013006816"
"US","US","P","B2","Motion capture while fishing","Various implementations described herein are directed to a non-transitory computer readable medium having stored thereon computer-executable instructions which, when executed by a computer, may cause the computer to automatically receive motion capture data recorded by one or more cameras. The computer may analyze the motion capture data to detect a cast, catch, or bite. The computer may store a record of the cast, catch, or bite.","1. A non-transitory computer-readable medium having stored thereon a plurality of computer-executable instructions which, when executed by a computer, cause the computer to: receive motion capture data recorded by one or more cameras directed toward a fisherman during a fishing trip, wherein the motion capture data comprises motion of the fisherman during the fishing trip;analyze the motion capture data to detect an occurrence of a catch;determine, using a marine electronic device and in response to detecting the occurrence of the catch, a current location of the fisherman;determine, based on the motion capture data and in response to detecting the occurrence of the catch, fish characteristic data, wherein the fish characteristic data comprises at least one of a species of the caught fish, a length of the caught fish, or the length of fight that resulted in the caught fish; andstore a record of the catch, the current location, and the fish characteristic data in memory.","19","14/461394","2014-08-16","2015-0055827","2015-02-26","9596839","2017-03-21","NAVICO HOLDING AS","Paul Robert  Bailey","","","","A01K-0097/00","A01K-0097/00 | A01K-0079/00 | A01K-0099/00 | A61B-0005/1118 | A61B-0005/1123 | G01B-0021/00 | G01C-0021/20 | G01C-0021/203 | G06F-0003/014 | G06F-0003/017 | G06F-0003/0231 | G06F-0003/0346 | G06F-0011/3438 | G06F-0011/3476 | G06F-0015/0225 | G06F-0017/30867 | G06K-0009/00342 | G06Q-0010/00 | G06Q-0050/01 | G06T-0007/2033 | G06T-0007/2093 | G06T-0007/60 | G06T-0011/206 | G08C-0017/02 | G11B-0027/031 | G11B-0027/17 | G11B-0027/28 | G11B-0027/34 | G11B-0031/006 | H04N-0005/232 | H04N-0005/91 | H04N-0021/4335 | H04Q-0009/00 | B63B-0049/00 | G01S-0007/003 | G01S-0015/96 | G06F-0011/3013 | G06F-0011/3058 | G06F-2201/835 | G06T-2207/10016 | G06T-2207/30196 | G08C-2201/32 | H04Q-2209/43 | Y02B-0060/165","G06T-007/00","G06T-007/00 | A01K-097/00 | H04N-005/232 | H04N-005/91 | H04N-021/4335 | G08C-017/02 | G06F-003/01 | G06F-003/023 | G06F-015/02 | G06T-011/20 | G06T-007/20 | G06T-007/60 | G11B-027/031 | G11B-027/17 | G11B-031/00 | A01K-099/00 | G01C-021/20 | A61B-005/11 | G01B-021/00 | G06Q-010/00 | G06Q-050/00 | G06F-017/30 | A01K-079/00 | G06F-011/34 | G06K-009/00 | G11B-027/28 | G11B-027/34 | G06F-003/0346 | H04Q-009/00 | B63B-049/00 | G01S-015/96 | G06F-011/30 | G01S-007/00","","","","","","4917012000699"
"US","US","P","B2","Biological-information obtaining apparatus and method thereof","A biological-information obtaining apparatus includes a light-emitting unit configured to emit light, an image-capturing unit configured to capture images, in time sequence, obtained by irradiating a living body with the light emitted and by causing the light to be transmitted through or reflected by the living body, the image-capturing unit being sensitive to at least two color components, an extreme generation unit configure to generate, for each of the captured images in the time sequence, a maximum value and a minimum value of each of the color components in a certain area of the captured image, and an oxygen-saturation calculation unit configured to calculate oxygen saturation on the basis of the maximum value and the minimum value of each of the color components in the certain area of the captured image.","1. A biological-information obtaining apparatus comprising: light-emitting means for emitting light;image-capturing means for capturing images, in time sequence, obtained by irradiating a living body with the light emitted and by causing the light to be transmitted through or reflected by the living body, the image-capturing means being sensitive to at least two color components;extreme generation means for generating a maximum value and a minimum value, in time sequence, of each of the color components for certain regions of the captured images; andoxygen-saturation calculation means for calculating oxygen saturation on the basis of the maximum value and the minimum value of each of the color components.","9","12/110537","2008-04-28","2008-0306366","2008-12-11","9597033","2017-03-21","SONY CORPORATION","Mitsuharu  Ohki | Tomonori  Masuno","2007-149857","JP","2007-06-06","A61B-0005/6826","A61B-0005/6826 | A61B-0005/14551 | A61B-0005/6838 | G06F-0021/32 | G06T-0007/0012 | G06T-2207/10016 | G06T-2207/10024 | G06T-2207/30101","A61B-005/00","A61B-005/00 | A61B-005/1455 | G06F-021/32 | G06T-007/00","","","","","","4917012000892"
"US","US","P","B2","Method for a brain region location and shape prediction","A volumetric segmentation method is disclosed for brain region analysis, in particular but not limited to, regions of the basal ganglia such as the subthalamic nucleus (STN). This serves for visualization and localization within the sub-cortical region of the basal ganglia, as an example of prediction of a region of interest for deep brain stimulation procedures. A statistical shape model is applied for variation modes of the STN, or the corresponding regions of interest, and its predictors on high-quality training sets obtained from high-field, e.g., 7T, MR imaging. The partial least squares regression (PLSR) method is applied to induce the spatial relationship between the region to be predicted, e.g., STN, and its predictors. The prediction accuracy for validating the invention is evaluated by measuring the shape similarity and the errors in position, size, and orientation between manually segmented STN and its predicted one.","1. A method for operating an electronic device to generate a patient-specific brain image atlas, comprising: receiving a patient'ss brain image having a region of interest that is produced using an imaging modality, wherein the patient'ss brain image is associated with a patient having characteristics;accessing a database of additional metadata-annotated brain images including images different than the patient'ss brain image, wherein the database includes: registered first imaging modality brain image sets and associated metadata from each of a plurality of individuals, wherein the image sets include predicted regions of interest that correspond to the regions of interest in the patient'ss brain image and predictor regions that are anatomically different than and associated with the predicted regions; andregistered second imaging modality brain image sets and associated metadata from at least some of the plurality of individuals, wherein the second modality is different than the first modality, and wherein the image sets include predicted regions of interest that correspond to the regions of interest in the patient'ss brain image and predictor regions that are anatomically different than and associated with the predicted regions; andregistered additional modality brain image sets and associated metadata from at least some of the plurality of individuals, wherein the additional modality is different than the first and second modalities, and wherein the image sets include predicted regions of interest that correspond to the regions of interest in the patient'ss brain image and predictor regions that are anatomically different than and associated with the predicted regions;selecting one or more of the additional brain images from the database based on a correlation of the metadata elements of the one or more additional images to the patient'ss characteristics and the imaging modality of the patient'ss brain image for the clinical purpose of deep brain stimulation electrode placement to have predictor regions associated with predicted regions of interest that correspond to the regions of interest in the patient'ss brain image;processing, using the electronic device, the patient'ss brain image to segment one or more predictors corresponding to registered predictors of the selected one or more additional brain images;processing, using the electronic device, the patient'ss brain image and the selected one or more additional brain images as a function of the segmented one or more predictors in the patient'ss brain image and registered predictors of the selected one or more additional brain images, to predict one or more of the shape, location, size or orientation of the region of interest in the patient'ss brain image; andprocessing, using the electronic device, the patient'ss brain image as a function of the predicted one or more of the shape, location, size or orientation of the region of interest to incorporate the predicted one or more of the shape, location, size or orientation of the region of interest into the patient'ss brain image to generate a patient-specific atlas having enhanced regions of interest.","14","14/317925","2014-06-27","2015-0012466","2015-01-08","9600778","2017-03-21","SURGICAL INFORMATION SCIENCES, INC.","Guillermo  Sapiro | Noam  Harel | Yuval  Duchin | Jinyoung  Kim","","","","G06N-0099/005","G06N-0099/005 | A61B-0005/055 | G06F-0017/30244 | G06K-0009/00 | G06K-0009/6289 | G06T-0007/337 | A61B-0005/0035 | A61B-0006/032 | A61B-0006/037 | A61B-0006/12 | A61B-0006/469 | A61B-0006/501 | A61B-0006/5247 | A61B-0006/563 | A61B-2576/026 | G06T-2207/10088 | G06T-2207/20128 | G06T-2207/30016","G06N-099/00","G06N-099/00 | G06F-017/30 | G06K-009/00 | G06K-009/62 | A61B-005/055 | A61B-006/03 | A61B-006/12 | A61B-006/00 | A61B-005/00","","","","","","4917012004615"
"US","US","P","B2","Web based fast query visualization of time-varying multi-variate vessel flow field by using uniform partition strategy","A method for visualizing flow data from computation fluid dynamics (CFD) applications in 2-dimensions (2D) includes receiving a 3-dimensional (3D) image volume from a CFD simulation of fluids flowing through vessels in a patient that is a snapshot of a fluid flow in the vessels at a certain time, subdividing the 3D image volume into 3D data blocks, minimizing a sum over a matrix of energy interactions defined for each pair of data blocks in the 3D image volume, where the minimization preserves a local shape of the vessels, where minimizing the sum over the matrix of energy interactions is performed on a graphics processing unit (GPU), and using the minimized energy interaction matrix to display on a monitor a 2D sketch of the 3D image volume, where the 2D sketch is displayed in real-time with respect to the time scale of the CFD simulation.","1. A method for visualizing flow data from computation fluid dynamics (CFD) applications in 2-dimensions (2D), comprising the steps of: receiving a 3-dimensional (3D) image volume from a CFD simulation of fluids flowing through vessels in a patient that is a snapshot of a fluid flow in the vessels at a certain time;subdividing the 3D image volume into 3D data blocks;minimizing a sum over energy interactions defined for each pair of data blocks in the 3D image volume, wherein said minimization preserves a local shape of the vessels, wherein minimizing the sum over energy interactions is performed on a graphics processing unit (GPU), wherein minimizing the sum over the energy interactions comprises minimizing E=√{square root over (ΣijEij2)}wherein wherein wn and wnn are weights for neighboring and non-neighboring blocks, respectively, tij=|vi?vj| is a target distance between blocks bi and bj in a 2D image wherein vi and vj are 2D positions of bi and bj, eij is a Euclidean distance between bi and bj in the 3D volume, gij is a geodesic distance between bi and bj in the vessels in the 3D image, and d is a threshold that separates neighboring blocks from non-neighboring blocks, wherein the minimization is performed by varying the target positions vi and vj; andusing the minimized energy E to display on a monitor a 2D sketch of the 3D image volume, wherein the 2D sketch is displayed in real-time with respect to the time scale of the CFD simulation.","22","14/508527","2014-10-07","2015-0097836","2015-04-09","9600891","2017-03-21","SIEMENS HEALTHCARE GMBH","Xiaoke  Huang | Jun  Tao | Feng  Qiu | Daphne  Yu","","","","G06T-0007/0081","G06T-0007/0081 | A61B-0005/7425 | G06T-0019/20 | A61B-0005/026 | A61B-0005/055 | A61B-0006/504 | A61B-0008/06 | A61B-2576/02 | G06F-0017/5009","G06T-019/20","G06T-019/20 | G06T-007/00 | A61B-005/00 | G06F-017/50 | A61B-006/00 | A61B-008/06 | A61B-005/026 | A61B-005/055","","","","","","4917012004728"
"US","US","P","B2","Systems, devices, components and methods for communicating with an IMD using a portable electronic device and a mobile computing device","The present disclosure involves a method of communicating with an implantable medical device. An authentication process is performed to verify an identity of a user of a mobile computing device. A request is received from the user to access an implantable medical device via the mobile computing device. Based on the identity of the user, a first user interface suitable for the user is selected from a plurality of user interfaces that are each configured to control an implantable medical device. The plurality of user interfaces have different visual characteristics and different levels of access to the implantable medical device. The first user interface is displayed on the mobile computing device.","1. A medical system, comprising: an implantable medical device;a mobile computing device, the mobile computing device including a screen, wherein the mobile computing device is configured to display on the screen: in response to an authentication of a first user, a first user interface for controlling the implantable medical device based on one or more first commands received from the first user, the first user interface mimicking a user interface of a patient programmer device; andin response to an authentication of a second user, a second user interface for controlling the implantable medical device based on one or more second commands received from the second user, the second user interface mimicking a user interface of a clinician programmer device having a greater number of programming options than the patient programmer device and offers a greater level of access to the implantable medical device than the patient programmer device, wherein the first user interface and the second user interface have different visual appearances; anda portable electronic device, wherein the portable electronic device includes: a first communications component configured to conduct telecommunications with the implantable medical device under a first communications protocol; anda second communications component configured to conduct telecommunications with the mobile computing device under a second communications protocol different from the first communications protocol;and wherein the portable electronic device is configured to: perform a safety control inspection on the one or more first commands or second commands; anduse the first and second communications components to relay the one or more first commands or the one or more second commands to the implantable medical device in response to the one or more first commands or second commands passing the safety control inspection.","36","14/245225","2014-04-04","2014-0304773","2014-10-09","9596224","2017-03-14","NUVECTRA CORPORATION","Thomas F.  Woods | Norbert  Kaula | Yohannes  Iyassu","","","","H04L-0063/08","H04L-0063/08 | A61N-0001/37247 | A61B-0005/002 | A61B-0005/0031 | H04L-0063/083 | H04L-0063/0861 | H04L-0067/12","H04L-029/06","H04L-029/06 | A61N-001/372 | H04L-029/08 | A61B-005/00","","","","","","4917011004928"
"US","US","P","B2","Registration of anatomical data sets","Methods and systems are disclosed for relating additional spatial information associated with one volume data set of an anatomical structure with another volume data set of the anatomical structure where the spatial information is not available. A unique spatial characteristic of the volume data set is identified, such as an image moment of inertia, and an arbitrary reference frame is assigned to the volume data set and correlated with the unique spatial characteristic. The additional spatial information is also correlated with the arbitrary reference frame. The additional spatial information is then correlated to a second volume data set of the anatomical structure by registering the first and second volume data sets based on the unique spatial characteristic. The methods and systems allow registration of different volume data sets of the same anatomical structure and transfer of the additional spatial information without establishing a local reference frame based on predefined landmarks.","1. A system for collecting and manipulating a volume data set of an anatomical structure, the system comprising: an imaging device for obtaining a first volume data set of an anatomical structure of a patient and a second volume data set of the anatomical structure; anda computer comprising a processing unit and a memory unit, wherein the computer is configured to: calculate an inherent feature of the first volume data set and the second volume data set, wherein the inherent feature has a unique position and orientation in relation to the anatomical structure that can be identified from any reference position;assign a first arbitrary reference frame to the first volume data set and a second arbitrary reference frame to the second volume data set;correlate the inherent feature to the first arbitrary reference frame;associate additional spatial information with the first volume data set, wherein the additional spatial information has a unique spatial relationship correlated with the first arbitrary reference frame;register the first volume data set with the second volume data set based on the inherent feature; andcorrelate the additional spatial information to the second volume data set.","27","14/100055","2013-12-09","2014-0094694","2014-04-03","9572548","2017-02-21","STRYKER EUROPEAN HOLDINGS I, LLC | STRYKER EUROPEAN HOLDINGS VI, LLC","Jose Luis  Moctezuma de la Barrera","","","","A61B-0008/5292","A61B-0008/5292 | A61B-0005/1073 | A61B-0005/1128 | A61B-0006/032 | A61B-0006/037 | A61B-0008/0875 | A61B-0008/12 | A61B-0008/4254 | A61B-0008/5223 | A61B-0034/20 | A61B-0090/30 | A61B-0090/361 | G06F-0019/321 | G06F-0019/322 | G06Q-0050/22 | G06T-0007/0024 | A61B-2090/363 | A61B-2090/364 | A61B-2090/378 | G06T-2207/10072 | G06T-2207/30008","G06K-009/00","G06K-009/00 | A61B-005/05 | A61B-005/103 | A61B-005/117 | A61B-008/08 | G06F-019/00 | G06Q-050/22 | G06T-007/00 | A61B-005/107 | A61B-005/11 | A61B-006/03 | A61B-008/12 | A61B-008/00","","","","","","4917008000909"
"US","US","P","B2","Mechanism for facilitating user-controlled management of webpage elements for dynamic customization of information","In accordance with embodiments, there are provided mechanisms and methods for facilitating user-controlled management of webpage elements for dynamic customization of relevant information. In one embodiment and by way of example, a method includes receiving, in real-time, a request for performing one or more tasks relating to dynamic customization of webpage elements relating to a webpage package. The request may be received at a first computing device over a network. The method may further include performing, in real-time, the one or more tasks.","1. A computer-implemented method comprising: receiving, in real-time, by a server computing device, a request from a user to alter a live version of a webpage associated with the user having access to a client computing device;offering access, by the server computing device, to perform, via the client computing device, real-time interactive manipulation of one or more widgets associated with the webpage without employing an editable version or template of the webpage or programming code inputs relating to the one or more widgets, wherein the interactive manipulation includes at least one of interactively creating, adding, removing, defining, deploying, cross-citing, subscribing, and sharing of the one or more widgets;dynamically altering, in real-time, by the server computing device, the webpage based on the real-time interactive manipulation of the one or more widgets; andproviding, in real-time, by the server computing device, the dynamically altered webpage to at least the user via the client computing device.","12","13/665500","2012-10-31","2014-0122993","2014-05-01","9572614","2017-02-21","SALESFORCE.COM,INC.","Philip Norman  Calvin | Sonali  Agrawal | Beril Guvendik  Maples | Eric  Dorgelo | Shelby  Hubick","","","","A61B-0017/8833","A61B-0017/8833 | A61F-0002/28 | G06F-0017/30893 | A61F-2002/2835","G06F-003/048","G06F-003/048 | G06F-017/00 | A61B-017/88 | G06F-017/30 | A61F-002/28","","","","","","4917008000975"
"US","US","P","B2","Method and apparatus for selecting seed area for tracking nerve fibers in brain","A method for selecting a seed area for tracking nerve fibers in a brain includes performing registration of an atlas which shows a plurality of areas which are included in the brain and image data which relates to the brain, displaying a brain area list with respect to the plurality of areas, selecting a first area from the atlas based on a first user input with respect to the brain area list, extracting an area of the image data which corresponds to the first area, as a seed area, based on a result of the registration, and generating a first image which corresponds to the seed area from the image data, and displaying the generated first image.","1. A method for selecting a seed area for tracking nerve fibers in a brain, the method comprising: performing a registration of an atlas which shows a plurality of areas which are included in the brain and image data which relates to the brain;displaying a brain area list with respect to the plurality of areas;selecting a first area from the atlas based on a first user input with respect to the brain area list;extracting, as the seed area, an area of the image data which corresponds to the first area, based on a result of the performing the registration; andgenerating a first image which corresponds to the seed area from the image data, and displaying the generated first image,wherein the generating and displaying the first image comprises:sequentially calculating a plurality of nerve fibers which pass through the seed area; andupdating the first image based on a result of the calculating, wherein the first image includes image data which corresponds to at least one of the calculated plurality of nerve fibers.","17","14/334001","2014-07-17","2015-0023556","2015-01-22","9569840","2017-02-14","SAMSUNG ELECTRONICS CO., LTD. | INDUSTRY-UNIVERSITY COOPERATION FOUNDATION HANYANG UNIVERSITY","Hei-soog  Kim | Hyug-rae  Cho | Jun-sung  Park | Jong-min  Lee","10-2013-0084383","KR","2013-07-17","G06T-0007/0012","G06T-0007/0012 | A61B-0005/055 | A61B-0005/4064 | G01R-0033/5608 | G01R-0033/56341 | G06F-0003/04842 | G06T-0003/0068 | A61B-2576/026 | G06T-2200/24 | G06T-2207/10092 | G06T-2207/30016","G06K-009/00","G06K-009/00 | G06T-007/00 | G06F-003/0484 | G06T-003/00 | A61B-005/055 | G01R-033/56 | G01R-033/563 | A61B-005/00","","","","","","4917007004685"
"US","US","P","B2","System and method for communication between functional device and home automation","A functional device is disclosed that can collect and process data/information/parameter values from one or more sensors and compares the same with one or more predefined/threshold value to suggest one or more actions and/or generate alerts/messages/suggestions to be performed by one or a combination of remote system, wearer, home automation network, healthcare provider, doctor, caretaker, among other stakeholders. Communication between the functional device, home automation server and a computational server that stores the data is also disclosed.","1. A system, comprising: a functional device configured in an automobile, said functional device comprising one or more sensors that measure at least one health parameter of an occupant of the automobile, and further comprising a user interface;a home automation gateway (HAG), said HAG comprising one or more home automation systems (HAS) sensors placed inside a building; anda first computing device and a second computing device; wherein said functional device is configured to retrieve one or more automobile parameters and settings, wherein said functional device stores said at least one health parameter in real-time in secured form on the first computing device, wherein said functional device is further remotely coupled with the home automation gateway (HAG) in a manner that enables presentation of reading of the one or more home automation system (HAS) sensors on the user interface of said functional device, and wherein reading of the one or more home automation system (HAS) sensors are stored in real time by said HAG in secured form on the second computing device,wherein said functional device is further configured to enable the occupant of the automobile to, upon authorization, control any or combination of said one or more automobile parameters and settings, said at least one health parameter through the user interface, and one or more HAS sensors,wherein said functional device accesses said health parameters and reading of said one or more home automation system (HAS) sensors by a web application that is configured on a web server, andwherein said functional device is connected with said HAG by a Virtual Private Network (VPN) connection.","6","14/736607","2015-06-11","2015-0280937","2015-10-01","9571297","2017-02-14","Rajendra Padma Sadhu","Rajendra Padma  Sadhu","","","","H04L-0012/2825","H04L-0012/2825 | A61B-0005/0022 | A61B-0005/0205 | A61B-0005/1112 | A61B-0005/1176 | A61B-0005/7465 | G06F-0003/04842 | G06K-0009/00832 | G06K-0009/00885 | H04L-0012/2827 | A61B-0005/01 | A61B-0005/021 | A61B-0005/02438 | A61B-0005/0404 | A61B-0005/0816 | A61B-0005/14532 | G06K-2009/00939 | H04L-0067/12 | H04L-2012/40273 | H04W-0004/046 | H04W-0084/005","H04L-012/28","H04L-012/28 | H04L-029/08 | H04L-012/40 | H04W-004/04 | H04W-084/00 | A61B-005/00 | A61B-005/0205 | A61B-005/11 | A61B-005/01 | A61B-005/021 | A61B-005/024 | A61B-005/0404 | A61B-005/08 | A61B-005/145 | G06F-003/0484 | G06K-009/00 | A61B-005/117","","","","","","4917007006131"
"US","US","P","B2","Technique for operating a vehicle effectively and safely","A control system is employed in a vehicle to assist a user to operate the vehicle effectively and safely. In accordance with the invention, the system provides driving assistance to the user by taking into account the user's physical condition, the vehicle condition and the surrounding conditions. The surrounding conditions include, e.g., road, weather and traffic conditions, external to the vehicle. The vehicle condition concerns the conditions of the brakes, steering, tires, radiator, etc. of the vehicle. Signs of fatigue, stress and illness of the user are monitored by the control system to assess the user's physical condition.","1. A method for use in a system allowing for personalizing a vehicle, comprising: collecting information about a user from the user via a user interface, the information comprising user display preferences, collecting information from the user comprising: allowing selection by the user of a first one of a plurality of dashboard display templates;establishing the first dashboard display template as a user display preference associated with a first user profile that is maintained in a memory, the first user profile comprising a first plurality of user preferences;allowing selection by the user of a second one of a plurality of dashboard display templates; andestablishing the second dashboard display template as a user display preference associated with a second user profile that is maintained in the memory, the second user profile comprising a second plurality of user preferences;selecting the first user profile during a first mode of driving, and selecting the second user profile during a second mode of driving;displaying data concerning one or more vehicle components on a dashboard display device;if the first user profile is selected, configuring display on the dashboard display device in accordance with the first dashboard display template; andif the second user profile is selected, configuring display on the dashboard display device in accordance with the second dashboard display template.","15","14/133548","2013-12-18","2014-0107894","2014-04-17","9571449","2017-02-14","AUTO DIRECTOR TECHNOLOGIES, INC.","Michael L.  Obradovich","","","","H04L-0061/2553","H04L-0061/2553 | G06F-0007/00 | G06F-0017/30315 | H04L-0043/08","G06F-007/00","G06F-007/00 | H04L-029/12 | G06F-017/30 | H04L-012/26","","","","","","4917007006282"
"US","US","P","B2","Information recording medium, columnar body having information recording medium affixed thereto, information reading device therefor, pharmaceutical injection device using this information reading device, information reading method, and non-transitory computer readable medium","It is an object to provide an information recording medium with which information symbols can be suitably read. This information recording medium comprises a sheet-form member (33), a plurality of information symbols (18) that are displayed on the surface of the sheet-form member (33) and each have the same information, and an edge line (34) that is provided at one end and/or the other end of the sheet-form member (33) and allows an information reading device which reads the information symbols (18) to recognize the end of the sheet-form member (33).","1. A columnar body, comprising: an information recording medium;a columnar main body having an outer peripheral face of which the information recording medium is affixed; and wherein the information recording medium, comprises:a sheet-form member;a plurality of information symbols displayed on the surface of the sheet-form member, each having the same information; andan end recognition component provided at at least one end of the sheet-form member;wherein the end recognition component is configured to allow an information reading device, capable of reading the information symbols, recognize the end of the sheet-form member, andthe information recording medium is affixed to the outer peripheral face; andthe information recording medium is wound around the columnar main body such that a portion of the information recording medium overlaps itself.","13","14/236329","2012-08-02","2014-0166742","2014-06-19","9563790","2017-02-07","PANASONIC CORPORATION | PANASONIC HEALTHCARE HOLDINGS CO., LTD.","Tooru  Aoki | Seiji  Kikuchi | Mitsuteru  Fujimoto","2011-169853","JP","2011-08-03","G06K-0005/00","G06K-0005/00 | A61M-0005/20 | G06K-0007/10722 | G06K-0019/06009 | G06K-0019/06056 | A61M-0005/24 | A61M-0005/3146 | A61M-2005/206 | A61M-2005/3125 | A61M-2005/3126 | A61M-2205/6072","G06F-017/00","G06F-017/00 | G06K-005/00 | A61M-005/20 | G06K-019/06 | G06K-007/10 | A61M-005/24 | A61M-005/31","","","","","","4917006003495"
"US","US","P","B2","Diabetes care system for detection of an analyte and method for selective data transmission","A diabetes care system for detection of an analyte and method for selective data transmission are disclosed. The diabetes care system has a mobile component and a base station, wherein a data transmission occurring between the mobile component and the base station within a time interval in which a wireless communication link exists, wherein is selectively performed in such a manner that within the time interval, a first partial set of the data is transmitted from the mobile component to the base station. The first partial set is selected using a processor-controlled selection algorithm in such a manner that the data transmitted in the time interval is representative of the entirety of the data stored in the mobile component.","1. A diabetes care system for use on a person, comprising: a base station having a communication unit for wirelessly receiving data, a memory unit for storing transmitted data, and optionally an output unit for displaying the transmitted data; anda mobile component configured to be carried by the person and including, a continuous measurement unit implantable in the person for measuring relevant data for treatment of diabetes mellitus, a memory for storing the measured data for the treatment of diabetes mellitus, a communication unit for wirelessly transmitting the measured data for treatment of diabetes mellitus to the base station, and a processor programmed to control a selection algorithm, and cooperatively operable with the communication unit to selectively perform a data transmission in such a manner that within a first time interval, in which a wireless communication link between the mobile component and the base station exists, a first partial set, selected from all of the measured data for treatment of diabetes mellitus stored in the memory of the mobile component, is transmitted from the mobile component to the base station, and the first partial set is selected using the processor-controlled selection algorithm,wherein the selection algorithm selects a subset of the measured data for treatment of diabetes mellitus using a variable time raster without analyzing all of the measured data for treatment of diabetes mellitus stored in the mobile component, identifies one or more outlier values in the subset of data which lie outside a predefined and changeable tolerance band and further selects data from the subset of measured data within a time interval around each of the outlier values using a constant time raster, such that the first partial data set includes the further selected data.","8","11/763004","2007-06-14","2007-0299324","2007-12-27","9554703","2017-01-31","ROCHE DIABETES CARE, INC.","Jurgen  Rasch-Menges | Paul  Jansen | Hans-Peter  Haar | Ulrich  Haueter | Andreas  Poredda","2006-012693","EP","2006-06-21","A61B-0005/0002","A61B-0005/0002 | A61B-0005/14532 | G01N-0033/48792 | H04L-0067/14 | A61N-0001/37252 | A61N-0001/37276","A61B-005/00","A61B-005/00 | A61B-005/145 | G01N-033/487 | H04L-029/08 | A61N-001/372","","","","","","4917005000861"
"US","US","P","B2","System and method for developing a model indicative of a subject's emotional state when listening to musical pieces","A method for deriving optimal discriminating features indicative of a subject state when the subject listens to one of a set of musical pieces, comprising a step of extracting frequency features from the subject's EEG signal when the subject is in a first subject state and a second subject state, the frequency features being extracted from more than one frequency band in one set of time segments; and identifying optimal discriminating features from the extracted frequency features, the optimal discriminating features indicative of characteristics of the EEG signal when the subject is in the first subject state and the second subject state, wherein one of the first subject state and the second subject state indicates that the subject likes a musical piece while the other state indicates that the subject does not like the musical piece.","1. A method for deriving optimal discriminating features indicative of a subject state when the subject listens to one of a set of musical pieces, the method comprising: extracting frequency features from the subject'ss EEG signal when the subject is in a first subject state and a second subject state, the frequency features being extracted from more than one frequency band in one set of time segments;identifying optimal discriminating features from the extracted frequency features, the optimal discriminating features indicative of characteristics of the EEG signal when the subject is in the first subject state and the second subject state;extracting musical features associated with each of the set of the musical pieces; andcomparing the extracted musical features with the optimal discriminating features to determine which of the extracted musical features are indicative of characteristics of musical pieces that the subject prefers,wherein one of the first subject state and the second subject state indicates that the subject prefers a musical piece while the other state indicates that the subject does not prefer the musical piece.","18","14/428852","2013-09-17","2015-0235134","2015-08-20","9557957","2017-01-31","AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH","Cuntai  Guan | Juanhong  Yu | Yaozhang  Pan","201206897-9","SG","2012-09-17","G06F-0003/165","G06F-0003/165 | A61B-0005/0476 | A61B-0005/04845 | A61M-2230/10","G06F-017/00","G06F-017/00 | G06F-003/16 | A61B-005/0484 | A61B-005/0476","","","","","","4917005004097"
"US","US","P","B2","Methods and systems for assessing psychological characteristics","A method for assessing a pre-cognitive emotional response from a test subject, using responses obtained during the first moments of brain activity after presentation of a stimulus, includes exposing the test subject to a visual stimulus for between approximately 500 milliseconds and approximately 1 second, and receiving an input from the subject while the subject is exposed to the visual stimulus or within approximately 300 milliseconds after the subject is first exposed to the stimulus. The method further includes storing, in response to receiving the input, a user response that identifies one of a plurality of emotional reactions that is associated with the visual stimulus. Each of the exposing, receiving, and storing acts is repeated for a plurality of visual stimuli. The method further includes determining, based on each of the stored user responses, one or more dominant emotional characteristics of the subject.","1. A method comprising: maintaining a set of visual stimuli, each of the visual stimuli being associated with an identified emotional reaction that is likely to be elicited in a subject to whom the stimulus is presented,identifying to a subject, by computer through a user interface, a context with which emotional reactions are to be associated;after identifying the context to the subject, presenting, to the subject, by a computer through a presentation interface, the visual stimuli to the subject, including, for each visual stimulus: presenting the visual stimulus for a limited period of time having a predefined duration of more than 500 milliseconds and less than 1000 milliseconds, the duration of the limited period of time being enforced by computer and being sufficiently brief as to limit or prevent cognitive processing of the visual stimulus by the subject,ending the presenting of the visual stimulus at the end of the limited period of time,providing a grace period immediately following the end of the limited period of time, the grace period having a predefined duration of up to 300 milliseconds during which none of the visual stimuli is presented, the duration of the grace period being enforced by computer, andpresenting a subsequent visual stimulus at the end of the grace period;by a computer, receiving a response, by the subject, to at least one of the visual stimuli during a response period including the first limited period of time and the grace period, the response of the subject to a particular visual stimulus representing a emotional reaction of the subject to the particular visual stimulus in relation to the context;by a computer, storing information that represents the pre-cognitive emotional reaction of the subject to each of the at least one visual stimuli for which a response was received;andby a computer, determining, based on at least some of the stored information, one or more dominant emotional characteristics of the subject in relation to the context.","15","12/872531","2010-08-31","2011-0020778","2011-01-27","9558499","2017-01-31","THE FORBES CONSULTING GROUP, LLC","David L.  Forbes","","","","G06Q-0030/02","G06Q-0030/02 | A61B-0005/04842 | A61B-0005/16 | A61B-0005/162 | A61B-0005/164 | A61B-0005/165 | A61B-0005/167 | A61B-0005/4803 | G06F-0003/048 | G06F-0017/30032 | G06F-0019/324 | G06F-0019/3443 | G06K-0009/00308 | G06K-0009/00315 | G06K-0009/00335 | G06Q-0010/06398 | G06Q-0030/0203 | G06Q-0030/0242 | G09B-0007/00 | G09B-0019/00 | G06F-0019/345 | G06F-0019/363 | G06F-2203/011","G06F-017/00","G06F-017/00 | G06Q-030/02 | A61B-005/16 | G06Q-010/06 | A61B-005/0484 | A61B-005/00 | G06F-017/30 | G09B-019/00 | G06F-003/048 | G06F-019/00 | G09B-007/00 | G06K-009/00","","","","","","4917005004635"
"US","US","P","B2","Wearable device and method for controlling the same","A wearable device and a method for controlling the same are disclosed herein. The wearable device, comprising a bio-signal sensor unit configured to sense a bio-signal; a storage unit configured to store data; and a processor configured to control the bio-signal sensor unit and the storage unit, wherein the processor is further configured to: generate first reference data including a weight of a first reference object and a first bio-signal being generated by holding the first reference object when the first bio-signal is detected, generate measurement data including a second bio-signal being generated by holding a measurement object, when the second bio-signal is detected, and obtain a weight of the measurement object by comparing the measurement data with the first reference data.","1. A wearable device, comprising: a bio-signal sensor unit configured to sense a bio-signal;a storage unit configured to store data; anda processor configured to control the bio-signal sensor unit and the storage unit,wherein the processor is further configured to:generate first reference data including a weight of a first reference object and a first bio-signal generated by holding the first reference object when the first bio-signal is detected,generate measurement data including a second bio-signal generated by holding a measurement object when the second bio-signal is detected, andobtain a weight of the measurement object by comparing the measurement data with the first reference data.","19","14/176753","2014-02-10","2015-0149116","2015-05-28","9551608","2017-01-24","LG ELECTRONICS INC.","Eunhyung  Cho | Sinae  Chun | Jongho  Kim | Jihwan  Kim","10-2013-0145079","KR","2013-11-27","G01G-0009/00","G01G-0009/00 | A61B-0005/1107 | A61B-0005/681 | G06K-0009/00342 | G06Q-0050/22 | A61B-0005/01 | A61B-0005/021 | A61B-0005/026 | A61B-0005/02438 | A61B-0005/0404 | A61B-0005/0476 | A61B-0005/0488 | A61B-0005/0531 | A61B-0005/0816","G01G-009/00","G01G-009/00 | A61B-005/00 | A61B-005/11 | G06K-009/00 | G06Q-050/22 | A61B-005/01 | A61B-005/021 | A61B-005/024 | A61B-005/026 | A61B-005/0404 | A61B-005/0476 | A61B-005/0488 | A61B-005/053 | A61B-005/08","","","","","","4917004002658"
"US","US","P","B2","Fixation filter assembly","A filter assembly is provided for collecting samples in a fluid environment, the assembly utilizing a laminar convective flow to cause the flow of a preservative/fixative and a filtrate through a filter. A substantially concave dead space around the filter is flushed free of the preservative and the differential in density of the preservative and filtrate causes the more dense fluid to collect in the reservoir and preserve the collected specimen.","1. A filter assembly for flow of filtrate comprising: a. an inlet and outlet for flow of first fluid filtrate containing a biological specimen containing microorganisms having a density D1 and a reservoir containing a second fluid having a density D2;b. an interior space for filter media, wherein said filter media divides said interior space into a first interior space proximal to said inlet and a second interior space proximal to said outlet, said first interior space opposing said second interior space relative to said filter media wherein said filter media collects said biological specimen;c. a reservoir plate to partition said reservoir from said second interior space wherein said reservoir plate includes at least two openings in communication with said reservoir and said second interior space, wherein said second fluid in said reservoir is a preservative for said biological specimen and is capable of exchange with said first fluid in said interior space due to differential density of said first and second fluids, wherein: (1) when said filtrate has a density D1 that is greater than D2, said filtrate flows out of said interior space into said reservoir and said second fluid preservative replaces said filtrate in said interior space; or(2) when said filtrate has a density D1 that is less than D2, said second fluid preservative flows from said reservoir into said interior space and said second fluid replaces said filtrate in said interior space.","16","13/852027","2013-03-28","2013-0206668","2013-08-15","9552545","2017-01-24","MCLANE RESEARCH LABORATORIES, INC.","Craig D.  Taylor | Kenneth W.  Doherty | Susumu  Honjo","","","","G06N-0003/08","G06N-0003/08 | A61B-0005/04001 | A61F-0002/72 | G06F-0003/015 | Y10S-0128/905","G01N-001/34","G01N-001/34 | G06N-003/08 | A61B-005/04 | A61F-002/72 | G06F-003/01","","","","","","4917004003588"
"US","US","P","B2","Modular communicator for use in life critical network","A modular patient communicator provides for communications with a patient implantable medical device (PIMD) and connectivity with a central authority (CA) via an unsecured network. Medical firmware and a radio facilitate wireless interrogation of the PIMD and acquisition of PIMD data. A universal communications port facilitates mechanical and signal connectivity with one or a multiplicity of disparate detachable modules, some of which provide the communicator with an external communications facility and have disparate communication protocols. The communicator is devoid of an external communications facility other than the radio and universal communications port. Life critical network software is executed in cooperation with an attached module to cause the communicator to transmit a request to a network access facility for a connection to the unsecured network, authenticate the communicator to the CA, and facilitate secured communication between the communicator and CA upon successful communicator authentication.","1. A modular communicator for communicating with physiological sensors comprising: a housing;a processor disposed in the housing;a user interface in communication with the processor; a universal communications port supported by the housing and in communication with the processor, the communications port comprising a connector configured to mechanically detachably engage with each of a plurality of disparate modules, wherein the processor is configured to establish connectivity with one or more particular physiological sensors through one or more mechanically engaged module of the plurality of disparate modules;memory disposed in the housing and coupled to the processor, the memory configured to store program instructions for communication with each of the one or more particular physiological sensors;wherein the processor is configured to communicatively couple to a network communication hub by executing program instructions stored on at least one mechanically engaged module of the plurality of disparate modules.","19","14/139569","2013-12-23","2014-0111353","2014-04-24","9552722","2017-01-24","Cardiac Pacemakers, Inc.","Jim  Sievert | William R.  Mass","","","","G08C-0017/02","G08C-0017/02 | A61B-0005/0022 | G06F-0019/3418 | H04L-0063/0853 | A61B-0005/01 | A61B-0005/02 | A61B-0005/145 | A61N-0001/37282 | G06F-0019/3412","G08C-019/16","G08C-019/16 | G08C-017/02 | H04L-029/06 | A61B-005/00 | A61B-005/01 | A61B-005/02 | A61B-005/145 | A61N-001/372 | G06F-019/00","","","","","","4917004003762"
"US","US","P","B2","Active interface device","An active interface device including a transducer or sensor array having a plurality of transducers or sensors arranged to transform a cell activity into an electrical signal, at least one detection unit for detecting the electrical signal(s), at least one recording unit for recording the electrical signal(s), comprising a plurality of recording channels arranged for being routed to the transducers or sensors, and at least one control unit. The control unit is arranged for addressing the transducers or sensors to the detection unit(s), for activating transducers or sensors, and for routing the recording channels to activated transducers or sensors.","1. An active interface device comprising: a transducer or sensor array comprising a plurality of transducers or sensors arranged to transform a cell activity into an electrical signal, each transducer or sensor comprising a switch for activating the transducer or sensor;at least one detection unit configured to detect one or more electrical signals generated by the transducer or sensor array, wherein the detection unit comprises at least one comparator configured to compare the one or more electrical signals to a predetermined threshold signal;at least one recording unit configured to record the one or more electrical signals and having a plurality of recording channels to electrically connect to the transducers or sensors in real-time, wherein the recording channels are resources at a disposal of the transducer or sensor array to record cell activity;a first die and a second die coupled to the first die, wherein the plurality of transducers or sensors is arranged on the first die, wherein the plurality of recording channels is arranged on the second die;a three-dimensional via array that provides a plurality of electrical connections through the first die to the second die, wherein the plurality of transducers or sensors are operable to be switchably electrically connected to the plurality of recording channels using at least one electrical connection provided by the three-dimensional via array;at least two amplifying blocks for amplifying the one or more electrical signals, wherein a first amplification is performed by a first amplifying means disposed in the detection unit and a second amplification is performed by a second amplifying means disposed in the recording unit, wherein an amplitude of the predetermined threshold signal is greater than a noise level of the first amplifying means; andat least one control unit configured to: determine a cell activity based on the comparison between the one or more electrical signals from the first amplifying means and the predetermined threshold signal; andresponsive to determining the cell activity, activate the second amplifying means associated with respective transducers or sensors corresponding to the determined cell activity by turning on the switch of the respective transducer or sensor; andfurther responsive to determining the cell activity, route an electrical signal from a respective activated transducer or sensor to an available recording channel using at least one electrical connection provided by the three-dimensional via array.","21","12/840002","2010-07-20","2011-0015866","2011-01-20","9545519","2017-01-17","IMEC | KATHOLIEKE UNIVERSITEIT LEUVEN, K.U. LEUVEN R&D","Junaid  Aslam | Patrick  Merken | Chris  Van Hoof","","","","A61N-0001/37211","A61N-0001/37211 | A61B-0005/04001 | A61B-0005/04004 | A61N-0001/025 | A61B-2562/0209 | A61B-2562/046","A61N-001/372","A61N-001/372 | G06Q-050/22 | G01N-033/487 | A61B-005/04 | A61N-001/02","","","","","","4917003001012"
"US","US","P","B2","Signal strength enhancement in a biometric sensor array","A biometric imager may comprise a plurality of sensor element traces formed in or on a sensor substrate which may comprise at least a portion of a display screen defining a biometric sensing area and forming in-active pixel locations; an auxiliary active circuit formed in or on the sensor substrate on the periphery of the biometric sensing area and in direct or indirect electrical contact with the sensor element traces; and providing a signal processing interface to a remotely located controller integrated circuit. The sensor element traces may form a portion of one dimensional linear sensor array or pixel locations in a two dimensional grid array capacitive gap biometric imaging sensor. The auxiliary circuit may provide pixel location selection or pixel signal amplification. The auxiliary circuit may be mounted on a surface of the display screen. The auxiliary circuit further comprising a separate pixel location selection controller circuit.","1. A biometric object image sensor comprising: a plurality of capacitive gap sensor electrode traces formed on a glass substrate, wherein the plurality of capacitive gap sensor electrode traces form an array of biometric sensor imaging pixel locations within a biometric sensing area of the biometric image sensor, wherein at least one of the capacitive gap sensor electrode traces comprises a transmitter electrode trace and at least one of the capacitive gap sensor electrode traces comprises a receiver electrode trace, wherein a change in a resulting signal received by the receiver electrode trace is indicative of a biometric image characteristic at a respective pixel location in the array of biometric sensor imaging pixel locations; anda controller integrated circuit (IC) mounted to the glass substrate, wherein the controller IC is in electrical contact with the plurality of capacitive gap sensor electrode traces.","18","14/880887","2015-10-12","2016-0034740","2016-02-04","9542589","2017-01-10","SYNAPTICS INCORPORATED","Khamvong  Thammasouk | Young Seen  Lee | Paul  Wickboldt","","","","G06K-0009/0002","G06K-0009/0002 | G06F-0003/044 | G06F-0021/32 | G06K-0009/00026 | G06K-0019/07756 | H01L-0027/14678 | H04L-0009/3231 | A61B-0005/117 | G07C-0009/00071 | G07C-2009/00095 | H04N-0021/4415","G06K-009/00","G06K-009/00 | G06K-019/077 | H01L-027/146 | G06F-021/32 | H04L-009/32 | G06F-003/044 | G07C-009/00 | A61B-005/117 | H04N-021/4415","","","","","","4917002004523"
"US","US","P","B2","Medical image display apparatus and medical image display method","To retrieve a desired image from plural types of successive images arranged based on various physical quantities, a cuboid object that is an assembly of multiple unit cells is displayed on a display device, a successive image group is arranged according to the physical quantities of the three axes of the cuboid object that are respectively the body-axis direction position, the first time phase intervals, and the second time phase intervals narrower than the first time phase intervals, and the respective images included in the successive image group and the respective unit cells are associated on one-to-one basis and stored in a main memory. When a three-dimensional position in the cuboid object is input by a mouse operation etc., the CPU retrieves one or multiple images associated with one or multiple unit cells determined according to the input three-dimensional position from the main memory and displays the images in an image display region.","1. A medical image display device that displays medical images, comprising: a display unit displaying a cuboid object that is an assembly of multiple unit cells;a storage unit memorizing images included in a successive image group and corresponding to respective unit cells, each unit cell of the cuboid object being associated on one-to-one basis with a corresponding image according to predetermined physical quantities for the respective three directions of the three axes of the cuboid object;an input unit inputting a three-dimensional position in the cuboid object, anda control unit controlling so that one or multiple images associated with one or multiple unit cells determined according to the three-dimensional position input from the input unit are retrieved from the storage unit and are displayed on the display unit,wherein the input unit inputs the three-dimensional position in the cuboid object using a positioning line, andthe control unit controls so that the display unit displays the positioning line superimposed on the cuboid object, andwherein the input unit inputs a line width of the positioning line, andthe control unit controls so that the number of images that the display unit displays is changed according to the line width of the positioning line that is input by the input unit.","11","14/376522","2013-02-27","2015-0015572","2015-01-15","9542744","2017-01-10","HITACHI, LTD.","Hirohisa  Izumo | Kentaro  Takahashi | Takayuki  Kadomura","2012-045211","JP","2012-03-01","G06T-0007/004","G06T-0007/004 | A61B-0005/055 | A61B-0005/743 | A61B-0005/748 | G06F-0003/04815 | G06F-0003/04845 | G06T-0007/0012 | G06T-0019/00 | A61B-0005/7425 | A61B-0006/032 | A61B-0006/463 | A61B-0006/5288 | A61B-2576/023 | G01R-0033/5608 | G06F-2203/04802 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/30004 | G06T-2219/008","G06T-007/00","G06T-007/00 | G06T-019/00 | G06F-003/0481 | G06F-003/0484 | A61B-005/055 | A61B-005/00 | A61B-006/00 | A61B-006/03 | G01R-033/56","","","","","","4917002004678"
"US","US","P","B2","Microprocessor controlled ambulatory medical apparatus with hand held communication device","An implantable infusion pump possesses operational functionality that is, at least in part, controlled by software operating in two processor ICs which are configured to perform some different and some duplicate functions. The pump exchanges messages with an external device via telemetry. Each processor controls a different part of the drug infusion mechanism such that both processors must agree on the appropriateness of drug delivery for infusion to occur. Delivery accumulators are incremented and decremented with delivery requests and with deliveries made. When accumulated amounts reach or exceed, quantized deliverable amounts, infusion is made to occur. The accumulators are capable of being incremented by two or more independent types of delivery requests. Operational modes of the infusion device are changed automatically in view of various system errors that are trapped, various system alarm conditions that are detected, and when excess periods of time lapse between pump and external device interactions.","1. A communication system for a medical device, the system comprising: an ambulatory medical device (MD) configured to provide a treatment to a body of a patient having a housing, the MD further including within the housing: (1) a reservoir capable of containing a drug, (2) a pumping mechanism for transferring the drug from the reservoir to the body of a patient, (3) a MD electronic control circuitry that further comprises at least one MD telemetry system and at least one MD processor that controls, at least in part, operation of the MD telemetry system and operation of the MD, including, at least in part, operation of the pumping mechanism, and wherein a first portion of the MD telemetry system is incorporated into the MD processor and a second portion of the MD telemetry system is external to the MD processor, and (4) a MD memory; anda communication device (CD) comprising:at least one CD telemetry system configured to send messages to or receive messages from the MD telemetry system;at least one CD memory; andat least one CD processor that controls, at least in part, operation of the CD telemetry system and operation of the CD, wherein the MD is configured to selectively disable a MD component or activity of a MD component for transmission or reception of messages by the MD telemetry system, further wherein the MD is configured to selectively enable and disable the MD telemetry system; andwherein the MD is configured to disable the MD component or activity of the MD component when the MD telemetry system is enabled.","3","14/528909","2014-10-30","2015-0057518","2015-02-26","9533096","2017-01-03","MEDTRONIC MINIMED, INC.","Ronald J.  Lebel | Timothy J.  Starkweather | Philip T.  Weiss","","","","A61M-0005/172","A61M-0005/172 | A61B-0005/0002 | A61B-0005/14532 | A61B-0005/6847 | A61M-0005/14244 | A61M-0005/14276 | A61M-0005/168 | A61N-0001/3727 | A61N-0001/37211 | A61N-0001/37247 | A61N-0001/37252 | A61N-0001/37258 | A61N-0001/37264 | A61N-0001/37276 | G06F-0003/065 | G06F-0003/0619 | G06F-0003/0673 | G06F-0008/60 | G06F-0008/65 | G06F-0019/3412 | G06F-0019/3468 | G06Q-0050/22 | A61B-2560/0209 | A61M-0005/16831 | A61M-2005/14208 | A61M-2205/18 | A61M-2205/3507 | A61M-2205/3523 | A61M-2205/50 | A61M-2205/581 | A61M-2205/582 | A61M-2205/6018 | A61M-2205/8206 | A61M-2207/00 | A61N-0001/375 | Y02B-0060/183 | Y10S-0128/13 | Y10S-0128/903 | Y10T-0029/49117 | Y10T-0029/49826","A61M-005/172","A61M-005/172 | A61M-005/142 | A61M-005/168 | A61N-001/372 | G06F-009/445 | G06F-019/00 | G06Q-050/22 | A61B-005/00 | A61B-005/145 | G06F-003/06 | A61N-001/375","","","","","","4917001000942"
"US","US","P","B2","System and method for selecting features for identifying human activities in a human-computer interacting environment","A System and method for identifying one or more human activities in a human-computer interacting environment. Skeleton points associated with a human are received. A data variation factor for the skeleton points is calculated, and a set of skeleton points is selected based on the data variation factor. One or more features are defined from the set of skeleton points by identifying a variance in coordinates of the set of skeleton points by using one or more statistical parameters. The one or more features are used to identify the one or more human activities.","1. A system for selecting one or more features to identify one or more human activities in a human-computer interacting environment, the system comprising: a processor;a non-transitory memory coupled to the processor, wherein the processor is capable of executing a plurality of modules stored in the memory, and wherein the plurality of modules comprise: a receiving module that receives skeleton points associated with one or more humans, wherein the one or more humans perform the one or more human activities, and wherein the skeleton points comprise a plurality of position coordinates of the one or more humans;a computation module that: calculates a data variation factor for the skeleton points, wherein the data variation factor identifies a variation between two or more of the plurality of position coordinates of the one or more human, and wherein the data variation factor is indicative of a variation between the one or more humans performing one or more activities and a variation between the one or more human activities;scales the data variation factor with respect to a maximum and a minimum value and sorts the data variation factor by distance metrics in a descending order such that the skeleton point is independent of the one or more human; andcomputes the distance metrics by scaling first four maximum values, wherein first four maximum values correspond to five position coordinates from amongst the plurality of position coordinates;a selection module that selects a set of skeleton points from the skeleton points based on the scaled data variation factor;a feature defining module that: identifies a change in position coordinates associated with the set of skeleton points by using one or more statistical parameters, wherein the set of skeleton points defines the one or more human activity to be identified; andextracts one or more features from the set of skeleton points based on the change in the position coordinates; andan identification module to identify the one or more human activities based on the extracted one or more features.","13","14/576627","2014-12-19","2015-0186724","2015-07-02","9536145","2017-01-03","TATA CONSULTANCY SERVICES LIMITED","Ramu Reddy  Vempada | Tanushyam  Chattopadhyay","04097/MUM/2013","IN","2013-12-27","G06K-0009/00624","G06K-0009/00624 | A61B-0005/1123 | A61B-0005/1128 | A61B-0005/7267 | G06F-0003/017 | G06K-0009/00342 | G06K-0009/00348 | G06K-0009/44 | G06K-0009/52 | G06K-0009/6269","G06K-009/00","G06K-009/00 | A61B-005/11 | G06F-003/01 | G06K-009/52 | A61B-005/00 | G06K-009/44 | G06K-009/62","","","","","","4917001003977"
"US","US","P","B2","Management, control and communication with sensors","A voice call is established using a computing device. A user is instructed to prepare a first device for pairing with the computing device and a server may instruct the computing device to scan for additional devices. The server may identify a first device from a list of devices and may instruct the computing device to pair with the first device.","1. A method comprising: initiating a voice call with a remote operator in a call center;receiving instructions from the remote operator for a user to prepare a first device for pairing with a wearable device;receiving a first user input at the first device indicating a pairing request for the wearable device;after receiving the first user input, requesting, by a server, a list of one or more devices that are available for communication with the wearable device;receiving, at the server, the list of the one or more devices available for communication with the wearable device;receiving, at the server, a second user input identifying the first device from the list of one or more devices, wherein the first device comprises a health sensor; andtransmitting, from the server to the wearable device and in response to the second user input identifying the first device, one or more instructions for use by the wearable device in pairing the health sensor with the wearable device.","20","14/062688","2013-10-24","2014-0118159","2014-05-01","9526420","2016-12-27","NORTEK SECURITY & CONTROL LLC","Ram David Adva  Fish | Henry  Messenger","","","","A61B-0005/0022","A61B-0005/0022 | A61B-0005/6801 | G08C-0017/02 | H04Q-0009/00 | A61B-0005/02055 | A61B-0005/1112 | A61B-0005/747 | A61B-2560/0266 | G08C-0017/00 | G08C-2201/31","G08C-019/16","G08C-019/16 | G06F-017/30 | G06F-003/00 | G06Q-010/00 | A61B-005/00 | G08C-017/02 | H04Q-009/00 | A61B-005/0205 | A61B-005/11 | G08C-017/00","","","","","","4916052000981"
"US","US","P","B2","System for monitoring individuals with a monitoring device, telemetry system, activity manager and a feedback system","A monitoring device, with one or more sensors detects or measures individual information selected from of at least one of, an individual's activities, behaviors and habit information, and an individual's health. The monitoring device includes ID circuitry with an ID storage that contains a unique individual ID, a communication system which reads and transmits the unique individual ID from the ID storage, a power source and a pathway system. A telemetry system is in communication with the monitoring device. An activity manager is in communication with the monitoring device. The activity manager provides information analysis of the individual information received from the monitoring device, the individual information selected from at least one of, individual physiological information, information that is indicative of the individual's activities, data indicative of one or more contextual parameters of the individual and monitoring a degree to which an individual has followed a routine.","1. A system for determining sleep monitored information about an individual, comprising: a monitoring device that includes a microphone, an RF transmitter and sensors to determine air quality, sound level/quality, light quality and ambient temperature near the individual configured to assist to determine individual sleep information and sleep behavior information, the RF transmitter serving as a communication device;an accelerometer configured to detect a user'ss movement information, the accelerometer and the monitoring system configured to assist to determine individual sleep information and sleep behavior information, the microphone configured to record user movement sounds detected by the accelerometer, the accelerometer configured to cause the microphone to stop recording user movement sounds when the movement sounds are not directed to a sleep related parameter;a telemetry system in communication with the monitoring device;a sleep related activity manager in communication with the monitoring device, the sleep related activity manager analyzing telemetry data based on sleep onset and wake time, sleep interruptions, and the quality and depth of sleep; anda feedback system or subsystem in communication with the sleep related activity manager and in operation is configured to communicate the sleep related information.","12","13/967120","2013-08-14","2014-0247150","2014-09-04","9526422","2016-12-27","HELLO INC.","James  Proud","","","","A61B-0005/0024","A61B-0005/0024 | A61B-0005/0022 | A61B-0005/02055 | A61B-0090/90 | A61B-0090/98 | H02J-0007/025 | H02J-0017/00 | A61B-0005/0205 | A61B-0005/1112 | A61B-0005/1118 | A61B-0005/443 | A61B-0005/6831 | A61B-0005/6898 | A61B-0005/743 | A61B-2560/0214 | A61B-2562/0233 | A61B-2562/08 | G06F-0008/60 | G06F-0008/61 | G06F-0008/65 | G06F-0008/67 | H02J-2007/0096 | H04L-0067/12 | H04L-0067/22","G06F-009/44","G06F-009/44 | A61B-005/00 | H02J-007/02 | H02J-017/00 | G06F-009/445 | H02J-007/00 | A61B-005/0205 | A61B-005/11 | H04L-029/08","","","","","","4916052000983"
"US","US","P","B2","System and method for evaluating a patient status for use in heart failure assessment","A system and method for evaluating a patient status from sampled physiometry for use in heart failure assessment is presented. Physiological measures, including at least one of direct measures regularly recorded on a substantially continuous basis by a medical device and measures derived from the direct measures are stored. At least one of those of the physiological measures, which relate to a same type of physiometry, and those of the physiological measures, which relate to a different type of physiometry are sampled. A status is determined for a patient through analysis of those sampled measures assembled from a plurality of recordation points. The sampled measures are evaluated. Trends that are indicated by the patient status, including one of a status quo and a change, which might affect cardiac performance of the patient, are identified. Each trend is compared to worsening heart failure indications to generate a notification of parameter violations.","1. A computer-implemented system for evaluating a patient status for use in heart failure assessment, comprising: a data module configured to assemble physiological measures which were electronically stored in a memory and directly recorded as data on a substantially continuous basis by medical device for a patient or indirectly derived from the data, wherein the physiological measures comprise measures for the patient and one or more of measures for a peer group of disease specific patients and measures for an overall patient population;a status module configured to sample the physiological measures over a plurality of data assembly points;an evaluation module configured to evaluate and match at each data assembly point the sampled physiological measures to determine a patient status indicator;a diagnosis module configured to determine one of a status quo and a change in cardiac performance of the patient and compare the change in the cardiac performance to worsening heart failure indications;a quality of life module configured to query the patient on a regular basis and collect quality of life measures and to chronicle the quality of life measures with the physiological measures; anda feedback module configured to provide tiered feedback based on the patient status indicator comprising: a first level module configured to communicate, at a first level, an interpretation of the change in the cardiac performance;a second level module configured to communicate, at a second level, a notification of potential medical concern based on the change in the cardiac performance to the patient;a third level module configured to communicate, at a third level, a notification of potential medical concern based on the change in the cardiac performance to medical personnel; anda fourth level module configured to communicate to a patient medical device of the patient, at a fourth level, a set of reprogramming instructions based on the change in the cardiac performance;wherein the tiered feedback has increasing levels of patient involvement and medical care intervention.","24","11/894281","2007-08-20","2007-0293738","2007-12-20","9526456","2016-12-27","CARDIAC PACEMAKERS, INC.","Gust H.  Bardy","","","","A61B-0005/7275","A61B-0005/7275 | A61B-0005/0002 | A61B-0005/0006 | A61B-0005/0022 | A61B-0005/0031 | A61B-0005/021 | A61B-0005/0205 | A61B-0005/02028 | A61B-0005/1116 | A61B-0005/1118 | A61B-0005/4878 | A61B-0005/686 | A61B-0005/7246 | A61B-0005/746 | A61B-0007/02 | A61N-0001/37258 | A61N-0001/3962 | G06F-0019/322 | G06F-0019/345 | G06F-0019/3418 | G06F-0019/3431 | G06F-0019/3487 | G06Q-0050/24 | A61B-0005/0215 | A61B-0005/0432 | A61B-0005/0826 | A61B-0005/145 | A61N-0001/37282 | Y10S-0128/92","A61N-005/00","A61N-005/00 | G06F-019/00 | A61B-005/00 | A61N-001/39 | A61N-001/372 | A61B-005/02 | A61B-005/0205 | G06Q-050/24 | A61B-005/021 | A61B-005/11 | A61B-007/02 | A61B-005/0215 | A61B-005/0432 | A61B-005/145 | A61B-005/08","","","","","","4916052001017"
"US","US","P","B2","Displaying a barcode on a display of an infusion pump","An infusion pump system includes an infusion channel, and a display associated with the infusion channel. The display is for rendering a scannable barcode.","1. An infusion pump system comprising: an infusion channel;a display associated with the infusion channel for rendering scannable barcodes;a wireless interface; anda barcode generator to generate in real-time a first scannable barcode and a second scannable barcode in response to input information comprising configuration information received via the wireless interface from a remote medical system, wherein the configuration information includes a volume infused by the infusion pump system via the infusion channel and a volume of medication remaining, wherein the second scannable barcode replaces the first scannable barcode on the display.","13","14/886974","2015-10-19","2016-0042264","2016-02-11","9530087","2016-12-27","CAREFUSION 303, INC.","Gregory  Borges | Jeffrey L.  Gaetano | Daniel  Vik","","","","G06K-0019/06112","G06K-0019/06112 | A61M-0005/142 | G06F-0017/30879 | G06F-0019/3406 | G06F-0019/3468 | G06F-0019/36 | G06K-0007/1095 | G06K-0019/06028 | G06Q-0050/24 | A61M-2205/3569 | A61M-2205/502 | A61M-2205/6063 | A61M-2205/6072","G06K-019/00","G06K-019/00 | G06K-019/06 | G06F-019/00 | G06Q-050/24 | A61M-005/142 | G06F-017/30 | G06K-007/10","","","","","","4916052004625"
"US","US","P","B2","Modifying a person's eating and activity habits","A system for managing the food intake of a person comprises means for collecting information about food consumed by the subject, and means for providing feedback to the subject regarding the food consumed. It further comprises a sensor 57 for obtaining a signal related to the person and monitoring means for generating the information by performing a pattern recognition of the obtained signal for detecting whether the person is consuming food. The sensor comprises a camera and the pattern recognition comprises image processing. The image processing comprises the detection of a mouth and of a hand and of food. The system further comprises means for causing an audio/video-rendering device 56 to deliver the feedback. The camera is attached to the rendering device. The system further comprises means for identifying available rendering devices 56 arranged for being caused to deliver feedback.","1. An apparatus, comprising: a microprocessor configured to:receive image data of a food;receive data corresponding to movement by a subject relative to the food;based on the image data, determine that the food is unhealthy;based on the determination that the food is unhealthy and further based on a determination by the microprocessor that the data about the movement by the subject corresponds to a limited movement pattern, determine that the subject is engaged in unhealthy behavior;based on the determination of the unhealthy behavior, provide feedback related to the unhealthy behavior; andstore in memory the image data and the data corresponding to movement by the subject over a predefined time duration and provide the feedback after the predefined time duration.","19","14/989828","2016-01-07","2016-0117952","2016-04-28","9524654","2016-12-20","KONINKLIJKE PHILIPS N.V.","Mariana  Simons-Nikolova | Maarten Peter  Bodlaender","2005-112219","EP","2005-12-15","G09B-0019/0092","G09B-0019/0092 | A61B-0005/1123 | A61B-0005/1128 | G06F-0019/3418 | G06F-0019/3475 | G06T-0007/20 | A61B-2562/0219","G09B-019/00","G09B-019/00 | A61B-005/11 | G06F-019/00 | G06T-007/20 | G06F-003/048","","","","","","4916051003329"
"US","US","P","B2","Method of operating an electronic device providing a bioeffect image","A method of operating an electronic device includes displaying a first image, extracting a user-interested region from a region including the first image, and displaying a bioeffect image at the user-interested region. The first image and bioeffect image are different images.","1. A method of operating an electronic device, the method comprising: displaying a first image;detecting a plurality of positions designated by an input device during a plurality of frames;calculating an average position by averaging the positions;identifying a user-interested region from a region including the first image based on the average position; anddisplaying a bioeffect image at the user-interested region, wherein the first image and the bioeffect image are different images, and wherein the bioeffect image is a type which is to induce at least one of a therapeutic effect or a predetermined physiological response of a person.","17","14/589035","2015-01-05","2015-0356954","2015-12-10","9524703","2016-12-20","SAMSUNG DISPLAY CO., LTD.","Chang-Hoon  Lee | IL-Nam  Kim | Jong-In  Baek | Yi-Joon  Ahn","10-2014-0070024","KR","2014-06-10","G09G-0005/377","G09G-0005/377 | A61N-0005/06 | G06F-0003/013 | G06F-0003/0227 | G06F-0003/03543 | G06F-0003/041 | G06F-0019/34 | G06F-0019/3406 | G06K-0009/2081 | G06T-0013/80 | A61N-2005/0626 | G09G-2354/00 | G09G-2380/08","G09G-005/377","G09G-005/377 | G06K-009/20 | G06T-013/80 | G06F-003/041 | G06F-003/0354 | G06F-003/02 | G06F-003/01 | A61N-005/06 | G06F-019/00","","","","","","4916051003378"
"US","US","P","B2","Semiconductor device having a transistor with an oxide semiconductor layer between a first gate electrode and a second gate electrode","A transistor a gate of which, one of a source and a drain of which, and the other are electrically connected to a selection signal line, an output signal line, and a reference signal line, respectively and a photodiode one of an anode and a cathode of which and the other are electrically connected to a reset signal line and a back gate of the transistor, respectively are included. The photodiode is forward biased to initialize the back-gate potential of the transistor, the back-gate potential is changed by current of the inversely-biased photodiode flowing in an inverse direction in accordance with the light intensity, and the transistor is turned on to change the potential of the output signal line, so that a signal in accordance with the intensity is obtained.","1. A semiconductor device comprising: a photodiode; anda transistor comprising: a first gate electrode;an oxide semiconductor layer over the first gate electrode; anda second gate electrode over the oxide semiconductor layer,wherein one electrode of the photodiode is connected to the second gate electrode of the transistor, andwherein the other electrode of the photodiode is connected to a reset signal line.","19","14/074034","2013-11-07","2014-0061739","2014-03-06","9524993","2016-12-20","Semiconductor Energy Laboratory Co., Ltd.","Yoshiyuki  Kurokawa","2010-028970 | 2010-053647","JP | JP","2010-02-12 | 2010-03-10","H01L-0027/146","H01L-0027/146 | G06F-0003/0412 | G06K-0009/0002 | G09G-0003/3648 | H01L-0027/1225 | H01L-0027/14632 | H01L-0029/7869 | H04N-0001/195 | H04N-0005/3745 | A61B-0005/1172 | G02F-0001/13318 | G02F-0001/13338 | G02F-0001/133512 | G02F-0001/133615 | G02F-0001/136209 | G02F-2001/13356 | G02F-2001/13685 | G02F-2001/133622 | G09G-2320/0666 | G09G-2360/145 | H01L-0027/14643 | H01L-0027/14678","H01L-027/146","H01L-027/146 | G06F-003/041 | H04N-005/3745 | H04N-001/195 | G06K-009/00 | H01L-029/786 | H01L-027/12 | G09G-003/36 | G02F-001/133 | G02F-001/1333 | A61B-005/117 | G02F-001/1335 | G02F-001/1362 | G02F-001/1368","","","","","","4916051003664"
"US","US","P","B2","Method and system for providing information from a patient-specific model of blood flow","Embodiments include a system for providing blood flow information for a patient. The system may include at least one computer system including a touchscreen. The at least one computer system may be configured to display, on the touchscreen, a three-dimensional model representing at least a portion of an anatomical structure of the patient based on patient-specific data. The at least one computer system may also be configured to receive a first input relating to a first location on the touchscreen indicated by at least one pointing object controlled by a user, and the first location on the touchscreen may indicate a first location on the displayed three-dimensional model. The at least one computer system may be further configured to display first information on the touchscreen, and the first information may indicate a blood flow characteristic at the first location.","1. A method for providing patient-specific blood flow information using at least a computer system, the method comprising: receiving over an electronic network, at the computer system, patient-specific anatomical data;generating, based on the received patient-specific anatomical data, a geometric model representing at least a portion of an anatomical structure of a patient, and a reduced-order model of the portion of the anatomical structure;transmitting over the electronic network one or both of the geometric model and the reduced-order model to a portable computer including a touchscreen;receiving over the electronic network, at the computer system, a user intervention input entered by a user on the touchscreen indicating a potential treatment of the anatomical structure that initiates a modification of the reduced-order model;calculating, at the computer system, at least one blood flow characteristic based on the received user intervention input and the modification of the reduced-order model; andtransmitting over the electronic network the calculated at least one blood flow characteristic to the portable computer.","30","14/177630","2014-02-11","2014-0292752","2014-10-02","9517040","2016-12-13","HEARTFLOW, INC.","Gregory R.  Hart | John H.  Stevens","","","","A61B-0006/466","A61B-0006/466 | A61B-0005/021 | A61B-0005/026 | A61B-0005/02007 | A61B-0005/0263 | A61B-0005/7275 | A61B-0005/7278 | A61B-0005/7425 | A61B-0005/7445 | A61B-0006/032 | A61B-0006/504 | A61B-0008/06 | A61B-0034/10 | G06F-0003/017 | G06F-0003/0486 | G06F-0003/0488 | G06F-0003/04815 | G06F-0017/5009 | G06F-0019/12 | G06F-0019/321 | G06F-0019/3437 | G06T-0015/00 | G06T-0017/00 | G06T-0019/20 | A61B-0005/022 | A61B-0005/055 | A61B-0006/03 | A61B-0006/5217 | A61B-2034/104 | A61B-2576/023 | G06T-2200/04 | G06T-2200/24 | G06T-2210/41 | G06T-2219/2016","G06G-007/48","G06G-007/48 | A61B-006/00 | G06T-019/20 | G06F-019/00 | A61B-005/026 | G06F-003/0481 | G06F-003/0488 | G06T-017/00 | G06T-015/00 | A61B-005/021 | A61B-005/00 | G06F-017/50 | G06F-019/12 | A61B-005/02 | G06F-003/0486 | A61B-008/06 | G06F-003/01 | A61B-006/03 | A61B-005/022 | A61B-005/055","","","","","","4916050000769"
"US","US","P","B2","Methods and systems for employing artificial intelligence in automated orthodontic diagnosis and treatment planning","A method for treating an orthodontic condition can include receiving patient data, such as through a website, accessing a database having information derived from patient treatments, generating a model of an orthodontic condition defining one or more anatomic features of a set of teeth, identifying a diagnosis of an orthodontic condition and identifying a treatment regimen for the diagnosis. A method can include tagging an anatomic feature with an electronic identifier and automatically generating a tooth setup. A system can include a server and a database, which can include information relating to patient treatments, and a website for receiving patient data. A system can include an electronic model representing anatomic features of a patient's teeth and an application adapted to identify a diagnosis and a treatment regimen for an orthodontic condition, which can include executing artificial intelligence and/or other algorithms.","1. A method for delivering a diagnosis and identification of a treatment for an orthodontic condition, comprising: providing a graphical user interface that prompts a user for electronic patient data regarding the orthodontic condition;providing access, through the graphical user interface, to a database that comprises or has access to information derived from patient treatments, the information derived from patient treatments including an electronically stored data set for each patient treatment, wherein each data set includes data that represents at least one of (a) a location and position of one or more teeth subject of a corresponding patient treatment and (b) a previously diagnosed orthodontic condition for the corresponding patient treatment;comparing coordinates that represent at least two anatomic features of a set of teeth to at least a portion of the information derived from patient treatments accessible via the database;identifying a best fit data set that represents a statistical or prioritized best fit for the coordinates;identifying at least one diagnosis of the orthodontic condition by prioritizing at least a portion of the data from a plurality of the data sets; anddelivering an electronic treatment model of the orthodontic condition that provides to the user one or more of (a) a diagnosis, (b) the diagnosis along with a probability value representing a likelihood the diagnosis is accurate, and (c) a plurality of diagnoses along with a plurality of probability values.","20","14/831648","2015-08-20","2015-0351870","2015-12-10","9517111","2016-12-13","CLEARCORRECT HOLDINGS, INC.","James  Mah","","","","A61C-0007/002","A61C-0007/002 | A61B-0005/0022 | A61B-0005/0088 | A61B-0005/4547 | A61B-0005/4552 | A61B-0005/7264 | A61B-0005/7475 | A61C-0019/05 | G06F-0017/30386 | G06F-0019/322 | G06F-0019/345 | G06K-0009/6267 | G06N-0005/02 | G06F-0019/324 | G06N-0099/005","G06F-015/18","G06F-015/18 | A61C-007/00 | G06F-019/00 | G06F-017/30 | G06N-005/02 | A61B-005/00 | A61C-019/05 | G06K-009/62 | G06N-099/00","","","","","","4916050000838"
"US","US","P","B2","Method and system for diagnosis of attention deficit hyperactivity disorder from magnetic resonance images","A method and system for automated diagnosis of attention deficit hyperactivity disorder (ADHD) from magnetic resonance images is disclosed. Anatomical features are extracted from a structural magnetic resonance image (MRI) of a patient. Functional features are extracted from a resting-state functional MRI (rsFMRI) series of the patient. An ADHD diagnosis for the patient is determined based on the anatomical features, the functional features, and phenotypic features of the patient using a trained classifier. An ADHD subtype may then be determined for patients diagnosed as ADHD positive using a second trained classifier.","1. A method for automated diagnosis of attention deficit hyperactivity disorder (ADHD), comprising: extracting anatomical features from a structural magnetic resonance image (MRI) of a patient;extracting functional features from a resting-state functional MRI (rsFMRI) series of the patient, comprising: extracting an rsFMRI time series for each of a plurality of brain regions by mapping voxels in each of a plurality of image volumes in the rsFMRI series to a plurality of brain regions and extracting an rsFMRI time series for each brain region based on the voxels mapped to that brain region in the plurality of image volumes in the rsFMRI series by calculating, for each of M brain regions, an average of voxels mapped to that brain region in each of N image volumes in the rsFMRI series, resulting in an M ×N matrix including the rsFMRI time series for each of the brain regions, andextracting the functional features based on the rsFMRI time series for each of the plurality of brain regions; anddetermining an ADHD diagnosis for the patient based on the anatomical features, the functional features, and phenotypic features of the patient using a trained machine learning classifier.","43","13/785050","2013-03-05","2013-0231552","2013-09-05","9510756","2016-12-06","SIEMENS HEALTHCARE GMBH","Leo  Grady | Sara  Saperstein | Jason  Bohland","","","","A61B-0005/0042","A61B-0005/0042 | A61B-0005/055 | A61B-0005/168 | A61B-0005/4076 | A61B-0005/7264 | A61B-0005/7267 | G06T-0007/0012 | A61B-2576/026 | G01R-0033/5602 | G06T-2207/10088 | G06T-2207/30016","G06K-007/00","G06K-007/00 | A61B-005/00 | A61B-005/055 | A61B-005/16 | G06T-007/00 | G01R-033/56","","","","","","4916049000905"
"US","US","P","B2","Method and system for reconstructing sampled signals","A method reconstructs a signal by sampling the signal using a sampling procedure to obtain an input signal. A consistent set is determined from the input signal including the first elements such that applying the sampling procedure to the first elements results in the input signal. According to the type of the signal, a guiding set is determined including second elements disjoint from the first elements. A reconstruction set including third elements is generated so that the third elements minimize a sum of a first similarity measure of the third elements to the second elements and a second similarity measure of the third elements to the first elements. A transformed signal that minimizes a function on the reconstruction set is determined. A reconstructed signal is rendered so that a third similarity measure of the reconstructed signal to the transformed signal is smaller than a tolerance.","1. A method for reconstructing a signal, wherein the signal is a light field, comprising steps of: sampling, using a sampling procedure, the signal to obtain an input signal, wherein the input signal is associated with a type;determining a consistent set from the input signal, wherein the consistent set includes first elements such that applying the sampling procedure to the first elements results in the input signal;determining, according to the type, a guiding set, wherein the guiding set includes second elements disjoint from the first elements;generating a reconstruction set, wherein the reconstruction set includes third elements, wherein the third elements minimize a sum of a first similarity measure of the third elements to the second elements and a second similarity measures of the third elements to the first elements;determining a transformed signal that minimizes a function on the reconstruction set;generating a reconstructed signal so that a third similarity measure of the reconstructed signal to the transformed signal is smaller than a tolerance; andrendering the reconstructed signal, wherein the input signal, the consistent set, the guiding set, the reconstruction set, the transformed signal and the reconstruction signal are stored in a memory connected to a processor performing the steps.","20","14/567015","2014-12-11","2016-0173736","2016-06-16","9510787","2016-12-06","MITSUBISHI ELECTRIC RESEARCH LABORATORIES, INC.","Andrei  Kniazev | Akshay  Gadde | Dong  Tian | Hassan  Mansour | Richard C  Waters","","","","A61B-0005/72","A61B-0005/72 | A61B-0005/0035 | A61B-0005/7257 | G01R-0033/5611 | G06F-0017/17 | G06K-0009/0057 | G06K-0009/527 | G06T-0003/40 | G06T-0011/003 | G10L-0021/00 | H04N-0019/00","A61B-005/00","A61B-005/00 | G01R-033/561 | G06T-011/00 | H04N-019/00 | G06K-009/00 | G06K-009/52 | G06F-017/17 | G06T-003/40 | G10L-021/00","","","","","","4916049000936"
"US","US","P","B2","Global enterprise printing and mailing","Systems, devices, and methods for global enterprise workflow management are disclosed. The system may include a communications module, memory, and processor for executing a method of managing job information. The system receives job information and uses a model to identify a desirable resource to execute the job. Then the system sends the job information to the identified resource for execution. The resource may send back information associated with the running and/or completion of the job. Various models may be used in identifying a desirable approach, including a cost model, a staffing model, and other models.","1. A system comprising: a communications network communicatively coupling a computing device with a plurality of resources that comprise at least two of an inserting device, sorting device, and printing device, wherein the plurality of resources are located in one or more different countries than that of the computing device; andthe computing device comprising: a communications module configured to communicate over the communications network with the plurality of resources;a memory configured to store job information and model information, wherein the model information identifies a utilization rating of each of the plurality of resources located in the one or more different countries, and wherein the model information further identifies a cost per piece of each of the plurality resources located in one or more different countries, the memory comprising non-volatile memory for storing computer-executable instructions; anda processor configured to execute the computer-executable instructions that, when executed by the processor, cause the computing device to perform a method comprising:receiving the job information;using the model information to automatically identify a desirable resource to execute a job corresponding to the job information, wherein the desirable resource is a first resource, which is located in a country different than that of the computing device, with a best utilization ranking as compared to utilization rankings of the other resources of the plurality of resources;communicating with the desirable resource to cause the desirable resource to prepare to process the job information;sending the job information to the desirable resource in a country different than that of the computing device, wherein the desirable resource comprises at least one of the printing device, the inserting device, and the sorting device, wherein the printing device causes a printed job to be printed before being mailed from that country of the desirable resource; andreceiving reporting information from the desirable resource, the reporting information being associated with the job information.","19","14/467510","2014-08-25","2014-0365267","2014-12-11","9514429","2016-12-06","KERN, INC.","Thomas J.  Brock | Pramod C.  Madala","","","","G06Q-0010/0633","G06Q-0010/0633 | A61B-0017/1666 | G06Q-0010/06 | G06Q-0010/063114 | H04L-0067/10 | A61B-2017/1602","G06Q-010/06","G06Q-010/06 | A61B-017/16 | H04L-029/08","","","","","","4916049004559"
"US","US","P","B2","Methods and arrangements for identifying dermatological diagnoses with clinically negligible probabilities","Reference imagery of dermatological conditions is compiled in a crowd-sourced database (contributed by clinicians and/or the lay public), together with associated diagnosis information. A user later submits a query image to the system (e.g., captured with a smartphone). Image-based derivatives for the query image are determined (e.g., color histograms, FFT-based metrics, etc.), and are compared against similar derivatives computed from the reference imagery. This comparison identifies diseases that are not consistent with the query image, and such information is reported to the user. Depending on the size of the database, and the specificity of the data, 90% or more of candidate conditions may be effectively ruled-out, possibly sparing the user from expensive and painful biopsy procedures, and granting some peace of mind (e.g., knowledge that an emerging pattern of small lesions on a forearm is probably not caused by shingles, bedbugs, malaria or AIDS). A great number of other features and arrangements are also detailed.","1. A method comprising: receiving first imagery depicting a part of a mammalian body that evidences a symptom of a possible pathological condition;processing the received imagery to derive one or more image parameter(s);searching a data structure for reference information, based on the derived image parameter(s);from the reference information, determining result information, said determining including identifying one or more particular pathological conditions that is inconsistent with the pathological condition evidenced by said depicted part of the body; andreporting, to a user, a name of at least one of said identified pathological conditions that is inconsistent with the pathological condition evidenced by said depicted part of the body.","9","14/289493","2014-05-28","2015-0003699","2015-01-01","9504420","2016-11-29","Digimarc Corporation","Bruce L.  Davis | Tony F.  Rodriguez | John  Stach","","","","A61B-0005/441","A61B-0005/441 | A61B-0005/0075 | A61B-0005/0077 | A61B-0005/1034 | A61B-0005/444 | A61B-0005/445 | A61B-0005/6898 | A61B-0005/7246 | A61B-0005/7278 | A61B-0005/743 | A61B-0005/7425 | A61B-0005/7485 | G06F-0017/30424 | G06F-0017/30554 | G06F-0019/345 | G06F-0019/3418 | G06F-0019/3443 | G06T-0005/40 | G06T-0007/0012 | G06T-0007/408 | G10L-0019/018 | A61B-0005/4806 | A61B-0005/7282 | A61B-2576/02 | G06T-2207/30088","G06F-009/00","G06F-009/00 | A61B-005/00 | G06F-019/00 | G06T-005/40 | G06T-007/00 | G06T-007/40 | A61B-005/103 | G06F-017/30 | G10L-019/018","","","","","","4916048000877"
"US","US","P","B2","System and method for using biometrics to predict and select music preferences","Systems and methods for using biometrics to select music preference are provided. A system for using biometrics to select music preferences for a user in a vehicle, comprises a music selection module electrically coupled to at least one biometric sensor in the vehicle, wherein the at least one biometric sensor senses a characteristic of the user and outputs data for the sensed characteristic to the music selection module, and wherein the music selection module selects a music selection for the user based on the sensed characteristic data, and a controller module electrically coupled to the music selection module to control playing of the music selection, wherein the controller module receives an output including the music selection from the music selection module.","1. A method for using biometrics to select music preferences for a user in a vehicle, the method comprising: monitoring the vehicle for an input from a biometric sensor;determining whether any inputs from the biometric sensor have been detected;determining whether a music selection is being played;interpreting the input from the biometric sensor to predict whether the sensory input indicates satisfaction with the music selection being played;selecting another music selection other than the music selection being played based on the interpretation of the input from the biometric sensor;categorizing the music selection being played as one the user likes or dislikes based on the interpretation of the input from the biometric sensor; andanalyzing models of biometric data applied on a filter;wherein the filter outputs a prediction of music selections for the user based on the models; andwherein the models are developed from reaction variant patterns, and the method further comprises:respectively categorizing existing reaction variant patterns under different music selections;detecting uncategorized reaction variant patterns;determining to which categorized reaction variant patterns the uncategorized reaction variant patterns are closest; andcategorizing the uncategorized reaction variant patterns under the same music selections as their closest categorized reaction variant patterns.","18","14/837910","2015-08-27","2015-0363491","2015-12-17","9507326","2016-11-29","INTERNATIONAL BUSINESS MACHINES CORPORATION","Sasha P.  Caskey | Dimitri  Kanevsky | Sameer R.  Maskey | Tara N.  Sainath","","","","G05B-0001/01","G05B-0001/01 | G06F-0003/165 | G06F-0017/30764 | G06F-0017/30778 | G06K-0009/00926","A61B-005/021","A61B-005/021 | A61B-005/0476 | A61B-005/0482 | A61B-005/0488 | A61B-005/01 | G05B-001/01 | G06F-017/30 | G06F-003/16 | G06K-009/00","","","","","","4916048003769"
"US","US","P","B2","Data communication with interventional instruments","The invention relates to a data communication system (100) and a method that can particularly be applied for communicating data from a medical instrument like a catheter or a guide-wire via a high-speedlink (101). The system (100) comprises (in-vivo) a slave component (150) with a controllable slave clock (153) and a transmitter (151) for transmitting a data signal (ds) that is clocked by the slave clock signal (clk). Moreover, it comprises (ex-vivo) a master component (110) with a clock controller (114,115,116) that receives a master clock signal (ref_clk) and the data signal (ds) and that generates a clock control signal (ccs) for adjusting the slave clock (153) to the master clock (113). The slave clock (153) may thus be realized with low space and energy requirements, e.g. by a voltage controlled oscillator (VCO). Moreover, the link (101) via which the data signal (ds) and the clock control signal (ccs) are exchanged may be realized by just two signal wires.","1. A medical system, comprising: a) an interventional instrument including a slave component further including: a1) a controlled oscillator for generating a slave clock signal in response to a received clock control signal via a link, anda2) a transmitter for transmitting a data signal that is clocked by the slave clock signal on the link, the data signal includes encoded data from sensors, actuators, or imaging devices; andb) external equipment including a master component further including: b1) a receiver for receiving said data signal via the link,b2) a master clock unit for generating a master clock signal, andb3) a clock controller being configured to i) receive the master clock signal and the data signal, ii) recover the slave clock signal from the received data signal, and iii) compare the frequency of the recovered slave clock signal and the master in order to generate the clock control signal for adjusting the controlled oscillator to the master clock unit,b4) a transmitter for transmitting at least the clock control signal via the link; andc) the link includes at least two wires.","13","14/362650","2012-10-25","2014-0336623","2014-11-13","9503250","2016-11-22","KONINKLIJKE PHILIPS N.V.","Antonia Cornelia  Van Rens | Neil Francis  Joye | Bout  Marcelis","","","","H04L-0007/0008","H04L-0007/0008 | A61M-0025/00 | A61M-0025/09 | H04L-0007/02 | H04L-0067/12 | A61B-0005/0013 | A61M-2205/3576","H04L-007/00","H04L-007/00 | H04L-007/02 | A61M-025/00 | A61M-025/09 | H04L-029/08 | A61B-005/00","","","","","","4916047005977"
"US","US","P","B2","Methods and systems for indicating behavior in a population cohort","Avatars, methods, apparatuses, computer program products, devices and systems are described that carry out identifying a member of a population cohort; and indicating at least one behavior in the member of the population cohort based on an association between the population cohort and at least one cohort-linked avatar.","1. A system comprising: a presentation unit configured to present to at least one member of a population a plurality of avatars associated with at least one instance of media content;a physiologic activity measurement unit configured to measure at least one physiologic activity of the at least one member of the population, the at least one physiologic activity proximate to at least one presented avatar among the plurality of avatars associated with at least one instance of media content;an association unit configured to associate the at least one physiologic activity with at least one mental state; anda media content identification unit configured to identify at least one instance of media content based on the at least one mental state.","30","13/439733","2012-04-04","2012-0316793","2012-12-13","9495684","2016-11-15","The Invention Science Fund I, LLC","Edward K. Y.  Jung | Eric C.  Leuthardt | Royce A.  Levien | Robert W.  Lord | Mark A.  Malamud | John D.  Rinaldo, Jr. | Lowell L.  Wood, Jr.","","","","G06Q-0030/02","G06Q-0030/02 | A61B-0005/04842 | A61B-0005/16 | G06Q-0030/0204 | A61B-0005/04009 | A61B-0005/055 | A61B-0005/0533 | A61B-0005/14553 | A61B-0005/167 | A61B-0005/441 | A61B-0005/726","G06F-017/00","G06F-017/00 | G06N-005/02 | G06Q-030/02 | A61B-005/0484 | A61B-005/16 | A61B-005/04 | A61B-005/053 | A61B-005/055 | A61B-005/00 | A61B-005/1455","","","","","","4916046004368"
"US","US","P","B2","Emotive text-to-speech system and method","Information about a device may be emotively conveyed to a user of the device. Input indicative of an operating state of the device may be received. The input may be transformed into data representing a simulated emotional state. Data representing an avatar that expresses the simulated emotional state may be generated and displayed. A query from the user regarding the simulated emotional state expressed by the avatar may be received. The query may be responded to.","1. An emotive text-to-speech system comprising: a computer configured to receive data representing a text stream and a simulated emotion to be expressed by an audio output;selectively embed at least a portion of the data representing the simulated emotion in the data representing the text stream to form data representing an emotive text stream representing a spoken phrase having simulated emotional content; andoutput the emotive text stream data for play by the audio output.","5","12/265359","2008-11-05","2009-0063154","2009-03-05","9495787","2016-11-15","FORD GLOBAL TECHNOLOGIES, LLC","Oleg Yurievitch  Gusikhin | Perry Robinson  MacNeille | Erica  Klampfl | Kacie Alane  Theisen | Dimitar Petrov  Filev | Yifan  Chen | Basavaraj  Tonshal","","","","G06T-0013/40","G06T-0013/40 | A61B-0005/165 | A61B-0005/18 | A61B-0005/4803 | A61B-0005/744 | B60W-0050/10 | G01C-0021/3608 | G06F-0003/011 | G06N-0003/006 | G06T-0013/205 | G10L-0017/26 | A61B-0005/7264 | B60W-2040/089 | G06F-2203/011","G05D-001/00","G05D-001/00 | G05D-003/00 | G06F-007/00 | G06F-017/00 | G06T-013/40 | B60W-050/10 | G01C-021/36 | G06F-003/01 | G06N-003/00 | G10L-017/26 | G06T-013/20 | A61B-005/16 | A61B-005/18 | B60W-040/08 | A61B-005/00","","","","","","4916046004471"
"US","US","P","B2","Methods and apparatus for providing a snapshot truthing system for a tracker","A method for detecting and correcting drift associated with operation of a hybrid tracking system is provided. The method obtains a data signal from a first tracker subsystem having a first tracker latency time; for a defined window of time, the method captures snapshot input data for a second tracker subsystem having a second tracker latency time which is longer than the first tracker latency time; and captures synchronized data from the data signal which corresponds to the defined window of time; wherein the defined window of time comprises a time duration shorter than the second tracker latency time, to capture the snapshot input data. The method further determines a level of drift associated with operation of the first tracker subsystem; and adjusts operation of the first tracker subsystem according to the determined level of drift.","1. A method for detecting and correcting drift associated with operation of a hybrid tracking system, the method comprising: obtaining a data signal from a first tracker subsystem having a first tracker latency time;for a defined window of time, capturing snapshot input data for a second tracker subsystem having a second tracker latency time which is longer than the first tracker latency time; andcapturing synchronized data from the data signal which corresponds to the defined window of time;wherein the defined window of time comprises a time duration shorter than the second tracker latency time, to capture the snapshot input data;calculating second tracker snapshot results from the captured snapshot input data for the second tracker subsystem;calculating first tracker snapshot results from the captured synchronized data from the first tracker subsystem;calculating an error between the first tracker snapshot results and the second tracker snapshot results, to determine a level of drift associated with operation of the first tracker subsystem; andadjusting operation of the first tracker subsystem according to the determined level of drift.","20","14/669336","2015-03-26","2016-0282936","2016-09-29","9489045","2016-11-08","HONEYWELL INTERNATIONAL INC.","Brent D.  Larson | Ken  Leiphon","","","","G06F-0003/012","G06F-0003/012 | G02B-0027/0172 | G02B-0027/0179 | G06F-0003/017 | G02B-2027/014 | G02B-2027/0187","G01C-021/16","G01C-021/16 | G08G-005/02 | G01S-005/16 | G06F-003/03 | G06F-009/44 | G09B-005/06 | A61B-005/11 | H04L-029/08 | G05D-001/08 | G01C-017/38 | G01B-021/04 | G02B-027/01 | A61B-005/06 | G06F-003/01","","","","","","4916045003777"
"US","US","P","B2","Method for selecting music based on face recognition, music selecting system and electronic apparatus","A method for selecting music based on face recognition, a music selecting system and an electronic apparatus are provided. The method includes the following steps: accessing a database to retrieve a plurality of song emotion coordinates corresponding to a plurality of songs; mapping the song emotion coordinates to an emotion coordinate graph; capturing a human face image; identifying an emotion state corresponding to the human face image, and transforming the emotion state to a current emotion coordinate; mapping the current emotion coordinate to the emotion coordinate graph; updating a song playlist according to a relative position between the current emotion coordinate and a target emotion coordinate, wherein the song playlist includes a plurality of songs to be played that direct the current emotion coordinate to the target emotion coordinate.","1. A method for selecting music based on face recognition, adapted to a music selecting system comprising an image capturing device, an image processing device, a control device, a playing device and a database, the method for selecting music based on face recognition comprising: accessing, by the control device, the database to retrieve a plurality of song emotion coordinates corresponding to a plurality of songs;mapping, by the control device, the song emotion coordinates to an emotion coordinate graph;capturing, by the image capturing device, a human face image;recognizing, by the image processing device, an emotion state corresponding to the human face image, and transforming the emotion state to a current emotion coordinate;mapping, by the control device, the current emotion coordinate to the emotion coordinate graph;updating, by the control device, a song playlist according to a relative position between the current emotion coordinate and a target emotion coordinate, wherein the song playlist comprises a plurality of songs to be played that direct the current emotion coordinate to the target emotion coordinate; andplaying, by the playing device, the plurality of songs of the updated song playlist,wherein the step of updating the song playlist according to the relative position between the current emotion coordinate and the target emotion coordinate comprises:defining, by the control device, a plurality of reference emotion coordinates on a first connection line, wherein the first connection line is connected between the current emotion coordinate and the target emotion coordinate, the plurality of reference emotion coordinates are different from the current emotion coordinate and the target emotion coordinate; selecting, by the control device, a plurality of candidate song emotion coordinates closest to the reference emotion coordinates from the song emotion coordinates; andsetting, by the control device, the songs corresponding to the candidate song emotion coordinates to be the songs to be played,wherein the step of defining the reference emotion coordinates on the first connection line comprises:characterizing, by the control device, an nth reference emotion coordinate in the reference emotion coordinates as: wherein NR is a total number of the songs to be played, n is a positive integer between 1 and NR, dTS is a distance between the emotion coordinate and the target emotion coordinate, θTS is an included angle between a horizontal axis of the emotion coordinate graph and the first connection line, AEn is a vertical coordinate of the nth reference emotion coordinate on the emotion coordinate graph, VEn is a horizontal coordinate of the nth reference emotion coordinate on the emotion coordinate graph, AS is a vertical coordinate of the current emotion coordinate on the emotion coordinate graph, and VS is a horizontal coordinate of the current emotion coordinate on the emotion coordinate graph.","7","14/284405","2014-05-22","2015-0206523","2015-07-23","9489934","2016-11-08","NATIONAL CHIAO TUNG UNIVERSITY","Kai-Tai  Song | Chao-Yu  Lin","103102459 A","TW","2014-01-23","G10H-0007/002","G10H-0007/002 | A61B-0005/0077 | A61B-0005/165 | G10H-0001/0008 | G06F-0017/30026 | G06F-0017/30047 | G06K-0009/00221 | G10H-2220/131 | G10H-2220/455 | G10H-2240/085 | G10H-2240/131 | G10H-2240/141 | G10H-2250/131","G06F-017/30","G06F-017/30 | G06K-009/00 | G10H-007/00 | A61B-005/16 | A61B-005/00 | G10H-001/00","","","","","","4916045004664"
"US","US","P","B2","Direct neural interface system and method of calibrating it","A direct neural interface system comprised of electrodes for acquiring electrophysiological signals representative of a neuronal activity of a subject's brain; a pre-processor for conditioning, digitizing and preprocessing the electrophysiological signals; a processor for processing the digitized and preprocessed electrophysiological signals and generating command signals; and an output for outputting said command signals; wherein the processor is adapted for: representing the electrophysiological signals acquired over an observation time window in the form of a N-way data tensor, N being greater or equal to three; and generating command signals corresponding to the observation time window by applying a multi-way regression model over the data tensor. A method of calibrating the direct neural interface system.","1. A direct neural interface system comprising: signal acquisition mechanism configured for acquiring electrophysiological signals representative of a neuronal activity of a subject'ss brain (B);preprocessor (PPM) for conditioning, digitizing and preprocessing said electrophysiological signals;processor configured (PM) for processing the digitized and preprocessed electrophysiological signals and for generating command signals as a function thereof; andoutput for outputting said command signals configured for driving an external device;wherein said preprocessor and said processor are configured for: generating a N-way data tensor representing the electrophysiological signals acquired over an observation time window, N being greater or equal to two; andgenerating said command signals configured for driving the external device, wherein said command signals correspond to said observation time window by applying a multi-way regression model over said data tensor, andwherein said processor is configured for generating an output signal corresponding to said observation time window by applying a multi-way partial least square?or NPLS?regression model to said data tensor, which allows better utilization of available information and avoids the need for human intervention for associating electrophysiological activity to intended or motor action.","15","13/698166","2010-05-17","2013-0165812","2013-06-27","9480583","2016-11-01","COMMISSARIAT A L'ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES","Tetiana  Aksenova | Andriy  Yelisyeyev","","","","A61F-0002/72","A61F-0002/72 | A61B-0005/04012 | A61B-0005/0482 | A61F-0004/00 | G06F-0003/015 | A61B-0005/0476 | A61B-0005/726","A61B-005/04","A61B-005/04 | A61F-002/72 | A61B-005/0482 | A61F-004/00 | G06F-003/01 | A61B-005/0476 | A61B-005/00","","","","","","4916044001023"
"US","US","P","B2","Determination of neuropsychiatric therapy mechanisms of action","A computer implemented method, apparatus, and computer program product of determining mechanisms of action for therapies. A first set of brain scans for each subject in a plurality of subjects generated at a first time period and a second set of brain scans for each subject generated at a second time period are received. Each subject is diagnosed with a given condition and received a given therapy. A set of changes in the set of brain scans is identified for the each subject based on a comparison of a first set of regions of interest in the first set of scans for each subject with a second set of regions of interest in the second set of scans for each subject. A set of typical changes attributable to the given therapy is identified. A mechanism of action for the given therapy is generated based on the set of typical changes.","1. A computer implemented method of assessing neuroimaging and medical data to determine mechanisms of action for neuropsychiatric therapies, the computer implemented method comprising: receiving, at a processor via a network connection, neuroimaging data of a first set of human brain scans for each human subject in a plurality of human subjects diagnosed with a given neuropsychiatric condition generated at a first time period prior to beginning implementation of a neuropsychiatric therapy to treat the given neuropsychiatric condition and a second set of human brain scans for the each human subject in the plurality of human subjects diagnosed with the given neuropsychiatric condition generated at a second time period of a given amount of time after beginning the implementation of the neuropsychiatric therapy to treat the given neuropsychiatric condition, wherein a set of one or more scanning devices generate the neuroimaging data of the first set of human brain scans and the second set of human brain scans, and wherein the neuropsychiatric therapy is received by the each human subject in the plurality of human subjects diagnosed with the given neuropsychiatric condition;automatically searching, using the processor, via the network connection a set of online electronic medical literature sources for portions of medical literature describing the neuropsychiatric therapy used to treat the given neuropsychiatric condition;automatically identifying, using the processor, a first set of regions of interest in the first set of human brain scans for the each human subject in the plurality of human subjects diagnosed with the given neuropsychiatric condition generated at the first time period prior to beginning the implementation of the neuropsychiatric therapy to treat the given neuropsychiatric condition and a second set of regions of interest in the second set of human brain scans for the each human subject in the plurality of human subjects diagnosed with the given neuropsychiatric condition generated at the second time period of the given amount of time after beginning the implementation of the neuropsychiatric therapy to treat the given neuropsychiatric condition;identifying, using the processor, a set of changes in the neuroimaging data of the first set of human brain scans and the second set of human brain scans for the each human subject in the plurality of human subjects diagnosed with the given neuropsychiatric condition based on a comparison of the first set of regions of interest for the each human subject with the second set of regions of interest for the each human subject, wherein the set of changes comprises indicators of change occurring after the each human subject began receiving the neuropsychiatric therapy to treat the given neuropsychiatric condition;analyzing, using the processor, the set of changes for the each human subject with the portions of the medical literature describing the neuropsychiatric therapy used to treat the given neuropsychiatric condition to identify a set of changes attributable to the neuropsychiatric therapy;generating, using the processor, a mechanism of action for the neuropsychiatric therapy for the plurality of human subjects diagnosed with the given neuropsychiatric condition based on the analyzing of the set of changes for the each human subject, wherein the mechanism of action comprises a set of links to the portions of the medical literature associated with the neuropsychiatric therapy and each change in the set of changes identified from an automatic searching of the set of online electronic medical literature sources;generating, using the processor, the set of links to the portions of the medical literature associated with the neuropsychiatric therapy used to treat the given neuropsychiatric condition; andembedding, using the processor, the set of links to the portions of the medical literature associated with the neuropsychiatric therapy used to treat the given neuropsychiatric condition within the first set of regions of interest located in the first set of human brain scans for the each human subject in the plurality of human subjects diagnosed with the given neuropsychiatric condition and the second set of regions of interest located in the second set of human brain scans for the each human subject in the plurality of human subjects diagnosed with the given neuropsychiatric condition.","22","14/855987","2015-09-16","2016-0004821","2016-01-07","9483613","2016-11-01","INTERNTIONAL BUSINESS MACHINES CORPORATION","Joanna L.  Fueyo | Robert L.  Angell | Robert R.  Friedlander | James R.  Kraemer","","","","G06F-0019/321","G06F-0019/321 | A61B-0005/055 | A61B-0005/411 | A61B-0005/417 | A61B-0006/037 | A61B-0006/501 | A61B-0006/56 | A61B-0006/563 | A61B-0006/566 | G06F-0017/30011 | G06F-0017/30864 | G06F-0019/345 | G06F-0019/3443 | G06F-0019/3481 | G06K-0009/46 | G06K-0009/6215 | G06T-0007/0012 | G06F-0019/324 | G06K-2009/4666 | G06T-2207/10088 | G06T-2207/10104 | G06T-2207/30016","A61B-005/05","A61B-005/05 | G06F-019/00 | A61B-005/055 | A61B-005/00 | A61B-006/03 | A61B-006/00 | G06F-017/30 | G06K-009/46 | G06K-009/62 | G06T-007/00","","","","","","4916044004042"
"US","US","P","B2","Cost effective and robust system and method for eye tracking and driver drowsiness identification","A cost-effective and robust method for localizing and tracking drowsiness state of the eyes of driver by using images captured by near infrared (IR) camera disposed on the vehicle, the said method comprising the processor implemented steps of: Real-time tracking of the face and localizing eye bounding box within the face bounding box in the captured image by comparing the gray values with threshold using the segmentation process; tracking the eyes by computing the centroid of the eye, target model histogram and target candidate model histogram for one location to another by comparing them to identify distance and calculating the displacement of the target center by the weighted means, wherein the target model histogram and target candidate model histogram are computed based on the feature space; and detecting the drowsiness state of the eyes using histogram equalization, Morphological operations and texture based parameters using histogram and grey level co-occurrence matrices.","1. A computer implemented method for determining in real time a drowsiness state of a driver while driving by using images captured by a near infrared (IR) camera disposed on a vehicle, the method comprising: determining a face bounding box by determining face coordinates using a segmentation process by collecting one or more features of a face and by determining a face height based on a difference between at least one of a nose tip position, an eye brow position, and co-ordinates of the eye brow position;real time tracking of the face by collecting grey values of features of the face greater than threshold values of said features, obtained from the segmentation process;tracking the eyes by computing a centroid of the eye, and calculating a target model histogram and a target candidate model histogram based on a range of intensity of a histogram equalized image and a morphology transformed image;real time tracking of the eyes within a face bounding box and collecting a histogram equalization and a morphology transformation in the face bounding box;calculating the distance between the target model histogram and the target candidate model histogram and calculating a displacement of the target centre; anddetecting a drowsiness state of a driver from the eyes by using at least one of histogram equalization, morphological operations and texture based parameters by using histogram and grey level co-occurrence matrices.","8","13/513495","2010-12-02","2013-0010096","2013-01-10","9483695","2016-11-01","TATA CONSULTANCY SERVICES LIMITED","Chidanand K.  S. | Brojeshwar  Bhowmick","02784/MUM/2009","IN","2009-12-02","G06K-0009/00604","G06K-0009/00604 | A61B-0003/113 | A61B-0005/18 | G06F-0003/013 | G06K-0009/0061 | G06K-0009/00845 | G08B-0021/06","G08B-021/06","G08B-021/06 | G06K-009/00 | A61B-003/113 | A61B-005/18 | G06F-003/01","","","","","","4916044004124"
"US","US","P","B2","Trimming content for projection onto a target","Systems and methods are provided for trimming content for projection within the bounds of a projection target. The systems and methods trim the content for projection based on one or more characteristics of the projection target, including a shape, outline, and distance to the projection target. Moreover, the systems and methods designate void areas where no content will be projected based on the one or more characteristics, and the void areas will be generated or otherwise projected along with the content so that the content is projected onto the projection target and the void areas are projected outside of the projection target such that the projected content does not significantly spill onto surfaces or objects outside of the projection target.","1. A method, comprising: determining a projection target by using object recognition to recognize an object in one more image frames, the object recognition based on information associated with the target;determining one or more bounds of the projection target;determining, by one or more processors, a content area where content is to be projected and a void area where no content is to be projected, the content area and the void area determined based on the one or more bounds, wherein the content area is further determined based on a designated content area associated with the object;determining, by the one or more processors, a scaling factor;generating content for projection within the content area based on the scaling factor; andgenerating the void area.","32","14/136310","2013-12-20","2015-0179147","2015-06-25","9484005","2016-11-01","QUALCOMM INCORPORATED","Ramin  Rezaiifar | Joel Simbulan  Bernarte | Niccolo Andrew  Padovani | Virginia Walker  Keating","","","","G09G-0005/373","G09G-0005/373 | A61B-0005/1114 | G03B-0021/13 | G03B-0021/142 | G06F-0001/1694 | G06F-0003/017 | G06K-0009/00389 | G06T-0003/40 | G06T-0019/006 | H04N-0009/3185 | H04N-0009/3194 | G03B-2206/00 | G06K-0009/00671 | G06T-2210/22 | G06T-2210/32 | G09G-2340/04 | G09G-2354/00","G09G-005/30","G09G-005/30 | G09G-005/373 | G03B-021/14 | G06F-003/01 | G06T-003/40 | G06T-019/00 | A61B-005/11 | G06F-001/16 | H04N-009/31 | G06K-009/00 | G03B-021/13","","","","","","4916044004433"
"US","US","P","B2","Radio frequency based remote health monitoring","A modular self-care health monitoring system which employs a compact microprocessor-based unit such as a video game system of the type that includes switches for controlling device operation and a program cartridge. In accordance with the invention, the program cartridge adapts the microprocessor-based unit for operation with a glucose monitor (or, another type of health monitor). The microprocessor-based unit processes data supplied by the glucose monitor to supply signals for displaying relevant information on a display unit that may be included in the microprocessor-based unit or may be a separate unit such as a television or video display monitor. The system provides for transmission of signals to a remote clearinghouse or a healthcare facility via telephone lines or other transmission media. The clearinghouse includes signal processing capability for transmission of reports to a remotely located healthcare professional via facsimile transmission.","1. A health monitoring system comprising: a plurality of remote user sites, each of the remote user sites comprising at least one health monitoring device each comprising (i) an input for collection of user health data while the health monitoring device is in a collection mode of a plurality of user modes, (ii) a modem configured to operate in a cellular telephone system while the health monitoring device is in a communications mode of the plurality of user modes, (iii) a first display configured to show information while the health monitoring device is in a display mode of the plurality of user modes and (iv) a microprocessor configured to execute program instructions received via the cellular telephone system, wherein (a) the program instructions when executed generate selections of the user modes on the first display and (b) each of the health monitoring devices operates in a corresponding one of the user modes at a time as selected by a user;at least one remote computing facility comprising at least one central server configured for two-way communication with the health monitoring devices via the cellular telephone system to both (i) send the program instructions to the plurality of remote user sites and (ii) receive the user health data from the plurality of remote user sites; andat least one computer for use by a health care professional, remotely located from the central server and configured (i) for two-way signal communication with the central server via a communications network, and (ii) to receive at least one report via the communications network from the central server based on the user health data collected by the health monitoring device.","29","11/119335","2005-04-28","2005-0256739","2005-11-17","9477939","2016-10-25","Robert Bosch Healthcare Systems, Inc.","Stephen J.  Brown","","","","G06Q-0010/10","G06Q-0010/10 | A61B-0005/0022 | A61B-0005/087 | A61B-0005/14532 | A61B-0005/6896 | G01N-0033/48792 | G06F-0015/025 | G06F-0019/345 | G06F-0019/3406 | G06F-0019/3412 | G06F-0019/3418 | G06F-0019/3456 | G06F-0019/3487 | G06Q-0040/08 | G06Q-0040/12 | G06Q-0050/22 | G06Q-0050/24 | A61B-0005/0205 | A61B-0005/743 | A61B-2560/0443 | G06F-0019/322 | G06F-0019/3475 | G06F-0019/3481 | Y10S-0128/903","G06Q-010/00","G06Q-010/00 | G06Q-050/00 | G06Q-010/10 | A61B-005/087 | A61B-005/145 | A61B-005/00 | G01N-033/487 | G06F-015/02 | G06Q-040/08 | G06Q-050/22 | G06Q-050/24 | G06Q-040/00 | A61B-005/0205 | G06F-019/00","","","","","","4916043004300"
"US","US","P","B2","Time domain-based methods for noninvasive brain-machine interfaces","A noninvasive brain computer interface (BCI) system includes an electroencephalography (EEG) electrode array configured to acquire EEG signals generated by a subject. The subject observes movement of a stimulus. A computer is coupled to the EEG electrode array and configured to collected and process the acquired EEG signals. A decoding algorithm is used that analyzes low-frequency (delta band) brain waves in the time domain to continuously decode neural activity associated with the observed movement.","1. A method of decoding neural activity for a brain computer interface (BCI) system, comprising the steps of: recording noninvasively acquired electroencephalography (EEG) signals of a subject in a time domain when the subject observes movement of a stimulus while the subject is simultaneously imagining movement of a limb tracking the movement of the stimulus;continuously decoding only the recorded EEG signals having a frequency of less than 4 Hz and in the time domain associated with the observed movement and the imagined movement; andcorrelating fluctuations in amplitude of the decoded recorded EEG signals with an intent of the subject.","12","13/695631","2011-05-05","2014-0058528","2014-02-27","9468541","2016-10-18","UNIVERSITY OF MARYLAND COLLEGE PARK","Jose L.  Contreras-Vidal | Trent J.  Bradberry | Rodolphe J.  Gentili | Harshavardhan  Agashe","","","","A61F-0002/72","A61F-0002/72 | A61B-0005/04012 | A61B-0005/0478 | A61B-0005/0496 | A61B-0005/04842 | G06F-0003/015 | A61B-0005/04009 | G06F-0003/013","A61F-002/72","A61F-002/72 | A61B-005/0484 | A61B-005/0496 | A61B-005/0478 | A61B-005/04 | G06F-003/01","","","","","","4916042001046"
"US","US","P","B2","Brain-machine interface utilizing interventions to emphasize aspects of neural variance and decode speed and angle using a kinematics feedback filter that applies a covariance matrix","A brain machine interface (BMI) for restoring performance of poorly performing decoders is provided. The BMI has a decoder for decoding neural signals for controlling the brain machine interface. The decoder separates in part neural signals associated with a direction of movement and neural signals associated with a speed of movement of the brain machine interface. The decoder assigns relatively greater weight to the neural signals associated with a direction of movement.","1. An artificial controller of a prosthetic device, comprising: (a) a brain machine interface having an algorithm executable by a computer, wherein the brain machine interface comprises a mapping from neural signals to corresponding intention estimating kinematics of a limb trajectory, wherein the intention estimating kinematics comprises speeds and angles;b) the brain machine interface controlling the prosthetic device using recorded neural signals as input to the brain machine interface and the mapping of the brain machine interface determining the intention estimating kinematics to control the prosthetic device, wherein the controller results in an executed movement of the prosthetic device;(c) a modified brain machine interface having an algorithm executable by the computer for modifying during the control of the prosthetic device, at discrete time intervals over the course of the executed movement of the prosthetic device, the angles in the brain machine interface, wherein each of the modifications of the angles comprises changes in the direction of the angles towards an end target of the executed movement of the prosthetic device;(d) the modified brain machine interface controlling the prosthetic device; and(e) a kinematics feedback filter executable by the computer in both the brain machine interface and the modified brain machine interface, wherein the kinematics feedback filter applies a covariance matrix of an a posteriori estimate of the intention estimating kinematics at each time step of the discrete time intervals, whereby the kinematics are modeled as feedback from the interfaces to a user of the prosthetic device.","2","15/014328","2016-02-03","2016-0224891","2016-08-04","9471870","2016-10-18","THE BOARD OF TRUSTEES OF THE LELAND STANFORD JUNIOR UNIVERSITY","Jonathan C.  Kao | Chethan  Pandarinath | Paul  Nuyujukian | Krishna V.  Shenoy","","","","G06N-0003/08","G06N-0003/08 | A61B-0005/04001 | A61F-0002/72 | G06F-0003/015 | Y10S-0128/905","G06F-015/18","G06F-015/18 | G06N-003/08 | A61B-005/04 | A61F-002/72 | G06F-003/01","","","","","","4916042004357"
"US","US","P","B2","Phantom image classification","A computing device uses image metadata to perform a first sub-classification of an image, wherein the first sub-classification is deterministic, then uses a combination of image data and the image metadata to perform a second sub-classification, further in a third sub-classification, uses image data to make a probabilistic classification of an image according to a likely phantom type. Alternatively or additionally, a computing device receives a set of image analysis data, identifies an image analysis model to be trained, using the image analysis data, determines that the image analysis model can include an image permutation, and trains a new image analysis model including the image permutation.","1. A system, comprising a computing device that includes a processor and a memory, the memory storing instructions executable by the processor, the instructions including instructions for: using image metadata to perform a first sub-classification of an image, wherein the first sub-classification is deterministic;based in part on the deterministic first sub-classification, using a combination of image data of the image and the image metadata to perform a second sub-classification, andin a third sub-classification, based in part on the second sub-classification, using the image data to make a probabilistic classification of the image according to a likely phantom type.","19","13/952003","2013-07-26","2015-0016699","2015-01-15","9466012","2016-10-11","RADIOLOGICAL IMAGING TECHNOLOGY, INC.","Daniel M.  Ritt | Logan  Flewellen | Matthew L.  Whitaker | Ryan  Young","","","","G06K-0009/6262","G06K-0009/6262 | G06K-0009/6227 | G06K-0009/6282 | A61B-0006/583 | A61B-2017/00712 | G06F-0017/30 | G06F-0019/321 | G06K-2209/05 | G06K-2209/27","G06K-009/62","G06K-009/62 | A61B-006/00 | G06F-017/30 | A61B-017/00 | G06F-019/00","","","","","","4916041003885"
"US","US","P","B2","Mobile user borne brain activity data and surrounding environment data correlation system","A mobile user borne brain activity data and surrounding environment data correlation system comprising a brain activity sensing subsystem, a recording subsystem, a measurement computer subsystem, a user sensing subsystem, a surrounding environment sensing subsystem, a correlation subsystem, a user portable electronic device, a non-transitory computer readable medium, and a computer processing device. The mobile user borne system collects and records brain activity data and surrounding environment data and statistically correlates and processes the data for communicating the data into a recipient biological, mechanical, or bio-mechanical system.","1. A user borne system comprising: a brain activity sensing subsystem configured to collect data corresponding to brain activity of a user;a measurement computer subsystem configured to generate data representing quantifications of perceptions of said user;a user sensing subsystem configured to collect data corresponding to user events;a surrounding environment sensing subsystem configured to collect data corresponding to the user'ss surrounding environment;a recording subsystem configured to record said data from said brain activity sensing subsystem, measurement computer subsystem, user sensing subsystem, and surrounding environment sensing subsystem;a correlation subsystem configured to create correlation subsystem data comprising relationships between said data corresponding to said brain activity of said user and said data corresponding to said user events and surrounding environment;a user mobile electronic device in communication with said brain activity sensing subsystem, measurement computer subsystem, user sensing subsystem, surrounding environment sensing subsystem, and recording subsystem, said user mobile electronic device including an interactive graphic user interface and being configured to: operate as a host computer processing subsystem for command, control, and processing of signals to and from said brain activity sensing subsystem, user sensing subsystem, surrounding environment sensing subsystem, and correlation subsystem;command said brain activity sensing subsystem to transmit brain activity and pattern data to said correlation subsystem; andcommand said user sensing subsystem and surrounding environment sensing subsystem to transmit processed sensor data to said correlation subsystem,said correlation subsystem being configured to receive and perform correlation processing operations to determine an extent of neural relationships between data received from said user mobile electronic device and said brain activity sensing subsystem, user sensing subsystem, and surrounding environment sensing subsystem to derive neural correlates of consciousness of conscious precepts of said user;a non-transitory computer readable medium configured to store data from said brain activity sensing subsystem, measurement computer subsystem, user sensing subsystem, surrounding environment sensing subsystem, recording subsystem, and correlation subsystem for performing queries on real-time and near real-time data received from said brain activity sensing subsystem, measurement computer subsystem, user sensing subsystem, surrounding environment sensing subsystem, recording subsystem, and correlation subsystem for determining whether to keep or disregard said data from said brain activity sensing subsystem, measurement computer subsystem, user sensing subsystem, surrounding environment sensing subsystem, recording subsystem, and correlation subsystem based on pre-established rule-sets and user interactive command and control from said user mobile electronic device; anda computer processing device configured to process and communicate at least a portion of said data from said brain activity sensing subsystem, measurement computer subsystem, user sensing subsystem, surrounding environment sensing subsystem, recording subsystem, and correlation subsystem into at least one of a recipient biological, mechanical, or bio-mechanical system.","32","14/788437","2015-06-30","2015-0324692","2015-11-12","9451899","2016-09-27","VIRTUAL VIDEO REALITY BY RITCHEY, LLC","Kurtis John  Ritchey | Kenneth Ira  Ritchey","","","","A61B-0005/0476","A61B-0005/0476 | A61B-0005/0022 | A61B-0005/04008 | A61B-0005/055 | A61B-0005/1114 | A61B-0005/6803 | A61B-0005/686 | G03B-0037/00 | G06F-0001/1626 | G06F-0001/1686 | G06F-0003/013 | G06F-0003/015 | G06F-0003/038 | G06F-0015/18 | G06F-0019/3406 | H04N-0005/2259 | H04N-0005/335 | H04N-0007/18 | A61B-0005/0024 | A61B-0005/745 | A61B-2560/0242 | G01R-0033/4806 | G02B-0013/06 | G02B-0015/10 | G06F-2203/0381","G06F-013/00","G06F-013/00 | A61B-005/0476 | H04N-007/18 | G06F-003/038 | H04N-005/335 | G06F-015/18 | G03B-037/00 | H04N-005/225 | A61B-005/04 | A61B-005/055 | A61B-005/11 | G06F-019/00 | G06F-001/16 | G06F-003/01 | G02B-013/06 | G02B-015/10 | A61B-005/00 | G01R-033/48","","","","","","4916039000816"
"US","US","P","B2","Patient selectable joint arthroplasty devices and surgical tools","Disclosed herein are methods, compositions and tools for repairing articular surfaces repair materials and for repairing an articular surface. The articular surface repairs are customizable or highly selectable by patient and geared toward providing optimal fit and function. The surgical tools are designed to be customizable or highly selectable by patient to increase the speed, accuracy and simplicity of performing total or partial arthroplasty.","1. A surgical tool for use in surgery on a joint of a patient, comprising: a first portion having a patient-specific surface and a second portion having a guide to direct or accommodate a surgical instrument;wherein the patient-specific surface is substantially a negative of a corresponding surface of the joint;wherein the guide is configured relative to the patient-specific surface to define a predetermined path for the surgical instrument that is aligned through a portion of tissue associated with the joint when the patient specific surface is placed against and aligned with the corresponding surface; andwherein the path for the surgical instrument provides a desired anteversion or retroversion of at least one implant component for the joint,wherein the joint is a shoulder joint of the patient.","20","13/306509","2011-11-29","2012-0072185","2012-03-22","9451972","2016-09-27","ConforMIS, Inc.","Philipp  Lang | Wolfgang  Fitz","","","","A61B-0017/1739","A61B-0017/1739 | A61B-0017/15 | A61B-0017/154 | A61B-0017/155 | A61B-0017/157 | A61B-0017/1666 | A61B-0017/1677 | A61B-0017/1682 | A61B-0017/1703 | A61B-0017/1746 | A61B-0017/1767 | A61F-0002/30756 | A61F-0002/30942 | A61F-0002/38 | G06F-0017/50 | A61B-0005/4504 | A61B-0005/4514 | A61B-0005/4523 | A61B-0005/4528 | A61B-0005/4533 | A61B-0017/158 | A61B-0017/1675 | A61B-2017/568 | A61B-2034/105 | Y10T-0029/49","G06F-017/50","G06F-017/50 | A61B-017/17 | A61B-017/15 | A61B-017/16 | A61F-002/30 | A61F-002/38 | A61B-005/00 | A61B-017/56","","","","","","4916039000889"
"US","US","P","B2","Device for planning a neuromodulation therapy","A device for planning a neuromodulation therapy, whereby the device comprises receiving means to receive brain default mode network data of a patient, template means comprising a template brain default mode network data, normalizing means being configured such that normalized patient brain default mode network data can be prepared on the basis on the received brain default mode network data and the template brain default mode network data, storage means comprising a brain default mode network database and comparison means configured such that the normalized patient brain default mode network data and the data contained in the brain default mode network database can be compared.","1. A computing device for planning a neuromodulation therapy, comprising: receiving means for receiving brain default mode network data of a patient;template means for generating a template brain default mode network data;normalizing means for preparing normalized patient brain default mode network data on the basis of the received brain default mode network data and the template brain default mode network data;storage means for storing a brain default mode network database;comparison means for comparing the normalized patient brain default mode network data and the data contained in the brain default mode network database;planning means for generating a plan defining at least one implant position for neuromodulation therapy based on the comparison; andoutputting means for outputting an indication of the at least one implant position.","24","14/374212","2013-01-22","2015-0045851","2015-02-12","9452291","2016-09-27","MEDTRONIC BAKKEN RESEARCH CENTER B.V.","Hubert Cecile Francois  Martens | Michel Marcel Jose  Decre","2012-152272","EP","2012-01-24","A61N-0001/36139","A61N-0001/36139 | A61B-0005/0042 | A61B-0005/055 | A61N-0001/36182 | A61N-0001/37235 | A61N-0001/37247 | G06F-0017/5009 | G06F-0019/3437 | A61N-0001/37282","A61B-005/0476","A61B-005/0476 | A61B-005/055 | A61B-005/05 | A61N-001/36 | A61B-005/00 | G06F-017/50 | G06F-019/00 | A61N-001/372","","","","","","4916039001205"
"US","US","P","B2","Downloadable datasets for a patient monitoring system","In general, this disclosure describes techniques for remotely monitoring the health of an ambulatory patient. As described herein, an ambulatory patient may interact with a monitoring device that is located at the patient's home. The monitoring device may ask the patient to provide responses to health-related questions or requests for physiological characteristics and may upload the responses. A health care professional may then use the responses to evaluate the health of the patient. A set of firmware instructions stored on the monitoring device may cause the monitoring device to perform these functions. The monitoring device may download a prompt that is associated with at least one instruction in the set of firmware instructions. The prompt may cause the patient monitoring device to execute the at least one instruction in the set of firmware instructions to gather information relating to a patient.","1. A system comprising: a monitoring server;a patient monitoring device that comprises: a read-only memory that stores a set of firmware instructions; anda processor that executes instructions in the set of firmware instructions,?wherein when the processor executes the instructions in the set of firmware instructions, the instructions cause the patient monitoring device to:download a prompt from a monitoring server;store the prompt in the memory of the patient monitoring device, wherein the prompt is associated with at least one instruction in the set of firmware instructions, and wherein the prompt causes the patient monitoring device to execute the at least one instruction in the set of firmware instructions to gather information relating to a patient;receive information relating to the patient; andupload the information, the information being uploaded to the monitoring server, and?wherein after the processor finishes executing instructions in the stored set of firmware instructions, the stored set of firmware instructions is the same as before the processor executed the instructions in the stored set of firmware instructions; anda communications network that facilitates communication between the monitoring server and the patient monitoring device, the patient monitoring device downloading the prompt via the communications network and uploading the information via the communications network,?wherein the set of firmware instructions comprises: a first subset of the set of firmware instructions that, when executed by the processor, causes the patient monitoring device to download a first prompt;a second subset of the set of firmware instructions that, when executed by the processor after the processor executes the first subset of the set of firmware instructions, causes the patient monitoring device to store the first prompt in the memory of the patient monitoring device, wherein the first prompt is associated with a third subset of the set of firmware instructions, and wherein the first prompt causes the patient monitoring device to execute the third subset of the set of firmware instructions to gather information relating to a patient;the third subset of the set of firmware instructions that, when executed by the processor after the processor executes the second subset of the set of firmware instructions, causes the patient monitoring device to gather information relating to the patient; anda fourth subset of the set of firmware instructions that, when executed by the processor after the processor executes the third subset of the set of firmware instructions, causes the patient monitoring device to upload the information to the monitoring server.","4","13/860105","2013-04-10","2013-0297344","2013-11-07","9454644","2016-09-27","CARDIOCOM, LLC","Daniel L.  Cosentino | Louis C.  Cosentino | Brian A.  Golden | Todd F.  Young | Christopher T.  Abrahamson","","","","G06F-0019/322","G06F-0019/322 | A61B-0005/0022 | A61B-0005/0537 | A61B-0005/0538 | A61B-0005/4869 | A61N-0001/37211 | A61N-0001/37264 | G01G-0019/4146 | G01G-0019/44 | G01G-0023/3735 | G01G-0023/3742 | G06F-0019/3418 | G06F-0019/363 | G06Q-0050/24 | A61B-0005/002 | A61B-0005/0031 | A61B-0005/021 | A61B-0005/0402 | A61B-2562/0219 | A61N-0001/3627 | A61N-0001/36521 | A61N-0001/37282 | G06F-0019/3412 | G06F-0019/3456 | G06F-0019/3475 | G06F-0019/3481","A61N-001/372","A61N-001/372 | G06F-019/00 | A61B-005/053 | G01G-019/414 | G01G-019/44 | G01G-023/37 | G06Q-050/24 | A61B-005/00 | A61B-005/021 | A61B-005/0402 | A61N-001/362 | A61N-001/365","","","","","","4916039003545"
"US","US","P","B2","Method and system for gathering and computing an audience's neurologically-based reactions in a distributed framework involving remote storage and computing","Systems and methods for measuring biologically and behaviorally based responses to content in targeted demographics and locations by way of remote monitoring. Stimuli may be based on location, target demographics, and combinations thereof.","1. A system for adaptively presenting a target stimulus to a remotely located audience comprising: a processing computer operatively connected to a cloud infrastructure, the processing computer capable of creating and storing a content reel and project parameters, the content reel including at least target content and baseline content, the cloud infrastructure to receive the content reel and the project parameters from the processing computer and send the content reel and the project parameters to a plurality of remote units in geographically diverse locations;a first remote unit of the plurality of remote units, wherein the first remote unit includes:a first biologically based sensor to measure first unconscious responses for a first audience member; a first processor to receive first data representative of the first unconscious responses for the first audience member from a first location; anda first display, the first display and the first biologically based sensor operatively connected to the first processor, the first processor further including a first remote memory to receive and store the content reel and project parameters from the cloud infrastructure, the first processor to expose the first audience member to the content reel on the first display, the first processor to transmit the first data representative of the first unconscious responses collected from the first audience member in response to the content reel and first demographic information collected from the first audience member to the cloud infrastructure, the first demographic information including a demographic category;wherein the first remote unit is to receive a first capacity value for a first demographic category and first location for the content reel and send the first capacity value to the processing computer via the cloud infrastructure, the processing computer is to transmit an alternate content reel to the first remote unit via the cloud infrastructure, the first remote unit to expose the first audience member to the alternate content reel on the first display when the first capacity value is obtained, the alternate content reel including alternate target content and alternate baseline content, anda second remote unit of the plurality of remote units, wherein the second remote unit includes: a second biologically based sensor to measure second unconscious responses for a second audience member;a second processor to receive second data representative of the second unconscious responses for the second audience member from a second location; anda second display, the second display and second biologically based sensor operatively connected to the second processor, the second processor further including a second remote memory to receive and store the content reel and project parameters from the cloud infrastructure, the second processor to expose the second audience member to the content reel on the second display, the second processor to transmit the second data representative of the second unconscious responses collected from the second audience member in response to the content reel and second demographic information collected from the second audience member to the cloud infrastructure, the second demographic information including a second demographic category;wherein the second remote unit is to receive a second capacity value for a second demographic category and second location for the content reel and send the second capacity value to the processing computer via the cloud infrastructure, the processing computer is to transmit the alternate content reel to the second remote unit via the cloud infrastructure, the second remote unit to expose the second audience member to the alternate content reel on the second display when the second capacity value is obtained, the alternate content reel including alternate target content and alternate baseline content, andwherein the system is capable of analyzing the first data, second data, first demographic information and second demographic information received by the processing computer from the cloud infrastructure to generate a report including a comparison of responses to the target content to the baseline content or the alternate target content to the alternate baseline content.","16","13/779528","2013-02-27","2013-0318546","2013-11-28","9451303","2016-09-20","THE NIELSEN COMPANY (US), LLC","Ravi Kanth V.  Kothuri | Carl  Marci | Brian  Levine","","","","H04N-0021/24","H04N-0021/24 | A61B-0005/16 | G06Q-0030/0201 | H04H-0060/33 | A61B-0005/0002 | A61B-0005/02405 | A61B-0005/0476 | A61B-0005/0533 | A61B-0005/08 | A61B-0005/11 | A61B-0005/1112 | A61B-0005/225 | A61B-0005/6897 | H04H-0060/45","G06Q-010/00","G06Q-010/00 | G06Q-030/00 | H04N-021/24 | A61B-005/16 | H04H-060/33 | G06Q-030/02 | A61B-005/00 | A61B-005/024 | A61B-005/0476 | A61B-005/053 | A61B-005/08 | A61B-005/11 | A61B-005/22 | H04H-060/45","","","","","","4916038006467"
"US","US","P","B2","Ambulation prediction controller for lower limb assistive device","Embodiments of the systems and methods described herein relate to a control unit comprising a memory having stored thereon a feature database that includes feature data, a portion of which is labeled with a transition from an ambulation mode and a memory having stored thereon a pattern recognition controller that is trained using the labeled feature data, wherein the pattern recognition controller is configured to predict the ambulation mode of an assistive device and the control unit is configured to communicate with sensors coupled to the assistive device.","1. A control unit comprising: a. a memory having stored thereon a feature database that includes feature data, a portion of which is labeled with a transition from an ambulation mode; andb. a memory having stored thereon a pattern recognition controller that is trained using the labeled feature data;wherein the pattern recognition controller is configured to predict the ambulation mode of an assistive device and the control unit is configured to naturally transition the assistive device from operating in a prior stride to operating in the predicted ambulation mode in a next stride, wherein the prior stride is the stride immediately prior to the next stride.","73","13/925668","2013-06-24","2015-0262076","2015-09-17","9443203","2016-09-13","REHABILITATION INSTITUTE OF CHICAGO","Aaron  Young | Levi  Hargrove","","","","G06N-0099/005","G06N-0099/005 | A61F-0002/60 | A61F-0002/70 | G06F-0017/30424 | A61F-2002/704","G06N-099/00","G06N-099/00 | A61F-002/60 | A61F-002/70 | G06F-017/30","","","","","","4916037004469"
"US","US","P","B2","Systems and methods for remote image reconstruction","A system is provided including a processing unit including an input module, a processing module, and an output module. The processing unit is located at a first location that is remotely located from a scanning location at which a remote medical scanning system is located. The input module is configured to communicate with the remote medical scanning system to receive scanning data obtained during a scan performed by the remote medical scanning system, the scanning data corresponding to an object scanned by the remote medical scanning system. The processing module is configured to use the scanning data to reconstruct an image representing the object. The output module is configured to provide access to the image reconstructed by the processing module to at least one of the remote medical scanning system or a requester located remotely from the first location.","1. A system comprising: a processing unit located at a first location that is remote from a scanning location at which a remote medical scanning system is located, the processing unit comprising: an input module configured to communicate with the remote medical scanning system to receive scanning data obtained during a scan performed by the remote medical scanning system, the scanning data acquired by the remote medical scanning system during a scan performed on an object scanned by the remote medical scanning system;a processing module configured to use the scanning data to reconstruct an image representing the object using a reconstruction technique selected from a plurality of reconstruction techniques available to the processing module, the plurality of techniques including a plurality of sub-groups of techniques, the plurality of sub-groups relating to a corresponding plurality of imaging modalities, wherein the processing module is configured to select the reconstruction technique based on the scanning data, wherein the processing module is configured to autonomously select the reconstruction technique based upon at least one of a quantity or quality of the scanning data received by the input module; andan output module configured to provide access to the image reconstructed by the processing module to at least one of the remote medical scanning system or a requestor located remotely from the first location.","27","13/561508","2012-07-30","2014-0029818","2014-01-30","9436799","2016-09-06","GENERAL ELECTRIC COMPANY","Daniel  McCoy | Vinod  Palathinkara","","","","G06F-0019/321","G06F-0019/321 | G06F-0019/328 | G06T-0011/003","G06K-009/00","G06K-009/00 | A61B-006/00 | G01N-023/00 | G21K-001/12 | H05G-001/60 | G01N-023/04 | G06F-019/00 | G06T-011/00 | A61B-005/05 | G06Q-010/00 | G06Q-050/00","","","","","","4916036004270"
"US","US","P","B2","Medical decision making support apparatus and control method for the same","A medical decision making support apparatus performs the inference processing of obtaining an inference result by performing inference processing associated with medical diagnosis based on a plurality of pieces of input medical information, and the calculation processing of calculating the degree of denial or affirmation of the inference result in association with each of a plurality of partial sets including each medical information extracted from the plurality of pieces of medical information as an element. The medical decision making support apparatus presents a user an inference result obtained by the inference processing and negative information indicating medical information included in a partial set, of the plurality of partial sets, for which the degree of denial is calculated by the calculation processing.","1. A diagnosis support apparatus comprising: an inference unit configured to, based on a plurality of pieces of medical information, calculate an inference probability with respect to plural candidates of diagnosis name concerning medical diagnosis;a calculation unit configured to calculate, for a plurality of partial sets, each including, as an element, at least one piece of medical information retrieved from the plurality of pieces of medical information, a degree of effect on a respective inference probability of at least one of the plural candidates of diagnosis name, the calculation unit being configured to calculate the degree of effect individually for the at least one of the plural candidates of diagnosis name; anda display control unit configured to cause a display unit to display, as an inference result, the at least one of the plural candidates of diagnosis name, wherein the at least one of the plural candidates is specified based on the inference probability calculated by the inference unit, and to cause the display unit to display medical information included in a partial set of information retrieved from the plurality of pieces of medical information, wherein the partial set including the displayed medical information is retrieved from the plurality of pieces of medical information, based on the degree of effect calculated by the calculation unit based on the inference result.","33","14/495242","2014-09-24","2015-0012474","2015-01-08","9436915","2016-09-06","CANON KABUSHIKI KAISHA","Masami  Kawagishi | Yoshio  Iizuka","2009-047021","JP","2009-02-27","G06N-0005/048","G06N-0005/048 | G06F-0019/321 | G06F-0019/345","G06F-009/44","G06F-009/44 | G06N-007/02 | G06N-007/06 | G06N-005/04 | G06F-019/00","","","","","","4916036004385"
"US","US","P","B2","Touch-sensitive device and method","Techniques are generally described for touch-sensitive devices with biometric information determination capabilities. The touch-sensitive device may include one or more of a transmitter, a receiver, and a processor. The transmitter may be configured to emit light towards a surface of the touch-sensitive device and the receiver may be configured to receive reflected light from a touch to the touch-sensitive device. The processor may be arranged to receive signals from the receiver and determines biometric information, and in some examples location of touch, based on the signals.","1. A non-transitory computer accessible medium that includes computer executable instructions stored thereon, which in response to execution by a computer, cause the computer to perform or control performance of a procedure to determine a concentration of an analyte in blood, the procedure comprising: quantifying optical energy at a first wavelength, wherein the optical energy is detected at a sensor included in a touch panel of a display, wherein the touch panel is configured to receive an indication of a touch event, and wherein the display is viewable through the touch panel; anddetermining, based at least in part on the quantified optical energy, the concentration of the analyte in the blood.","23","14/256575","2014-04-18","2014-0228655","2014-08-14","9427192","2016-08-30","Empire Technology Development LLC","Seth Adrian  Miller","","","","A61B-0005/6898","A61B-0005/6898 | A61B-0005/1455 | A61B-0005/14532 | G06F-0003/042 | G06F-0003/044 | G06F-0003/0421 | G06K-0009/00013 | A61B-0005/14546 | A61B-0005/14551 | G01N-2021/3144 | G01N-2021/6419 | G06K-2009/0006 | G06K-2009/00932","A61B-005/00","A61B-005/00 | G06F-003/042 | A61B-005/145 | G06K-009/00 | G06F-003/044 | G01N-021/64 | A61B-005/1455 | G01N-021/31","","","","","","4916035000888"
"US","US","P","B2","Hearing device with brainwave dependent audio processing","A hearing device is adapted to be arranged on or at least partly implanted in an individual's head and comprises: an input unit providing an input audio signal; a signal processing circuit adapted to process the input audio signal; an output unit adapted to provide an audible signal to the individual; one or more electrodes adapted to detect electric brain potentials of the individual; and a brainwave measurement circuit adapted to determine one or more EEG signals from electric signals received from the one or more electrodes. The hearing device further comprises: a first spectrum analyzer determining first audio spectra; a reconstructor adapted to repeatedly reconstruct second audio spectra; a first correlator to determine coherence between the first and the second audio spectra; and a control unit adapted to alter said processing in dependence on the coherence.","1. A hearing device adapted to be arranged on or at least partly implanted in an individual'ss head and comprising: an input unit providing one or more input audio signals in an audible frequency range;a signal processing circuit adapted to process at least one of said one or more input audio signals to provide a processed audio signal;an output unit adapted to provide an audible signal to the individual in dependence on the processed audio signal;one or more electrodes adapted to detect electric brain potentials of the individual;a brainwave measurement circuit adapted to determine one or more EEG signals from electric signals received from the one or more electrodes;a first spectrum analyzer adapted to repeatedly determine first spectra in the audible frequency range of at least one signal from the group of signals consisting of said one or more input audio signals and the audible signal;a reconstructor adapted to repeatedly reconstruct second spectra in the audible frequency range from the one or more EEG signals;a first coherence calculation unit adapted to repeatedly determine a first coherence between the first and the second spectra; anda control unit adapted to alter said processing in dependence on the first coherence.","34","14/048883","2013-10-08","2014-0098981","2014-04-10","9432777","2016-08-30","OTICON A/S","Thomas  Lunner | Fredrik  Gustafsson","2012-187625 | 2012-190377","EP | EP","2012-10-08 | 2012-10-29","H04R-0025/50","H04R-0025/50 | H04R-0025/70 | A61B-0005/0484 | A61B-0005/04845 | A61B-0005/121 | A61B-0005/68 | A61B-0005/6815 | A61N-0001/0541 | G06F-0003/015 | H04R-2225/41","H04R-025/00","H04R-025/00 | G06F-003/01 | A61B-005/0484 | A61B-005/00 | A61B-005/12 | A61N-001/05","","","","","","4916035006440"
"US","US","P","B2","Image based clinical trial assessment","A method for assessing a treatment in a trial includes obtaining images generated from image data acquired at different times during a trial time period for a same region of interest of a subject. The treatment is administered to the subject for the trial. The method further includes co-registering the images and mapping the co-registered images to a reference image representing the region of interest. The method further includes generating a trial image of the region of interest showing at least one of structural or functional physiological changes that occurred during the trial time period based on the mapped co-registered images, and displaying the trial image.","1. A computer implemented method for determining an efficacy of a treatment in a trial, comprising: co-registering images of a set of images corresponding to a same region of interest of a subject to a baseline image via an affine registration by way of computer, wherein the baseline image is from the set of images and the set of images are acquired at different times after administering a trial treatment to the subject;applying a computer implemented transformation to the co-registered images to fit the co-registered images to an anatomical model representing the region of interest;generating a value representing a physiological change in the region of interest based on the mapped co-registered images; anddetermining an efficacy of the treatment based on the value.","20","14/334757","2014-07-18","2014-0328525","2014-11-06","9420972","2016-08-23","KONINKLIJKE PHILIPS N.V.","Frank O.  Thiele | Satoshi  Minoshima","","","","A61B-0005/4848","A61B-0005/4848 | G06F-0019/366 | G06Q-0010/06313 | G06T-0007/0012 | G06T-0007/0024 | G06T-0007/0032 | G06T-2207/10072 | G06T-2207/30004","G06K-009/00","G06K-009/00 | A61B-005/00 | G06T-007/00 | G06F-019/00 | G06Q-010/06","","","","","","4916034000868"
"US","US","P","B2","Method and system for sensitivity analysis in modeling blood flow characteristics","Methods for determining cardiovascular information for a patient include receiving patient-specific data regarding a geometry of the patient's vasculature; creating an anatomic model representing at least a portion of the patient's vasculature based on the patient-specific data; and creating a computational model of a blood flow characteristic based on the anatomic model. The method also includes identifying one or more of an uncertain parameter, an uncertain clinical variable, and an uncertain geometry; modifying a probability model based on one or more of the identified uncertain parameter, uncertain clinical variable, or uncertain geometry; determining a blood flow characteristic within the patient's vasculature based on the anatomic model and the computational model; and calculating, based on the probability model and the determined blood flow characteristic, a sensitivity of the determined fractional flow reserve to one or more of the identified uncertain parameter, uncertain clinical variable, or uncertain geometry.","1. A system for determining cardiovascular information for a patient, the system comprising: at least one computer system configured to: receive patient-specific data regarding a geometry of at least the patient'ss vasculature;create an anatomic model representing at least a portion of the patient'ss vasculature based on the patient-specific data;create a computational model of a blood flow characteristic based on the anatomic model;identify, using the computational model, a region within the patient'ss vasculature meeting a threshold value of the blood flow characteristic;identify one or more of an uncertain parameter, an uncertain clinical variable, and an uncertain geometry;modify a probability model based on one or more of the identified uncertain parameter, uncertain clinical variable, or uncertain geometry;determine the blood flow characteristic for the identified region within the patient'ss vasculature based on the anatomic model and the computational model of the blood flow characteristic of the patient'ss vasculature; andcalculate, based on the probability model and the determined blood flow characteristic for the identified region within the patient'ss vasculature, a sensitivity of the blood flow characteristic to one or more of the identified uncertain parameter, uncertain clinical variable, or uncertain geometry.","32","13/864996","2013-04-17","2014-0249784","2014-09-04","9424395","2016-08-23","HEARTFLOW, INC.","Sethuraman  Sankaran | Leo  Grady | Charles A.  Taylor","","","","G06F-0019/3437","G06F-0019/3437 | A61B-0005/026 | A61B-0005/02007 | A61B-0005/02028 | A61B-0005/055 | A61B-0006/032 | A61B-0006/504 | A61B-0006/5217 | G06T-0007/0012 | G06T-2207/10081 | G06T-2207/30104","G06F-017/10","G06F-017/10 | G06F-007/60 | G06F-019/00 | A61B-006/00 | A61B-005/02 | A61B-005/026 | G06T-007/00 | A61B-005/055 | A61B-006/03","","","","","","4916034004275"
"US","US","P","B2","Apparatus, system and method for administration of a substance","The present disclosure relates to an infusion control valve adapted to be actuated by a valve actuator. The present disclosure further relates to an infusion valve actuator adapted to actuate an infusion control valve upon being triggered by an authentication unit. Furthermore, the present disclosure relates to methods for the administration of a substance.","1. An infusion control valve functionally connected to an authentication unit; wherein said infusion control valve is normally closed thereby preventing an infusion liquid from reaching a patient; and wherein said authentication unit is configured to trigger opening of said valve when said authentication unit identifies a match between said patient and said infusion liquid, thereby initiating flow of said infusion liquid to the patient, wherein said infusion control valve is positioned above or below a drip chamber of an infusion line.","32","13/771463","2013-02-20","2013-0197469","2013-08-01","9415161","2016-08-16","PRO-IV LTD.","Pierre  Sharvit | Michal  Devir | Jacob  Nushbacher | Gershon  Goldenberg | Youval  Katzman","","","","A61M-0005/172","A61M-0005/172 | A61M-0001/02 | A61M-0005/162 | A61M-0039/22 | G06F-0019/3468 | G06Q-0010/00 | G06Q-0050/24 | A61B-0005/117 | A61B-0005/7495 | A61J-0001/1487 | A61J-2205/10 | A61J-2205/60 | A61M-2205/6009 | A61M-2205/6072","A61M-005/172","A61M-005/172 | A61M-001/02 | A61M-005/162 | A61M-039/22 | G06F-019/00 | G06Q-050/24 | G06Q-010/00 | A61B-005/117 | A61B-005/00","","","","","","4916033001256"
"US","US","P","B2","Method and device for detecting the orientation of an area of the body of an individual placed on an apposition area of a biometric sensor mounting","The present invention concerns a method and device for detecting the orientation of an area (DO) of the body of an individual placed on an apposition area (AP) of a biometric sensor mounting (P) designed to form a first image (I1) of the area (DO) of the body by total reflection of radiation on the apposition area (AP), and a second image (I2) of the area (DO) of the body from radiation able to pass through the tissues of the body and to be reflected on haemoglobin. The method is characterized in that it comprises a step of determining in a reference frame firstly the longitudinal axis (A) of the area of the body depicted in the first image and secondly two longitudinal edges (B1, B2) of the area of the body depicted in the second image, and a step of determining the orientation of the area of the body with respect to the mounting from the measurement of the relative positions of the two edges (B1, B2) and the axis (A) thus determined in the reference frame. The present invention also concerns a biometric sensor and an installation for identifying an individual comprising such a device.","1. Method for identifying an individual by reading a body print and a venous network taken on an area of a body of said individual, said method comprising: placing said area of said body on an apposition area of a biometric sensor mounting,forming a first image of the area of the body by total reflection of radiation on the apposition area,forming a second image of the area of the body from radiation able to pass through the tissues of the body and to be reflected on haemoglobin,comparing said first and second images thus formed with corresponding images formed during a prior registration phase,determining in a reference frame firstly the longitudinal axis of the area of the body depicted in the first image andsecondly two longitudinal edges of the area of the body depicted in the second image,determining the value and the sign of the placing angle formed between the transverse axis of the area of the body and the mounting from the measurement of the relative positions of the two edges and the axis thus determined in the reference frame, andcorrecting a representation of the area of the body carried by said first image from said value and said sign thus determined.","12","13/579345","2011-02-15","2013-0147726","2013-06-13","9411460","2016-08-09","MORPHO","Denis  Dumont | Edouard  Da Silva","2010-051123","FR","2010-02-17","G06F-0003/0416","G06F-0003/0416 | G06K-0009/0012 | G06K-0009/00013 | G06K-0009/00912 | G06K-2009/0006 | G06K-2009/00932","G06K-009/00","G06K-009/00 | G06F-003/041","","","","","","4916032003747"
"US","US","P","B2","Language placard for an automated external defibrillator","An automated external defibrillator (AED) 10 has a changeable language placard (20) which enables the AED to instruct the user in one or more languages. The placard includes a controlling element (120) which is sensed by the AED, and causes the AED to automatically switch the language mode into the corresponding placard language. The placard also includes visual guidance instructions (224, 226).","1. A portable medical device configurable to operate in multiple languages comprising: a controller;a memory disposed in electrical communication with the controller, the memory comprising data relating to user instructions in a plurality of languages;a case which houses the controller and memory and comprises a mount for a placard;a sensing element disposed adjacent the mount and in electrical communication with the controller;a placard having a visible user instruction in a first language and disposed to be removably secured in the mount;a controlling element disposed on the placard such that the sensing element senses the controlling element when the placard is secured in the mount,wherein the controller configures the portable medical device to operate in one of the plurality of languages based on the sensed controlling element.","20","14/376046","2013-01-25","2015-0005836","2015-01-01","9403026","2016-08-02","KONINKLIJKE PHILIPS ELECTRONICS N.V.","Eric  Jonsen | Jacco Christof  Eerden | Daniel J.  Powers | Kurt Vincent  Fischer | Christian James  Richard | Alan Paul  Greenstein","","","","A61N-0001/3993","A61N-0001/3993 | A61N-0001/37247 | G06F-0009/4448 | G06F-0017/289","A61N-001/39","A61N-001/39 | G06F-017/20 | G06F-017/27 | G06F-017/28 | G06F-009/44 | A61N-001/372","","","","","","4916031001334"
"US","US","P","B2","System for biometric identity confirmation","A portable testing unit for biometric identity confirmation includes a housing with an orifice to receive a breath sample from the test subject, a spirometric sensor, and a pulse sensor adjacent to the orifice. A processor analyzes spirometric data from the spirometric sensor and simultaneous pulse wave data from the pulse sensor during the breath sample, together with stored subject characterization data for a known subject to confirm whether the identity of the test subject matches the known subject. A communications link enables the processor to communicate to the external station whether the identity of the test subject matches the known subject. For example, this portable testing unit can be used to control access to a secure facility or computer, authenticate the identity of a party in a financial transaction, or confirm the identity of the subject of an alcohol monitoring test.","1. An apparatus for biometric confirmation of the identity of a test subject having a pulse and a respiratory cycle, said apparatus comprising: a housing with an orifice for receiving a breath sample from a test subject;a spirometric sensor generating spirometric data from the breath sample;a pulse sensor adjacent to the orifice and in contact with the test subject during the breath sample, said pulse sensor simultaneously generating pulse wave data for the test subject during the breath sample and having:(a) an infrared emitter adjacent to the orifice transmitting infrared light into the lip of the test subject; and(b) an infrared detector adjacent to the orifice receiving and measuring the infrared light traveling through the lip of the test subject from the infrared emitter; and(c) a ball lens protruding into the lip of the test subject adjacent to the orifice for receiving infrared light traveling from the infrared emitter through the lip of the test subject for the infrared detector;stored subject characterization data based on spirometric data and pulse wave data for a known subject; anda processor analyzing the spirometric data from the spirometric sensor, the pulse wave data from the pulse sensor, and the subject characterization data for the known subject to confirm whether the identity of the test subject matches the known subject.","9","13/706610","2012-12-06","2013-0150727","2013-06-13","9398858","2016-07-26","INTEGRATED MONITORING SYSTEMS, LLC","Brian Kirby  Phillips | Geoffrey A.  Wilson","","","","A61B-0005/0205","A61B-0005/0205 | A61B-0005/02433 | A61B-0005/087 | A61B-0005/117 | A61B-0005/682 | G06F-0021/32 | G06K-0009/00906 | A61B-0005/7225","G05B-019/00","G05B-019/00 | A61B-005/0205 | A61B-005/117 | A61B-005/024 | A61B-005/087 | G06F-021/32 | G06K-009/00 | A61B-005/00","","","","","","4916030000446"
"US","US","P","B2","Removable cassette for articular injection system","Systems for injecting fluids and/or other materials into a targeted anatomical location, in particular, an intra-articular space, include a handpiece assembly having a proximal end and a distal end, a needle extending from the distal end of the handpiece assembly, a fluid delivery module comprising a cassette and a fluid transfer device. A conduit is generally configured to place the fluid delivery module in fluid communication with the handpiece assembly. Medications, formulations and/or other fluids or materials contained within vials that are secured to the fluid delivery module can be selectively delivered into an anatomy through a needle located at the distal end of the handpiece assembly. In some embodiments, ultrasound or other imaging technologies can be used to locate a joint or other targeted anatomical location.","1. A removable cassette for use in an injection system, comprising: a housing defining an interior space;a first loading area configured to be placed in fluid communication with a first container;a second loading area configured to be placed in fluid communication with a second container;a first reservoir configured to be placed in fluid communication with an interior of the first container, and a second reservoir configured to be placed in fluid communication with an interior of the second container;wherein the first and second reservoirs are at least partially positioned within the interior space of the cassette;a first movable member slidably disposed within the first reservoir;a second movable member slidably disposed within the second reservoir;wherein the cassette is configured to be removably secured to a fluid delivery module of the injection system;wherein the first movable member is configured to be moved into or out of at least a portion of an interior of the first reservoir using at least one motor of the fluid delivery module;wherein the second movable member is configured to be moved into or out of at least a portion of an interior of the second reservoir using the at least one motor;at least one fluid outlet in fluid communication with the first and second reservoirs;wherein at least a portion of a fluid contained within the container is configured to be transferred to an interior of the first reservoir when the first movable member is moved in a first direction;wherein at least a portion of the fluid contained within the first reservoir is configured to be transferred to the at least one fluid outlet when the first movable member is moved in a second direction, wherein said second direction is generally opposite of said first direction; andwherein the first and second movable members are configured to be moved by a single motor.","18","13/214868","2011-08-22","2011-0306932","2011-12-15","9398894","2016-07-26","CARTICEPT MEDICAL, INC.","Timothy  Patrick | Richard  Knostman | Michael  Axelrod | Carribeth  Ramey","","","","A61B-0008/0841","A61B-0008/0841 | A61B-0008/00 | A61M-0005/1452 | A61M-0005/16827 | A61M-0019/00 | G06Q-0050/24 | A61B-0005/4839 | A61B-2017/3413 | A61M-0005/14216 | A61M-0005/162 | A61M-0005/20 | A61M-2005/3128 | A61M-2039/242 | A61M-2039/246 | A61M-2205/505","A61B-008/08","A61B-008/08 | A61M-005/145 | A61B-008/00 | A61M-005/168 | G06Q-050/24 | A61M-019/00 | A61B-005/00 | A61B-017/34 | A61M-005/142 | A61M-005/162 | A61M-005/20 | A61M-005/31 | A61M-039/24","","","","","","4916030000482"
"US","US","P","B2","Classification estimating system and classification estimating program","A classification estimating system can include an input element group; an intermediate element group into which are input values of first intermediate variables for which a first multiple desensitization, including an accumulation of values of each input element of a first input element group and each value of a first output sensitivity and each value of a first multiplex output sensitivity, has been carried out and calculated; an output element group into which is input a value of an output variable calculated based on a value of each intermediate element of a first intermediate element group and a value of each connection weight; a classification information estimating module for estimating classification information based on pre-stored correspondence relationship information and a value of the output variable; and a classification information display.","1. A classification estimating system for a subject'ss motion, based on a multi-layered neural network comprising: a first measuring device configured to measure first information as a first biosignal according to a first measuring section of the subject;a second measuring device configured to measure second information as a second biosignal according to a second measuring section of the subject;a computer-readable memory storing executable instructions; anda processor in communication with the computer-readable memory and the first and second measuring devices, wherein the processor is programmed by the executable instructions to at least:use the multi-layered neural network, the multi-layered neural network comprising an input element group in an input layer of the multi-layered neural network, an intermediate element group in a hidden layer of the multi-layered neural network and an output element group in an output layer of the multi-layered neural network, for estimating an action of the subject;wherein the input element group of the multi-layered neural network comprises a first input element group and a second input element group, the first element group comprising a first plurality of input elements, the second element group comprising a second plurality of input elements;determine values of a first input variable based on the first information;provide each value of the first input variable to each of the first plurality of input elements of the first input element group;determine values of a second input variable based on the second information;provide each value of the second input variable to each of the second plurality of input elements of the second input element group;wherein the intermediate element group of the multi-layered neural network comprises a first intermediate element group, the first intermediate element group comprising a plurality of intermediate elements;set values of a first output sensitivity according to each value of each input element of the second input element group in order for some values of a first intermediate variable to become zero, and the remaining values of the first intermediate variable to become discrete values other than zero;set values of a first multiplex output sensitivity according to each value of each element of a multiplex input element group in order for some values of the first intermediate variable to become zero, and the remaining values of the first intermediate variable to become discrete values other than zero;determine the first intermediate variable based upon a product of each value of input element of the first input element group, a value of the first output sensitivity, and the first multiplex output sensitivity such that the first intermediate variable is equal to zero when either the value of the first output sensitivity or the first multiplex output sensitivity is set equal to zero;wherein the output element group of the multi-layered neural network comprises a plurality of output elements;determine each output element based upon a value of output variables which is a product of said each value of intermediate element of the intermediate element group and a connection weight, wherein the values of output variables are zero or other than zero;wherein the connection weight corresponds to an importance of values of the intermediate elements;store correspondence relationship information that specifies a correspondence relationship between a plurality of classification information in order to classify an action of the subject, and a combination pattern of the values of said plurality of output elements which comprise discrete values of zero or discrete values other than zero;estimate said classification information for the subject'ss motion and information according to said first and second information based on said correspondence relationship information and the combination pattern of values of said plurality of output variables; anddisplay the classification information.","9","13/350711","2012-01-13","2012-0209134","2012-08-16","9392954","2016-07-19","UNIVERSITY OF TSUKUBA","Masahiko  Morita | Hiroshi  Kawata","2009-167222","JP","2009-07-15","A61B-0005/0488","A61B-0005/0488 | A61B-0005/04012 | A61B-0005/6824 | A61B-0005/7235 | A61B-0005/7267 | G06F-0003/015 | G06F-0003/017 | G06K-0009/00355 | G06N-0099/005","A61B-005/04","A61B-005/04 | A61B-005/05 | A61B-005/0488 | A61B-005/00 | G06K-009/00 | G06N-099/00 | G06F-003/01","","","","","","4916029000772"
"US","US","P","B2","Infusion management","Methods, computer systems and computer readable media for receiving data from infusion pumps in a healthcare setting and displaying the data on a user device are provided. Centralized clinician views are provided to manage individual and multiple patient infusions. Embodiments provide near real-time graphical displays of infusion data to clinicians on separate user devices. In addition, near real-time graphical displays of patient physiologic data is displayed simultaneously to a clinician along with the infusion data.","1. A method for automatically suggesting a pharmacy workflow that prioritizes infusion-pump-related orders, the method comprising: storing a plurality of orders in association with a plurality of identifiers, which identify a plurality of infusion pumps;receiving from each infusion pump of the plurality of infusion pumps a respective set of infusion-pump data, wherein each respective set of infusion- pump data includes:a total amount of fluid to be administered,a rate at which fluid is being administered, andan amount of fluid that has been administered;based on the respective set of infusion-pump data, calculating for each infusion pump a respective amount of remaining fluid to be administered and a respective amount of time to administer the respective amount of remaining fluid;sorting a first order and a second order, which are included in the plurality of orders, in order from highest priority to lowest priority based on a combination of two or more factors, wherein sorting includes:determining the first order includes a higher priority than the second order by comparing a first respective amount of time for the first order to be administered to a second respective amount of time for the second order to be administered to determine that the first respective amount of time is shorter than the second respective amount of time, anddeprioritizing the first order to include a lower priority than the second order when it is determined that inventory is available for a first infusion drug of the first order and that inventory is not available for a second infusion drug of the second order; anddisplaying the orders from highest priority to lowest priority in a graphical user interface by presenting the second order having a higher priority than the first order based on the inventory for the second infusion drug not being available.","6","13/651987","2012-10-15","2013-0042194","2013-02-14","9393366","2016-07-19","CERNER INNOVATION, INC.","Mary  Gannon | Lisa  Kelly | Stephanie  Rogers | Amanda  Buckley","","","","A61M-0005/172","A61M-0005/172 | G06F-0019/3468 | G06Q-0010/10 | G06Q-0050/22","G06F-019/00","G06F-019/00 | G06Q-050/24 | G06Q-050/22 | G06F-017/30 | A61M-005/172 | G06Q-010/10","","","","","","4916029001182"
"US","US","P","B2","Surgical procedure capture, modelling, and editing interactive playback","A system for generating surgical procedure training media draws upon the realistic data of an actual surgical procedure for realistic training without the risks. A 3D capturing component records three-dimensional model plus imaging data over time of a portion of a patient's body undergoing a surgical procedure. A spatial detection system detects an orientation of a surgical instrument relative to the patient's body during the surgical procedure. A modeling component creates a four-dimensional model (3D model+time) of the portion of the patient's body. Animation such as contingent events, trainee prompts, a virtual surgical instrument, etc., can be added to the model to expand upon the training potential. A user interface processes and edits training media for playback of the four-dimensional model including defining triggers responsive to a trainee simulated surgical inputs to pace sequencing of playback. An interactive player responds to pacing the playback of the editing training media or to a spatially detected simulated surgical instrument held by the student for direct tissue interaction.","1. A method for generating training media, comprising: capturing three-dimensional data over time of a portion of a human patient'ss body undergoing a surgical procedure, the capturing being performed at least in part by stereoscopic video cameras or by a three-dimensional camera;recording physiological readings over time of the portion of the human patient'ss body, the physiological readings comprise at least a movement cycle;capturing visual imagery of an exposed portion of the human patient'ss body;creating, using one or more processors, a four-dimensional model of the portion of the human patient'ss body based on the three-dimensional data, the physiological readings, and the visual imagery of the exposed portion of the human patient'ss body changing over time; andmodifying at least a portion of the three-dimensional data or visual imagery of the human patient'ss body to maintain privacy of the human patient'ss body.","21","12/139960","2008-06-16","2009-0311655","2009-12-17","9396669","2016-07-19","MICROSOFT TECHNOLOGY LICENSING, LLC","Chris Demetrios  Karkanias | Michael J.  Sinclair | James R.  Hamilton | Oren  Rosenbloom | Hubert  Van Hoof","","","","G09B-0023/28","G09B-0023/28 | A61B-0001/0005 | A61B-0001/00183 | A61B-0001/00193 | A61B-0001/018 | A61B-0001/04 | A61B-0001/042 | A61B-0001/3132 | A61B-0005/00 | A61B-0005/0215 | A61B-0005/061 | A61B-0005/1076 | A61B-0005/1455 | A61B-0019/22 | A61B-0019/30 | A61B-0019/50 | A61B-0019/5212 | A61B-0019/5244 | B25J-0009/1689 | G06F-0003/016 | G06F-0019/3418 | G06F-0019/3437 | G06F-0019/366 | G06T-0015/00 | G06T-0019/00 | G09B-0005/00 | G09B-0005/065 | G09B-0005/14 | G09B-0009/00 | G09B-0023/285 | G09B-0023/30 | G09B-0023/32 | G09B-0023/34 | A61B-2017/00115 | A61B-2017/00128 | A61B-2017/00707 | A61B-2017/3405 | A61B-2019/223 | A61B-2019/2211 | A61B-2019/2223 | A61B-2019/2292 | A61B-2019/2296 | A61B-2019/301 | A61B-2019/464 | A61B-2019/507 | A61B-2019/5255 | A61B-2019/5259 | A61B-2019/5265 | A61B-2019/5291 | A61B-2019/5483 | G06F-2203/015 | G06T-2207/10021 | G06T-2207/10068 | G06T-2207/30004 | G06T-2207/30241 | G06T-2210/41","G09B-023/28","G09B-023/28 | G06T-019/00 | A61B-005/00 | G06F-003/16 | G09B-023/30 | G09B-023/32 | G09B-023/34 | G09B-005/00 | G09B-005/06 | G09B-005/14 | G09B-009/00 | A61B-001/00 | A61B-001/018 | A61B-001/04 | A61B-001/313 | A61B-019/00 | A61B-005/0215 | A61B-005/06 | A61B-005/107 | A61B-005/1455 | B25J-009/16 | G06F-019/00 | G06F-003/01 | G06T-015/00 | A61B-017/00 | A61B-017/34","","","","","","4916029004456"
"US","US","P","B2","Processing method of pressure-sensitive light and shadow imaging system and formed footprint image","The pressure-sensitive light and shadow imaging system is comprised of carrier medium (1), inductive surface (2), photo source (3), photocell (5) and imaging surface (6), wherein the said carrier medium (1) is set on the top of the pressure-sensitive light and shadow imaging system, and the lower end contacts with the inductive surface (2) whose lower end is closely integrated with upper surface of the photocell (5). The imaging surface (6) is set underneath the photocell (5). Texture substance (7) contacts the carrier medium (1), which can form the pressure-sensitive image. The image can reflect the pressure distribution of the substance and compression sequence. With the processing method of footprint image formed by such pressure-sensitive light and shadow imaging system, several single-frame footprint images are processed as a complete footprint image containing all footprint features, which can eliminate background noise.","1. A pressure-sensitive light and shadow imaging system, including a carrier medium bearing pressure of a texture substance, a photocell, a light source, an inductive surface and an imaging surface, characterized in that the carrier medium is set as an uppermost layer of the pressure-sensitive light and shadow imaging system, the carrier medium is a plane substance comprising a synthetic fiber layer and an elastic composite layer; a lower surface of the carrier medium contacts with the inductive surface; the inductive surface is thicker than the elastic composite layer, a lower surface of the inductive surface closely contacts with an upper surface of the photocell; the imaging surface is set underneath the pressure-sensitive light and shadow imaging system, and the light source is set on at least one side of the photocell.","18","14/362921","2012-12-26","2015-0254821","2015-09-10","9390483","2016-07-12","DALIAN EVERSPRY SCI & TECH CO., LTD.","Xu  Xu | Guojian  Wang | Zhongjian  Tan","","","","G06T-0005/008","G06T-0005/008 | A43D-0001/02 | A43D-0001/08 | A61B-0005/1174 | G06F-0003/0414 | G06K-0009/00637 | G06K-0009/20 | G06K-0009/58 | G06T-0005/002 | G06T-0005/003 | G06T-0011/001 | H04N-0005/2355 | G06T-2207/10004 | G06T-2207/20182 | G06T-2207/20208","G06K-009/00","G06K-009/00 | G06T-005/00 | A61B-005/117 | A43D-001/08 | G06K-009/20 | A43D-001/02 | G06K-009/58 | G06T-011/00 | H04N-005/235 | G06F-003/041","","","","","","4916028004291"
"US","US","P","B2","Method of controlling a display component of an adaptive display system","An adaptive display system includes a display component to present an image to a user, a sensor for detecting a vision characteristic of the user and generating a sensor signal representing the vision characteristic of the user; and a processor in communication with the sensor and the display component, wherein the processor receives the sensor signal, analyzes the sensor signal based upon an instruction set to determine the vision characteristic of the user, and controls a visual output of the display component based upon the vision characteristic of the user.","1. A method of controlling a display component of a display system of a vehicle, the method comprising the steps of: providing the display component configured to present a menu system to a user, wherein the display component is a heads-up-display and the menu system includes a plurality of menus arranged along a common axis;providing a sensor to continuously detect a vision characteristic of a user;determining a field of focus of a user based upon the vision characteristic;determining the field of focus of the user is in a predetermined region of one of the menus of the menu system and selecting the one of the menus of the menu system;controlling a configuration of the selected menu automatically based only upon a current position of the field of focus by expanding the selected menu of the menu system from a minimized position to a maximized position revealing additional information,swapping the maximized selected menu of the menu system with another menu of the menu system in a desired position,wherein the swapping results in the selected menu of the menu system being moved to a center position of the menu system, andactivating a trigger mechanism while the field of focus of the user is in the predetermined region of the maximized selected menu in the center position of the menu system, anddisplaying an alternate view of the information presented by the maximized selected menu in the center position of the menu system.","9","13/271843","2011-10-12","2013-0097557","2013-04-18","9383579","2016-07-05","VISTEON GLOBAL TECHNOLOGIES, INC.","Dinu Petre  Madau | Matthew Mark  Mikolajczak | Paul  Morris","","","","G02B-0027/01","G02B-0027/01 | A61B-0003/113 | A61B-0005/18 | B60K-0035/00 | G06K-0009/00604 | G06K-0009/00845 | B60K-2350/2052 | B60K-2350/352 | B60K-2350/925 | G02B-2027/014 | G02B-2027/0187","G06F-003/048","G06F-003/048 | G02B-027/01 | A61B-005/18 | A61B-003/113 | B60K-035/00 | G06K-009/00","","","","","","4916027003389"
"US","US","P","B2","Hemodialysis patient data acquisition, management and analysis system","A hemodialysis patient data acquisition and management system resides on a host computer which receives information from one or more non-invasive, optical blood monitors associated with a hemodialysis system. When a patient is undergoing hemodialysis treatment, a sensor assembly monitors the patient's blood flowing through the hemodialysis system and a controller for the blood monitor generates data which includes at least an identification code for the patient undergoing the treatment on the respective system, and non-invasively determined blood data taken at the onset of the scheduled treatment, such as initial Hgb, HCT, and SAT values. A host computer communicates with the one or more optical blood monitors, preferably via a wireless network, and the patient's session commencement data is downloaded to the host computer. The host computer includes a patient database containing historical session commencement data for a plurality of patients, as well as screen displays for displaying historical data for individual patients, such as Hgb trends. The system also preferably provides a predictive algorithm for the patient's Hgb at the patient's next scheduled hemodialysis treatment session. The preferred system also includes software that provides a recommended dose of the anemia management drug for the patient.","1. An anemia management system for hemodialysis patients comprising: at least one hemodialysis system for drawing blood from a patient, passing the drawn blood through extracorporeal tubing and through a dialyzer, and returning the dialyzed blood through extracorporeal tubing to the patient, the hemodialysis system comprising: a blood chamber having an inlet and an outlet which are connected in line with the extracorporeal tubing of the hemodialysis system and a fluid passageway through which the drawn blood flows;a first photo emitter for emitting light at a first wavelength through the blood chamber and the drawn blood flowing through the blood chamber;a second photo emitter for emitting light at a second wavelength through the blood chamber and the drawn blood flowing through the blood chamber; andat least one photo detector for detecting the intensity of light at the first and second wavelength after it passes through the blood chamber and the drawn blood flowing through the blood chamber;a computing system, connected to the at least one hemodialysis system, the computing system comprising processor-executable instructions, stored on one or more non-transitory processor-readable media, and one or more processors for executing the processor-executable instructions, wherein the processor-executable instructions include instructions for: receiving a signal representing the detected light intensity levels from the at least one hemodialysis system;determining a value representing the patient'ss hemoglobin level based on the received signal;storing the determined value in a patient database of the computing system;determining, based on information stored in the patient database, a predicted value for the patient'ss hemoglobin level at the onset of a next treatment session by applying a statistical model to stored patient data, where the predicted value is based on multiple instances of the patient'ss previous hemoglobin levels corresponding to measurements taken at the onset of a series of treatment sessions, multiple coefficients determined based on the statistical model with each coefficient corresponding to one of the multiple instances of the patient'ss previous hemoglobin levels, and at least one previously administered dosage of an erythropoiesis stimulating agent (ESA);determining a recommended ESA dosage for the patient based on the predicted value; andoutputting the recommended ESA dosage via an output interface of the computing system.","7","12/265386","2008-11-05","2010-0113891","2010-05-06","9370324","2016-06-21","FRESENIUS MEDICAL CARE HOLDINGS, INC.","Louis LeeGrande  Barrett | David Wayne  Peterson | Brian Harris  Nathanson | Michael Jack  Germain | Michael K.  Black","","","","A61B-0005/14535","A61B-0005/14535 | A61B-0005/14557 | A61M-0001/16 | A61M-0001/361 | G06F-0019/322 | G06F-0019/3406 | G06F-0019/3481 | G06Q-0050/24 | A61B-2562/08 | A61M-2205/3313 | A61M-2205/3553 | A61M-2205/3592 | A61M-2205/52","G01N-033/48","G01N-033/48 | A61B-005/145 | A61B-005/1455 | A61M-001/16 | G06F-019/00 | G06Q-050/24 | A61M-001/36 | G06G-007/58","","","","","","4916025000829"
"US","US","P","B2","Safety glasses verification","Safety glasses verification methods and devices are described herein. One method in accordance with the present disclosure includes capturing an RGB image of an individual, capturing an infrared (IR) image of the individual, and verifying safety glasses are being worn by the individual based on the RGB image and the IR image.","1. A method for verifying safety glasses, comprising: capturing an RGB image of an individual;capturing an infrared (IR) image of the individual; andverifying, by a safety glasses verification device, safety glasses are being properly worn by the individual based on the RGB image and the IR image by: detecting a location of an eye of the individual in the RGB image;detecting a location of safety glasses in the IR image, wherein: the safety glasses include a single T-shaped material corresponding exclusively to a center of a frame of the safety glasses; andthe single T-shaped material is visible in the IR image and not visible in the RGB image; andverifying that the location of the eye of the individual in the RGB image corresponds to the location of the safety glasses in the IR image.","18","13/686540","2012-11-27","2013-0147938","2013-06-13","9364372","2016-06-14","HONEYWELL INTERNATIONAL INC.","Scott  McCloskey | Ryan A.  Lloyd","","","","A61F-0009/029","A61F-0009/029 | A61F-0009/02 | G06K-0009/2018 | G06Q-0030/018","G06Q-010/10","G06Q-010/10 | G06Q-030/02 | G06Q-030/06 | G06Q-010/04 | G06Q-010/06 | A61F-009/02 | G06Q-030/00 | G06K-009/20","","","","","","4916024001103"
"US","US","P","B2","Insulin on board compensation for a closed-loop insulin infusion system","An electronic controller for an insulin infusion device includes a processor architecture and at least one memory element. The memory element stores executable instructions that, when executed by the processor architecture, provide an insulin on board (IOB) compensation module to estimate a current IOB value that indicates an amount of active insulin in the body of the user, calculate an IOB rate based at least in part on the estimated current IOB value, determine an adjusted insulin infusion rate based at least in part on the calculated IOB rate and an uncompensated insulin infusion rate, select a final insulin infusion rate for the device, and provide the selected final insulin infusion rate to regulate delivery of insulin by the device.","1. An electronic insulin infusion device comprising: an insulin reservoir for insulin to be delivered from the insulin infusion device to a body of a user;a processor architecture comprising at least one processor device; and at least one memory element associated with the processor architecture, the at least one memory element storing processor-executable instructions that, when executed by the processor architecture, perform a method of controlling closed-loop delivery of insulin from the insulin reservoir to the body of the user, the method comprising: computing a current insulin on board (IOB) value that indicates an amount of active insulin in the body of the user;calculating an IOB rate based at least in part on the computed IOB value, wherein the IOB rate represents an amount of active insulin accumulated from manual boluses in the body of the user per unit of time;determining an adjusted insulin infusion rate based at least in part on the calculated IOB rate and an uncompensated insulin infusion rate;selecting a final insulin infusion rate for the insulin infusion device, wherein the selecting selects either the determined adjusted insulin infusion rate, the uncompensated insulin infusion rate, or a current basal rate as the final insulin infusion rate, wherein selecting the final insulin infusion rate is in accordance with either expression FinalRate(n)=max(Basal; AdjustedRate(n)) when PIDRate>Basal, or expression FinalRate(n)=PIDRate(n) when PIDRate Basal, wherein:FinalRate(n) is the selected final insulin infusion rate;Basal is the current basal rate;AdjustedRate(n) is the determined adjusted insulin infusion rate; andPIDRate(n) is the uncompensated insulin infusion rate; andoperating the insulin infusion device in a closed-loop mode to continuously deliver insulin from the insulin reservoir to the body of the user in accordance with the final insulin infusion rate that is selected, wherein the final insulin infusion rate represents an amount of insulin to be delivered per unit of time.","10","13/870902","2013-04-25","2014-0066892","2014-03-06","9364609","2016-06-14","MEDTRONIC MINIMED, INC.","Desmond Barry  Keenan | John J.  Mastrototaro | Benyamin  Grosman | Neha J.  Parikh | Anirban  Roy","","","","A61M-0005/1723","A61M-0005/1723 | A61B-0005/14503 | A61B-0005/14532 | A61B-0005/4839 | A61B-0005/746 | A61M-0005/172 | G06F-0019/3468","G06Q-010/00","G06Q-010/00 | A61M-005/172 | A61B-005/00 | A61B-005/145 | G06F-019/00","","","","","","4916024001335"
"US","US","P","B2","Methods, systems and computer program products for diagnosing conditions using unique codes generated from a multidimensional image of a sample","Methods of providing a diagnosis using a digital code associated with an image are provided including collecting a multidimensional image, the multidimensional image having at least two dimensions; extracting a two dimensional subset of the multidimensional image; reducing the multidimensional image to a first code that is unique to the multidimensional image based on the extracted two dimensional image; comparing the first unique code associated with the subject to a library of reference codes, each of the reference codes in the library of reference codes being indicative of a class of objects; determining if the subject associated with the first unique code falls into at least one of the classes of objects associated with the reference codes based on a result of the comparison; and formulating a diagnostic decision based on the whether the first unique code associated with the subject falls into at least one of the classes associated with the reference code. Related systems and computer program products are also provided herein.","1. A method of providing a diagnosis using a digital code associated with an image, the method comprising: collecting a multidimensional image of a subject, the multidimensional image having at least two dimensions;extracting a two dimensional subset of the multidimensional image;reducing the multidimensional image to a first code that is unique to the multidimensional image of the subject based on the extracted two dimensional image;comparing the first unique code associated with the subject to a library of reference codes, each of the reference codes in the library of reference codes being indicative of a class of objects;determining if the subject associated with the first unique code falls into at least one of the classes of objects associated with the reference codes based on a result of the comparison; andformulating a diagnostic decision based on the whether the first unique code associated with the subject falls into at least one of the classes associated with the reference code,wherein determining if the subject associated with the first unique reference code falls into at least one of the classes further includes determining if the subject associated with the first unique reference code has changed classes over time; andwherein formulating the diagnostic decision comprises formulating the diagnostic decision based on the change of class over time.","50","14/336062","2014-07-21","2014-0341459","2014-11-20","9361518","2016-06-07","Bioptigen, Inc.","Bradley A.  Bower | Eric L.  Buckland","","","","G06K-0009/00604","G06K-0009/00604 | A61B-0005/0062 | A61B-0005/117 | A61B-0005/6821 | A61B-0005/6826 | G06K-0007/1413 | G06K-0007/1417 | G06K-0007/1447 | G06K-0009/0008 | G06K-0009/00033 | G06K-0009/00892 | G06T-0011/006 | A61B-0005/0066 | A61B-0005/0068","G06K-009/00","G06K-009/00 | A61B-005/00 | A61B-005/117 | G06K-007/14 | G06T-011/00","","","","","","4916023004484"
"US","US","P","B2","Method and apparatus for real time performance assessment","An apparatus for monitoring performance comprises two elements: a first element (4) for attaching to a human or animal, containing two or more of physiological, biochemical, kinematic, and/or environmental sensors and a processing means which records in memory signals or derivates of signals from said sensors and contains a means of re-transmitting this data to a second element, and a second element (13, 16) containing a display (12, 17) or audio output to present the processed live or previous recorded data to the user.","1. A method of monitoring performance of a horse, the method using one or more reference signals derived from an apparatus for monitoring performance, the method comprising providing: (a) providing a girth for attaching to a horse, the girth comprising apparatus having two or more of physiological, biochemical, kinematic, and environmental sensors and a processor to record one or more signals from said sensors, wherein the sensors comprise at least an accelerometer sensor and a position sensor;(b) attaching the girth to the horse;(c) obtaining accelerometer data and position data using said two or more sensors;(d) the apparatus having a means of re-transmitting the data to an external device for storage, display or analysis;(e) transmitting said data to said external device;(f) using said accelerometer data and position data to determine at least a stride length of the horse by combining speed data derived from the position data from the position sensor and accelerometer data derived from the accelerometer sensor;wherein said sensors are only in the girth.","8","14/469848","2014-08-27","2014-0364980","2014-12-11","9355307","2016-05-31","GMAX TECHNOLOGY LTD.","William James  Bradley | Michael Roger  Cane | Dominique M.  Freeman","","","","G06K-0009/00342","G06K-0009/00342 | A01K-0011/008 | A01K-0029/00 | A01K-0029/005 | A61B-0005/002 | A61B-0005/0022 | A61B-0005/11","A63F-009/24","A63F-009/24 | A63F-013/00 | G06F-017/00 | G06F-019/00 | G06K-009/00 | A01K-011/00 | A01K-029/00 | A61B-005/00 | A61B-005/11","","","","","","4916022004535"
"US","US","P","B2","Time prediction system for the safe wearing of newly acquired footwear","The device relates to a system for predicting the period for children to safely wear newly acquired footwear without the risk of damage to their growing feet, which is directly applicable in shoe shops (at their computer cash registers). The essence of the solution for a system for predicting the period for children to safely wear newly acquired footwear rests in the fact that it contains an input module measuring foot length and input of information about the age of the monitored child to which is linked a model for predicting the growth of the child's foot by applying the laws of growth, possibly also including genetic and local influences, connected to a comparative and inferential module establishing the predicted course of growth in foot length of the monitored child, to which is then linked an output module designating the nearest date for the necessary replacement of shoe size for the monitored child.","1. A prediction system of the period for safely wearing newly acquired footwear for children without the risk of damaging their growing feet, the system comprising: an input module measuring sole length and input of information about the age of a monitored child and a date on which shoes were purchased for the monitored child, to which module is linked a prediction module of the growth of a child'ss feet implementing the laws of growth on the basis of the Carlberg growth model, including an empirical model originating from an analysis of child'ss foot length in connection with the age of children, performed on a group of at least 2000 children connected to a comparative and inferential module establishing a predicted course of sole length growth of the monitored child to which then is linked an output module designating a date when it will be necessary to stop using the purchased shoes.","6","13/981918","2012-01-25","2013-0332107","2013-12-12","9339084","2016-05-17","UNIVERZITA TOMASE BATI VE ZLINE","Petr  Hlavacek | Josef  Chlachula","2011-53","CZ","2011-01-31","A43D-0001/027","A43D-0001/027 | A43B-0003/30 | A61B-0005/1074 | G06Q-0010/04 | G06Q-0030/0627 | G06Q-0030/0281","A43D-001/02","A43D-001/02 | A61B-005/107 | A43B-003/30 | G06Q-030/06 | G06Q-010/04 | G06Q-030/02","","","","","","4916020000691"
"US","US","P","B2","Charger with data transfer capabilities","Gastric apparatus (18) is provided, including one or more sensors (70, 72, 74), adapted to generate respective sensor signals responsively to a gastrointestinal (GI) tract physiological parameter of a GI tract of a subject, and an implantable control unit (90), comprising a rechargeable battery and a first set of one or more transducers. The implantable control unit (90) is adapted to receive the sensor signals, using one or more of the transducers of the first set, and transmit data responsively to the sensor signals, using one or more of the transducers of the first set. An external control unit (200), including a power source and a second set of one or more transducers, is adapted to drive the power source to inductively transfer energy via one or more transducers of the second set, so as to recharge the battery, and receive the transmitted data, using one or more transducers of the second set.","1. Apparatus, comprising: one or more sensors, adapted to generate respective sensor signals responsively to a physiological parameter of a subject;an implantable control unit, comprising a rechargeable battery and a first set of one or more transducers, the implantable control unit adapted to receive the sensor signals, and transmit data responsively thereto, using one or more of the transducers of the first set; andan external control unit, comprising a power source, a second set of one or more transducers, and a display screen, the external control unit adapted to: drive the power source to wirelessly transfer energy via one or more of the transducers of the second set,receive the transmitted data, using one or more of the transducers of the second set,be in connective interface with a remote service provider over a connection over which the external control unit is recharged,send to the remote service provider eating-related information including a number of meals consumed per time period by the subject,receive, from the remote service provider, subject-specific recommendations generated by the remote service provider based on an analysis of received eating-related information, anddisplay the subject-specific recommendations on the display screen,wherein the implantable control unit is adapted to receive the transmitted energy, using one or more of the transducers of the first set, and charge the battery using the energy.","62","11/816574","2006-02-15","2012-0101874","2012-04-26","9339190","2016-05-17","SANDLEFORD PARK LIMITED, AS SECURITY AGENT | METACURE LIMITED","Shlomo  Ben-Haim | Shai  Policker | David  Prutchi | Benny  Rousso | Jason  Sholder","","","","A61B-0005/0031","A61B-0005/0031 | A61B-0005/04884 | A61B-0005/42 | A61F-0005/0026 | A61N-0001/36007 | G06F-0019/3406 | G06F-0019/3475 | G06Q-0030/0207 | A61N-0001/362 | A61N-0001/37235 | A61N-0001/37252 | A61N-0001/37282 | G06F-0019/3418","A61B-005/07","A61B-005/07 | A61B-005/00 | A61B-005/0488 | A61F-005/00 | A61N-001/36 | G06F-019/00 | G06Q-030/02 | A61N-001/362 | A61N-001/372","","","","","","4916020000797"
"US","US","P","B2","Systems and methods for determining blood flow characteristics using flow ratio","Embodiments include a system for determining cardiovascular information for a patient which may include at least one computer system configured to receive patient-specific data regarding a geometry of an anatomical structure of a patient; create a model representing at least a portion of the anatomical structure; create a physics-based model relating to a blood flow characteristic within the anatomical structure; determine a first blood flow rate at at least one point of interest in the model; modify the model; determine a second blood flow rate at a point in the modified model corresponding to the at least one point of interest in the model; and determine a fractional flow reserve value as a ratio of the second blood flow rate to the first blood flow rate.","1. A system for determining cardiovascular information for a patient, the system comprising: at least one computer system configured to: receive patient-specific image data regarding a geometry of an anatomical structure of a patient;create an anatomical model representing at least a portion of the anatomical structure of the patient based on the patient-specific image data;determine at least one point of interest of vasculature of the anatomical model;determine a first blood flow rate through the at least one point of interest of the vasculature;dilate vessel geometry of the vasculature at the at least one point of interest;determine a second blood flow rate resulting from the dilating of the vessel geometry at the at least one point of interest; anddetermine a flow rate ratio of the second blood flow rate to the first blood flow rate.","30","14/803722","2015-07-20","2015-0324545","2015-11-12","9339200","2016-05-17","HEARTFLOW, INC.","Timothy A.  Fonte","","","","A61B-0005/029","A61B-0005/029 | A61B-0005/02007 | A61B-0005/1073 | A61B-0005/7275 | A61B-0005/7278 | G06F-0017/10 | G06F-0017/5009 | G06F-0019/3437 | G06T-0019/00 | A61B-0005/0037 | A61B-0005/0044 | A61B-0005/021 | A61B-0005/026 | A61B-0005/02028 | G06T-2210/41","G06F-019/10","G06F-019/10 | G06F-019/00 | A61B-005/02 | G06K-009/00 | G06K-009/36 | A61B-005/029 | G06F-017/50 | G06F-017/10 | A61B-005/107 | G06T-019/00 | A61B-005/00 | A61B-005/021 | A61B-005/026","","","","","","4916020000807"
"US","US","P","B2","Exercise supporting device, exercise supporting method and exercise supporting program","An exercise supporting device including a detecting section which repeatedly detects motion data relative to the exercise motion status of a user during the exercise motion; an analyzing and judging section which obtains, based on the motion data, a first motion information value corresponding to the user's moving speed and a second motion information value corresponding to the user's footstep count per unit time or footstep width at each time the detecting section detects the motion data, and judges whether the first motion information value is out of a first numerical value range and whether the second motion information value is out of a second numerical value range; and an output section which, when at least one of the motion information values is judged as being out of the relevant numerical value range, performs an informing operation regarding this motion information value.","1. An exercise supporting device comprising: a detecting section which repeatedly detects motion data related to an exercise motion status of a user who is making an exercise motion by a moving motion;an analyzing and judging section which obtains, based on the detected motion data, a movement distance from a moving motion start point of the user, a first motion information value corresponding to a moving speed of the user and a second motion information value corresponding to a footstep count of the user per unit time or a footstep width of the user, at each time the detecting section detects the motion data, wherein a plurality of movement distance ranges respectively corresponding to different movement distances have a plurality of respective first numerical value ranges in each of which a plurality of values are set as an allowable range of the first motion information value and a plurality of respective second numerical value ranges in each of which a plurality of values are set as an allowable range of the second motion information value,wherein the analyzing and judging section judges whether or not the first motion information value is out of a specific first numerical value range set for a specific movement distance range in which the movement distance when the first motion information value is obtained is included from among the plurality of first numerical value ranges, at each time the first motion information value is obtained, andwherein the analyzing and judging section judges whether or not the second motion information value is out of a specific second numerical value range set for the specific movement distance range from among the plurality of second numerical value ranges, at each time the second motion information value is obtained; andan output section which, when at least one of the first motion information value and the second motion information value is judged by the analyzing and judging section as being out of a relevant one of the specific first numerical value range and the specific second numerical value range, performs an informing operation regarding the first motion information value or the second motion information value judged as being out of the relevant one of the specific first numerical value range and the specific second numerical value range, during the exercise motion of the user,wherein the output section includes a display section which displays an image including character information, and wherein the output section: performs, as the informing operation, a standard display on the display section with a first display format in which a display color of a background portion of the display section is set to a first background color, and character information included in a first image corresponding to the first motion information value and the second motion information value is displayed on the display section with a first size, when the analyzing and judging section judges that the first motion information value is within the specific first numerical value range and the second motion information value is within the specific second numerical value range;performs, as the informing operation, a caution display on the display section with a second display format which is different from the first display format and in which the display color of the background portion of the display section is set to a second background color different from the first background color, and character information included in a second image corresponding to one of the first motion information value and the second motion information value is displayed on the display section with a second size larger than the first size, when the analyzing and judging section judges that only said one of the first motion information value and the second motion information value is out of a relevant one of the specific first numerical value range and the specific second numerical value range; andperforms, as the informing operation, an alert display on the display section with a third display format which is different from the first display format and the second display format and in which the display color of the background portion of the display section is set to a third background color different from the first background color and the second background color, and character information included in a third image corresponding to the first motion information value and the second motion information value is displayed on the display section with a third size larger than the first size, when the analyzing and judging section judges that the first motion information value is out of the specific first numerical value range and the second motion information value is out of the specific second numerical value range.","14","14/011582","2013-08-27","2014-0067096","2014-03-06","9333411","2016-05-10","CASIO COMPUTER CO., LTD.","Takehiro  Aibara","2012-188410","JP","2012-08-29","A63B-0071/06","A63B-0071/06 | A61B-0005/11 | G06Q-0010/0639 | A61B-0005/1112 | A61B-0005/681 | A61B-0005/7275 | A61B-2503/10","G06F-017/00","G06F-017/00 | A63B-071/06 | A61B-005/11 | G06Q-010/06 | A61B-005/00","","","","","","4916019001356"
"US","US","P","B2","Integration of user inputs and correction of deformation vector field in deformable image registration workflow","Adeformation vector field (DVF) (22)is computed that relatively spatially registers a first image (16)and a second image (14). A contour (26)delineating a structure in the first image is adapted using the DVF to generate an initial contour (52)for the structure in the second image. A final contour (56)is received for the structure in the second image. The DVF is corrected based on the initial and final contours for the structure in the second image to generate a corrected DVF (32). The correction may comprise computing an adjustment DVF (62)relating the initial and final contours and combining the DVF and the adjustment DVF to generate the corrected DVF. The final contour may be received by displaying the second image overlaid with the initial contour, and receiving user adjustments of the overlaid contour with the overlaid contour updated for each received user adjustment.","1. A method comprising: computing a deformation vector field (DVF) relatively spatially registering first and second images;adapting a contour delineating a structure in the first image using the DVF to generate an initial contour for the structure in the second image;receiving a final contour for the structure in the second image; andcorrecting the DVF based on the initial and final contours for the structure in the second image to generate a corrected DVF;wherein the computing, adapting, and correcting are performed by an electronic processing device; andwherein the correcting comprises:computing an adjustment deformation vector field (adjustment DVF) relating the initial and final contours for the structure in the second image;and combining the DVF and the adjustment DVF to generate the corrected DVF.","17","14/237910","2012-08-16","2014-0201670","2014-07-17","9336591","2016-05-10","KONINKLIJKE PHILIPS ELECTRONICS N V","Yogisha  Mallya | Karl Antonin  Bzdusek","","","","G06T-0007/0012","G06T-0007/0012 | A61N-0005/103 | G06F-0003/0481 | G06F-0003/04845 | G06T-0007/0024 | G06T-2200/24 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/10104 | G06T-2207/10108 | G06T-2207/20012 | G06T-2207/20104 | G06T-2207/30096","G06K-009/00","G06K-009/00 | G06T-007/00 | A61N-005/10 | G06F-003/0481 | G06F-003/0484 | A61B-006/00","","","","","","4916019004518"
"US","US","P","B2","Preemptive machine learning-based gesture recognition","A system and method for detecting a viewing gesture with respect to a wrist-worn device employ a logistic-regression model to pre-learn gesture metrics for on events. An output model is produced for deployment on a consumer device, allowing real-time gesture detection with high accuracy and low latency.","1. A method of recognizing a viewing gesture made by a user of a user-wearable device having a three-dimensional (""3D"") accelerometer and a viewable display, the method comprising: providing one or more tester-wearable devices to be worn by testers, each tester-wearable device having at least a 3D accelerometer and a selection element;collecting accelerometer data and selection-element data as each of the one or more tester-wearable devices is worn, each tester selecting the selection element to signify on events when the display is desired to turn on;calculating at least one metric based on accelerometer data surrounding each on event and employing the at least one metric as a feature for logistic regression;generating a potential logistic-regression model describing a relationship between tester motion and tester viewing of the viewable display; andtraining, validating, and testing the potential logistic-regression model to generate an output model that includes a vector of metric means, a vector of metric standard deviations, and a vector of metric weights.","29","14/454069","2014-08-07","2015-0355718","2015-12-10","9329694","2016-05-03","GOOGLE TECHNOLOGY HOLDINGS LLC","Andrew M.  Slonneger","","","","G06F-0003/017","G06F-0003/017 | A61B-0005/681 | G06F-0003/014 | G06N-0007/023","G06F-003/01","G06F-003/01 | A61B-005/00 | G06N-007/02","","","","","","4916018003805"
"US","US","P","B2","Biometric apparatus and method for touch-sensitive devices","A touch sensor is configured to sense a contact event occurring between a body part of a user and the touch sensor. The touch sensor is configured to produce contact data in response to the sensed contact event. A processor is coupled to the touch sensor and memory. The processor is configured to store in the memory a sequence of data frames each comprising contact data associated with a different portion of the user's body part. The processor is further configured to generate biometric signature data using the sequence of data frames.","1. A processor-implemented method, comprising: sensing a contact event occurring between a body part of a user and a touch sensor;storing in a memory, for the contact event, a sequence of data frames, each of the data frames comprising a three-dimensional data set comprising two-dimensional contact data and a time-dependent reference associated with a contact pattern that evolves over time during contact between different portions of the user'ss body part and the touch sensor;measuring pressure exerted at different locations of the touch sensor by the user'ss body part during the contact event; andgenerating, by a processor, biometric signature data using the three-dimensional data sets of the sequence of data frames and the measured pressure.","23","13/651408","2012-10-13","2013-0094719","2013-04-18","9314193","2016-04-19","BIOGY, INC.","Waleed Sami  Haddad","","","","A61B-0005/117","A61B-0005/117 | A61B-0005/6898 | G06F-0003/011 | H04L-0063/0861 | H04W-0012/06 | G06F-0003/0414","G06K-009/00","G06K-009/00 | A61B-005/117 | H04W-012/06 | H04L-029/06 | A61B-005/00 | G06F-003/01 | G06F-003/041","","","","","","4916016000822"
"US","US","P","B2","Device and method for authorizing the operation of a medical apparatus using a portable identification device carried by an operator","Treatment system for a patient, preferably for performing a dialysis treatment, including a medical apparatus, preferably a dialysis apparatus, having a communication device which is configured to emit a wireless interrogation signal and receive a wireless identification signal, and an identification device which can be carried by an operator to identify the operator. The identification device is preferably embodied as a watch and is configured to send a wireless identification signal to the medical apparatus to confirm the identity of the operator and that the operator is authorized to operate the medical apparatus to which the signal has been sent.","1. A treatment system for a patient for performing a dialysis treatment comprising: a dialysis apparatus having a communication device which is configured to emit a wireless interrogation signal and receive a wireless identification signal; andan identification device that can be carried by an operator, said identification device configured to send a wireless identification signal to the dialysis apparatus, to emit an identification signal at least one of periodically and after reception of an interrogation signal from the communication device of the dialysis apparatus, and to receive and display information sent by the communication device, wherein the communication device is configured to verify whether the identification signal belongs to a member of the maintenance staff and, when the identification signal is an identification signal of a member of the maintenance staff and when a need for maintenance of the dialysis apparatus has been determined, to send at least one of a suitable alarm and suitable information to the identification device of the maintenance staff member regarding the need for maintenance, said maintenance staff member, in response to said at least one of an alarm and information, then acting to do at least one of determine what maintenance of the dialysis apparatus is required, and perform the required maintenance.","16","14/092007","2013-11-27","2014-0148104","2014-05-29","9314207","2016-04-19","FRESENIUS MEDICAL CARE DEUTSCHLAND GMBH","Stefan Konrad  Marterstock","10-2012-111523","DE","2012-11-28","A61B-0005/681","A61B-0005/681 | A61B-0005/4866 | A61B-0019/44 | A61M-0001/14 | G06F-0019/323 | G06F-0019/3406 | G06F-0019/3468 | H04L-0067/12 | H04W-0012/06 | A61B-2019/448 | A61M-2205/276 | A61M-2205/3561 | A61M-2205/3584 | A61M-2205/3592 | A61M-2205/52 | A61M-2205/60 | A61M-2205/6054","H04B-007/00","H04B-007/00 | A61B-005/00 | A61M-001/14 | H04W-012/06 | G06F-019/00 | H04L-029/08 | A61B-019/00","","","","","","4916016000836"
"US","US","P","B2","Response scoring system for verbal behavior within a behavioral stream with a remote central processing system and associated handheld communicating devices","A system, method and related devices for monitoring and improving the training and social eye contact and communication skills of developmentally challenged individuals such as autistic individuals with special needs in improving their interpersonal communicating and other skills. A WatchMe component of the system and method monitors and obtains qualitative and quantitative information about the eye contact habits of a subject being trained or interviewed. It provides stimuli that promotes and encourages improvements in the eye contact habits of the subject.","1. A system for encouraging a developmentally challenged patient to maintain eye contact with a human trainer, during verbal training communications, the system comprising: a first receiving device worn by the patient, located in a room in which training is administered, and configured to provide a direction indication representative of a direction to which the head of the patient is facing;a second transmitting device, worn by the human trainer located in the room, and configured to sense the direction indication from the first device via an alignment degree between the first device and the second device; anda circuit which outputs a reinforcement stimulation to the patient, to encourage the patient to orient her head toward the head of the trainer, in a manner which helps establish eye contact with the trainer.","15","13/468756","2012-05-10","2012-0329018","2012-12-27","9318029","2016-04-19","BARRY KATZ","Barry  Katz | Robert  Peterson","","","","G09B-0019/00","G09B-0019/00 | A61B-0003/0066 | A61B-0003/113 | A61B-0003/145 | A61B-0005/1114 | A61B-0005/6803 | A61B-0005/6821 | A61B-0005/7264 | G06F-0003/011 | G06F-0003/013 | G06Q-0050/22 | G06T-0007/004 | G06T-0011/00 | G09B-0001/00 | G09B-0005/00 | G09B-0005/062 | G09B-0007/00 | G09B-0023/28 | A61B-0005/04842 | A63F-2300/8082 | G02C-0005/001 | G06T-2207/30201","G06F-003/00","G06F-003/00 | G09B-019/00 | G06F-003/01 | A61B-003/113 | A61B-003/00 | A61B-003/14 | A61B-005/11 | A61B-005/00 | G09B-005/06 | G09B-001/00 | G09B-023/28 | G06T-007/00 | G06T-011/00 | G06Q-050/22 | G09B-005/00 | G09B-007/00 | A61B-005/0484 | G02C-005/00","","","","","","4916016004632"
"US","US","P","B2","System and method for estimating a quantity of interest of a dynamic artery/tissue/vein system","The invention relates to a system and a method for estimating a quantity of interest of a dynamic artery/tissue/vein system of an elementary volume?referred to as a voxel?of an organ based on medical images according to the methods referred to as oSVD or cSVD. The invention discloses two embodiments which are distinguished by the execution time necessary in order to produce the estimate of said quantity of interest and enable a therapeutic diagnosis including in an emergency situation.","1. A method implemented by a processing unit of a medical imaging analysis system for producing an estimate of a haemodynamic parameter in a dynamic artery/tissue/vein system, on the basis of experimental intensity signals S(t), wherein the method comprises: obtaining a signal S(t), wherein said signal S(t) represents the evolution of a voxel of interest of a plurality of voxels over time t, wherein the plurality of voxels constitute elementary volumes of an organ;deriving, from the signal S(t), a concentration curve c for the voxel of interest;performing, by the processing unit, a step for breaking down a convolution matrix A canonically into singular values in the form A=U·S·VT where S≡diag(σ1, . . . , σL) is the diagonal matrix of singular values classified by increasing order,VT is the transpose of a matrix V, andV=(vij) and U=(uij) are two unitary and real square matrices of dimension L×L, L?N, N being a defined number of samples, A and c respectively having dimensions L×L and L×1;performing, by the processing unit, at least one iterative step for: producing a pseudo-inverse ?1?1 of A, in the form ?1?1=V·Wl·UT, where UT designates the transpose of U, and where producing dl=??1·c;performing, by the processing unit, a step for producing the estimate of the haemodynamic parameter on the basis of an estimate of a quantity of interest {circumflex over (d)}=dlF produced with the iteration lF, where {circumflex over (d)} has dimensions L×1, and lF is positive and less than or equal to L;producing, by the processing unit, the estimate of the haemodynamic parameter in a format suitable for display on a man-machine interface; anddisplaying, on the man-machine interface, an illustration of the estimate.","14","14/240239","2012-08-24","2014-0219532","2014-08-07","9311702","2016-04-12","OLEA MEDICAL","Fabrice  Pautot","2011-057578","FR","2011-08-26","G06T-0007/0012","G06T-0007/0012 | A61B-0005/0042 | A61B-0005/055 | A61B-0006/507 | G01R-0033/56366 | G06F-0017/12 | G06F-0017/16 | G06T-0007/0016 | A61B-0005/0263 | A61B-2576/026 | G06T-2207/10081 | G06T-2207/10088 | G06T-2207/30016 | G06T-2207/30048 | G06T-2207/30101 | G06T-2207/30104","G06K-009/00","G06K-009/00 | G06T-007/00 | A61B-005/00 | A61B-005/055 | G01R-033/563 | G06F-017/12 | G06F-017/16 | A61B-006/00 | A61B-005/026","","","","","","4916015004536"
"US","US","P","B2","Method for assessing breast density","Breast density is a significant breast cancer risk factor measured from mammograms. Evidence suggests that the spatial variation in mammograms may also be associated with risk. The variation in calibrated mammograms as a breast cancer risk factor was investigated and its relationship with other measures of breast density was explored using full field digital mammography (FFDM) as described herein. A matched case-control analysis was used to assess a spatial variation breast density measure in calibrated FFDM images, normalized for the image acquisition technique variation. The findings indicate the variation measure is a viable automated method for assessing breast density. Insights gained by this work may be used to develop a standard for measuring breast density.","1. A method of assessing breast density for breast cancer risk applications, comprising: receiving digital image data including a plurality of pixels;calibrating the digital image data;measuring a variation of pixel values of the calibrated digital image data, wherein measuring a variation of pixel values of the calibrated digital image data further comprises at least one of calculating an l2 norm or order derived therefrom or calculating an l1 norm or order derived therefrom; andassociating the variation of pixel values with a measure of risk for breast cancer, wherein the variation of pixel values correlates with at least one of a relative risk for breast cancer, an odds ratio for breast cancer, or an absolute risk prediction for breast cancer.","21","13/994969","2011-12-15","2013-0272595","2013-10-17","9304973","2016-04-05","H. LEE MOFFITT CANCER CENTER AND RESEARCH INSTITUTE, INC.","John J.  Heine | Thomas A.  Sellers","","","","G06F-0017/18","G06F-0017/18 | A61B-0005/4312 | A61B-0006/502 | A61B-0006/5217 | A61B-0006/583 | G06F-0019/345 | G06F-0019/3431 | G06K-0009/00496 | G06K-0009/623 | G06T-0007/0012 | G06T-2207/10116 | G06T-2207/20076 | G06T-2207/30068","G06K-009/00","G06K-009/00 | G06F-017/18 | G06K-009/62 | A61B-005/00 | G06F-019/00 | A61B-006/00 | G06T-007/00","","","","","","4916014004081"
"US","US","P","B2","Method and system for managing inventories of orthopaedic implants","A system and method for managing inventories of orthopaedic implants includes receiving a medical image of a bone of a patient from a healthcare provider, performing a digital templating procedure on the medical image to determine an orthopaedic implant for use with the bone of the patient; transmitting the digital templated medical image to the healthcare provider, and shipping the orthopaedic implant to the healthcare provider in response to an electronic approval of the digital templated medical image received from the healthcare provider. Implant constraint data may also be received from the healthcare provider and used in determining the orthopaedic implant. In addition, a number of orthopaedic implants having a range of different sizes based on the size of the determined orthopaedic implant may be shipped to the healthcare provider. In some embodiments, the healthcare provider may perform the digital templating procedure on the medical image.","1. A method for managing inventories of orthopaedic implants, the method comprising: receiving, by a computing system and over a network, (i) an authorization to retrieve medical images and metadata associated with the medical images from a healthcare provider network and (ii) a location within the healthcare provider network from which the medical images and the metadata can be retrieved;retrieving, from the location within the healthcare provider network, (i) a medical image of a patient'ss bone and (ii) surgeon preference data, selected by a healthcare provider that identifies a desired characteristic of an orthopaedic implant, over the network by the computing system;selecting, by the computing system, a number of orthopaedic implants from an inventory of orthopaedic implants, the inventory of orthopaedic implants comprises a plurality of orthopaedic implants available for selection, the orthopaedic implants being selected based on the medical image and the surgeon preference data;retrieving, by the computing system, a stored digital template for each of the selected orthopaedic implants from a data repository comprising a plurality of digital templates;determining, by the computing system, an axis of the patient'ss bone from the medical image;performing, by the computing system, a number of digital templating procedures on the medical image to automatically superimpose each digital template of each selected orthopaedic implant onto the medical image in a location and orientation that is automatically selected as a function of the determined axis of the patient'ss bone and an amount of bone to be resected from the patient'ss bone during an orthopaedic surgical procedure to generate a number of digital templated images; andtransmitting, by a communication circuit of the computing system, the number of digital templated images generated from the number of digital templating procedures to the healthcare provider over the network using a communication protocol.","7","14/104216","2013-12-12","2014-0100886","2014-04-10","9299117","2016-03-29","DEPUY SYNTHES PRODUCTS, INC.","Sherrod A.  Woods | Mark R.  DiSilvestro","","","","G06Q-0050/22","G06Q-0050/22 | G06F-0019/321 | G06F-0019/328 | G06Q-0010/087 | A61F-2002/30953","G06Q-010/00","G06Q-010/00 | G06Q-050/00 | G06Q-050/22 | G06F-019/00 | G06Q-010/08 | A61F-002/30","","","","","","4916013004480"
"US","US","P","B2","Biosleeve human-machine interface","Systems and methods for sensing human muscle action and gestures in order to control machines or robotic devices are disclosed. One exemplary system employs a tight fitting sleeve worn on a user arm and including a plurality of electromyography (EMG) sensors and at least one inertial measurement unit (IMU). Power, signal processing, and communications electronics may be built into the sleeve and control data may be transmitted wirelessly to the controlled machine or robotic device.","1. An apparatus for sensing user input, comprising: an elastic material for fitting tightly to a body portion of a user, the body portion having underlying muscles of the user;an array of electromyography (EMG) sensors disposed in the elastic material to be proximate to the underlying muscles of the user in order to sense activity of the underlying muscles and yield EMG electrical signals therefrom;a plurality of inertial measurement units (IMUs) each disposed on a separately moving portion of the user for determining position and orientation of each of the plurality of inertial measurement units (IMUs) in order to sense differential movement between body parts and yielding corresponding IMU data, each IMU providing nine-axis measurements, three for gyrometers, three for accelerometers and three for magnetic field vector;a processor for receiving the EMG electrical signals and the IMU data and deriving control data for a robotic device; anda power supply powering the processor and the plurality of IMUs.","18","13/903781","2013-05-28","2013-0317648","2013-11-28","9278453","2016-03-08","CALIFORNIA INSTITUTE OF TECHNOLOGY","Christopher  Assad","","","","B25J-0009/1694","B25J-0009/1694 | A61B-0005/04888 | B25J-0009/104 | G06F-0003/011 | G06F-0003/014 | A61B-0005/1116 | A61B-0005/1122 | A61B-0005/6825 | A61B-0005/6826 | A61B-0005/6831 | A61B-0005/721 | A61B-0005/7267 | G05B-2219/36435 | G06K-0009/00355","B25J-009/16","B25J-009/16 | G06F-003/01 | B25J-009/10 | A61B-005/0488 | A61B-005/00 | A61B-005/11 | G06K-009/00","","","","","","4916010001222"
"US","US","P","B2","Adaptive application of accessory device settings","A system for adaptive application of device settings is disclosed. In the system, a first device may receive information identifying settings that are applied to one or more second devices. The settings may correspond to interactions, by a user, with the one or more second devices over a period of time. The one or more second devices be may non-mobile devices associated with one or more facilities. The first device may determine information identifying one or more conditions, associated with environmental conditions or conditions associated with the user's mood or physical state, under which the settings are applied to the one or more second devices; store information that correlates the settings of the one or more second devices with the one or more conditions; determine that at least one of the one or more conditions is met; and apply the settings to the one or more second devices.","1. A method comprising: receiving, by a first device, information identifying settings that are applied by a user to one or more second devices over a period of time, the one or more second devices being non-mobile devices associated with one or more particular facilities;receiving, by the first device and from one or more third devices, information regarding one or more user-related conditions and one or more environmental conditions, the one or more third devices including a plurality of sensory devices,the one or more user-related conditions being based on physiological measurements relating to a mood or a physical state of the user, andthe one or more environmental conditions being based on an environment associated with the one or more second devices;determining, by the first device and based on the information regarding the one or more user-related conditions and the one or more environmental conditions, a pattern of one or more conditions under which the settings are applied by the user to the one or more second devices, the one or more conditions including one or more of the one or more user-related conditions or the one or more environmental conditions;storing, by the first device, information that correlates the settings, of the one or more second devices, with the one or more conditions;receiving, by the first device, additional information from a sensory device, of the plurality of sensory devices, after storing the information that correlates the settings with the one or more conditions;determining, by the first device, that at least one of the one or more conditions is met based on the additional information from the sensory device; andapplying, by the first device and without interaction of the user, at least one of the settings to at least one of the one or more second devices based on determining that the at least one of the one or more conditions is met.","20","14/058942","2013-10-21","2015-0113262","2015-04-23","9280366","2016-03-08","CELLCO PARTNERSHIP D/B/A VERIZON WIRELESS","Ashfaq  Kamal | Brigitte  Bastaldo-Tsampalis | Rita  Sadhvani | Manuel E  Caceres | Ioannis  Tsampalis","","","","G06F-0009/44505","G06F-0009/44505 | A61B-0005/7275 | A61B-0005/002 | A61B-0005/1113","G06F-003/00","G06F-003/00 | G06F-009/445 | A61B-005/00 | A61B-005/11","","","","","","4916010003127"
"US","US","P","B2","Systems and devices for selective cell lysis and methods of using same","A device for generating microbubbles in a gas and liquid mixture and injection device, the device comprising: a housing defining a mixing chamber; means for mixing solution contained in the mixing chamber to generate microbubbles in the solution; a needle array removably attached to the housing and in fluid connection with the mixing chamber, the needle array including at least one needle; and at least one pressure sensor for measuring tissue apposition pressure, the pressure sensor being mounted on one of the housing and the needle array.","1. A system for the generation and delivery of microbubbles, comprising: a liquid reservoir configured to contain a fluid;a gas reservoir configured to contain a gas or vapor;a bubble generator, wherein the bubble generator is in fluidic communication with the liquid reservoir and the gas reservoir,wherein the bubble generator is configured to receive liquid from the liquid reservoir and gas from the gas reservoir and combine the received liquid and gas to create a solution comprising microbubbles;a fluid injection device, wherein the fluid injection device comprises a needle array comprising one or more needles; andwherein the fluid injection device is in fluidic communication with the bubble generator and is configured to receive the solution comprising microbubbles and to inject the solution comprising microbubbles into a region of target tissue.","20","14/536375","2014-11-07","2015-0112245","2015-04-23","9272124","2016-03-01","Ulthera, Inc.","Adnan I.  Merchant | Mark E.  Deem","","","","A61M-0037/00","A61M-0037/00 | A61M-0005/142 | A61M-0005/158 | A61M-0005/165 | A61M-0005/16827 | A61M-0005/445 | G06Q-0010/02 | G06Q-0010/06 | A61M-2005/006 | A61M-2005/1585 | A61M-2005/1655","G06F-017/50","G06F-017/50 | G06Q-010/02 | A61M-037/00 | G06Q-010/06 | A61M-005/142 | A61M-005/158 | A61M-005/165 | A61M-005/168 | A61M-005/44 | A61M-005/00","","","","","","4916009001238"
"US","US","P","B2","Image search engine","An embodiment of the current invention includes a non-invasive imaging system, comprising: an imaging scanner suitable to generate an image representing a tissue region of a subject under observation, the tissue region having at least one substructure and the image comprising a plurality of image voxels; a signal processing system in communication with the imaging scanner to receive the imaging signal from the imaging scanner; and a data storage unit in communication with the signal processing system, wherein the data storage unit is configured to store: an atlas comprising spatial information of the at least one substructure in the tissue region, and a database comprising a plurality of pre-stored medical images representing the tissue region, and wherein the signal processing system is adapted to: identify, based on the atlas and for each of the at least one substructure, a corresponding portion of image voxels in the image; provide a computed quantification of the corresponding portion of image voxels for each of the at least one substructure of the tissue region by performing spatial filtering on the image; and search the database to provide at least one selected medical image from the plurality of pre-stored medical images, the at least one selected medical image having a corresponding quantification that is substantially similar to the computed quantification.","1. A non-invasive imaging system, comprising: an imaging scanner suitable to generate an image representing a tissue region of a subject under observation, the tissue region having at least one substructure and said image comprising a plurality of image voxels;a signal processing system in communication with said imaging scanner to receive the image from said imaging scanner; anda data storage unit in communication with said signal processing system,wherein said data storage unit is configured to store:an atlas comprising spatial information of said at least one substructure in the tissue region, anda database comprising a plurality of pre-stored medical images representing said tissue region, andwherein said signal processing system is adapted to:segment said image, for each of the at least one substructure, into a corresponding portion of image voxels in said image using the atlas;store a computed quantification of the corresponding portion of image voxels for each of the at least one substructure of said tissue region in said database, said computed quantification being calculated by performing spatial filtering on said image, said spatial filtering including said segmenting; andsearch said database using a computed quantification value as input to provide at least one selected medical image from the plurality of pre-stored medical images, the at least one selected medical image having a corresponding quantification that is substantially similar to said computed quantification value.","29","13/824853","2011-10-25","2013-0223716","2013-08-29","9275456","2016-03-01","THE JOHNS HOPKINS UNIVERSITY","Susumu  Mori | Michael I.  Miller | Kenichi  Oishi | Andreia V.  Faria","","","","G06T-0007/0014","G06T-0007/0014 | A61B-0005/0013 | A61B-0005/055 | G06F-0017/30247 | G06F-0019/321 | G06F-0019/3443 | A61B-0006/032 | A61B-0006/501 | A61B-0006/56 | A61B-0008/56 | A61B-0008/565","G06T-007/00","G06T-007/00 | A61B-005/00 | A61B-005/055 | G06F-017/30 | G06F-019/00 | A61B-006/03 | A61B-006/00 | A61B-008/00","","","","","","4916009004542"
"US","US","P","B2","Adaptive gesture-based method, system and computer program product for preventing and rehabilitating an injury","In an approach to allowing a user to operate a computing device while preventing and/or rehabilitating an injury, three-dimensional gestures of a user are translated into corresponding movement of a cursor on a display device. Different gestures can indicate the same motion of the cursor. As the user gestures to move the cursor, the software determines, based on a history of use specific to the user, whether the user can continue without feeling pain or fatigue. If it is determined that continued use will cause or is likely to cause pain or fatigue, the software can request the user to take a break, or can switch the gesture or motion required by the user to move the cursor in a similar manner.","1. A method comprising the steps of: creating, by a computer, a plurality of movement profiles, each movement profile being in a manner which a cursor moves in response to one or more gestures performed by a user and wherein each movement profile includes one or more different gestures corresponding to a same movement of the cursor, such that a user can perform either at least a first gesture or a second gesture and achieve the same movement of the cursor;tracking, via one or more sensor devices connected to the said computer, the one or more gestures performed by a user, wherein a gesture is a detectable movement of a body or a part of the body;in response to the tracking of the one or more gestures performed by a user, moving a cursor on a display device of the said computer in a manner which corresponds to both the one or more gestures and at least one movement profile of the plurality of movement profiles indicating a predefined set of one or more gestures that move the cursor;receiving, based at least on one of data gathered from the gestures performed and a direct notification from the user, an indication that the user is experiencing fatigue or pain;in response to the received indication that the user is experiencing fatigue or pain, determining, by the said computer, a threshold level for potential injury for the one or more gestures; andusing the threshold level to determine if subsequent repeated gestures similar to any of the one or more gestures are nearing a point of potential injury;in response to receiving no indication that the user is experiencing fatigue or pain, and based at least in part on the at least one movement profile and an analysis of the one or more gestures, determining whether a subsequent performance of one or more of the one or more gestures are potentially injurious;in response to determining the subsequent gestures would cause the user potential injury, taking, by the said computer, a preventative action, wherein taking the preventative action comprises changing, by the said computer, the at least one movement profile such that subsequent gestures must differ from the one or more potentially injurious gestures to accomplish a similar movement of the cursor.","20","13/523934","2012-06-15","2013-0339908","2013-12-19","9268405","2016-02-23","INTERNATIONAL BUSINESS MACHINES CORPORATION","Gemma M.  Bailey | Leon  Chen | James K.  Hook | Melanie S.  Hopper | Susannah Marie  Lindsay","","","","G06F-0003/017","G06F-0003/017 | G06F-0003/0484 | A61B-0005/11 | A61B-0005/1116 | A61B-0005/1121 | A61B-0005/1124","G06F-003/01","G06F-003/01 | G06F-003/048 | G01H-011/00 | H04B-005/00 | G06F-017/30 | G06F-003/0484 | A61B-005/11","","","","","","4916008003737"
"US","US","P","B2","Method and system for processing information based on detected biometric event data","A system and method is provided for processing and storing captured data in a wireless communication device based on detected biometric event data. The captured data may be acquired through a data acquisition system with devices or sensors in an integrated or distributed configuration. The captured data may include multimedia data of an event with time, date and/or location stamping, and captured physiological and behavioral biometric event data in response to the event. The captured data may be dynamically stored in a data binding format or as raw data in a local host device or communicated externally to be stored in a remote host or storage. At least one user preference may be specified for linking a biometric event data to the mapped, analyzed, categorized and stored captured data in a database. Captured data may be retrieved by matching biometric event data to at least one user preference from the database.","1. A method comprising: capturing, in a computing device, input data;capturing, in the computing device, biometric event data via one or more biometric sensors concurrent to the capturing of the input data; andmapping at least a portion of the biometric event data to at least a portion of the captured input data, wherein:the mapping comprises mapping the at least a portion of the biometric event data to a biometric event database; andthe mapped at least a portion of the biometric event data indicates a behavioral condition of a user during the capturing of the input data.","20","13/903606","2013-05-28","2013-0262491","2013-10-03","9268876","2016-02-23","BROADCOM CORPORATION","Alexander  MacInnis | Arya  Behzad | Mark  Buer | Jeyhan  Karaoguz | Thomas  Quigley | John  Walley","","","","G06F-0017/30914","G06F-0017/30914 | A61B-0005/002 | A61B-0005/0024 | A61B-0005/02055 | A61B-0005/0476 | A61B-0005/1112 | A61B-0005/165 | A61B-0005/4803 | A61B-0005/681 | A61B-0005/6814 | G01D-0009/005 | G01D-0021/00 | G06K-0009/00892 | G06K-0009/00979 | H04L-0063/0861 | H04W-0012/06 | A61B-0003/112 | A61B-0003/113 | A61B-0005/0022 | A61B-0005/024 | A61B-0005/0402 | A61B-0005/0488 | A61B-0005/0531 | A61B-0005/0816 | A61B-0005/117 | A61B-0005/16 | H04M-0001/7253 | H04M-0001/72569 | H04M-2250/10 | H04M-2250/12 | H04W-0088/02","G06F-017/30","G06F-017/30 | A61B-005/00 | A61B-005/0205 | A61B-005/0476 | A61B-005/11 | G01D-009/00 | G01D-021/00 | G06K-009/00 | H04L-029/06 | H04W-012/06 | A61B-003/11 | A61B-003/113 | A61B-005/024 | A61B-005/0402 | A61B-005/0488 | A61B-005/053 | A61B-005/08 | A61B-005/117 | A61B-005/16 | H04M-001/725 | H04W-088/02","","","","","","4916008004204"
"US","US","P","B2","Method and apparatus for providing adaptive display and filtering of sensors and sensor data","An approach is provided for adaptive display and filtering of sensors and sensor data. A sensor manager determines one or more signals associated with one or more sensors. The sensor manager then processes and/or facilitates a processing of the one or more signals for comparison against one or more predetermined signals. The sensor manager determines one or more parameters for one or more filters based, at least in part, on the comparison, wherein the one or more filters operate, at least in part, on the one or more sensors, one or more other signals determined form the one or more sensors, or a combination thereof.","1. A method comprising facilitating a processing of and/or processing (1) data and/or (2) information and/or (3) at least one signal, the (1) data and/or (2) information and/or (3) at least one signal based, at least in part, on the following: one or more signals associated with one or more sensors, the one or more sensors associated with determining at least one operational state of one or more other sensors;a processing of the one or more signals for comparison against one or more predetermined signals; andone or more parameters for one or more filters based, at least in part, on the comparison,wherein the one or more filters operate, at least in part, on the one or more sensors, one or more other signals determined from the one or more other sensors, or a combination thereof,transmitting, via a transceiver, the one or more signals.","26","13/663285","2012-10-29","2013-0060480","2013-03-07","9269000","2016-02-23","NOKIA TECHNOLOGIES OY","Ilkka  Korhonen | Jari Olavi  Nousiainen | Tero Markuu  Makela","","","","G06K-0009/00536","G06K-0009/00536 | A61B-0005/04017 | A61B-0005/1118 | A61B-0005/721 | A61B-0005/725 | G06K-0009/6293 | G06K-0009/685 | H03H-0021/0012 | A61B-0005/0006 | A61B-0005/0022 | A61B-0005/0024 | A61B-2560/0209 | A61B-2562/0219 | G01R-0015/00 | G01R-0029/00 | G06F-0017/40 | G06F-0019/00","G01R-015/00","G01R-015/00 | G01R-029/00 | G06F-017/40 | G06F-019/00 | G06K-009/00 | H03H-021/00 | A61B-005/00 | A61B-005/04 | A61B-005/11 | G06K-009/62 | G06K-009/68","","","","","","4916008004328"
"US","US","P","B2","Medical data transport over wireless life critical network","A communicator facilitates communications with a remote server via a wireless network supporting a plurality of disparate data transport mechanisms having differing characteristics. A processor coupled to memory is disposed in a communicator housing, which is configured for portability. The memory stores wireless radio firmware and data transfer instructions that are executable by the processor for transferring data to the remote server in accordance with a priority level. The priority level is based in part on criticality of the data and the communicator status. A radio disposed in the housing effects communications via the wireless network in accordance with the firmware. A power source in the housing supplies power for communicator components. The processor executes program instructions for selecting a data transport mechanism among the plurality transport mechanisms based on the priority level, and transmits the data via the wireless network via the radio using the selected transport mechanism.","1. A communicator configured to facilitate communications with a remote server, the communicator comprising: a processor;memory coupled to the processor, wherein the memory stores firmware and data transfer instructions, the data transfer instructions executable by the processor for transferring data to the remote server in accordance with a priority level;a communications module configured to effect communications with the remote server using each of a plurality of communications protocols, in accordance with program instructions of the firmware executable by the processor; andthe processor configured to execute program instructions for selecting a communications protocol from the plurality of communications protocols based at least in part on the priority level and transmitting the data to the remote server using the selected transport mechanism via the communications protocol.","20","14/576997","2014-12-19","2015-0206408","2015-07-23","9269251","2016-02-23","Cardiac Pacemakers, Inc.","John  LaLonde | William R.  Mass | Kenneth P.  Hoyme | David C.  Johnson | Joseph E.  Bange | Mark  Gryzwa","","","","G08B-0021/02","G08B-0021/02 | A61B-0005/0026 | A61B-0005/0452 | A61B-0005/747 | A61N-0001/37211 | A61N-0001/37282 | G06F-0019/3418 | G06Q-0050/24 | G08C-0017/02 | G06F-0019/327 | G06F-0019/3412 | H04L-0067/12 | H04W-0012/04 | H04W-0012/06","G08B-001/08","G08B-001/08 | G08B-021/02 | A61N-001/372 | G06Q-050/24 | G08C-017/02 | A61B-005/00 | A61B-005/0452 | G06F-019/00 | H04L-029/08 | H04W-012/04 | H04W-012/06","","","","","","4916008004579"
"US","US","P","B2","Techniques for data retention upon detection of an event in an implantable medical device","Methods and apparatus for storing data records associated with a medical monitoring event in a data structure. These include initiating loop recording in an implantable medical device upon determination of a neurological event, wherein loop recording comprises storing a data record of a plurality of data records in a data structure, the plurality of data records representing information about determined neurological events. Methods and apparatus can further include determining a priority index for the plurality of data records based on severity levels of the determined neurological events and replacing older data records of the plurality of data records on the data structure with new data records according to the priority index, wherein the new data records selectively replace those data records in the data structure having the lowest associated priority index.","1. A method of selective data retention in an implantable medical device, the method comprising: sensing a neurological event that includes ictal content;creating a data record of the neurological event that includes the ictal content;determining a severity level of the neurological event by analyzing the ictal content;storing the data record in a data structure containing a plurality of data records, the plurality of data records representing information about a plurality of neurological events;determining a priority index for the plurality of data records based on severity levels of the determined neurological events where the higher the severity level the higher the priority index; andonce the data structure is full, selectively replacing an existing data record in the data structure with a newer data record that has a higher priority index than the existing data record.","15","14/452312","2014-08-05","2015-0080674","2015-03-19","9259177","2016-02-16","MEDTRONIC, INC.","Touby A.  Drew | Jonathon E.  Giftakis | David L.  Carlson | Eric J.  Panken | Jonathan C.  Werder | Nina M.  Graves","","","","A61B-0005/4094","A61B-0005/4094 | A61B-0005/0006 | A61B-0005/0031 | A61B-0005/02055 | A61B-0005/04001 | A61B-0005/0402 | A61B-0005/04012 | A61B-0005/0476 | A61B-0005/1118 | A61B-0005/165 | A61B-0005/4082 | A61B-0005/686 | A61B-0005/7282 | A61N-0001/36135 | A61N-0001/37252 | G06F-0017/30336 | G06F-0019/322 | G06F-0019/3418 | A61B-0005/021 | A61B-0005/024 | A61B-0005/031 | A61B-0005/0816 | A61B-0005/7232 | A61N-0001/36132 | A61N-0001/36521 | A61N-0001/36585 | A61N-0001/3702 | A61N-0001/37282 | G06F-0019/3406","A61B-005/024","A61B-005/024 | A61B-005/00 | A61B-005/04 | A61N-001/372 | G06F-019/00 | G06F-017/30 | A61B-005/0205 | A61B-005/0402 | A61B-005/0476 | A61B-005/11 | A61B-005/16 | A61N-001/36 | A61N-001/365 | A61N-001/37 | A61B-005/021 | A61B-005/03 | A61B-005/08","","","","","","4916007000782"
"US","US","P","B2","Systems and methods using a wearable device to determine an individuals daily routine","The methods and systems described herein may involve determining at least one lifeotype of at least one individual, analyzing the at least one lifeotype, and delivering content to at least one individual based on the analysis. The methods and systems described herein may involve providing a game, determining at least one lifeotype of at least one player of the game, analyzing the at least one lifeotype, and affecting the game play based on the analysis. The methods and systems described herein may involve providing an interactive space, determining at least one lifeotype of at least one individual in the space, analyzing the at least one lifeotype, and modifying at least one attribute of the space based on the analysis.","1. A computer-system-implemented method, the computer system having at least one programmed processor to implement the method, the method comprising: continuously collecting data components with respect to an individual from a wearable sensor device; andcollecting another set of data components with respect to the individual from a source separate from the wearable device; the computer system? (i) assembling a byte data structure for the individual that includes at least one bit determined from the collected data components from the wearable sensor device and at least one bit determined from said another set of data components;(ii) accessing data stored with respect to at least one other individual;(iii) determining a lifeotype for the individual by matching the byte data structure to the byte data structure of at least one other individual; and(iv) based on the determined type and the individual'ss collected data components, predicting at least one component of the individual'ss daily routine.","11","14/081406","2013-11-15","2014-0180018","2014-06-26","9262772","2016-02-16","BODYMEDIA, INC.","John M.  Stivoric | Eric  Teller | David  Andre | John A.  Monocello, III","","","","G06Q-0030/0251","G06Q-0030/0251 | A61B-0005/021 | A61B-0005/0826 | A61B-0005/1118 | A61B-0005/1123 | A61B-0005/16 | A61B-0005/168 | A61B-0005/4806 | A61B-0005/4812 | A61B-0005/4815 | A61B-0005/4818 | A61B-0005/4833 | A61B-0005/4836 | A61B-0005/6801 | A61B-0005/6802 | A61B-0005/72 | A61B-0005/7275 | A61B-0005/7278 | A61B-0005/7282 | A61B-0005/742 | A61B-0005/746 | A61B-0005/747 | A61B-0005/7475 | A61M-0021/00 | A61M-0021/02 | G06F-0017/30528 | G06F-0017/30554 | G06F-0017/30557 | G06F-0017/30598 | G06F-0017/30722 | G06F-0017/30985 | G06F-0019/10 | G06F-0019/24 | G06F-0019/322 | G06F-0019/345 | G06F-0019/3443 | G06F-0019/36 | G06N-0005/04 | G06N-0099/005 | G06Q-0030/0242 | G06Q-0030/0269 | G06Q-0030/0271 | G06Q-0030/0277 | G06Q-0040/08 | G06Q-0050/22 | G06Q-0050/24 | G09B-0005/00 | G09B-0019/00 | A61M-2021/005 | A61M-2021/0027 | G06F-0019/3431 | G06F-0019/3437","G06F-017/30","G06F-017/30 | G06Q-030/02 | G06Q-040/08 | G06Q-050/22 | G06Q-050/24 | G09B-019/00 | A61B-005/16 | A61B-005/00 | G06F-019/10 | G06N-005/04 | A61B-005/11 | G09B-005/00 | A61M-021/02 | A61B-005/021 | A61B-005/08 | G06N-099/00 | G06F-019/24 | G06F-019/00 | A61M-021/00","","","","","","4916007004360"
"US","US","P","B2","Magnetic assembly and method for defining a magnetic field for an imaging volume","Disclosed herein is a magnet assembly that includes at least two magnets arranged in a fixed spaced relationship with one another thereby to define a space between the magnets that encompasses an imaging volume. Each of the magnets produces a variety of magnetic field strengths across inward-facing surfaces thereof that, in combination, produce an acceptably homogeneous magnetic field in the imaging volume. Also disclosed is a method of defining a magnetic field for an imaging volume. The method comprises generating an initial model of a magnet assembly; estimating a magnetic field for the imaging volume based on the model; calculating deviation between the estimated magnetic field and a target magnetic field for the imaging volume; and updating the model to reduce the deviation by modifying the magnet assembly to produce a variety of magnetic field strengths that, in combination, produce substantially the target magnetic field in the imaging volume.","1. A method of defining a target magnetic field for a target volume in a Magnetic Resonance Imaging (MRI) machine, the method comprising: generating an initial model comprising: a magnet assembly comprising a first magnet and a second magnet maintained in a fixed spaced relationship by a yoke assembly, the magnet assembly having an axis extending generally from a center of the first magnet to a center of the second magnet, the first and second magnets being axisymmetrically shaped; andone or more fixed objects, including the yoke assembly, capable of disturbing the magnetic field in the target volume in a non-axisymmetric manner that would cause the magnetic field in the target volume to be unacceptably inhomogeneous for imaging;estimating a magnetic field for the target volume based on the model;calculating deviation between the estimated magnetic field and the target magnetic field for the target volume; andupdating the model to reduce the deviation by non-axisymmetrically modifying one or more parameters representing one or both of the first and second magnets to produce a variety of magnetic field strengths that, in combination, produce substantially the target magnetic field in the imaging volume.","14","14/174423","2014-02-06","2014-0229141","2014-08-14","9255978","2016-02-09","ALBERTA HEALTH SERVICES","B. Gino  Fallone | Tony  Tadic | Brad  Murray","","","","G01R-0033/543","G01R-0033/543 | G01R-0033/383 | G01R-0033/3806 | G06F-0017/50 | G21K-0001/093 | A61B-0005/055 | A61N-0005/1043 | A61N-2005/1087 | A61N-2005/1089 | H01F-0007/0278","G01R-033/54","G01R-033/54 | G01R-033/38 | G01R-033/383 | G21K-001/093 | G06F-017/50 | A61B-005/055 | A61N-005/10 | H01F-007/02","","","","","","4916006002440"
"US","US","P","B2","Method for gaze-controlled text size control, and methods for gaze-based measuring of a text reading speed and of a number of visual saccades per text line","For gaze-controlled text size control of a display, the invention proposes to probe, sample and record a user's horizontal gaze Signal; to subject the gaze Signal to a subband filterbank or wavelet transform; to detect line delimiters in the gaze Signal; to derive a reading speed; to determine, as a number of saccades per text line the number of locations where the gaze Signal has sudden high slope portions surrounded on both sides by portions of markedly smaller slope; to detect, based on the reading speed and the number of saccades, a too small font size Status or a too big font size Status; and to initiate a corresponding font size change. Parts of this method can be used for gaze-based measuring of text reading speed and for gaze-based measuring of number of saccades.","1. A method for gaze-controlled text size control, comprising: probing, sampling and recording a user'ss horizontal gaze signal at a predefined sampling frequency;subjecting the horizontal gaze signal to a frequency or wavelet transform on several levels;detecting, in the transformed horizontal gaze signal, line delimiters;deriving, for each pair of consecutive line delimiters enclosing the transformed horizontal gaze signal of a current line, a reading speed from the distance in samples of the pair of line delimiters, in relation to the sampling frequency of the horizontal gaze signal;determining, from the transformed horizontal gaze signal of the current line, a number of saccades in the current line, by counting those locations, where the horizontal gaze signal has a sudden high slope portion surrounded on both sides by portions of markedly smaller slope, and wherein the number of the saccades is determined by determining a positive saccade count, determining a negative saccade count, and calculating the number of saccades as a difference between the positive saccade count and the negative saccade count; whereinan increase of the font size is initiated if the number of saccades is above a first threshold or if the reading speed is below a second threshold, and a decrease of the font size is initiated if the number of saccades is less than a third threshold.","6","14/239360","2012-08-10","2014-0327609","2014-11-06","9256285","2016-02-09","THOMPSON LICENSING SA","Arnaud  Leroy | Julien  Fleureau | Philippe  Guillotel","2011-290378","EP","2011-08-19","G06F-0003/013","G06F-0003/013 | A61B-0005/726 | G06F-0003/015 | G06F-0017/148 | G06F-0017/214","G06F-003/01","G06F-003/01 | G06F-017/21 | G06F-017/14 | A61B-005/00","","","","","","4916006002744"
"US","US","P","B2","ECG measuring device and method thereof","The present invention discloses at least two electrodes disposed at the body of the ECG measuring device of the present invention. When a user normally uses the ECG measuring device, the two electrodes are just adhered to the hands and the face of the user. The ECG measuring method of the present invention is to measure a first ECG signal from the left hand to the left side of face of the user and a second ECG signal from the right hand to the right side of face of the user. Then a plurality of ECG features are obtained from the first ECG signal, the second ECG signal and the result, as related coefficients, of the interactive computing, as a method of plus and subtract, of the first ECG signal and the second ECG signal. Hence, a biometric authorization process is engaged according to the plurality of ECG features.","1. An electrocardiogram (ECG) measuring device, which measures subsets of Lead-I ECG vector, comprising: a first electrode, disposed at a lateral surface or a back surface of a body of the measuring device;a second electrode, disposed at a front surface of the body of the measuring device; anda microprocessor, electrically connected with the first electrode and the second electrode, the microprocessor capturing a first ECG signal when the first electrode and the second electrode touch the left hand and the left side of face of a user respectively, capturing a second ECG signal when the first electrode and the second electrode touch the right hand and the right side of face of the user respectively, and captures an entire ECG signal defined as a Lead-I ECG signal when the first electrode and the second electrode touch the left hand and right hand of the user respectively;wherein the microprocessor subtracts the first ECG signal and the second ECG signal from the entire ECG signal so as to obtain a third ECG signal, and engages the first ECG signal, the second ECG signal and the third ECG signal in a noise filtering process;wherein the microprocessor compares the first ECG signal, the second ECG signal and the third ECG signal with an ECG template, and determines whether the first ECG signal, the second ECG signal and the third ECG signal pass a prescreen process;wherein the microprocessor determines that the user does not pass a biometric authorization process if the first ECG signal, the second ECG signal and the third ECG signal do not pass the prescreen process, and the microprocessor extracts a first preset amount of ECG features from the first ECG signal, a second preset amount of ECG features from the second ECG signal, and a third preset amount of ECG features from the third ECG signal if the first ECG signal, the second ECG signal and the third ECG signal pass the prescreen process, and the user is engaged in the biometric authorization process according to the first preset amount, the second preset amount and the third preset amount of ECG features simultaneously.","12","14/066029","2013-10-29","2014-0120876","2014-05-01","9258300","2016-02-09","TZU CHI UNIVERSITY","Tsu-Wang  Shen","","","","H04L-0063/0861","H04L-0063/0861 | A61B-0005/04525 | A61B-0005/117 | A61B-0005/6898 | G06K-0009/00536 | G06K-0009/00885 | H04W-0012/06 | G06K-2009/00939","G06F-021/00","G06F-021/00 | H04L-029/06 | H04W-012/06 | A61B-005/0452 | A61B-005/00 | A61B-005/117 | G06K-009/00","","","","","","4916006004742"
"US","US","P","B2","Bilingual language controller for an automated external defibrillator","A language controller (20) is described which can be installed on the front face of an automated external defibrillator (AED) in order to establish the language of the AED user interface. The language controller is in the form of a labeled plaque (210) which informs the user which language is currently in use. The plaque may also contain a button (222) which enables toggling from one language to another. Memory may also reside in the plaque to provide language data to the AED.","1. A portable medical device configurable to operate in multiple languages comprising: a controller;a memory disposed in electrical communication with the controller, the memory comprising data relating to user instructions in a plurality of languages;a case which houses the controller and memory and comprises a mount disposed on the front face of the case;a sensing element disposed adjacent the mount and in electrical communication with the controller; anda language controller comprising a plaque having a visible language indicator of a first language and disposed to be secured in the mount;a controlling element disposed on the plaque such that the sensing element senses the controlling element when the plaque is secured in the mount,wherein the controller configures the portable medical device to operate in a first language of the plurality of languages based on the sensing element sensing the controlling element.","19","14/375991","2013-02-01","2015-0046149","2015-02-12","9248307","2016-02-02","KONINKLIJKE PHILIPS ELECTRONIC N.V.","Jacco Christof  Eerden | Alan Paul  Greenstein","","","","A61N-0001/3993","A61N-0001/3993 | G06F-0009/4448 | G06F-0017/289","G06F-017/20","G06F-017/20 | G06F-017/27 | A61N-001/39 | G06F-009/44 | G06F-017/28","","","","","","4916005001190"
"US","US","P","B2","Method for finding and digitally evaluating illegal image material","A method for finding and digitally evaluating illegal image material is provided, wherein a data memory is searched for image material. Image material that is found is classified as potentially illegal image material or as legal image material by means of a classification method on the basis of an image content that is presented. The image material graded as potentially illegal has the age of the persons shown determined, and potentially illegal image material which shows at least one person whose ascertained age is below a prescribed age is graded as illegal image material. Biometric features of the persons shown in the illegal image material are detected and are compared with at least one database which contains biometric features. In the illegal image material, at least one further feature which it contains is detected and is compared with at least one appropriate database.","1. A method for automatically finding and digitally evaluating illegal image material, wherein a data memory is searched for image material, the method comprising: classifying, by a computer, found image material from the data memory that depicts image content that is potentially illegal image material;performing, by the computer, an age determination of the depicted persons in the image material classified as potentially illegal image material, and determining whether at least one person depicted in the image material classified as potentially illegal image material falls below a predetermined age;after performing the age determination, detecting, by the computer, biometric features of the persons shown in the potentially illegal image material and comparing the detected biometric features with at least one database containing previously detected biometric features; anddetecting, by the computer, at least one contained additional feature in the potentially illegal image material and comparing the at least one contained additional feature with at least one relevant database,wherein a personal visual inspection of the image material is not performed.","17","13/792840","2013-03-11","2013-0188842","2013-07-25","9251403","2016-02-02","ATG ADVANCED SWISS TECHNOLOGY GROUP AG","Rudolf  Hauke","","","","G06K-0009/00288","G06K-0009/00288 | G06K-0009/00718 | G06Q-0010/10 | A61B-0005/117 | A61B-0005/1176 | A61B-0005/1178","G06K-009/00","G06K-009/00 | G06Q-010/10 | A61B-005/117","","","","","","4916005004263"
"US","US","P","B2","Biological information obtaining apparatus and biological information collating apparatus","An obtaining unit of a biological information obtaining apparatus obtains biological information for authentication, and an extracting unit extracts first feature information from biological information for authentication. A generating unit of a biological information collating apparatus generates encrypted position correction information, and encrypted position correction information is transmitted to the biological information obtaining apparatus. A correcting unit decrypts encrypted position correction information to obtain position correction information, and by correcting first feature information, performs alignment between first feature information and second feature information extracted from biological information for registration. A transforming unit transforms corrected first feature information, and transmits transformed first feature information to the biological information collating apparatus. A collating unit collates transformed first feature information and transformed second feature information stored in a storing unit, and transmits a collation result to biological information obtaining apparatus.","1. A non-transitory computer-readable recording medium having stored therein a program for causing a computer to execute a process comprising: obtaining biological information for authentication;extracting first feature information from the biological information for authentication;encrypting the first feature information;transmitting encrypted first feature information to a biological information collating apparatus or a position correction supporting apparatus;receiving encrypted position correction information from the biological information collating apparatus or the position correction supporting apparatus, wherein encrypted second feature information is generated by encrypting second feature information extracted from biological information for registration and the encrypted position correction information is generated by an arithmetic operation using the encrypted first feature information and the encrypted second feature information;obtaining position correction information by decrypting the encrypted position correction information based on a characteristic of the arithmetic operation;performing position alignment between the first feature information and the second feature information by correcting the first feature information based on obtained position correction information;transforming corrected first feature information;transmitting transformed first feature information to the biological information collating apparatus that stores transformed second feature information; andreceiving a result of collation of the transformed first feature information with the transformed second feature information from the biological information collating apparatus.","10","14/025393","2013-09-12","2014-0016834","2014-01-16","9245178","2016-01-26","FUJITSU LIMITED","Toshio  Endoh | Takashi  Shinzaki","","","","G06K-0009/00362","G06K-0009/00362 | G06F-0021/32 | G06F-0021/6245 | G06K-0009/00087 | G06K-2009/00932 | G06K-2009/00953 | G07C-2209/12","G06K-009/00","G06K-009/00 | G06F-021/32 | G06F-021/62","","","","","","4916004004276"
"US","US","P","B2","Indwelling transfusion catheter, transfusion cannula kit and method for testing a transfusion system","The present disclosure relates to an indwelling catheter having a cannula device (2, 4) and a reservoir, which is connected in a use position to the cannula device (2, 4), such that blood can flow from the cannula device (2, 4) into the reservoir (6), wherein the housing (3) has housing identifiers (8) and the reservoir (6) has reservoir identifiers (9), and the housing identifiers (8) and the reservoir identifiers (9) give mutually assigned codes. In addition, the disclosure relates to a transfusion cannula kit and the method for testing a transfusion system.","1. A method for testing a transfusion system, wherein the method comprises the following steps: providing an indwelling catheter, comprising a cannula device, a housing for the cannula device, and a reservoir, wherein the housing has housing identifiers thereon and the reservoir has reservoir identifiers thereon, and the housing identifiers and the reservoir identifiers show mutually assigned codes;filling the reservoir through the cannula device with blood from a source of blood;removing the reservoir with blood from the indwelling catheter;evaluating the reservoir identifiers;generating fluid identifiers with a fluid code derived from the evaluation of the reservoir identifiers;providing a transfusion fluid in a fluid reservoir, for further testing of the fluid in the fluid reservoir, and providing the fluid identifiers on the fluid reservoir;evaluating a code given by the housing identifiers and the fluid code given by the fluid identifiers by means of an evaluation unit configured to detect and compare the two codes; andoutputting a signal by means of the evaluation unit as a function of whether or not the identifiers are recognized as assigned to one another in the comparison,wherein, before the step of providing the transfusion fluid in the fluid reservoir is performed, the steps of generating the fluid identifiers provided to the fluid reservoir and providing the fluid identifiers on the fluid reservoir are performed.","2","13/264195","2010-04-27","2012-0091196","2012-04-19","9232914","2016-01-12","CHARITE - UNIVERSITATSMEDIZIN BERLIN","Michael  Notter","10-2009-018837","DE","2009-04-28","A61B-0005/1405","A61B-0005/1405 | A61M-0025/0017 | A61J-2205/30 | A61J-2205/60 | A61M-0001/0209 | A61M-2025/0008 | A61M-2205/60 | A61M-2205/6063 | A61M-2205/6072 | G06F-0019/366 | G06Q-0050/22 | G06Q-0050/24","A61B-005/15","A61B-005/15 | A61M-025/00 | G06Q-050/24 | G06F-019/00 | A61M-001/02 | G06Q-050/22","","","","","","4916002000773"
"US","US","P","B2","Handheld device for a patient","A handheld device (10) has a graphic display (12), an interface (18) for wireless data transmission, an input unit (14) for input of control commands, and a control unit (16) connected to the display (12), the interface (18), and the input unit (14). The control unit (16) is designed to display a schematic diagram of a human body on the graphic display (12) and to allow a selection of partial regions of the diagram with the help of the input unit (14).","1. A handheld device (10) including: a. a graphic display (12),b. an input unit (14) for entering control commands,c. an interface (18) for wireless data transmission, andd. a control unit (16) in communication with the graphic display (12), the interface (18), and the input unit (14), wherein the control unit (16): (1) controls the display of a schematic diagram of a human body on the graphic display (12), and(2) collects input from the input unit (14) corresponding to the selection of one or more partial regions of the schematic diagram.","20","12/427781","2009-04-22","2009-0284486","2009-11-19","9233252","2016-01-12","BIOTRONIK CRM PATENT AG","Marco  Albus","10-2008-023328","DE","2008-05-13","A61N-0001/37247","A61N-0001/37247 | A61B-0005/743 | A61B-0005/7435 | A61B-0005/7475 | G06F-0019/3406 | G06F-0019/3412 | G08C-0017/00 | A61N-0001/0551 | A61N-0001/36071","G06F-003/041","G06F-003/041 | A61N-001/372 | A61B-005/00 | G06F-019/00 | G08C-017/00 | A61N-001/05 | A61N-001/36","","","","","","4916002001111"
"US","US","P","B2","Establishing secure communication between an implantable medical device and an external device","Establishing secure communication between an implantable medical device and an external device includes: accessing, at the implantable medical device, biological data; utilizing the biological data, at the implantable medical device, to generate a public cryptographic key; and utilizing the public cryptographic key, at the implantable medical device, to generate a private cryptographic key.","1. A medical device, comprising: a converting module configured to convert biometric activity to a digital representation, to compute a metric based on the digital representation of the biometric activity, and to obtain a digital representation of the metric; anda cryptographic key generator configured to generate a cryptographic key corresponding to a portion of a random number derived directly from the digital representation of the metric.","20","14/676759","2015-04-01","2015-0207622","2015-07-23","9237012","2016-01-12","NEUROPACE, INC.","Dean P  Andersen","","","","H04L-0009/0869","H04L-0009/0869 | A61B-0005/0006 | A61B-0005/0476 | A61N-0001/36064 | G06F-0007/588 | G06F-0019/3406 | G06F-0021/606 | H04L-0009/0816 | H04L-0067/12 | H04W-0012/04 | H04W-0012/06 | H04L-2209/24","H04L-029/06","H04L-029/06 | H04L-009/08 | H04W-012/04 | H04W-012/06 | G06F-007/58 | H04L-029/08 | G06F-019/00 | G06F-021/60 | A61B-005/00 | A61B-005/0476 | A61N-001/36","","","","","","4916002004852"
"US","US","P","B2","Image processing device, image processing method and program","An image processing device includes: a first feature amount extraction unit configured to extract a first feature amount from an image; a position detection unit configured to detect observation positions from the image based on a position detection dictionary, and the first feature amount extracted from the image; a second feature amount extraction unit configured to extract a second feature amount from the observation position; an observation-order determining unit configured to determine the order of observing the observation positions based on an order generation dictionary, and respective second feature amounts of the observation positions; and an image generation unit configured to generate observation images for displaying the observation positions in the observation order based on the image, the detected observation positions and the determined observation order.","1. An image processing device comprising: circuitry configured to: extract first feature amounts from an image to be processed;detect observation positions from the image to which attention should be paid by applying a position detection dictionary to the first feature amounts extracted from the image, wherein the position detection dictionary is generated by statistical learning in advance;extract a second feature amount from each of the detected observation positions on the image, wherein the second feature amount is a distribution of pixel luminance values in a respective observation position;determine an order of observing the observation positions on the image by applying an order generation dictionary to the distribution of pixel luminance values of the observation positions on the image, wherein the order generation dictionary is generated based on an observation log obtained by observing regions of images in the past for statistical learning; andgenerate observation images for displaying the observation positions on the image in the determined order.","9","13/349970","2012-01-13","2012-0188283","2012-07-26","9230058","2016-01-05","SONY CORPORATION","Takeshi  Ohashi","2011-012952","JP","2011-01-25","G06F-0019/321","G06F-0019/321 | G06F-0019/345 | G06T-0007/0081 | A61B-0005/7267 | A61B-2576/00 | G06F-0017/30056 | G06T-2207/10056 | G06T-2207/30024","G06F-019/00","G06F-019/00 | G06T-007/00 | G06F-017/30 | A61B-005/00","","","","","","4916001004150"
"US","US","P","B2","Intention conveyance support device and method","According to a conventional BMI technology for controlling external equipment or transmitting an intention to another person by focusing on a biosignal such as brain activity, there has been the problem that a large-sized apparatus is required, the operation method is complex from the user's viewpoint, and noise is large. The present invention provides an apparatus and method such that an intention in the brain can be analyzed with high accuracy and at high speed and transmitted in real-time. A communication assist apparatus according to the present invention comprises an apparatus for presenting a visual stimulus on a display screen and the like, and a processing apparatus for processing brain wave data from an electroencephalograph that measures a brain wave after stimulus presentation by the presenting apparatus. The processing apparatus determines that a specific intention decision has been made in the brain when the product of an accumulated discrimination score according to a discriminant analysis function obtained by analyzing the brain wave data and a success rate exceeds a threshold value, and then outputs a determination result to a device.","1. A communication assist method, comprising: obtaining brain wave data from an electroencephalograph;analyzing the brain wave data;determining a discriminant function based on the analyzed brain wave data;determining a success rate based on the discriminant function;determining that a specific intention decision has been made in the brain when a product of an accumulated discrimination score according to the discriminant function and the success rate exceeds a threshold value; andoutputting a determination result of the specific intention decision to an electronic device;wherein the analyzing and determining steps are performed by a communication assist apparatus, the communication assist apparatus comprising: a stimulus-presenting apparatus; anda processing apparatus that processes the brain wave data from the electroencephalograph that measures a brain wave after stimulus presentation by the stimulus-presenting apparatus.","4","13/819901","2011-08-30","2013-0158883","2013-06-20","9230065","2016-01-05","NATIONAL INSTITUTE OF ADVANCED INDUSTRIAL SCIENCE AND TECHNOLOGY","Ryohei  Hasegawa | Yukako  Hasegawa | Hideaki  Takai","2010-195463","JP","2010-09-01","G06F-0019/36","G06F-0019/36 | A61B-0005/0476 | A61B-0005/0482 | A61B-0005/04842 | A61B-0005/16 | A61B-0005/7264 | G06F-0003/015 | G06K-0009/00563","G06F-019/00","G06F-019/00 | A61B-005/0476 | A61B-005/16 | G06F-003/01 | A61B-005/00 | A61B-005/0482 | A61B-005/0484 | G06K-009/00","","","","","","4916001004157"
